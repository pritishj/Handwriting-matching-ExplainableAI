{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "kIPqRFMFe3ts",
        "outputId": "f7849450-2ba3-416a-d35a-dfecdd73c5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import time\n",
        "import gc\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from keras.layers import Activation\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import concatenate\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.models import load_model\n",
        "#from google.colab import files\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "38CtTjw45ocC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "jEEFlVs9Il5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def invert(img):\n",
        "    return 255-img\n",
        "\n",
        "\n",
        "def datasets(data_path):\n",
        "    train_path = join(data_path,'TrainingSet')\n",
        "    train = {}\n",
        "    onlyfiles = [f for f in listdir(train_path) if isfile(join(train_path, f))]\n",
        "    for i in onlyfiles:\n",
        "        train[i]=invert(cv2.imread(join(train_path, i),0)).reshape((64,64,1))\n",
        "    \n",
        "    val_path = join(data_path,'ValidationSet')\n",
        "    val = {}\n",
        "    onlyfiles = [f for f in listdir(val_path) if isfile(join(val_path, f))]\n",
        "    for i in onlyfiles:\n",
        "        val[i]=invert(cv2.imread(join(val_path, i),0)).reshape((64,64,1))\n",
        "    \n",
        "    train_pairs = pd.read_csv(join(data_path,'dataset_seen_training_siamese.csv'),index_col=0)\n",
        "    train_pairs['left'] = train_pairs['left'].apply(lambda x:train[x])\n",
        "    train_pairs['right'] = train_pairs['right'].apply(lambda x:train[x])\n",
        "    #train_imgs = pd.DataFrame.from_dict(train, orient='index')\n",
        "\n",
        "    \n",
        "    val_pairs = pd.read_csv(join(data_path,'dataset_seen_validation_siamese.csv'),index_col=0)\n",
        "    val_pairs['left'] = val_pairs['left'].apply(lambda x:val[x])\n",
        "    val_pairs['right'] = val_pairs['right'].apply(lambda x:val[x])\n",
        "    #val_imgs = pd.DataFrame.from_dict(val, orient='index')\n",
        "    \n",
        "\n",
        "    \n",
        "    return {\"train_left\":train_pairs['left'],\"train_right\":train_pairs['right'],\"train_target\":train_pairs['label'],\"train_imgs\":train,\n",
        "            \"val_left\":val_pairs['left'],\"val_right\":val_pairs['right'],\"val_target\":val_pairs['label'],\"val_imgs\":val}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krVBeyGPIl7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seen_dataset = datasets(\"../seen-dataset\")\n",
        "shuffled_dataset = datasets(\"../shuffled-dataset\")\n",
        "unseen_dataset = datasets(\"../unseen-dataset\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8NBq3dg5tNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Code to import data from pickle for google colab"
      ]
    },
    {
      "metadata": {
        "id": "zzNusDjcIl7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "import pickle\n",
        "with open('../seen_dataset.pickle', 'wb') as f:\n",
        "    pickle.dump(seen_dataset,f)\n",
        "with open('../unseen_dataset.pickle', 'wb') as f:\n",
        "    pickle.dump(unseen_dataset,f)\n",
        "with open('../shuffled_dataset.pickle', 'wb') as f:\n",
        "    # Pickle the 'data' dictionary using the highest protocol available.\n",
        "    pickle.dump(shuffled_dataset,f)\n",
        "'''\n",
        "\n",
        "import pickle\n",
        "\n",
        "\n",
        "with open('../seen_dataset.pickle', 'rb') as f:\n",
        "    seen_dataset = pickle.load(f)\n",
        "with open('../unseen_dataset.pickle', 'rb') as f:\n",
        "    unseen_dataset = pickle.load(f)\n",
        "with open('../shuffled_dataset.pickle', 'rb') as f:\n",
        "    shuffled_dataset = pickle.load(f)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yVbf9RWx57Ly",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Neural Network"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_Kpo-T57e3uE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input,Dense, Conv2D, MaxPooling2D, BatchNormalization, Activation, Reshape, UpSampling2D, Flatten\n",
        "from IPython.display import SVG,Image\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M0r2Ua7Me3vb"
      },
      "cell_type": "markdown",
      "source": [
        "# Siamese"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zZr3xSHse3ve",
        "outputId": "234f4e16-4fd2-41e2-e5cb-dc23160778a3",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1108
        }
      },
      "cell_type": "code",
      "source": [
        "imDim = 64\n",
        "input_shape  = (imDim,imDim,1)\n",
        "inp_img = Input(shape = (imDim,imDim,1), name = 'ImageInput')\n",
        "model = inp_img\n",
        "\n",
        "\n",
        "model = Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=input_shape,padding='valid')(model)\n",
        "\n",
        "model = MaxPooling2D((2,2), padding='valid')(model)\n",
        "model = Conv2D(64, (3, 3), activation='relu',padding='valid')(model)\n",
        "\n",
        "model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "model = Conv2D(128, (3, 3), activation='relu',padding='valid')(model)\n",
        "model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "\n",
        "model = Conv2D(256, (1, 1), activation='relu',padding='valid')(model)\n",
        "model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "model = Conv2D(64, (1, 1), activation='relu',padding='valid')(model)\n",
        "\n",
        "model = Flatten()(model)\n",
        "\n",
        "feat = Model(inputs=[inp_img], outputs=[model],name = 'Feat_Model')\n",
        "feat.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "left_img = Input(shape = (imDim,imDim,1), name = 'left_img')\n",
        "right_img = Input(shape = (imDim,imDim,1), name = 'right_img')\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "left_feats = feat(left_img)\n",
        "right_feats = feat(right_img)\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "\n",
        "tb_batch_size = 64\n",
        "early_patience = 10\n",
        "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
        "# Earlystopping is used to stop training epochs when specified monitored parameter stops improving \n",
        "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
        "\n",
        "\n",
        "merged_feats = concatenate([left_feats, right_feats], name = 'concat_feats')\n",
        "merged_feats = Dense(1024, activation = 'linear')(merged_feats)\n",
        "merged_feats = BatchNormalization()(merged_feats)\n",
        "merged_feats = Activation('relu')(merged_feats)\n",
        "merged_feats = Dense(4, activation = 'linear')(merged_feats)\n",
        "merged_feats = BatchNormalization()(merged_feats)\n",
        "merged_feats = Activation('relu')(merged_feats)\n",
        "merged_feats = Dense(1, activation = 'sigmoid')(merged_feats)\n",
        "similarity_model = Model(inputs = [left_img, right_img], outputs = [merged_feats], name = 'Similarity_Model')\n",
        "similarity_model.summary()\n",
        "optimizer = Adam(lr = 0.0006)\n",
        "similarity_model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "ImageInput (InputLayer)      (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 6, 6, 256)         33024     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 3, 3, 64)          16448     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "=================================================================\n",
            "Total params: 142,144\n",
            "Trainable params: 142,144\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_img (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_img (InputLayer)          (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Feat_Model (Model)              (None, 576)          142144      left_img[0][0]                   \n",
            "                                                                 right_img[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat_feats (Concatenate)      (None, 1152)         0           Feat_Model[1][0]                 \n",
            "                                                                 Feat_Model[2][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         1180672     concat_feats[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1024)         0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4)            4100        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 4)            16          dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4)            0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            5           activation_2[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,331,033\n",
            "Trainable params: 1,328,977\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FZ78ZG0Ka1tM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1090
        },
        "outputId": "713462dd-e14b-473f-b204-6e40f2fffc20"
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(similarity_model, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"802pt\" viewBox=\"0.00 0.00 657.50 802.00\" width=\"658pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-798 653.5,-798 653.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140023598685376 -->\n<g class=\"node\" id=\"node1\">\n<title>140023598685376</title>\n<polygon fill=\"none\" points=\"0,-747.5 0,-793.5 311,-793.5 311,-747.5 0,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-766.8\">left_img: InputLayer</text>\n<polyline fill=\"none\" points=\"136,-747.5 136,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"136,-770.5 194,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"165\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"194,-747.5 194,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252.5\" y=\"-778.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"194,-770.5 311,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"252.5\" y=\"-755.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023598682856 -->\n<g class=\"node\" id=\"node3\">\n<title>140023598682856</title>\n<polygon fill=\"none\" points=\"169.5,-664.5 169.5,-710.5 475.5,-710.5 475.5,-664.5 169.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-683.8\">Feat_Model: Model</text>\n<polyline fill=\"none\" points=\"300.5,-664.5 300.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"300.5,-687.5 358.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"329.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"358.5,-664.5 358.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-695.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"358.5,-687.5 475.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"417\" y=\"-672.3\">(None, 576)</text>\n</g>\n<!-- 140023598685376&#45;&gt;140023598682856 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140023598685376-&gt;140023598682856</title>\n<path d=\"M202.0188,-747.3799C222.1117,-737.3936 245.7848,-725.6279 266.8043,-715.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"268.5441,-718.2249 275.9413,-710.6399 265.4286,-711.9564 268.5441,-718.2249\" stroke=\"#000000\"/>\n</g>\n<!-- 140023598771952 -->\n<g class=\"node\" id=\"node2\">\n<title>140023598771952</title>\n<polygon fill=\"none\" points=\"329.5,-747.5 329.5,-793.5 649.5,-793.5 649.5,-747.5 329.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"402\" y=\"-766.8\">right_img: InputLayer</text>\n<polyline fill=\"none\" points=\"474.5,-747.5 474.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"474.5,-770.5 532.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"532.5,-747.5 532.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-778.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"532.5,-770.5 649.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591\" y=\"-755.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023598771952&#45;&gt;140023598682856 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140023598771952-&gt;140023598682856</title>\n<path d=\"M442.9812,-747.3799C422.8883,-737.3936 399.2152,-725.6279 378.1957,-715.1811\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"379.5714,-711.9564 369.0587,-710.6399 376.4559,-718.2249 379.5714,-711.9564\" stroke=\"#000000\"/>\n</g>\n<!-- 140023598849160 -->\n<g class=\"node\" id=\"node4\">\n<title>140023598849160</title>\n<polygon fill=\"none\" points=\"124.5,-581.5 124.5,-627.5 520.5,-627.5 520.5,-581.5 124.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206.5\" y=\"-600.8\">concat_feats: Concatenate</text>\n<polyline fill=\"none\" points=\"288.5,-581.5 288.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"288.5,-604.5 346.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"346.5,-581.5 346.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"433.5\" y=\"-612.3\">[(None, 576), (None, 576)]</text>\n<polyline fill=\"none\" points=\"346.5,-604.5 520.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"433.5\" y=\"-589.3\">(None, 1152)</text>\n</g>\n<!-- 140023598682856&#45;&gt;140023598849160 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140023598682856-&gt;140023598849160</title>\n<path d=\"M322.5,-664.3799C322.5,-656.1745 322.5,-646.7679 322.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-637.784 322.5,-627.784 319.0001,-637.784 326.0001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023598849552 -->\n<g class=\"node\" id=\"node5\">\n<title>140023598849552</title>\n<polygon fill=\"none\" points=\"192.5,-498.5 192.5,-544.5 452.5,-544.5 452.5,-498.5 192.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-517.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"299.5,-498.5 299.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"299.5,-521.5 357.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"357.5,-498.5 357.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-529.3\">(None, 1152)</text>\n<polyline fill=\"none\" points=\"357.5,-521.5 452.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-506.3\">(None, 1024)</text>\n</g>\n<!-- 140023598849160&#45;&gt;140023598849552 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140023598849160-&gt;140023598849552</title>\n<path d=\"M322.5,-581.3799C322.5,-573.1745 322.5,-563.7679 322.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-554.784 322.5,-544.784 319.0001,-554.784 326.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023598425704 -->\n<g class=\"node\" id=\"node6\">\n<title>140023598425704</title>\n<polygon fill=\"none\" points=\"110.5,-415.5 110.5,-461.5 534.5,-461.5 534.5,-415.5 110.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-434.8\">batch_normalization_1: BatchNormalization</text>\n<polyline fill=\"none\" points=\"381.5,-415.5 381.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"410.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"381.5,-438.5 439.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"410.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"439.5,-415.5 439.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-446.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"439.5,-438.5 534.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-423.3\">(None, 1024)</text>\n</g>\n<!-- 140023598849552&#45;&gt;140023598425704 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140023598849552-&gt;140023598425704</title>\n<path d=\"M322.5,-498.3799C322.5,-490.1745 322.5,-480.7679 322.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-471.784 322.5,-461.784 319.0001,-471.784 326.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023520099632 -->\n<g class=\"node\" id=\"node7\">\n<title>140023520099632</title>\n<polygon fill=\"none\" points=\"169,-332.5 169,-378.5 476,-378.5 476,-332.5 169,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-351.8\">activation_1: Activation</text>\n<polyline fill=\"none\" points=\"323,-332.5 323,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"352\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"323,-355.5 381,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"352\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"381,-332.5 381,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428.5\" y=\"-363.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"381,-355.5 476,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428.5\" y=\"-340.3\">(None, 1024)</text>\n</g>\n<!-- 140023598425704&#45;&gt;140023520099632 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140023598425704-&gt;140023520099632</title>\n<path d=\"M322.5,-415.3799C322.5,-407.1745 322.5,-397.7679 322.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-388.784 322.5,-378.784 319.0001,-388.784 326.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023520226664 -->\n<g class=\"node\" id=\"node8\">\n<title>140023520226664</title>\n<polygon fill=\"none\" points=\"192.5,-249.5 192.5,-295.5 452.5,-295.5 452.5,-249.5 192.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-268.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"299.5,-249.5 299.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"299.5,-272.5 357.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"357.5,-249.5 357.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-280.3\">(None, 1024)</text>\n<polyline fill=\"none\" points=\"357.5,-272.5 452.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-257.3\">(None, 4)</text>\n</g>\n<!-- 140023520099632&#45;&gt;140023520226664 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140023520099632-&gt;140023520226664</title>\n<path d=\"M322.5,-332.3799C322.5,-324.1745 322.5,-314.7679 322.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-305.784 322.5,-295.784 319.0001,-305.784 326.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023520149288 -->\n<g class=\"node\" id=\"node9\">\n<title>140023520149288</title>\n<polygon fill=\"none\" points=\"122,-166.5 122,-212.5 523,-212.5 523,-166.5 122,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.5\" y=\"-185.8\">batch_normalization_2: BatchNormalization</text>\n<polyline fill=\"none\" points=\"393,-166.5 393,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"393,-189.5 451,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"422\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"451,-166.5 451,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-197.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"451,-189.5 523,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487\" y=\"-174.3\">(None, 4)</text>\n</g>\n<!-- 140023520226664&#45;&gt;140023520149288 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140023520226664-&gt;140023520149288</title>\n<path d=\"M322.5,-249.3799C322.5,-241.1745 322.5,-231.7679 322.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-222.784 322.5,-212.784 319.0001,-222.784 326.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023518967568 -->\n<g class=\"node\" id=\"node10\">\n<title>140023518967568</title>\n<polygon fill=\"none\" points=\"180.5,-83.5 180.5,-129.5 464.5,-129.5 464.5,-83.5 180.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.5\" y=\"-102.8\">activation_2: Activation</text>\n<polyline fill=\"none\" points=\"334.5,-83.5 334.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"334.5,-106.5 392.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"392.5,-83.5 392.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428.5\" y=\"-114.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"392.5,-106.5 464.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"428.5\" y=\"-91.3\">(None, 4)</text>\n</g>\n<!-- 140023520149288&#45;&gt;140023518967568 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140023520149288-&gt;140023518967568</title>\n<path d=\"M322.5,-166.3799C322.5,-158.1745 322.5,-148.7679 322.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-139.784 322.5,-129.784 319.0001,-139.784 326.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023518966616 -->\n<g class=\"node\" id=\"node11\">\n<title>140023518966616</title>\n<polygon fill=\"none\" points=\"204,-.5 204,-46.5 441,-46.5 441,-.5 204,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.5\" y=\"-19.8\">dense_3: Dense</text>\n<polyline fill=\"none\" points=\"311,-.5 311,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"311,-23.5 369,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"340\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"369,-.5 369,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-31.3\">(None, 4)</text>\n<polyline fill=\"none\" points=\"369,-23.5 441,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140023518967568&#45;&gt;140023518966616 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140023518967568-&gt;140023518966616</title>\n<path d=\"M322.5,-83.3799C322.5,-75.1745 322.5,-65.7679 322.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"326.0001,-56.784 322.5,-46.784 319.0001,-56.784 326.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "8h_hGVLn6Bot",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Batch generator"
      ]
    },
    {
      "metadata": {
        "id": "ZvDKYFMyIl_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(left,right, labels, batch_size):\n",
        "    index = np.random.permutation(len(left))\n",
        "    batch_right = np.zeros((batch_size, 64, 64, 1))\n",
        "    batch_left = np.zeros((batch_size, 64, 64, 1))\n",
        "    batch_labels = np.zeros((batch_size))\n",
        "    counter = 0\n",
        "    while True:\n",
        "        \n",
        "         # choose random index in features\n",
        "        if counter+batch_size<=len(left):\n",
        "            batch_left = conv(left.iloc[index[counter:counter+batch_size]])\n",
        "            batch_right = conv(right.iloc[index[counter:counter+batch_size]])\n",
        "            batch_labels = np.array(labels.iloc[index[counter:counter+batch_size]])\n",
        "            counter+=batch_size\n",
        "            #print(counter)\n",
        "            yield [batch_left.astype('float32') / 255.,batch_right.astype('float32') / 255.], batch_labels\n",
        "        else:\n",
        "            yield [conv(left.iloc[counter:]).astype('float32') / 255.,conv(right.iloc[counter:]).astype('float32') / 255.],labels[counter:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkVmOGK1LoYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(col):\n",
        "    tmp = np.empty((len(col),64,64,1))\n",
        "  \n",
        "    for i in range(len(col)):\n",
        "        tmp[i]=col.iloc[i]\n",
        "    return tmp\n",
        "\n",
        "def convert(dic):\n",
        "    dic['val_left'] = conv(dic['val_left']).astype('float32') / 255.\n",
        "    dic['val_right'] = conv(dic['val_right']).astype('float32') / 255.\n",
        "    dic['val_target'] = np.array(dic['val_target'])\n",
        "    return dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3V0fdXLtNEnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "seen_dataset = convert(seen_dataset)\n",
        "\n",
        "unseen_dataset = convert(unseen_dataset)\n",
        "\n",
        "shuffled_dataset = convert(shuffled_dataset)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XylAPlR0ImAe",
        "colab_type": "code",
        "outputId": "05716cd0-8e86-4d89-cdc8-0d26b6414757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "def train(dataset,optimizer = Adam(lr = 0.0006)):\n",
        "    imDim = 64\n",
        "    input_shape  = (imDim,imDim,1)\n",
        "    inp_img = Input(shape = (imDim,imDim,1), name = 'ImageInput')\n",
        "    model = inp_img\n",
        "\n",
        "\n",
        "    model = Conv2D(32,kernel_size=(3, 3),activation='relu',input_shape=input_shape,padding='valid')(model)\n",
        "\n",
        "    model = MaxPooling2D((2,2), padding='valid')(model)\n",
        "    model = Conv2D(64, (3, 3), activation='relu',padding='valid')(model)\n",
        "\n",
        "    model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "    model = Conv2D(128, (3, 3), activation='relu',padding='valid')(model)\n",
        "    model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "\n",
        "    model = Conv2D(256, (1, 1), activation='relu',padding='valid')(model)\n",
        "    model = MaxPooling2D((2,2),padding='valid')(model)\n",
        "\n",
        "    model = Conv2D(64, (1, 1), activation='relu',padding='valid')(model)\n",
        "\n",
        "    model = Flatten()(model)\n",
        "\n",
        "    feat = Model(inputs=[inp_img], outputs=[model],name = 'Feat_Model')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    left_img = Input(shape = (imDim,imDim,1), name = 'left_img')\n",
        "    right_img = Input(shape = (imDim,imDim,1), name = 'right_img')\n",
        "\n",
        "\n",
        "# In[28]:\n",
        "\n",
        "    left_feats = feat(left_img)\n",
        "    right_feats = feat(right_img)\n",
        "\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "    tb_batch_size = 64\n",
        "    early_patience = 10\n",
        "    tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
        "# Earlystopping is used to stop training epochs when specified monitored parameter stops improving \n",
        "    earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
        "\n",
        "\n",
        "    merged_feats = concatenate([left_feats, right_feats], name = 'concat_feats')\n",
        "    merged_feats = Dense(1024, activation = 'linear')(merged_feats)\n",
        "    merged_feats = BatchNormalization()(merged_feats)\n",
        "    merged_feats = Activation('relu')(merged_feats)\n",
        "    merged_feats = Dense(4, activation = 'linear')(merged_feats)\n",
        "    merged_feats = BatchNormalization()(merged_feats)\n",
        "    merged_feats = Activation('relu')(merged_feats)\n",
        "    merged_feats = Dense(1, activation = 'sigmoid')(merged_feats)\n",
        "    similarity_model = Model(inputs = [left_img, right_img], outputs = [merged_feats], name = 'Similarity_Model')\n",
        "    similarity_model.summary()\n",
        "    similarity_model.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])\n",
        "    runtime = time.time()\n",
        "    batch_size = 64\n",
        "    history = similarity_model.fit_generator(generator(dataset['train_left'],dataset['train_right'],dataset['train_target'],batch_size=batch_size),\n",
        "                                epochs=500,\n",
        "                                verbose=1,\n",
        "                                shuffle=True,\n",
        "                                steps_per_epoch = 1,\n",
        "                                validation_data=([dataset['val_left'],dataset['val_right']],dataset['val_target']),\n",
        "                                callbacks = [tensorboard_cb])\n",
        "    runtime = time.time()-runtime\n",
        "    %matplotlib inline\n",
        "    df = pd.DataFrame(history.history)\n",
        "    df.plot(subplots=True, grid=True, figsize=(10,15))\n",
        "    print(\"Runtime : %f s\"%runtime)\n",
        "    return similarity_model,history,runtime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dtLj_ZOb5KNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seen pairs training"
      ]
    },
    {
      "metadata": {
        "id": "FaKAKx7JImAz",
        "colab_type": "code",
        "outputId": "e49f8b7b-1aa4-41c5-913c-ad008c48f546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20159
        }
      },
      "cell_type": "code",
      "source": [
        "seen_training = train(seen_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_img (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_img (InputLayer)          (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Feat_Model (Model)              (None, 576)          142144      left_img[0][0]                   \n",
            "                                                                 right_img[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat_feats (Concatenate)      (None, 1152)         0           Feat_Model[1][0]                 \n",
            "                                                                 Feat_Model[2][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         1180672     concat_feats[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1024)         4096        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1024)         0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            4100        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4)            16          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4)            0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            5           activation_4[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,331,033\n",
            "Trainable params: 1,328,977\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.8200 - acc: 0.4688 - val_loss: 0.9910 - val_acc: 0.5000\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4616 - acc: 0.8594 - val_loss: 2.6776 - val_acc: 0.5000\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4528 - acc: 0.8750 - val_loss: 1.9296 - val_acc: 0.5000\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3755 - acc: 0.9844 - val_loss: 2.0443 - val_acc: 0.5000\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3526 - acc: 0.9688 - val_loss: 1.8983 - val_acc: 0.5000\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3756 - acc: 0.9375 - val_loss: 1.5052 - val_acc: 0.4989\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2864 - acc: 1.0000 - val_loss: 1.2812 - val_acc: 0.4989\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3405 - acc: 0.9844 - val_loss: 1.1024 - val_acc: 0.4978\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3302 - acc: 0.9531 - val_loss: 0.9541 - val_acc: 0.4978\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3147 - acc: 0.9688 - val_loss: 0.8148 - val_acc: 0.4912\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3164 - acc: 0.9531 - val_loss: 0.7424 - val_acc: 0.4879\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2901 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.4912\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2766 - acc: 1.0000 - val_loss: 0.6968 - val_acc: 0.4890\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2729 - acc: 1.0000 - val_loss: 0.7015 - val_acc: 0.4901\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.7086 - val_acc: 0.4901\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2671 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 0.4934\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2586 - acc: 1.0000 - val_loss: 0.7185 - val_acc: 0.4989\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2730 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.4989\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2567 - acc: 1.0000 - val_loss: 0.7439 - val_acc: 0.5000\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2685 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.5000\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2503 - acc: 1.0000 - val_loss: 0.7809 - val_acc: 0.5000\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2471 - acc: 1.0000 - val_loss: 0.8048 - val_acc: 0.5000\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2732 - acc: 1.0000 - val_loss: 0.8078 - val_acc: 0.5000\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2462 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.5000\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2684 - acc: 1.0000 - val_loss: 0.7950 - val_acc: 0.5000\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2362 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.5000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2411 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.5000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2353 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.5000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2356 - acc: 1.0000 - val_loss: 0.7819 - val_acc: 0.5000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2519 - acc: 1.0000 - val_loss: 0.7690 - val_acc: 0.5000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2324 - acc: 1.0000 - val_loss: 0.7591 - val_acc: 0.5000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2333 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.5000\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2604 - acc: 0.9844 - val_loss: 0.7425 - val_acc: 0.5000\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2367 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.4989\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2348 - acc: 1.0000 - val_loss: 0.7379 - val_acc: 0.4978\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2335 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.4978\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2802 - acc: 0.9844 - val_loss: 0.7334 - val_acc: 0.4978\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2352 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.4978\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2392 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.4978\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2421 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.4978\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2252 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.4978\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2224 - acc: 1.0000 - val_loss: 0.7521 - val_acc: 0.4989\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2244 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5000\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2219 - acc: 1.0000 - val_loss: 0.7630 - val_acc: 0.5000\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2460 - acc: 0.9844 - val_loss: 0.7778 - val_acc: 0.5000\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2276 - acc: 1.0000 - val_loss: 0.7930 - val_acc: 0.5000\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2215 - acc: 1.0000 - val_loss: 0.8047 - val_acc: 0.5000\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2270 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.5000\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2232 - acc: 1.0000 - val_loss: 0.8023 - val_acc: 0.5000\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2247 - acc: 1.0000 - val_loss: 0.8003 - val_acc: 0.5000\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2194 - acc: 1.0000 - val_loss: 0.8042 - val_acc: 0.5000\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2183 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.5000\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2156 - acc: 1.0000 - val_loss: 0.8102 - val_acc: 0.5000\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2158 - acc: 1.0000 - val_loss: 0.8155 - val_acc: 0.5000\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2148 - acc: 1.0000 - val_loss: 0.8249 - val_acc: 0.5000\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2137 - acc: 1.0000 - val_loss: 0.8309 - val_acc: 0.5000\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2136 - acc: 1.0000 - val_loss: 0.8383 - val_acc: 0.5000\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2126 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.5000\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2342 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.5000\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2179 - acc: 1.0000 - val_loss: 0.8415 - val_acc: 0.5000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2273 - acc: 1.0000 - val_loss: 0.8401 - val_acc: 0.5000\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2106 - acc: 1.0000 - val_loss: 0.8387 - val_acc: 0.5000\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2109 - acc: 1.0000 - val_loss: 0.8338 - val_acc: 0.5000\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2182 - acc: 1.0000 - val_loss: 0.8282 - val_acc: 0.5000\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2083 - acc: 1.0000 - val_loss: 0.8211 - val_acc: 0.5000\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2077 - acc: 1.0000 - val_loss: 0.8186 - val_acc: 0.5000\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2110 - acc: 1.0000 - val_loss: 0.8160 - val_acc: 0.5000\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2131 - acc: 1.0000 - val_loss: 0.8130 - val_acc: 0.5000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2078 - acc: 1.0000 - val_loss: 0.8109 - val_acc: 0.5000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2328 - acc: 1.0000 - val_loss: 0.8041 - val_acc: 0.5000\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2057 - acc: 1.0000 - val_loss: 0.8018 - val_acc: 0.5000\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2048 - acc: 1.0000 - val_loss: 0.8020 - val_acc: 0.5000\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2073 - acc: 1.0000 - val_loss: 0.8007 - val_acc: 0.5000\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2025 - acc: 1.0000 - val_loss: 0.8038 - val_acc: 0.5000\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2273 - acc: 1.0000 - val_loss: 0.8086 - val_acc: 0.5000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2018 - acc: 1.0000 - val_loss: 0.8115 - val_acc: 0.5000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2036 - acc: 1.0000 - val_loss: 0.8104 - val_acc: 0.5000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2022 - acc: 1.0000 - val_loss: 0.8065 - val_acc: 0.5000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2162 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.5000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2010 - acc: 1.0000 - val_loss: 0.8044 - val_acc: 0.5000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1998 - acc: 1.0000 - val_loss: 0.8043 - val_acc: 0.5000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2303 - acc: 1.0000 - val_loss: 0.8105 - val_acc: 0.5000\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2197 - acc: 1.0000 - val_loss: 0.8127 - val_acc: 0.5000\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2063 - acc: 1.0000 - val_loss: 0.8168 - val_acc: 0.5000\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2034 - acc: 1.0000 - val_loss: 0.8224 - val_acc: 0.5000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2004 - acc: 1.0000 - val_loss: 0.8288 - val_acc: 0.5000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1980 - acc: 1.0000 - val_loss: 0.8331 - val_acc: 0.5000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1975 - acc: 1.0000 - val_loss: 0.8394 - val_acc: 0.5000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2037 - acc: 1.0000 - val_loss: 0.8457 - val_acc: 0.5000\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1976 - acc: 1.0000 - val_loss: 0.8526 - val_acc: 0.5000\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1934 - acc: 1.0000 - val_loss: 0.8618 - val_acc: 0.5000\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1925 - acc: 1.0000 - val_loss: 0.8717 - val_acc: 0.5000\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1925 - acc: 1.0000 - val_loss: 0.8808 - val_acc: 0.5000\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1958 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.5000\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2183 - acc: 1.0000 - val_loss: 0.8889 - val_acc: 0.5000\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1909 - acc: 1.0000 - val_loss: 0.8924 - val_acc: 0.5000\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1911 - acc: 1.0000 - val_loss: 0.8944 - val_acc: 0.5000\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1986 - acc: 1.0000 - val_loss: 0.8947 - val_acc: 0.5000\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1929 - acc: 1.0000 - val_loss: 0.8971 - val_acc: 0.5000\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1947 - acc: 1.0000 - val_loss: 0.9004 - val_acc: 0.5000\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2014 - acc: 1.0000 - val_loss: 0.8992 - val_acc: 0.5000\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1872 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.5000\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1930 - acc: 1.0000 - val_loss: 0.8945 - val_acc: 0.5000\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1885 - acc: 1.0000 - val_loss: 0.8911 - val_acc: 0.5000\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2141 - acc: 0.9844 - val_loss: 0.8794 - val_acc: 0.5000\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2065 - acc: 1.0000 - val_loss: 0.8775 - val_acc: 0.5000\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1849 - acc: 1.0000 - val_loss: 0.8753 - val_acc: 0.5000\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1848 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.5000\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1938 - acc: 1.0000 - val_loss: 0.8744 - val_acc: 0.5000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2002 - acc: 1.0000 - val_loss: 0.8749 - val_acc: 0.5000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1892 - acc: 1.0000 - val_loss: 0.8741 - val_acc: 0.5000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1925 - acc: 1.0000 - val_loss: 0.8774 - val_acc: 0.5000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1846 - acc: 1.0000 - val_loss: 0.8815 - val_acc: 0.5000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1953 - acc: 1.0000 - val_loss: 0.8882 - val_acc: 0.5000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1855 - acc: 1.0000 - val_loss: 0.8937 - val_acc: 0.5000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1971 - acc: 1.0000 - val_loss: 0.8971 - val_acc: 0.5000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1801 - acc: 1.0000 - val_loss: 0.9003 - val_acc: 0.5000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1799 - acc: 1.0000 - val_loss: 0.9028 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1811 - acc: 1.0000 - val_loss: 0.9047 - val_acc: 0.5000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1828 - acc: 1.0000 - val_loss: 0.9057 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1781 - acc: 1.0000 - val_loss: 0.9041 - val_acc: 0.5000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1844 - acc: 1.0000 - val_loss: 0.9016 - val_acc: 0.5000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1839 - acc: 1.0000 - val_loss: 0.8983 - val_acc: 0.5000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1892 - acc: 1.0000 - val_loss: 0.8945 - val_acc: 0.5000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1803 - acc: 1.0000 - val_loss: 0.8910 - val_acc: 0.5000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1759 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.5000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1753 - acc: 1.0000 - val_loss: 0.8865 - val_acc: 0.5000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1810 - acc: 1.0000 - val_loss: 0.8833 - val_acc: 0.5000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2059 - acc: 1.0000 - val_loss: 0.8788 - val_acc: 0.5000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1739 - acc: 1.0000 - val_loss: 0.8752 - val_acc: 0.5000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1739 - acc: 1.0000 - val_loss: 0.8730 - val_acc: 0.5000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1895 - acc: 1.0000 - val_loss: 0.8710 - val_acc: 0.5000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1933 - acc: 1.0000 - val_loss: 0.8690 - val_acc: 0.5000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1725 - acc: 1.0000 - val_loss: 0.8696 - val_acc: 0.5000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1718 - acc: 1.0000 - val_loss: 0.8704 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.8736 - val_acc: 0.5000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1872 - acc: 1.0000 - val_loss: 0.8787 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1707 - acc: 1.0000 - val_loss: 0.8855 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1704 - acc: 1.0000 - val_loss: 0.8972 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1901 - acc: 1.0000 - val_loss: 0.9086 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1703 - acc: 1.0000 - val_loss: 0.9211 - val_acc: 0.5000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1803 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.5000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1837 - acc: 1.0000 - val_loss: 0.9437 - val_acc: 0.5000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1695 - acc: 1.0000 - val_loss: 0.9535 - val_acc: 0.5000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1701 - acc: 1.0000 - val_loss: 0.9631 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.9698 - val_acc: 0.5000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1656 - acc: 1.0000 - val_loss: 0.9754 - val_acc: 0.5000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1691 - acc: 1.0000 - val_loss: 0.9764 - val_acc: 0.5000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1687 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.5000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1679 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.5000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1648 - acc: 1.0000 - val_loss: 0.9783 - val_acc: 0.5000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1693 - acc: 1.0000 - val_loss: 0.9776 - val_acc: 0.5000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1639 - acc: 1.0000 - val_loss: 0.9785 - val_acc: 0.5000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1628 - acc: 1.0000 - val_loss: 0.9812 - val_acc: 0.5000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1708 - acc: 1.0000 - val_loss: 0.9828 - val_acc: 0.5000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1736 - acc: 1.0000 - val_loss: 0.9840 - val_acc: 0.5000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1699 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.5000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1626 - acc: 1.0000 - val_loss: 0.9848 - val_acc: 0.5000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1612 - acc: 1.0000 - val_loss: 0.9850 - val_acc: 0.5000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1658 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.5000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1918 - acc: 0.9844 - val_loss: 0.9858 - val_acc: 0.5000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1657 - acc: 1.0000 - val_loss: 0.9884 - val_acc: 0.5000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1637 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.5000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1643 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.5000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1639 - acc: 1.0000 - val_loss: 0.9795 - val_acc: 0.5000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1576 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.5000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1578 - acc: 1.0000 - val_loss: 0.9687 - val_acc: 0.5000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1727 - acc: 1.0000 - val_loss: 0.9614 - val_acc: 0.5000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1720 - acc: 1.0000 - val_loss: 0.9577 - val_acc: 0.5000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1596 - acc: 1.0000 - val_loss: 0.9558 - val_acc: 0.5000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1573 - acc: 1.0000 - val_loss: 0.9561 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1584 - acc: 1.0000 - val_loss: 0.9594 - val_acc: 0.5000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1551 - acc: 1.0000 - val_loss: 0.9633 - val_acc: 0.5000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1563 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.5000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1538 - acc: 1.0000 - val_loss: 0.9694 - val_acc: 0.5000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1537 - acc: 1.0000 - val_loss: 0.9723 - val_acc: 0.5000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1545 - acc: 1.0000 - val_loss: 0.9744 - val_acc: 0.5000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1684 - acc: 1.0000 - val_loss: 0.9742 - val_acc: 0.5000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.9733 - val_acc: 0.5000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1737 - acc: 1.0000 - val_loss: 0.9799 - val_acc: 0.5000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1596 - acc: 1.0000 - val_loss: 0.9855 - val_acc: 0.5000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1542 - acc: 1.0000 - val_loss: 0.9913 - val_acc: 0.5000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.9971 - val_acc: 0.5000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1505 - acc: 1.0000 - val_loss: 1.0045 - val_acc: 0.5000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1620 - acc: 1.0000 - val_loss: 1.0076 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1527 - acc: 1.0000 - val_loss: 1.0083 - val_acc: 0.5000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1492 - acc: 1.0000 - val_loss: 1.0080 - val_acc: 0.5000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1637 - acc: 1.0000 - val_loss: 1.0005 - val_acc: 0.5000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1483 - acc: 1.0000 - val_loss: 0.9928 - val_acc: 0.5000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1481 - acc: 1.0000 - val_loss: 0.9842 - val_acc: 0.5000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1529 - acc: 1.0000 - val_loss: 0.9786 - val_acc: 0.5000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1485 - acc: 1.0000 - val_loss: 0.9718 - val_acc: 0.5000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1910 - acc: 0.9844 - val_loss: 0.9577 - val_acc: 0.5000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1544 - acc: 1.0000 - val_loss: 0.9475 - val_acc: 0.5000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1481 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1494 - acc: 1.0000 - val_loss: 0.9386 - val_acc: 0.5000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1471 - acc: 1.0000 - val_loss: 0.9384 - val_acc: 0.5000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1503 - acc: 1.0000 - val_loss: 0.9389 - val_acc: 0.5000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1474 - acc: 1.0000 - val_loss: 0.9404 - val_acc: 0.5000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1492 - acc: 1.0000 - val_loss: 0.9397 - val_acc: 0.5000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1436 - acc: 1.0000 - val_loss: 0.9393 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1439 - acc: 1.0000 - val_loss: 0.9373 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1458 - acc: 1.0000 - val_loss: 0.9344 - val_acc: 0.5000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1618 - acc: 1.0000 - val_loss: 0.9332 - val_acc: 0.5000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1422 - acc: 1.0000 - val_loss: 0.9351 - val_acc: 0.5000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1472 - acc: 1.0000 - val_loss: 0.9407 - val_acc: 0.5000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1418 - acc: 1.0000 - val_loss: 0.9482 - val_acc: 0.5000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1423 - acc: 1.0000 - val_loss: 0.9570 - val_acc: 0.5000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1445 - acc: 1.0000 - val_loss: 0.9641 - val_acc: 0.5000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1551 - acc: 1.0000 - val_loss: 0.9689 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1402 - acc: 1.0000 - val_loss: 0.9747 - val_acc: 0.5000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1399 - acc: 1.0000 - val_loss: 0.9790 - val_acc: 0.5000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1400 - acc: 1.0000 - val_loss: 0.9807 - val_acc: 0.5000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1386 - acc: 1.0000 - val_loss: 0.9830 - val_acc: 0.5000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1392 - acc: 1.0000 - val_loss: 0.9859 - val_acc: 0.5000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1433 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.5000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1377 - acc: 1.0000 - val_loss: 0.9959 - val_acc: 0.5000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1369 - acc: 1.0000 - val_loss: 0.9993 - val_acc: 0.5000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1384 - acc: 1.0000 - val_loss: 1.0017 - val_acc: 0.5000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1369 - acc: 1.0000 - val_loss: 1.0042 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1373 - acc: 1.0000 - val_loss: 1.0045 - val_acc: 0.5000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1504 - acc: 1.0000 - val_loss: 1.0046 - val_acc: 0.5000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1350 - acc: 1.0000 - val_loss: 1.0089 - val_acc: 0.5000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1381 - acc: 1.0000 - val_loss: 1.0158 - val_acc: 0.5000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1348 - acc: 1.0000 - val_loss: 1.0233 - val_acc: 0.5000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1340 - acc: 1.0000 - val_loss: 1.0320 - val_acc: 0.5000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1340 - acc: 1.0000 - val_loss: 1.0392 - val_acc: 0.5000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1363 - acc: 1.0000 - val_loss: 1.0437 - val_acc: 0.5000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1410 - acc: 1.0000 - val_loss: 1.0457 - val_acc: 0.5000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1346 - acc: 1.0000 - val_loss: 1.0457 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1339 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1335 - acc: 1.0000 - val_loss: 1.0408 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1396 - acc: 1.0000 - val_loss: 1.0378 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1326 - acc: 1.0000 - val_loss: 1.0391 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1456 - acc: 1.0000 - val_loss: 1.0375 - val_acc: 0.5000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1336 - acc: 1.0000 - val_loss: 1.0398 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1303 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1329 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.5000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1370 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.5000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1293 - acc: 1.0000 - val_loss: 1.0450 - val_acc: 0.5000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1340 - acc: 1.0000 - val_loss: 1.0450 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1283 - acc: 1.0000 - val_loss: 1.0465 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1308 - acc: 1.0000 - val_loss: 1.0467 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1276 - acc: 1.0000 - val_loss: 1.0480 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1351 - acc: 1.0000 - val_loss: 1.0477 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1276 - acc: 1.0000 - val_loss: 1.0501 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1280 - acc: 1.0000 - val_loss: 1.0542 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1264 - acc: 1.0000 - val_loss: 1.0590 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1493 - acc: 1.0000 - val_loss: 1.0591 - val_acc: 0.5000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1401 - acc: 1.0000 - val_loss: 1.0595 - val_acc: 0.5000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1271 - acc: 1.0000 - val_loss: 1.0612 - val_acc: 0.5000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1262 - acc: 1.0000 - val_loss: 1.0620 - val_acc: 0.5000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1294 - acc: 1.0000 - val_loss: 1.0601 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1317 - acc: 1.0000 - val_loss: 1.0582 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1707 - acc: 1.0000 - val_loss: 1.0549 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1251 - acc: 1.0000 - val_loss: 1.0558 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1261 - acc: 1.0000 - val_loss: 1.0577 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1228 - acc: 1.0000 - val_loss: 1.0595 - val_acc: 0.5000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1224 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1227 - acc: 1.0000 - val_loss: 1.0589 - val_acc: 0.5000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1247 - acc: 1.0000 - val_loss: 1.0566 - val_acc: 0.5000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1218 - acc: 1.0000 - val_loss: 1.0565 - val_acc: 0.5000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1218 - acc: 1.0000 - val_loss: 1.0576 - val_acc: 0.5000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1210 - acc: 1.0000 - val_loss: 1.0576 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1254 - acc: 1.0000 - val_loss: 1.0583 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1308 - acc: 1.0000 - val_loss: 1.0595 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1272 - acc: 1.0000 - val_loss: 1.0616 - val_acc: 0.5000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1196 - acc: 1.0000 - val_loss: 1.0659 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1192 - acc: 1.0000 - val_loss: 1.0705 - val_acc: 0.5000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1218 - acc: 1.0000 - val_loss: 1.0739 - val_acc: 0.5000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1235 - acc: 1.0000 - val_loss: 1.0769 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1188 - acc: 1.0000 - val_loss: 1.0777 - val_acc: 0.5000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1181 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1181 - acc: 1.0000 - val_loss: 1.0766 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1224 - acc: 1.0000 - val_loss: 1.0777 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1170 - acc: 1.0000 - val_loss: 1.0809 - val_acc: 0.5000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1188 - acc: 1.0000 - val_loss: 1.0843 - val_acc: 0.5000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1170 - acc: 1.0000 - val_loss: 1.0876 - val_acc: 0.5000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1516 - acc: 0.9844 - val_loss: 1.0827 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1163 - acc: 1.0000 - val_loss: 1.0791 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1193 - acc: 1.0000 - val_loss: 1.0761 - val_acc: 0.5000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1612 - acc: 1.0000 - val_loss: 1.0695 - val_acc: 0.5000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1303 - acc: 1.0000 - val_loss: 1.0641 - val_acc: 0.5000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1332 - acc: 1.0000 - val_loss: 1.0621 - val_acc: 0.5000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1174 - acc: 1.0000 - val_loss: 1.0658 - val_acc: 0.5000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1153 - acc: 1.0000 - val_loss: 1.0743 - val_acc: 0.5000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1141 - acc: 1.0000 - val_loss: 1.0834 - val_acc: 0.5000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1146 - acc: 1.0000 - val_loss: 1.0927 - val_acc: 0.5000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1203 - acc: 1.0000 - val_loss: 1.1010 - val_acc: 0.5000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1202 - acc: 1.0000 - val_loss: 1.1096 - val_acc: 0.5000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1187 - acc: 1.0000 - val_loss: 1.1162 - val_acc: 0.5000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1157 - acc: 1.0000 - val_loss: 1.1203 - val_acc: 0.5000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1129 - acc: 1.0000 - val_loss: 1.1246 - val_acc: 0.5000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1127 - acc: 1.0000 - val_loss: 1.1263 - val_acc: 0.5000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1136 - acc: 1.0000 - val_loss: 1.1259 - val_acc: 0.5000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1124 - acc: 1.0000 - val_loss: 1.1225 - val_acc: 0.5000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1242 - acc: 1.0000 - val_loss: 1.1188 - val_acc: 0.5000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1166 - acc: 1.0000 - val_loss: 1.1217 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1172 - acc: 1.0000 - val_loss: 1.1226 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1103 - acc: 1.0000 - val_loss: 1.1256 - val_acc: 0.5000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1116 - acc: 1.0000 - val_loss: 1.1302 - val_acc: 0.5000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1101 - acc: 1.0000 - val_loss: 1.1329 - val_acc: 0.5000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1162 - acc: 1.0000 - val_loss: 1.1331 - val_acc: 0.5000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1156 - acc: 1.0000 - val_loss: 1.1321 - val_acc: 0.5000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1096 - acc: 1.0000 - val_loss: 1.1311 - val_acc: 0.5000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1253 - acc: 1.0000 - val_loss: 1.1287 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1125 - acc: 1.0000 - val_loss: 1.1276 - val_acc: 0.5000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1176 - acc: 1.0000 - val_loss: 1.1257 - val_acc: 0.5000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1121 - acc: 1.0000 - val_loss: 1.1230 - val_acc: 0.5000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1074 - acc: 1.0000 - val_loss: 1.1216 - val_acc: 0.5000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1080 - acc: 1.0000 - val_loss: 1.1213 - val_acc: 0.5000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1162 - acc: 1.0000 - val_loss: 1.1196 - val_acc: 0.5000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1060 - acc: 1.0000 - val_loss: 1.1200 - val_acc: 0.5000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1157 - acc: 1.0000 - val_loss: 1.1198 - val_acc: 0.5000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1268 - acc: 1.0000 - val_loss: 1.1181 - val_acc: 0.5000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1122 - acc: 1.0000 - val_loss: 1.1169 - val_acc: 0.5000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1076 - acc: 1.0000 - val_loss: 1.1164 - val_acc: 0.5000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1050 - acc: 1.0000 - val_loss: 1.1155 - val_acc: 0.5000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1054 - acc: 1.0000 - val_loss: 1.1155 - val_acc: 0.5000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1041 - acc: 1.0000 - val_loss: 1.1153 - val_acc: 0.5000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1040 - acc: 1.0000 - val_loss: 1.1174 - val_acc: 0.5000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1103 - acc: 1.0000 - val_loss: 1.1196 - val_acc: 0.5000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1077 - acc: 1.0000 - val_loss: 1.1212 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1126 - acc: 1.0000 - val_loss: 1.1220 - val_acc: 0.5000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1071 - acc: 1.0000 - val_loss: 1.1220 - val_acc: 0.5000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1233 - acc: 1.0000 - val_loss: 1.1207 - val_acc: 0.5000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1116 - acc: 1.0000 - val_loss: 1.1209 - val_acc: 0.5000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1114 - acc: 1.0000 - val_loss: 1.1210 - val_acc: 0.5000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1042 - acc: 1.0000 - val_loss: 1.1270 - val_acc: 0.5000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1019 - acc: 1.0000 - val_loss: 1.1335 - val_acc: 0.5000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1051 - acc: 1.0000 - val_loss: 1.1393 - val_acc: 0.5000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1032 - acc: 1.0000 - val_loss: 1.1423 - val_acc: 0.5000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1072 - acc: 1.0000 - val_loss: 1.1453 - val_acc: 0.5000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1014 - acc: 1.0000 - val_loss: 1.1483 - val_acc: 0.5000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1002 - acc: 1.0000 - val_loss: 1.1502 - val_acc: 0.5000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1091 - acc: 1.0000 - val_loss: 1.1495 - val_acc: 0.5000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1007 - acc: 1.0000 - val_loss: 1.1503 - val_acc: 0.5000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1016 - acc: 1.0000 - val_loss: 1.1531 - val_acc: 0.5000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1001 - acc: 1.0000 - val_loss: 1.1568 - val_acc: 0.5000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0997 - acc: 1.0000 - val_loss: 1.1602 - val_acc: 0.5000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0987 - acc: 1.0000 - val_loss: 1.1614 - val_acc: 0.5000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1005 - acc: 1.0000 - val_loss: 1.1615 - val_acc: 0.5000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1043 - acc: 1.0000 - val_loss: 1.1612 - val_acc: 0.5000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0987 - acc: 1.0000 - val_loss: 1.1610 - val_acc: 0.5000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0997 - acc: 1.0000 - val_loss: 1.1593 - val_acc: 0.5000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1388 - acc: 1.0000 - val_loss: 1.1544 - val_acc: 0.5000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0993 - acc: 1.0000 - val_loss: 1.1540 - val_acc: 0.5000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0971 - acc: 1.0000 - val_loss: 1.1539 - val_acc: 0.5000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1054 - acc: 1.0000 - val_loss: 1.1511 - val_acc: 0.5000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0973 - acc: 1.0000 - val_loss: 1.1502 - val_acc: 0.5000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0981 - acc: 1.0000 - val_loss: 1.1487 - val_acc: 0.5000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1114 - acc: 1.0000 - val_loss: 1.1473 - val_acc: 0.5000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1198 - acc: 1.0000 - val_loss: 1.1443 - val_acc: 0.5000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1082 - acc: 1.0000 - val_loss: 1.1464 - val_acc: 0.5000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0950 - acc: 1.0000 - val_loss: 1.1465 - val_acc: 0.5000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0947 - acc: 1.0000 - val_loss: 1.1472 - val_acc: 0.5000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0954 - acc: 1.0000 - val_loss: 1.1488 - val_acc: 0.5000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0981 - acc: 1.0000 - val_loss: 1.1490 - val_acc: 0.5000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0940 - acc: 1.0000 - val_loss: 1.1503 - val_acc: 0.5000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1024 - acc: 1.0000 - val_loss: 1.1497 - val_acc: 0.5000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1129 - acc: 1.0000 - val_loss: 1.1473 - val_acc: 0.5000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0944 - acc: 1.0000 - val_loss: 1.1466 - val_acc: 0.5000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0954 - acc: 1.0000 - val_loss: 1.1462 - val_acc: 0.5000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0949 - acc: 1.0000 - val_loss: 1.1451 - val_acc: 0.5000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1079 - acc: 1.0000 - val_loss: 1.1426 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1009 - acc: 1.0000 - val_loss: 1.1421 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0987 - acc: 1.0000 - val_loss: 1.1455 - val_acc: 0.5000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0922 - acc: 1.0000 - val_loss: 1.1469 - val_acc: 0.5000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1002 - acc: 1.0000 - val_loss: 1.1484 - val_acc: 0.5000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0926 - acc: 1.0000 - val_loss: 1.1526 - val_acc: 0.5000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0919 - acc: 1.0000 - val_loss: 1.1558 - val_acc: 0.5000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0914 - acc: 1.0000 - val_loss: 1.1573 - val_acc: 0.5000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0930 - acc: 1.0000 - val_loss: 1.1584 - val_acc: 0.5000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0907 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.5000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0908 - acc: 1.0000 - val_loss: 1.1629 - val_acc: 0.5000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0942 - acc: 1.0000 - val_loss: 1.1664 - val_acc: 0.5000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0899 - acc: 1.0000 - val_loss: 1.1697 - val_acc: 0.5000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1024 - acc: 1.0000 - val_loss: 1.1738 - val_acc: 0.5000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0951 - acc: 1.0000 - val_loss: 1.1745 - val_acc: 0.5000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0949 - acc: 1.0000 - val_loss: 1.1751 - val_acc: 0.5000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0924 - acc: 1.0000 - val_loss: 1.1763 - val_acc: 0.5000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0922 - acc: 1.0000 - val_loss: 1.1787 - val_acc: 0.5000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0942 - acc: 1.0000 - val_loss: 1.1811 - val_acc: 0.5000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0901 - acc: 1.0000 - val_loss: 1.1839 - val_acc: 0.5000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0882 - acc: 1.0000 - val_loss: 1.1875 - val_acc: 0.5000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0917 - acc: 1.0000 - val_loss: 1.1914 - val_acc: 0.5000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0875 - acc: 1.0000 - val_loss: 1.1937 - val_acc: 0.5000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0930 - acc: 1.0000 - val_loss: 1.1939 - val_acc: 0.5000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0929 - acc: 1.0000 - val_loss: 1.1935 - val_acc: 0.5000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0984 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 0.5000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0923 - acc: 1.0000 - val_loss: 1.1861 - val_acc: 0.5000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1369 - acc: 0.9844 - val_loss: 1.1849 - val_acc: 0.5000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0985 - acc: 1.0000 - val_loss: 1.1871 - val_acc: 0.5000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0945 - acc: 1.0000 - val_loss: 1.1924 - val_acc: 0.5000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0954 - acc: 1.0000 - val_loss: 1.2072 - val_acc: 0.5000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0994 - acc: 1.0000 - val_loss: 1.2254 - val_acc: 0.5000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0922 - acc: 1.0000 - val_loss: 1.2340 - val_acc: 0.5000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0909 - acc: 1.0000 - val_loss: 1.2401 - val_acc: 0.5000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0891 - acc: 1.0000 - val_loss: 1.2367 - val_acc: 0.5000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0885 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 0.5000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0857 - acc: 1.0000 - val_loss: 1.2121 - val_acc: 0.5000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0850 - acc: 1.0000 - val_loss: 1.1984 - val_acc: 0.5000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0900 - acc: 1.0000 - val_loss: 1.1976 - val_acc: 0.5000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0867 - acc: 1.0000 - val_loss: 1.2032 - val_acc: 0.5000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0860 - acc: 1.0000 - val_loss: 1.2090 - val_acc: 0.5000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1025 - acc: 1.0000 - val_loss: 1.2164 - val_acc: 0.5000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1617 - acc: 0.9844 - val_loss: 1.2167 - val_acc: 0.5000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0876 - acc: 1.0000 - val_loss: 1.2207 - val_acc: 0.5000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0891 - acc: 1.0000 - val_loss: 1.2284 - val_acc: 0.5000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0909 - acc: 1.0000 - val_loss: 1.2319 - val_acc: 0.5000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0944 - acc: 1.0000 - val_loss: 1.2395 - val_acc: 0.5000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0861 - acc: 1.0000 - val_loss: 1.2483 - val_acc: 0.5000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0895 - acc: 1.0000 - val_loss: 1.2532 - val_acc: 0.5000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0984 - acc: 1.0000 - val_loss: 1.2575 - val_acc: 0.5000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0859 - acc: 1.0000 - val_loss: 1.2682 - val_acc: 0.5000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0851 - acc: 1.0000 - val_loss: 1.2803 - val_acc: 0.5000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0906 - acc: 1.0000 - val_loss: 1.2935 - val_acc: 0.5000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0831 - acc: 1.0000 - val_loss: 1.3019 - val_acc: 0.5000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1098 - acc: 1.0000 - val_loss: 1.3156 - val_acc: 0.5000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0851 - acc: 1.0000 - val_loss: 1.3225 - val_acc: 0.5000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0823 - acc: 1.0000 - val_loss: 1.3241 - val_acc: 0.5000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0929 - acc: 1.0000 - val_loss: 1.3152 - val_acc: 0.5000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0871 - acc: 1.0000 - val_loss: 1.3013 - val_acc: 0.5000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0828 - acc: 1.0000 - val_loss: 1.2874 - val_acc: 0.5000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0821 - acc: 1.0000 - val_loss: 1.2801 - val_acc: 0.5000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0799 - acc: 1.0000 - val_loss: 1.2777 - val_acc: 0.5000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0832 - acc: 1.0000 - val_loss: 1.2773 - val_acc: 0.5000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0807 - acc: 1.0000 - val_loss: 1.2826 - val_acc: 0.5000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0838 - acc: 1.0000 - val_loss: 1.2974 - val_acc: 0.5000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0792 - acc: 1.0000 - val_loss: 1.3163 - val_acc: 0.5000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0791 - acc: 1.0000 - val_loss: 1.3309 - val_acc: 0.5000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0807 - acc: 1.0000 - val_loss: 1.3354 - val_acc: 0.5000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0997 - acc: 1.0000 - val_loss: 1.3363 - val_acc: 0.5000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0859 - acc: 1.0000 - val_loss: 1.3295 - val_acc: 0.5000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0814 - acc: 1.0000 - val_loss: 1.3185 - val_acc: 0.5000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0785 - acc: 1.0000 - val_loss: 1.3100 - val_acc: 0.5000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0775 - acc: 1.0000 - val_loss: 1.3024 - val_acc: 0.5000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0952 - acc: 1.0000 - val_loss: 1.2958 - val_acc: 0.5000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0778 - acc: 1.0000 - val_loss: 1.2967 - val_acc: 0.5000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0801 - acc: 1.0000 - val_loss: 1.2976 - val_acc: 0.5000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0859 - acc: 1.0000 - val_loss: 1.2991 - val_acc: 0.5000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0775 - acc: 1.0000 - val_loss: 1.2996 - val_acc: 0.5000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0796 - acc: 1.0000 - val_loss: 1.2928 - val_acc: 0.5000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0901 - acc: 1.0000 - val_loss: 1.2831 - val_acc: 0.5000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0847 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.5000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0865 - acc: 1.0000 - val_loss: 1.2652 - val_acc: 0.5000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0833 - acc: 1.0000 - val_loss: 1.2522 - val_acc: 0.5000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0807 - acc: 1.0000 - val_loss: 1.2445 - val_acc: 0.5000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0926 - acc: 1.0000 - val_loss: 1.2346 - val_acc: 0.5000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0780 - acc: 1.0000 - val_loss: 1.2288 - val_acc: 0.5000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0784 - acc: 1.0000 - val_loss: 1.2267 - val_acc: 0.5000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0820 - acc: 1.0000 - val_loss: 1.2214 - val_acc: 0.5000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0805 - acc: 1.0000 - val_loss: 1.2204 - val_acc: 0.5000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0773 - acc: 1.0000 - val_loss: 1.2197 - val_acc: 0.5000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0760 - acc: 1.0000 - val_loss: 1.2237 - val_acc: 0.5000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0754 - acc: 1.0000 - val_loss: 1.2295 - val_acc: 0.5000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0736 - acc: 1.0000 - val_loss: 1.2350 - val_acc: 0.5000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0754 - acc: 1.0000 - val_loss: 1.2389 - val_acc: 0.5000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0729 - acc: 1.0000 - val_loss: 1.2423 - val_acc: 0.5000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0746 - acc: 1.0000 - val_loss: 1.2432 - val_acc: 0.5000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0728 - acc: 1.0000 - val_loss: 1.2477 - val_acc: 0.5000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0723 - acc: 1.0000 - val_loss: 1.2527 - val_acc: 0.5000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0729 - acc: 1.0000 - val_loss: 1.2564 - val_acc: 0.5000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0773 - acc: 1.0000 - val_loss: 1.2591 - val_acc: 0.5000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0728 - acc: 1.0000 - val_loss: 1.2641 - val_acc: 0.5000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0715 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.5000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0748 - acc: 1.0000 - val_loss: 1.2714 - val_acc: 0.5000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0732 - acc: 1.0000 - val_loss: 1.2747 - val_acc: 0.5000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0848 - acc: 1.0000 - val_loss: 1.2751 - val_acc: 0.5000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0812 - acc: 1.0000 - val_loss: 1.2758 - val_acc: 0.5000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0707 - acc: 1.0000 - val_loss: 1.2784 - val_acc: 0.5000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0709 - acc: 1.0000 - val_loss: 1.2812 - val_acc: 0.5000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0703 - acc: 1.0000 - val_loss: 1.2842 - val_acc: 0.5000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0701 - acc: 1.0000 - val_loss: 1.2863 - val_acc: 0.5000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0701 - acc: 1.0000 - val_loss: 1.2867 - val_acc: 0.5000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0701 - acc: 1.0000 - val_loss: 1.2902 - val_acc: 0.5000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0707 - acc: 1.0000 - val_loss: 1.2934 - val_acc: 0.5000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0695 - acc: 1.0000 - val_loss: 1.2957 - val_acc: 0.5000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0711 - acc: 1.0000 - val_loss: 1.2999 - val_acc: 0.5000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0693 - acc: 1.0000 - val_loss: 1.3044 - val_acc: 0.5000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0699 - acc: 1.0000 - val_loss: 1.3102 - val_acc: 0.5000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0823 - acc: 1.0000 - val_loss: 1.3117 - val_acc: 0.5000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0689 - acc: 1.0000 - val_loss: 1.3153 - val_acc: 0.5000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0703 - acc: 1.0000 - val_loss: 1.3165 - val_acc: 0.5000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0685 - acc: 1.0000 - val_loss: 1.3190 - val_acc: 0.5000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0689 - acc: 1.0000 - val_loss: 1.3197 - val_acc: 0.5000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0680 - acc: 1.0000 - val_loss: 1.3188 - val_acc: 0.5000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0739 - acc: 1.0000 - val_loss: 1.3198 - val_acc: 0.5000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1196 - acc: 0.9844 - val_loss: 1.3166 - val_acc: 0.5000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0700 - acc: 1.0000 - val_loss: 1.3181 - val_acc: 0.5000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.1039 - acc: 0.9844 - val_loss: 1.3196 - val_acc: 0.5000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0825 - acc: 1.0000 - val_loss: 1.3200 - val_acc: 0.5000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0715 - acc: 1.0000 - val_loss: 1.3239 - val_acc: 0.5000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0732 - acc: 1.0000 - val_loss: 1.3266 - val_acc: 0.5000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0708 - acc: 1.0000 - val_loss: 1.3303 - val_acc: 0.5000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0701 - acc: 1.0000 - val_loss: 1.3325 - val_acc: 0.5000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0673 - acc: 1.0000 - val_loss: 1.3375 - val_acc: 0.5000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0750 - acc: 1.0000 - val_loss: 1.3355 - val_acc: 0.5000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0684 - acc: 1.0000 - val_loss: 1.3283 - val_acc: 0.5000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0682 - acc: 1.0000 - val_loss: 1.3171 - val_acc: 0.5000\n",
            "Runtime : 2462.276621 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAMECAYAAABqtvueAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERyTElXCIiIiI59v+3j1ygqz6JuQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "RbjTvQWK5SNQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unseen pairs training"
      ]
    },
    {
      "metadata": {
        "id": "dqPzmYRuhWlU",
        "colab_type": "code",
        "outputId": "7322b6bf-cb8c-4a63-f207-ace108b36694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20215
        }
      },
      "cell_type": "code",
      "source": [
        "unseen_training = train(unseen_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_img (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_img (InputLayer)          (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Feat_Model (Model)              (None, 576)          142144      left_img[0][0]                   \n",
            "                                                                 right_img[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat_feats (Concatenate)      (None, 1152)         0           Feat_Model[1][0]                 \n",
            "                                                                 Feat_Model[2][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         1180672     concat_feats[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 1024)         4096        dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 1024)         0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 4)            4100        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 4)            16          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4)            0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            5           activation_4[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,331,033\n",
            "Trainable params: 1,328,977\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 33s 33s/step - loss: 0.7432 - acc: 0.5156 - val_loss: 1.3168 - val_acc: 0.4945\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.6011 - acc: 0.6250 - val_loss: 0.9062 - val_acc: 0.4695\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.4566 - acc: 0.9062 - val_loss: 0.7572 - val_acc: 0.5413\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.4387 - acc: 0.8594 - val_loss: 0.7623 - val_acc: 0.5574\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 33s 33s/step - loss: 0.4382 - acc: 0.9062 - val_loss: 0.7862 - val_acc: 0.5559\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.4726 - acc: 0.8438 - val_loss: 0.8540 - val_acc: 0.5075\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3772 - acc: 0.9688 - val_loss: 0.9124 - val_acc: 0.4925\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3634 - acc: 0.9531 - val_loss: 0.9432 - val_acc: 0.4885\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3408 - acc: 0.9688 - val_loss: 0.9577 - val_acc: 0.4913\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3296 - acc: 1.0000 - val_loss: 0.9634 - val_acc: 0.4925\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3632 - acc: 0.9375 - val_loss: 0.9374 - val_acc: 0.4945\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3723 - acc: 0.9062 - val_loss: 0.9146 - val_acc: 0.4916\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3111 - acc: 0.9844 - val_loss: 0.9236 - val_acc: 0.4930\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3387 - acc: 0.9688 - val_loss: 0.8988 - val_acc: 0.4954\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3032 - acc: 0.9844 - val_loss: 0.8583 - val_acc: 0.4962\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3193 - acc: 0.9688 - val_loss: 0.7983 - val_acc: 0.4962\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3224 - acc: 1.0000 - val_loss: 0.7561 - val_acc: 0.4983\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2833 - acc: 1.0000 - val_loss: 0.7339 - val_acc: 0.4995\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2865 - acc: 1.0000 - val_loss: 0.7215 - val_acc: 0.4999\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2966 - acc: 1.0000 - val_loss: 0.7136 - val_acc: 0.4999\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3230 - acc: 1.0000 - val_loss: 0.7092 - val_acc: 0.5000\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2937 - acc: 1.0000 - val_loss: 0.7079 - val_acc: 0.5000\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2910 - acc: 1.0000 - val_loss: 0.7080 - val_acc: 0.4999\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2827 - acc: 0.9844 - val_loss: 0.7085 - val_acc: 0.4997\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2773 - acc: 1.0000 - val_loss: 0.7094 - val_acc: 0.4992\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3045 - acc: 1.0000 - val_loss: 0.7103 - val_acc: 0.4987\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2772 - acc: 1.0000 - val_loss: 0.7132 - val_acc: 0.4976\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3721 - acc: 0.9688 - val_loss: 0.7164 - val_acc: 0.4972\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2832 - acc: 1.0000 - val_loss: 0.7204 - val_acc: 0.4959\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3208 - acc: 1.0000 - val_loss: 0.7229 - val_acc: 0.4945\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2986 - acc: 1.0000 - val_loss: 0.7247 - val_acc: 0.4930\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2834 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.4921\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3434 - acc: 0.9844 - val_loss: 0.7297 - val_acc: 0.4921\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2805 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.4935\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2865 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.4949\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2828 - acc: 1.0000 - val_loss: 0.7406 - val_acc: 0.4951\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2801 - acc: 1.0000 - val_loss: 0.7469 - val_acc: 0.4960\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2940 - acc: 1.0000 - val_loss: 0.7537 - val_acc: 0.4964\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3222 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.4975\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2631 - acc: 1.0000 - val_loss: 0.7651 - val_acc: 0.4978\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2551 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.4984\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2803 - acc: 1.0000 - val_loss: 0.7751 - val_acc: 0.4985\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2850 - acc: 1.0000 - val_loss: 0.7759 - val_acc: 0.4988\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2655 - acc: 1.0000 - val_loss: 0.7755 - val_acc: 0.4991\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2892 - acc: 0.9844 - val_loss: 0.7733 - val_acc: 0.4991\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2767 - acc: 0.9688 - val_loss: 0.7735 - val_acc: 0.4991\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2918 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.4992\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2717 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.4993\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2904 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.4995\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2586 - acc: 1.0000 - val_loss: 0.7656 - val_acc: 0.4993\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2861 - acc: 0.9844 - val_loss: 0.7621 - val_acc: 0.4993\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2991 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.4992\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2892 - acc: 1.0000 - val_loss: 0.7530 - val_acc: 0.4992\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2712 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 0.4992\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2737 - acc: 1.0000 - val_loss: 0.7452 - val_acc: 0.4991\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2819 - acc: 1.0000 - val_loss: 0.7415 - val_acc: 0.4991\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2572 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.4993\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2563 - acc: 0.9844 - val_loss: 0.7361 - val_acc: 0.4995\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3016 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.4996\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2690 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 0.4996\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3022 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.4996\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2561 - acc: 1.0000 - val_loss: 0.7284 - val_acc: 0.4996\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2459 - acc: 1.0000 - val_loss: 0.7289 - val_acc: 0.4997\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2816 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.4997\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2614 - acc: 0.9688 - val_loss: 0.7292 - val_acc: 0.4997\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2836 - acc: 1.0000 - val_loss: 0.7290 - val_acc: 0.4997\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2571 - acc: 1.0000 - val_loss: 0.7286 - val_acc: 0.4997\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2518 - acc: 1.0000 - val_loss: 0.7284 - val_acc: 0.4997\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2595 - acc: 0.9844 - val_loss: 0.7283 - val_acc: 0.4997\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2988 - acc: 0.9844 - val_loss: 0.7275 - val_acc: 0.4997\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2939 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.4997\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2743 - acc: 1.0000 - val_loss: 0.7268 - val_acc: 0.4997\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2519 - acc: 1.0000 - val_loss: 0.7274 - val_acc: 0.4997\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2853 - acc: 1.0000 - val_loss: 0.7280 - val_acc: 0.4997\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2827 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.4997\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2394 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.4997\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2460 - acc: 1.0000 - val_loss: 0.7315 - val_acc: 0.4999\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2656 - acc: 1.0000 - val_loss: 0.7327 - val_acc: 0.4999\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2459 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.4999\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2579 - acc: 0.9844 - val_loss: 0.7359 - val_acc: 0.4999\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2479 - acc: 0.9844 - val_loss: 0.7391 - val_acc: 0.4999\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2769 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 0.4999\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2999 - acc: 1.0000 - val_loss: 0.7460 - val_acc: 0.4999\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.3468 - acc: 1.0000 - val_loss: 0.7481 - val_acc: 0.4999\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2337 - acc: 0.9844 - val_loss: 0.7520 - val_acc: 0.5000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2566 - acc: 1.0000 - val_loss: 0.7558 - val_acc: 0.5000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2568 - acc: 0.9844 - val_loss: 0.7591 - val_acc: 0.5000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2878 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 0.5000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2649 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.4999\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2826 - acc: 1.0000 - val_loss: 0.7599 - val_acc: 0.4999\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2299 - acc: 1.0000 - val_loss: 0.7604 - val_acc: 0.4999\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2718 - acc: 1.0000 - val_loss: 0.7609 - val_acc: 0.4999\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2898 - acc: 1.0000 - val_loss: 0.7612 - val_acc: 0.4999\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2759 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.4997\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2804 - acc: 1.0000 - val_loss: 0.7603 - val_acc: 0.4997\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2679 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.4997\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2405 - acc: 1.0000 - val_loss: 0.7583 - val_acc: 0.4999\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2290 - acc: 1.0000 - val_loss: 0.7583 - val_acc: 0.4999\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2465 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.4999\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2485 - acc: 1.0000 - val_loss: 0.7569 - val_acc: 0.4999\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2667 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.4999\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2564 - acc: 1.0000 - val_loss: 0.7559 - val_acc: 0.4999\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2231 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.4999\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2289 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.4999\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2522 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.4999\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2513 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.4999\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2839 - acc: 1.0000 - val_loss: 0.7531 - val_acc: 0.4999\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2398 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.4999\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2520 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.5000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2358 - acc: 1.0000 - val_loss: 0.7566 - val_acc: 0.5000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2244 - acc: 1.0000 - val_loss: 0.7589 - val_acc: 0.5000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2240 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.5000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2955 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.5000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2195 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.5000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2353 - acc: 1.0000 - val_loss: 0.7629 - val_acc: 0.5000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2171 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.5000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2931 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.5000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2617 - acc: 1.0000 - val_loss: 0.7633 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2474 - acc: 1.0000 - val_loss: 0.7637 - val_acc: 0.5000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2523 - acc: 1.0000 - val_loss: 0.7642 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2167 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.5000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2501 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2423 - acc: 1.0000 - val_loss: 0.7670 - val_acc: 0.5000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2739 - acc: 1.0000 - val_loss: 0.7675 - val_acc: 0.5000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2144 - acc: 1.0000 - val_loss: 0.7688 - val_acc: 0.5000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2145 - acc: 1.0000 - val_loss: 0.7698 - val_acc: 0.5000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2844 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.5000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2338 - acc: 1.0000 - val_loss: 0.7716 - val_acc: 0.5000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2183 - acc: 1.0000 - val_loss: 0.7735 - val_acc: 0.5000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2580 - acc: 1.0000 - val_loss: 0.7755 - val_acc: 0.5000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2334 - acc: 1.0000 - val_loss: 0.7779 - val_acc: 0.5000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2203 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.5000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2429 - acc: 1.0000 - val_loss: 0.7828 - val_acc: 0.5000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2068 - acc: 1.0000 - val_loss: 0.7857 - val_acc: 0.5000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2193 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2438 - acc: 1.0000 - val_loss: 0.7884 - val_acc: 0.5000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2222 - acc: 1.0000 - val_loss: 0.7890 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2025 - acc: 1.0000 - val_loss: 0.7903 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2124 - acc: 1.0000 - val_loss: 0.7906 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2467 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2170 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.5000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2321 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.5000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.2304 - acc: 1.0000 - val_loss: 0.7905 - val_acc: 0.5000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2579 - acc: 1.0000 - val_loss: 0.7897 - val_acc: 0.5000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2403 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2885 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.5000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2121 - acc: 1.0000 - val_loss: 0.7886 - val_acc: 0.5000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2402 - acc: 1.0000 - val_loss: 0.7889 - val_acc: 0.5000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2668 - acc: 1.0000 - val_loss: 0.7887 - val_acc: 0.5000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2125 - acc: 1.0000 - val_loss: 0.7891 - val_acc: 0.5000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2162 - acc: 1.0000 - val_loss: 0.7901 - val_acc: 0.5000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2469 - acc: 1.0000 - val_loss: 0.7912 - val_acc: 0.5000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2119 - acc: 1.0000 - val_loss: 0.7927 - val_acc: 0.5000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2417 - acc: 0.9844 - val_loss: 0.7950 - val_acc: 0.5000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2250 - acc: 1.0000 - val_loss: 0.7974 - val_acc: 0.5000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2355 - acc: 1.0000 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2128 - acc: 1.0000 - val_loss: 0.7980 - val_acc: 0.5000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2093 - acc: 1.0000 - val_loss: 0.7985 - val_acc: 0.5000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2321 - acc: 1.0000 - val_loss: 0.7979 - val_acc: 0.5000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2112 - acc: 1.0000 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1944 - acc: 1.0000 - val_loss: 0.7984 - val_acc: 0.5000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2151 - acc: 1.0000 - val_loss: 0.7987 - val_acc: 0.5000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2191 - acc: 1.0000 - val_loss: 0.7986 - val_acc: 0.5000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2292 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.5000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2427 - acc: 1.0000 - val_loss: 0.7966 - val_acc: 0.5000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2192 - acc: 1.0000 - val_loss: 0.7955 - val_acc: 0.5000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2360 - acc: 1.0000 - val_loss: 0.7954 - val_acc: 0.5000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.2073 - acc: 1.0000 - val_loss: 0.7955 - val_acc: 0.5000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2160 - acc: 1.0000 - val_loss: 0.7955 - val_acc: 0.5000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2212 - acc: 1.0000 - val_loss: 0.7957 - val_acc: 0.5000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1944 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2147 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.5000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2251 - acc: 1.0000 - val_loss: 0.7978 - val_acc: 0.5000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2349 - acc: 1.0000 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2159 - acc: 1.0000 - val_loss: 0.7977 - val_acc: 0.5000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2316 - acc: 1.0000 - val_loss: 0.7982 - val_acc: 0.5000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2013 - acc: 1.0000 - val_loss: 0.7991 - val_acc: 0.5000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2108 - acc: 1.0000 - val_loss: 0.8000 - val_acc: 0.5000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2387 - acc: 1.0000 - val_loss: 0.8007 - val_acc: 0.5000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2115 - acc: 1.0000 - val_loss: 0.8015 - val_acc: 0.5000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2382 - acc: 1.0000 - val_loss: 0.8012 - val_acc: 0.5000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2053 - acc: 1.0000 - val_loss: 0.8014 - val_acc: 0.5000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2260 - acc: 1.0000 - val_loss: 0.8017 - val_acc: 0.5000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2056 - acc: 1.0000 - val_loss: 0.8028 - val_acc: 0.5000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2091 - acc: 1.0000 - val_loss: 0.8038 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1994 - acc: 1.0000 - val_loss: 0.8049 - val_acc: 0.5000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2106 - acc: 1.0000 - val_loss: 0.8054 - val_acc: 0.5000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1960 - acc: 1.0000 - val_loss: 0.8064 - val_acc: 0.5000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2161 - acc: 1.0000 - val_loss: 0.8071 - val_acc: 0.5000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2402 - acc: 1.0000 - val_loss: 0.8068 - val_acc: 0.5000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1953 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.5000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1879 - acc: 1.0000 - val_loss: 0.8076 - val_acc: 0.5000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1979 - acc: 1.0000 - val_loss: 0.8072 - val_acc: 0.5000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2006 - acc: 1.0000 - val_loss: 0.8069 - val_acc: 0.5000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1916 - acc: 1.0000 - val_loss: 0.8066 - val_acc: 0.5000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2275 - acc: 1.0000 - val_loss: 0.8056 - val_acc: 0.5000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2351 - acc: 1.0000 - val_loss: 0.8051 - val_acc: 0.5000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1894 - acc: 1.0000 - val_loss: 0.8058 - val_acc: 0.5000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1853 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.5000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1834 - acc: 1.0000 - val_loss: 0.8083 - val_acc: 0.5000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1843 - acc: 1.0000 - val_loss: 0.8090 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1941 - acc: 1.0000 - val_loss: 0.8089 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1835 - acc: 1.0000 - val_loss: 0.8091 - val_acc: 0.5000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1935 - acc: 1.0000 - val_loss: 0.8087 - val_acc: 0.5000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1736 - acc: 1.0000 - val_loss: 0.8095 - val_acc: 0.5000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2028 - acc: 1.0000 - val_loss: 0.8099 - val_acc: 0.5000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1911 - acc: 1.0000 - val_loss: 0.8111 - val_acc: 0.5000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2502 - acc: 1.0000 - val_loss: 0.8111 - val_acc: 0.5000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1960 - acc: 1.0000 - val_loss: 0.8128 - val_acc: 0.5000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1823 - acc: 1.0000 - val_loss: 0.8150 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2140 - acc: 1.0000 - val_loss: 0.8163 - val_acc: 0.5000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1872 - acc: 1.0000 - val_loss: 0.8178 - val_acc: 0.5000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1824 - acc: 1.0000 - val_loss: 0.8196 - val_acc: 0.5000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1846 - acc: 1.0000 - val_loss: 0.8206 - val_acc: 0.5000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1734 - acc: 1.0000 - val_loss: 0.8218 - val_acc: 0.5000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1980 - acc: 1.0000 - val_loss: 0.8225 - val_acc: 0.5000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1856 - acc: 1.0000 - val_loss: 0.8233 - val_acc: 0.5000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1909 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.5000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1696 - acc: 1.0000 - val_loss: 0.8255 - val_acc: 0.5000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1828 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1847 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.5000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1717 - acc: 1.0000 - val_loss: 0.8281 - val_acc: 0.5000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2125 - acc: 1.0000 - val_loss: 0.8281 - val_acc: 0.5000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2100 - acc: 1.0000 - val_loss: 0.8274 - val_acc: 0.5000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1827 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.5000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1829 - acc: 1.0000 - val_loss: 0.8258 - val_acc: 0.5000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1868 - acc: 1.0000 - val_loss: 0.8247 - val_acc: 0.5000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.8247 - val_acc: 0.5000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2053 - acc: 1.0000 - val_loss: 0.8243 - val_acc: 0.5000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1845 - acc: 1.0000 - val_loss: 0.8245 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1935 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2184 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1971 - acc: 1.0000 - val_loss: 0.8238 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2069 - acc: 1.0000 - val_loss: 0.8236 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2178 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.5000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2024 - acc: 1.0000 - val_loss: 0.8237 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1727 - acc: 1.0000 - val_loss: 0.8240 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1640 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 0.5000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1992 - acc: 1.0000 - val_loss: 0.8248 - val_acc: 0.5000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1718 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.5000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1613 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1877 - acc: 1.0000 - val_loss: 0.8266 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1773 - acc: 1.0000 - val_loss: 0.8265 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1907 - acc: 1.0000 - val_loss: 0.8263 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1643 - acc: 1.0000 - val_loss: 0.8275 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1955 - acc: 1.0000 - val_loss: 0.8277 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1834 - acc: 1.0000 - val_loss: 0.8277 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2009 - acc: 1.0000 - val_loss: 0.8269 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1738 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.5000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1819 - acc: 1.0000 - val_loss: 0.8257 - val_acc: 0.5000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1931 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.5000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1789 - acc: 1.0000 - val_loss: 0.8260 - val_acc: 0.5000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1848 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1999 - acc: 1.0000 - val_loss: 0.8278 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1628 - acc: 1.0000 - val_loss: 0.8295 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1586 - acc: 1.0000 - val_loss: 0.8322 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1708 - acc: 1.0000 - val_loss: 0.8341 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1648 - acc: 1.0000 - val_loss: 0.8356 - val_acc: 0.5000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1930 - acc: 1.0000 - val_loss: 0.8360 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1850 - acc: 1.0000 - val_loss: 0.8364 - val_acc: 0.5000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1751 - acc: 1.0000 - val_loss: 0.8368 - val_acc: 0.5000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1752 - acc: 1.0000 - val_loss: 0.8374 - val_acc: 0.5000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2029 - acc: 1.0000 - val_loss: 0.8373 - val_acc: 0.5000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1681 - acc: 1.0000 - val_loss: 0.8385 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1576 - acc: 1.0000 - val_loss: 0.8405 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1834 - acc: 1.0000 - val_loss: 0.8414 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1705 - acc: 1.0000 - val_loss: 0.8421 - val_acc: 0.5000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1718 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2070 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.5000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1688 - acc: 1.0000 - val_loss: 0.8420 - val_acc: 0.5000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1858 - acc: 1.0000 - val_loss: 0.8422 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1858 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.5000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1588 - acc: 1.0000 - val_loss: 0.8446 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1982 - acc: 1.0000 - val_loss: 0.8454 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1691 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1668 - acc: 1.0000 - val_loss: 0.8475 - val_acc: 0.5000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1785 - acc: 1.0000 - val_loss: 0.8479 - val_acc: 0.5000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1863 - acc: 1.0000 - val_loss: 0.8476 - val_acc: 0.5000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1724 - acc: 1.0000 - val_loss: 0.8473 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1923 - acc: 1.0000 - val_loss: 0.8466 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1581 - acc: 1.0000 - val_loss: 0.8469 - val_acc: 0.5000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1626 - acc: 1.0000 - val_loss: 0.8471 - val_acc: 0.5000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1785 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.5000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1557 - acc: 1.0000 - val_loss: 0.8487 - val_acc: 0.5000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1721 - acc: 1.0000 - val_loss: 0.8499 - val_acc: 0.5000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1672 - acc: 1.0000 - val_loss: 0.8508 - val_acc: 0.5000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1472 - acc: 1.0000 - val_loss: 0.8521 - val_acc: 0.5000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1485 - acc: 1.0000 - val_loss: 0.8531 - val_acc: 0.5000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1483 - acc: 1.0000 - val_loss: 0.8533 - val_acc: 0.5000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1437 - acc: 1.0000 - val_loss: 0.8539 - val_acc: 0.5000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2057 - acc: 1.0000 - val_loss: 0.8531 - val_acc: 0.5000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1761 - acc: 1.0000 - val_loss: 0.8527 - val_acc: 0.5000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1914 - acc: 1.0000 - val_loss: 0.8520 - val_acc: 0.5000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1600 - acc: 1.0000 - val_loss: 0.8527 - val_acc: 0.5000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 31s 31s/step - loss: 0.1579 - acc: 1.0000 - val_loss: 0.8539 - val_acc: 0.5000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1641 - acc: 1.0000 - val_loss: 0.8546 - val_acc: 0.5000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1624 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 0.5000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1885 - acc: 1.0000 - val_loss: 0.8554 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1518 - acc: 1.0000 - val_loss: 0.8567 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1514 - acc: 1.0000 - val_loss: 0.8583 - val_acc: 0.5000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1662 - acc: 1.0000 - val_loss: 0.8587 - val_acc: 0.5000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1891 - acc: 1.0000 - val_loss: 0.8588 - val_acc: 0.5000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1521 - acc: 1.0000 - val_loss: 0.8599 - val_acc: 0.5000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1745 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.5000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1519 - acc: 1.0000 - val_loss: 0.8614 - val_acc: 0.5000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1509 - acc: 1.0000 - val_loss: 0.8624 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1605 - acc: 1.0000 - val_loss: 0.8634 - val_acc: 0.5000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1374 - acc: 1.0000 - val_loss: 0.8648 - val_acc: 0.5000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1447 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.5000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2115 - acc: 0.9844 - val_loss: 0.8618 - val_acc: 0.5000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1611 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.5000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1630 - acc: 1.0000 - val_loss: 0.8628 - val_acc: 0.5000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2004 - acc: 1.0000 - val_loss: 0.8661 - val_acc: 0.5000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1497 - acc: 1.0000 - val_loss: 0.8721 - val_acc: 0.5000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1507 - acc: 1.0000 - val_loss: 0.8777 - val_acc: 0.5000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2266 - acc: 1.0000 - val_loss: 0.8800 - val_acc: 0.5000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1494 - acc: 1.0000 - val_loss: 0.8820 - val_acc: 0.5000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1778 - acc: 1.0000 - val_loss: 0.8821 - val_acc: 0.5000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1664 - acc: 1.0000 - val_loss: 0.8831 - val_acc: 0.5000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2039 - acc: 0.9844 - val_loss: 0.8847 - val_acc: 0.5000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1442 - acc: 1.0000 - val_loss: 0.8852 - val_acc: 0.5000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1731 - acc: 1.0000 - val_loss: 0.8851 - val_acc: 0.5000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1412 - acc: 1.0000 - val_loss: 0.8872 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1603 - acc: 1.0000 - val_loss: 0.8891 - val_acc: 0.5000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1555 - acc: 1.0000 - val_loss: 0.8907 - val_acc: 0.5000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1653 - acc: 1.0000 - val_loss: 0.8927 - val_acc: 0.5000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1632 - acc: 1.0000 - val_loss: 0.8953 - val_acc: 0.5000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1679 - acc: 1.0000 - val_loss: 0.8962 - val_acc: 0.5000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1649 - acc: 1.0000 - val_loss: 0.8967 - val_acc: 0.5000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1591 - acc: 1.0000 - val_loss: 0.8956 - val_acc: 0.5000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1378 - acc: 1.0000 - val_loss: 0.8942 - val_acc: 0.5000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1401 - acc: 1.0000 - val_loss: 0.8930 - val_acc: 0.5000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1364 - acc: 1.0000 - val_loss: 0.8930 - val_acc: 0.5000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1977 - acc: 1.0000 - val_loss: 0.8914 - val_acc: 0.5000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.8904 - val_acc: 0.5000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1493 - acc: 1.0000 - val_loss: 0.8905 - val_acc: 0.5000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1642 - acc: 1.0000 - val_loss: 0.8903 - val_acc: 0.5000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1355 - acc: 1.0000 - val_loss: 0.8906 - val_acc: 0.5000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1288 - acc: 1.0000 - val_loss: 0.8924 - val_acc: 0.5000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1498 - acc: 1.0000 - val_loss: 0.8930 - val_acc: 0.5000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1695 - acc: 1.0000 - val_loss: 0.8944 - val_acc: 0.5000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1570 - acc: 1.0000 - val_loss: 0.8960 - val_acc: 0.5000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1538 - acc: 1.0000 - val_loss: 0.8976 - val_acc: 0.5000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2179 - acc: 0.9844 - val_loss: 0.9033 - val_acc: 0.5000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1326 - acc: 1.0000 - val_loss: 0.9106 - val_acc: 0.5000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1560 - acc: 1.0000 - val_loss: 0.9152 - val_acc: 0.5000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1411 - acc: 1.0000 - val_loss: 0.9182 - val_acc: 0.5000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1671 - acc: 1.0000 - val_loss: 0.9202 - val_acc: 0.5000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1742 - acc: 1.0000 - val_loss: 0.9202 - val_acc: 0.5000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1619 - acc: 1.0000 - val_loss: 0.9189 - val_acc: 0.5000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1379 - acc: 1.0000 - val_loss: 0.9191 - val_acc: 0.5000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1353 - acc: 1.0000 - val_loss: 0.9199 - val_acc: 0.5000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1332 - acc: 1.0000 - val_loss: 0.9210 - val_acc: 0.5000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1498 - acc: 1.0000 - val_loss: 0.9212 - val_acc: 0.5000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1283 - acc: 1.0000 - val_loss: 0.9217 - val_acc: 0.5000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1438 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.5000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1313 - acc: 1.0000 - val_loss: 0.9165 - val_acc: 0.5000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1673 - acc: 1.0000 - val_loss: 0.9125 - val_acc: 0.5000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1768 - acc: 1.0000 - val_loss: 0.9083 - val_acc: 0.5000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1627 - acc: 1.0000 - val_loss: 0.9050 - val_acc: 0.5000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1360 - acc: 1.0000 - val_loss: 0.9035 - val_acc: 0.5000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1339 - acc: 1.0000 - val_loss: 0.9034 - val_acc: 0.5000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1464 - acc: 1.0000 - val_loss: 0.9035 - val_acc: 0.5000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1261 - acc: 1.0000 - val_loss: 0.9069 - val_acc: 0.5000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1308 - acc: 1.0000 - val_loss: 0.9102 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1615 - acc: 1.0000 - val_loss: 0.9124 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1357 - acc: 1.0000 - val_loss: 0.9140 - val_acc: 0.5000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1511 - acc: 1.0000 - val_loss: 0.9135 - val_acc: 0.5000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1407 - acc: 1.0000 - val_loss: 0.9136 - val_acc: 0.5000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1412 - acc: 1.0000 - val_loss: 0.9127 - val_acc: 0.5000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1318 - acc: 1.0000 - val_loss: 0.9121 - val_acc: 0.5000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1214 - acc: 1.0000 - val_loss: 0.9131 - val_acc: 0.5000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1334 - acc: 1.0000 - val_loss: 0.9145 - val_acc: 0.5000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1248 - acc: 1.0000 - val_loss: 0.9172 - val_acc: 0.5000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.9198 - val_acc: 0.5000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1553 - acc: 1.0000 - val_loss: 0.9207 - val_acc: 0.5000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1391 - acc: 1.0000 - val_loss: 0.9230 - val_acc: 0.5000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1382 - acc: 1.0000 - val_loss: 0.9254 - val_acc: 0.5000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1342 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.5000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1474 - acc: 1.0000 - val_loss: 0.9302 - val_acc: 0.5000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1311 - acc: 1.0000 - val_loss: 0.9324 - val_acc: 0.5000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1207 - acc: 1.0000 - val_loss: 0.9344 - val_acc: 0.5000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1338 - acc: 1.0000 - val_loss: 0.9347 - val_acc: 0.5000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1254 - acc: 1.0000 - val_loss: 0.9350 - val_acc: 0.5000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1338 - acc: 1.0000 - val_loss: 0.9348 - val_acc: 0.5000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1209 - acc: 1.0000 - val_loss: 0.9343 - val_acc: 0.5000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1150 - acc: 1.0000 - val_loss: 0.9345 - val_acc: 0.5000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1544 - acc: 1.0000 - val_loss: 0.9327 - val_acc: 0.5000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1369 - acc: 1.0000 - val_loss: 0.9321 - val_acc: 0.5000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1343 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 0.5000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1275 - acc: 1.0000 - val_loss: 0.9310 - val_acc: 0.5000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1143 - acc: 1.0000 - val_loss: 0.9325 - val_acc: 0.5000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1277 - acc: 1.0000 - val_loss: 0.9336 - val_acc: 0.5000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.9325 - val_acc: 0.5000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1306 - acc: 1.0000 - val_loss: 0.9320 - val_acc: 0.5000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2118 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.5000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1187 - acc: 1.0000 - val_loss: 0.9264 - val_acc: 0.5000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1384 - acc: 1.0000 - val_loss: 0.9244 - val_acc: 0.5000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1291 - acc: 1.0000 - val_loss: 0.9230 - val_acc: 0.5000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1695 - acc: 1.0000 - val_loss: 0.9216 - val_acc: 0.5000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1587 - acc: 1.0000 - val_loss: 0.9202 - val_acc: 0.5000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1564 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.5000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1304 - acc: 1.0000 - val_loss: 0.9204 - val_acc: 0.5000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1230 - acc: 1.0000 - val_loss: 0.9218 - val_acc: 0.5000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1366 - acc: 1.0000 - val_loss: 0.9231 - val_acc: 0.5000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1244 - acc: 1.0000 - val_loss: 0.9252 - val_acc: 0.5000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1379 - acc: 1.0000 - val_loss: 0.9268 - val_acc: 0.5000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1327 - acc: 1.0000 - val_loss: 0.9281 - val_acc: 0.5000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1434 - acc: 1.0000 - val_loss: 0.9292 - val_acc: 0.5000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1263 - acc: 1.0000 - val_loss: 0.9301 - val_acc: 0.5000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1215 - acc: 1.0000 - val_loss: 0.9308 - val_acc: 0.5000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1230 - acc: 1.0000 - val_loss: 0.9308 - val_acc: 0.5000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1163 - acc: 1.0000 - val_loss: 0.9307 - val_acc: 0.5000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1379 - acc: 1.0000 - val_loss: 0.9297 - val_acc: 0.5000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1284 - acc: 1.0000 - val_loss: 0.9294 - val_acc: 0.5000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1359 - acc: 1.0000 - val_loss: 0.9288 - val_acc: 0.5000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1145 - acc: 1.0000 - val_loss: 0.9296 - val_acc: 0.5000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1682 - acc: 0.9844 - val_loss: 0.9303 - val_acc: 0.5000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1327 - acc: 1.0000 - val_loss: 0.9304 - val_acc: 0.5000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1125 - acc: 1.0000 - val_loss: 0.9312 - val_acc: 0.5000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1118 - acc: 1.0000 - val_loss: 0.9321 - val_acc: 0.5000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.9329 - val_acc: 0.5000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1858 - acc: 1.0000 - val_loss: 0.9311 - val_acc: 0.5000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1388 - acc: 1.0000 - val_loss: 0.9306 - val_acc: 0.5000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1561 - acc: 1.0000 - val_loss: 0.9304 - val_acc: 0.5000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1226 - acc: 1.0000 - val_loss: 0.9317 - val_acc: 0.5000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1295 - acc: 1.0000 - val_loss: 0.9338 - val_acc: 0.5000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1074 - acc: 1.0000 - val_loss: 0.9377 - val_acc: 0.5000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1341 - acc: 1.0000 - val_loss: 0.9411 - val_acc: 0.5000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1511 - acc: 1.0000 - val_loss: 0.9425 - val_acc: 0.5000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1227 - acc: 1.0000 - val_loss: 0.9431 - val_acc: 0.5000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1375 - acc: 1.0000 - val_loss: 0.9420 - val_acc: 0.5000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1114 - acc: 1.0000 - val_loss: 0.9417 - val_acc: 0.5000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1381 - acc: 1.0000 - val_loss: 0.9401 - val_acc: 0.5000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1422 - acc: 1.0000 - val_loss: 0.9384 - val_acc: 0.5000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1047 - acc: 1.0000 - val_loss: 0.9392 - val_acc: 0.5000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.2034 - acc: 1.0000 - val_loss: 0.9370 - val_acc: 0.5000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1123 - acc: 1.0000 - val_loss: 0.9373 - val_acc: 0.5000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1286 - acc: 1.0000 - val_loss: 0.9369 - val_acc: 0.5000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1642 - acc: 1.0000 - val_loss: 0.9354 - val_acc: 0.5000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1313 - acc: 1.0000 - val_loss: 0.9354 - val_acc: 0.5000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1290 - acc: 1.0000 - val_loss: 0.9352 - val_acc: 0.5000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1341 - acc: 1.0000 - val_loss: 0.9345 - val_acc: 0.5000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1032 - acc: 1.0000 - val_loss: 0.9360 - val_acc: 0.5000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1212 - acc: 1.0000 - val_loss: 0.9366 - val_acc: 0.5000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1025 - acc: 1.0000 - val_loss: 0.9384 - val_acc: 0.5000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1306 - acc: 1.0000 - val_loss: 0.9383 - val_acc: 0.5000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1130 - acc: 1.0000 - val_loss: 0.9386 - val_acc: 0.5000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1042 - acc: 1.0000 - val_loss: 0.9403 - val_acc: 0.5000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1037 - acc: 1.0000 - val_loss: 0.9427 - val_acc: 0.5000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1295 - acc: 1.0000 - val_loss: 0.9434 - val_acc: 0.5000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1139 - acc: 1.0000 - val_loss: 0.9444 - val_acc: 0.5000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1278 - acc: 1.0000 - val_loss: 0.9450 - val_acc: 0.5000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1114 - acc: 1.0000 - val_loss: 0.9461 - val_acc: 0.5000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1133 - acc: 1.0000 - val_loss: 0.9475 - val_acc: 0.5000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1022 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.5000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1474 - acc: 1.0000 - val_loss: 0.9496 - val_acc: 0.5000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1024 - acc: 1.0000 - val_loss: 0.9508 - val_acc: 0.5000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1390 - acc: 1.0000 - val_loss: 0.9508 - val_acc: 0.5000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1444 - acc: 1.0000 - val_loss: 0.9497 - val_acc: 0.5000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.9487 - val_acc: 0.5000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1117 - acc: 1.0000 - val_loss: 0.9486 - val_acc: 0.5000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1213 - acc: 1.0000 - val_loss: 0.9485 - val_acc: 0.5000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1171 - acc: 1.0000 - val_loss: 0.9495 - val_acc: 0.5000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1251 - acc: 1.0000 - val_loss: 0.9506 - val_acc: 0.5000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1076 - acc: 1.0000 - val_loss: 0.9525 - val_acc: 0.5000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1156 - acc: 1.0000 - val_loss: 0.9540 - val_acc: 0.5000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1242 - acc: 1.0000 - val_loss: 0.9554 - val_acc: 0.5000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1189 - acc: 1.0000 - val_loss: 0.9570 - val_acc: 0.5000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1288 - acc: 1.0000 - val_loss: 0.9575 - val_acc: 0.5000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0956 - acc: 1.0000 - val_loss: 0.9589 - val_acc: 0.5000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1328 - acc: 1.0000 - val_loss: 0.9588 - val_acc: 0.5000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1020 - acc: 1.0000 - val_loss: 0.9593 - val_acc: 0.5000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1013 - acc: 1.0000 - val_loss: 0.9602 - val_acc: 0.5000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0984 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.5000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1224 - acc: 1.0000 - val_loss: 0.9613 - val_acc: 0.5000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1077 - acc: 1.0000 - val_loss: 0.9621 - val_acc: 0.5000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1056 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.5000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1011 - acc: 1.0000 - val_loss: 0.9658 - val_acc: 0.5000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1258 - acc: 1.0000 - val_loss: 0.9666 - val_acc: 0.5000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1059 - acc: 1.0000 - val_loss: 0.9676 - val_acc: 0.5000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1162 - acc: 1.0000 - val_loss: 0.9675 - val_acc: 0.5000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1066 - acc: 1.0000 - val_loss: 0.9674 - val_acc: 0.5000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1066 - acc: 1.0000 - val_loss: 0.9672 - val_acc: 0.5000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1041 - acc: 1.0000 - val_loss: 0.9679 - val_acc: 0.5000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1293 - acc: 1.0000 - val_loss: 0.9680 - val_acc: 0.5000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1170 - acc: 1.0000 - val_loss: 0.9676 - val_acc: 0.5000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0994 - acc: 1.0000 - val_loss: 0.9684 - val_acc: 0.5000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0983 - acc: 1.0000 - val_loss: 0.9694 - val_acc: 0.5000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0982 - acc: 1.0000 - val_loss: 0.9705 - val_acc: 0.5000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1191 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.5000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1103 - acc: 1.0000 - val_loss: 0.9716 - val_acc: 0.5000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1003 - acc: 1.0000 - val_loss: 0.9724 - val_acc: 0.5000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.0926 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.5000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1230 - acc: 1.0000 - val_loss: 0.9732 - val_acc: 0.5000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1044 - acc: 1.0000 - val_loss: 0.9741 - val_acc: 0.5000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1044 - acc: 1.0000 - val_loss: 0.9760 - val_acc: 0.5000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1109 - acc: 1.0000 - val_loss: 0.9776 - val_acc: 0.5000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1084 - acc: 1.0000 - val_loss: 0.9800 - val_acc: 0.5000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 32s 32s/step - loss: 0.1032 - acc: 1.0000 - val_loss: 0.9831 - val_acc: 0.5000\n",
            "Runtime : 15903.028237 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAMECAYAAACSVgBpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJYQQQghRQv8fJobcbcD9vTgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8UZmgSG55Y_h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Shuffled pairs training"
      ]
    },
    {
      "metadata": {
        "id": "tZIy1s3yjDjf",
        "colab_type": "code",
        "outputId": "a3e044ab-3a29-4a3b-d9ea-d066fe9c75d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19247
        }
      },
      "cell_type": "code",
      "source": [
        "shuffled_training = train(shuffled_dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_img (InputLayer)           (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_img (InputLayer)          (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Feat_Model (Model)              (None, 576)          142144      left_img[0][0]                   \n",
            "                                                                 right_img[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concat_feats (Concatenate)      (None, 1152)         0           Feat_Model[1][0]                 \n",
            "                                                                 Feat_Model[2][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1024)         1180672     concat_feats[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 1024)         4096        dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 1024)         0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 4)            4100        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 4)            16          dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4)            0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            5           activation_6[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,331,033\n",
            "Trainable params: 1,328,977\n",
            "Non-trainable params: 2,056\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.7741 - acc: 0.4531 - val_loss: 1.8038 - val_acc: 0.4866\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.5910 - acc: 0.7188 - val_loss: 2.1558 - val_acc: 0.4947\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.5190 - acc: 0.8125 - val_loss: 2.7229 - val_acc: 0.4917\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.5006 - acc: 0.7344 - val_loss: 3.2928 - val_acc: 0.4991\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.5243 - acc: 0.7344 - val_loss: 2.4749 - val_acc: 0.4992\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.4551 - acc: 0.8906 - val_loss: 1.4001 - val_acc: 0.5047\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.4496 - acc: 0.8750 - val_loss: 1.0220 - val_acc: 0.5030\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.4405 - acc: 0.8906 - val_loss: 1.0722 - val_acc: 0.5000\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.4117 - acc: 0.9688 - val_loss: 0.9824 - val_acc: 0.4970\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.4475 - acc: 0.8906 - val_loss: 1.1353 - val_acc: 0.4972\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3722 - acc: 0.9844 - val_loss: 1.0418 - val_acc: 0.4947\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3954 - acc: 0.9375 - val_loss: 1.5907 - val_acc: 0.4991\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3631 - acc: 1.0000 - val_loss: 1.9210 - val_acc: 0.5000\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3649 - acc: 1.0000 - val_loss: 2.1497 - val_acc: 0.5000\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3883 - acc: 0.9531 - val_loss: 2.0831 - val_acc: 0.5000\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3499 - acc: 1.0000 - val_loss: 1.6268 - val_acc: 0.5000\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3429 - acc: 1.0000 - val_loss: 1.0806 - val_acc: 0.4985\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3741 - acc: 0.9844 - val_loss: 0.7963 - val_acc: 0.4830\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3331 - acc: 1.0000 - val_loss: 0.6824 - val_acc: 0.4054\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3344 - acc: 0.9844 - val_loss: 0.6651 - val_acc: 0.3725\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3373 - acc: 0.9844 - val_loss: 0.6751 - val_acc: 0.3652\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3263 - acc: 1.0000 - val_loss: 0.6774 - val_acc: 0.3637\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3425 - acc: 1.0000 - val_loss: 0.7454 - val_acc: 0.4724\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3280 - acc: 1.0000 - val_loss: 0.9734 - val_acc: 0.4992\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3340 - acc: 1.0000 - val_loss: 1.3121 - val_acc: 0.4994\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3084 - acc: 1.0000 - val_loss: 1.5859 - val_acc: 0.5000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3153 - acc: 1.0000 - val_loss: 1.7688 - val_acc: 0.5000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3087 - acc: 1.0000 - val_loss: 1.8359 - val_acc: 0.5000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3077 - acc: 1.0000 - val_loss: 1.8319 - val_acc: 0.5000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3104 - acc: 1.0000 - val_loss: 1.7631 - val_acc: 0.5000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3012 - acc: 1.0000 - val_loss: 1.6562 - val_acc: 0.5000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3180 - acc: 0.9844 - val_loss: 1.5553 - val_acc: 0.5000\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3093 - acc: 1.0000 - val_loss: 1.4829 - val_acc: 0.5000\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3010 - acc: 1.0000 - val_loss: 1.4186 - val_acc: 0.5000\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.3020 - acc: 1.0000 - val_loss: 1.3127 - val_acc: 0.5000\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2901 - acc: 1.0000 - val_loss: 1.2083 - val_acc: 0.5000\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2927 - acc: 1.0000 - val_loss: 1.1027 - val_acc: 0.4994\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.3017 - acc: 1.0000 - val_loss: 1.0180 - val_acc: 0.4994\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2810 - acc: 1.0000 - val_loss: 0.9565 - val_acc: 0.4994\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2916 - acc: 1.0000 - val_loss: 0.9303 - val_acc: 0.4994\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2894 - acc: 1.0000 - val_loss: 0.9198 - val_acc: 0.4992\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2741 - acc: 1.0000 - val_loss: 0.9120 - val_acc: 0.4992\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2808 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.4994\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2822 - acc: 1.0000 - val_loss: 0.9136 - val_acc: 0.4994\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2758 - acc: 1.0000 - val_loss: 0.9047 - val_acc: 0.4994\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2685 - acc: 1.0000 - val_loss: 0.9103 - val_acc: 0.4994\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2642 - acc: 1.0000 - val_loss: 0.9158 - val_acc: 0.4996\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2599 - acc: 1.0000 - val_loss: 0.9306 - val_acc: 0.5000\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2655 - acc: 1.0000 - val_loss: 0.9597 - val_acc: 0.5000\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2570 - acc: 1.0000 - val_loss: 1.0185 - val_acc: 0.5000\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2651 - acc: 1.0000 - val_loss: 1.0777 - val_acc: 0.5000\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2582 - acc: 1.0000 - val_loss: 1.1387 - val_acc: 0.5000\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2549 - acc: 1.0000 - val_loss: 1.2047 - val_acc: 0.5000\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2556 - acc: 1.0000 - val_loss: 1.2549 - val_acc: 0.5000\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2802 - acc: 1.0000 - val_loss: 1.3037 - val_acc: 0.5000\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2582 - acc: 1.0000 - val_loss: 1.3220 - val_acc: 0.5000\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2707 - acc: 1.0000 - val_loss: 1.2952 - val_acc: 0.5000\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2574 - acc: 1.0000 - val_loss: 1.2631 - val_acc: 0.5000\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2470 - acc: 1.0000 - val_loss: 1.2225 - val_acc: 0.5000\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2531 - acc: 1.0000 - val_loss: 1.1849 - val_acc: 0.5000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2464 - acc: 1.0000 - val_loss: 1.1448 - val_acc: 0.5000\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2612 - acc: 1.0000 - val_loss: 1.1167 - val_acc: 0.5000\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2348 - acc: 1.0000 - val_loss: 1.0897 - val_acc: 0.5000\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2470 - acc: 1.0000 - val_loss: 1.0549 - val_acc: 0.5000\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2466 - acc: 1.0000 - val_loss: 1.0234 - val_acc: 0.5000\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2376 - acc: 1.0000 - val_loss: 1.0009 - val_acc: 0.5000\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2295 - acc: 1.0000 - val_loss: 0.9753 - val_acc: 0.5000\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2332 - acc: 1.0000 - val_loss: 0.9545 - val_acc: 0.5000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2435 - acc: 1.0000 - val_loss: 0.9296 - val_acc: 0.5000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2444 - acc: 1.0000 - val_loss: 0.9197 - val_acc: 0.4998\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2376 - acc: 1.0000 - val_loss: 0.9142 - val_acc: 0.4998\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.9113 - val_acc: 0.4998\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2330 - acc: 1.0000 - val_loss: 0.9054 - val_acc: 0.4998\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2305 - acc: 1.0000 - val_loss: 0.9031 - val_acc: 0.4998\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2263 - acc: 1.0000 - val_loss: 0.9093 - val_acc: 0.5000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2385 - acc: 1.0000 - val_loss: 0.9237 - val_acc: 0.5000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2201 - acc: 1.0000 - val_loss: 0.9399 - val_acc: 0.5000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2236 - acc: 1.0000 - val_loss: 0.9551 - val_acc: 0.5000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2203 - acc: 1.0000 - val_loss: 0.9773 - val_acc: 0.5000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2165 - acc: 1.0000 - val_loss: 1.0008 - val_acc: 0.5000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2489 - acc: 0.9688 - val_loss: 1.0201 - val_acc: 0.5000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2316 - acc: 1.0000 - val_loss: 1.0399 - val_acc: 0.5000\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2229 - acc: 1.0000 - val_loss: 1.0518 - val_acc: 0.5000\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2181 - acc: 1.0000 - val_loss: 1.0433 - val_acc: 0.5000\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2117 - acc: 1.0000 - val_loss: 1.0398 - val_acc: 0.5000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2142 - acc: 1.0000 - val_loss: 1.0412 - val_acc: 0.5000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2233 - acc: 1.0000 - val_loss: 1.0429 - val_acc: 0.5000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2060 - acc: 1.0000 - val_loss: 1.0420 - val_acc: 0.5000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2043 - acc: 1.0000 - val_loss: 1.0372 - val_acc: 0.5000\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2023 - acc: 1.0000 - val_loss: 1.0226 - val_acc: 0.5000\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2202 - acc: 1.0000 - val_loss: 1.0085 - val_acc: 0.5000\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2117 - acc: 1.0000 - val_loss: 1.0033 - val_acc: 0.5000\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2081 - acc: 1.0000 - val_loss: 0.9986 - val_acc: 0.5000\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.2115 - acc: 1.0000 - val_loss: 0.9906 - val_acc: 0.5000\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2002 - acc: 1.0000 - val_loss: 0.9863 - val_acc: 0.5000\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1987 - acc: 1.0000 - val_loss: 0.9858 - val_acc: 0.5000\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1888 - acc: 1.0000 - val_loss: 0.9827 - val_acc: 0.5000\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1964 - acc: 1.0000 - val_loss: 0.9835 - val_acc: 0.5000\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2043 - acc: 1.0000 - val_loss: 0.9821 - val_acc: 0.5000\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2101 - acc: 1.0000 - val_loss: 0.9862 - val_acc: 0.5000\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2134 - acc: 1.0000 - val_loss: 0.9829 - val_acc: 0.5000\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.2071 - acc: 1.0000 - val_loss: 0.9861 - val_acc: 0.5000\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1976 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.5000\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1954 - acc: 1.0000 - val_loss: 0.9958 - val_acc: 0.5000\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1925 - acc: 1.0000 - val_loss: 0.9949 - val_acc: 0.5000\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1841 - acc: 1.0000 - val_loss: 0.9934 - val_acc: 0.5000\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1931 - acc: 1.0000 - val_loss: 0.9932 - val_acc: 0.5000\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1832 - acc: 1.0000 - val_loss: 0.9946 - val_acc: 0.5000\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1801 - acc: 1.0000 - val_loss: 0.9956 - val_acc: 0.5000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1839 - acc: 1.0000 - val_loss: 1.0043 - val_acc: 0.5000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1839 - acc: 1.0000 - val_loss: 1.0107 - val_acc: 0.5000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1872 - acc: 1.0000 - val_loss: 1.0192 - val_acc: 0.5000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1788 - acc: 1.0000 - val_loss: 1.0268 - val_acc: 0.5000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1932 - acc: 1.0000 - val_loss: 1.0348 - val_acc: 0.5000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1856 - acc: 1.0000 - val_loss: 1.0462 - val_acc: 0.5000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1923 - acc: 1.0000 - val_loss: 1.0660 - val_acc: 0.5000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1741 - acc: 1.0000 - val_loss: 1.0812 - val_acc: 0.5000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1815 - acc: 1.0000 - val_loss: 1.0956 - val_acc: 0.5000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1830 - acc: 1.0000 - val_loss: 1.1095 - val_acc: 0.5000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1799 - acc: 1.0000 - val_loss: 1.1247 - val_acc: 0.5000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1766 - acc: 1.0000 - val_loss: 1.1304 - val_acc: 0.5000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1851 - acc: 1.0000 - val_loss: 1.1348 - val_acc: 0.5000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1724 - acc: 1.0000 - val_loss: 1.1363 - val_acc: 0.5000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1672 - acc: 1.0000 - val_loss: 1.1375 - val_acc: 0.5000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1764 - acc: 1.0000 - val_loss: 1.1305 - val_acc: 0.5000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1699 - acc: 1.0000 - val_loss: 1.1241 - val_acc: 0.5000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1861 - acc: 1.0000 - val_loss: 1.1105 - val_acc: 0.5000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1647 - acc: 1.0000 - val_loss: 1.0971 - val_acc: 0.5000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1693 - acc: 1.0000 - val_loss: 1.0853 - val_acc: 0.5000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1652 - acc: 1.0000 - val_loss: 1.0722 - val_acc: 0.5000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1615 - acc: 1.0000 - val_loss: 1.0521 - val_acc: 0.5000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1569 - acc: 1.0000 - val_loss: 1.0295 - val_acc: 0.5000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1604 - acc: 1.0000 - val_loss: 1.0130 - val_acc: 0.5000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1748 - acc: 1.0000 - val_loss: 1.0011 - val_acc: 0.5000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1559 - acc: 1.0000 - val_loss: 0.9847 - val_acc: 0.5000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1733 - acc: 1.0000 - val_loss: 0.9752 - val_acc: 0.5000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1645 - acc: 1.0000 - val_loss: 0.9667 - val_acc: 0.5000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1696 - acc: 1.0000 - val_loss: 0.9651 - val_acc: 0.5000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1692 - acc: 1.0000 - val_loss: 0.9679 - val_acc: 0.5000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1732 - acc: 1.0000 - val_loss: 0.9751 - val_acc: 0.5000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1681 - acc: 1.0000 - val_loss: 0.9853 - val_acc: 0.5000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1812 - acc: 0.9844 - val_loss: 1.0077 - val_acc: 0.5000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1576 - acc: 1.0000 - val_loss: 1.0269 - val_acc: 0.5000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1651 - acc: 1.0000 - val_loss: 1.0434 - val_acc: 0.5000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1579 - acc: 1.0000 - val_loss: 1.0553 - val_acc: 0.5000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1546 - acc: 1.0000 - val_loss: 1.0713 - val_acc: 0.5000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1561 - acc: 1.0000 - val_loss: 1.0813 - val_acc: 0.5000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1526 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.5000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1606 - acc: 1.0000 - val_loss: 1.1028 - val_acc: 0.5000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1587 - acc: 1.0000 - val_loss: 1.1111 - val_acc: 0.5000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1433 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.5000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1508 - acc: 1.0000 - val_loss: 1.1145 - val_acc: 0.5000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1437 - acc: 1.0000 - val_loss: 1.1063 - val_acc: 0.5000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1573 - acc: 1.0000 - val_loss: 1.0951 - val_acc: 0.5000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1485 - acc: 1.0000 - val_loss: 1.0909 - val_acc: 0.5000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1535 - acc: 1.0000 - val_loss: 1.0891 - val_acc: 0.5000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1567 - acc: 1.0000 - val_loss: 1.0870 - val_acc: 0.5000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1607 - acc: 1.0000 - val_loss: 1.0941 - val_acc: 0.5000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1413 - acc: 1.0000 - val_loss: 1.1024 - val_acc: 0.5000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1423 - acc: 1.0000 - val_loss: 1.1179 - val_acc: 0.5000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1568 - acc: 1.0000 - val_loss: 1.1304 - val_acc: 0.5000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1548 - acc: 1.0000 - val_loss: 1.1434 - val_acc: 0.5000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1538 - acc: 1.0000 - val_loss: 1.1566 - val_acc: 0.5000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1424 - acc: 1.0000 - val_loss: 1.1652 - val_acc: 0.5000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1492 - acc: 1.0000 - val_loss: 1.1721 - val_acc: 0.5000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1556 - acc: 1.0000 - val_loss: 1.1786 - val_acc: 0.5000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1547 - acc: 1.0000 - val_loss: 1.1873 - val_acc: 0.5000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1342 - acc: 1.0000 - val_loss: 1.1897 - val_acc: 0.5000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1452 - acc: 1.0000 - val_loss: 1.1794 - val_acc: 0.5000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1455 - acc: 1.0000 - val_loss: 1.1765 - val_acc: 0.5000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1691 - acc: 1.0000 - val_loss: 1.1631 - val_acc: 0.5000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1433 - acc: 1.0000 - val_loss: 1.1566 - val_acc: 0.5000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1416 - acc: 1.0000 - val_loss: 1.1495 - val_acc: 0.5000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1406 - acc: 1.0000 - val_loss: 1.1354 - val_acc: 0.5000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1463 - acc: 1.0000 - val_loss: 1.1186 - val_acc: 0.5000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1469 - acc: 1.0000 - val_loss: 1.1074 - val_acc: 0.5000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1360 - acc: 1.0000 - val_loss: 1.0959 - val_acc: 0.5000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1422 - acc: 1.0000 - val_loss: 1.0890 - val_acc: 0.5000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1350 - acc: 1.0000 - val_loss: 1.0892 - val_acc: 0.5000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1430 - acc: 1.0000 - val_loss: 1.0868 - val_acc: 0.5000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1406 - acc: 1.0000 - val_loss: 1.0842 - val_acc: 0.5000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1450 - acc: 1.0000 - val_loss: 1.0807 - val_acc: 0.5000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1384 - acc: 1.0000 - val_loss: 1.0867 - val_acc: 0.5000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1511 - acc: 1.0000 - val_loss: 1.0988 - val_acc: 0.5000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1463 - acc: 1.0000 - val_loss: 1.1115 - val_acc: 0.5000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1368 - acc: 1.0000 - val_loss: 1.1190 - val_acc: 0.5000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1331 - acc: 1.0000 - val_loss: 1.1294 - val_acc: 0.5000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1283 - acc: 1.0000 - val_loss: 1.1389 - val_acc: 0.5000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1302 - acc: 1.0000 - val_loss: 1.1502 - val_acc: 0.5000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1240 - acc: 1.0000 - val_loss: 1.1519 - val_acc: 0.5000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1334 - acc: 1.0000 - val_loss: 1.1547 - val_acc: 0.5000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1395 - acc: 1.0000 - val_loss: 1.1544 - val_acc: 0.5000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1237 - acc: 1.0000 - val_loss: 1.1511 - val_acc: 0.5000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1403 - acc: 1.0000 - val_loss: 1.1508 - val_acc: 0.5000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1150 - acc: 1.0000 - val_loss: 1.1496 - val_acc: 0.5000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1235 - acc: 1.0000 - val_loss: 1.1492 - val_acc: 0.5000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1276 - acc: 1.0000 - val_loss: 1.1416 - val_acc: 0.5000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1214 - acc: 1.0000 - val_loss: 1.1373 - val_acc: 0.5000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1240 - acc: 1.0000 - val_loss: 1.1417 - val_acc: 0.5000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1333 - acc: 1.0000 - val_loss: 1.1465 - val_acc: 0.5000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1184 - acc: 1.0000 - val_loss: 1.1524 - val_acc: 0.5000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1117 - acc: 1.0000 - val_loss: 1.1600 - val_acc: 0.5000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1164 - acc: 1.0000 - val_loss: 1.1651 - val_acc: 0.5000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1537 - acc: 1.0000 - val_loss: 1.1669 - val_acc: 0.5000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1211 - acc: 1.0000 - val_loss: 1.1664 - val_acc: 0.5000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1205 - acc: 1.0000 - val_loss: 1.1705 - val_acc: 0.5000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1098 - acc: 1.0000 - val_loss: 1.1890 - val_acc: 0.5000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1149 - acc: 1.0000 - val_loss: 1.2041 - val_acc: 0.5000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1231 - acc: 1.0000 - val_loss: 1.2156 - val_acc: 0.5000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1188 - acc: 1.0000 - val_loss: 1.2128 - val_acc: 0.5000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1181 - acc: 1.0000 - val_loss: 1.2074 - val_acc: 0.5000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1202 - acc: 1.0000 - val_loss: 1.2043 - val_acc: 0.5000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1548 - acc: 1.0000 - val_loss: 1.1981 - val_acc: 0.5000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1390 - acc: 1.0000 - val_loss: 1.1907 - val_acc: 0.5000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1194 - acc: 1.0000 - val_loss: 1.1858 - val_acc: 0.5000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1171 - acc: 1.0000 - val_loss: 1.1819 - val_acc: 0.5000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1255 - acc: 1.0000 - val_loss: 1.1769 - val_acc: 0.5000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1105 - acc: 1.0000 - val_loss: 1.1722 - val_acc: 0.5000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1078 - acc: 1.0000 - val_loss: 1.1701 - val_acc: 0.5000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1272 - acc: 1.0000 - val_loss: 1.1693 - val_acc: 0.5000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1144 - acc: 1.0000 - val_loss: 1.1690 - val_acc: 0.5000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1132 - acc: 1.0000 - val_loss: 1.1723 - val_acc: 0.5000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1137 - acc: 1.0000 - val_loss: 1.1776 - val_acc: 0.5000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1191 - acc: 1.0000 - val_loss: 1.1870 - val_acc: 0.5000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1029 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.5000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1294 - acc: 1.0000 - val_loss: 1.1982 - val_acc: 0.5000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1166 - acc: 1.0000 - val_loss: 1.2056 - val_acc: 0.5000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1097 - acc: 1.0000 - val_loss: 1.2123 - val_acc: 0.5000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1093 - acc: 1.0000 - val_loss: 1.2145 - val_acc: 0.5000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1157 - acc: 1.0000 - val_loss: 1.2169 - val_acc: 0.5000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1071 - acc: 1.0000 - val_loss: 1.2203 - val_acc: 0.5000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1098 - acc: 1.0000 - val_loss: 1.2280 - val_acc: 0.5000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1153 - acc: 1.0000 - val_loss: 1.2388 - val_acc: 0.5000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1122 - acc: 1.0000 - val_loss: 1.2524 - val_acc: 0.5000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1118 - acc: 1.0000 - val_loss: 1.2647 - val_acc: 0.5000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1147 - acc: 1.0000 - val_loss: 1.2694 - val_acc: 0.5000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1118 - acc: 1.0000 - val_loss: 1.2744 - val_acc: 0.5000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1043 - acc: 1.0000 - val_loss: 1.2764 - val_acc: 0.5000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1076 - acc: 1.0000 - val_loss: 1.2765 - val_acc: 0.5000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1119 - acc: 1.0000 - val_loss: 1.2769 - val_acc: 0.5000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1041 - acc: 1.0000 - val_loss: 1.2767 - val_acc: 0.5000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1049 - acc: 1.0000 - val_loss: 1.2719 - val_acc: 0.5000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0980 - acc: 1.0000 - val_loss: 1.2589 - val_acc: 0.5000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1089 - acc: 1.0000 - val_loss: 1.2435 - val_acc: 0.5000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1095 - acc: 1.0000 - val_loss: 1.2297 - val_acc: 0.5000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0967 - acc: 1.0000 - val_loss: 1.2154 - val_acc: 0.5000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1121 - acc: 1.0000 - val_loss: 1.2063 - val_acc: 0.5000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1003 - acc: 1.0000 - val_loss: 1.2029 - val_acc: 0.5000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1142 - acc: 1.0000 - val_loss: 1.2029 - val_acc: 0.5000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1111 - acc: 1.0000 - val_loss: 1.2028 - val_acc: 0.5000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0957 - acc: 1.0000 - val_loss: 1.2022 - val_acc: 0.5000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1014 - acc: 1.0000 - val_loss: 1.2066 - val_acc: 0.5000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1392 - acc: 0.9844 - val_loss: 1.2085 - val_acc: 0.5000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1020 - acc: 1.0000 - val_loss: 1.2122 - val_acc: 0.5000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0959 - acc: 1.0000 - val_loss: 1.2159 - val_acc: 0.5000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0926 - acc: 1.0000 - val_loss: 1.2256 - val_acc: 0.5000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1073 - acc: 1.0000 - val_loss: 1.2319 - val_acc: 0.5000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1072 - acc: 1.0000 - val_loss: 1.2439 - val_acc: 0.5000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0906 - acc: 1.0000 - val_loss: 1.2508 - val_acc: 0.5000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1149 - acc: 1.0000 - val_loss: 1.2546 - val_acc: 0.5000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0937 - acc: 1.0000 - val_loss: 1.2585 - val_acc: 0.5000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1106 - acc: 1.0000 - val_loss: 1.2635 - val_acc: 0.5000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1184 - acc: 1.0000 - val_loss: 1.2686 - val_acc: 0.5000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0990 - acc: 1.0000 - val_loss: 1.2727 - val_acc: 0.5000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0940 - acc: 1.0000 - val_loss: 1.2760 - val_acc: 0.5000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1029 - acc: 1.0000 - val_loss: 1.2733 - val_acc: 0.5000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0947 - acc: 1.0000 - val_loss: 1.2664 - val_acc: 0.5000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0926 - acc: 1.0000 - val_loss: 1.2587 - val_acc: 0.5000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0925 - acc: 1.0000 - val_loss: 1.2475 - val_acc: 0.5000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1130 - acc: 1.0000 - val_loss: 1.2416 - val_acc: 0.5000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1019 - acc: 1.0000 - val_loss: 1.2372 - val_acc: 0.5000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0917 - acc: 1.0000 - val_loss: 1.2364 - val_acc: 0.5000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0963 - acc: 1.0000 - val_loss: 1.2387 - val_acc: 0.5000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1026 - acc: 1.0000 - val_loss: 1.2394 - val_acc: 0.5000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0885 - acc: 1.0000 - val_loss: 1.2403 - val_acc: 0.5000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1146 - acc: 1.0000 - val_loss: 1.2431 - val_acc: 0.5000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0899 - acc: 1.0000 - val_loss: 1.2498 - val_acc: 0.5000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0994 - acc: 1.0000 - val_loss: 1.2548 - val_acc: 0.5000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1009 - acc: 1.0000 - val_loss: 1.2592 - val_acc: 0.5000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0946 - acc: 1.0000 - val_loss: 1.2645 - val_acc: 0.5000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0863 - acc: 1.0000 - val_loss: 1.2704 - val_acc: 0.5000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1036 - acc: 1.0000 - val_loss: 1.2779 - val_acc: 0.5000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0958 - acc: 1.0000 - val_loss: 1.2834 - val_acc: 0.5000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0958 - acc: 1.0000 - val_loss: 1.2849 - val_acc: 0.5000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0834 - acc: 1.0000 - val_loss: 1.2836 - val_acc: 0.5000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1135 - acc: 1.0000 - val_loss: 1.2831 - val_acc: 0.5000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0885 - acc: 1.0000 - val_loss: 1.2810 - val_acc: 0.5000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0814 - acc: 1.0000 - val_loss: 1.2772 - val_acc: 0.5000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0919 - acc: 1.0000 - val_loss: 1.2742 - val_acc: 0.5000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0896 - acc: 1.0000 - val_loss: 1.2715 - val_acc: 0.5000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0790 - acc: 1.0000 - val_loss: 1.2704 - val_acc: 0.5000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0964 - acc: 1.0000 - val_loss: 1.2670 - val_acc: 0.5000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0849 - acc: 1.0000 - val_loss: 1.2704 - val_acc: 0.5000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1040 - acc: 1.0000 - val_loss: 1.2731 - val_acc: 0.5000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0920 - acc: 1.0000 - val_loss: 1.2786 - val_acc: 0.5000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0873 - acc: 1.0000 - val_loss: 1.2849 - val_acc: 0.5000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0841 - acc: 1.0000 - val_loss: 1.2893 - val_acc: 0.5000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0816 - acc: 1.0000 - val_loss: 1.2953 - val_acc: 0.5000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0731 - acc: 1.0000 - val_loss: 1.3021 - val_acc: 0.5000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0773 - acc: 1.0000 - val_loss: 1.3023 - val_acc: 0.5000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0901 - acc: 1.0000 - val_loss: 1.3063 - val_acc: 0.5000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0960 - acc: 1.0000 - val_loss: 1.3116 - val_acc: 0.5000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0841 - acc: 1.0000 - val_loss: 1.3203 - val_acc: 0.5000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0908 - acc: 1.0000 - val_loss: 1.3305 - val_acc: 0.5000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0952 - acc: 1.0000 - val_loss: 1.3466 - val_acc: 0.5000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0834 - acc: 1.0000 - val_loss: 1.3600 - val_acc: 0.5000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0791 - acc: 1.0000 - val_loss: 1.3680 - val_acc: 0.5000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0773 - acc: 1.0000 - val_loss: 1.3741 - val_acc: 0.5000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0734 - acc: 1.0000 - val_loss: 1.3807 - val_acc: 0.5000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0873 - acc: 1.0000 - val_loss: 1.3853 - val_acc: 0.5000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0910 - acc: 1.0000 - val_loss: 1.3827 - val_acc: 0.5000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0818 - acc: 1.0000 - val_loss: 1.3813 - val_acc: 0.5000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0856 - acc: 1.0000 - val_loss: 1.3740 - val_acc: 0.5000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0780 - acc: 1.0000 - val_loss: 1.3676 - val_acc: 0.5000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0785 - acc: 1.0000 - val_loss: 1.3619 - val_acc: 0.5000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0867 - acc: 1.0000 - val_loss: 1.3508 - val_acc: 0.5000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0762 - acc: 1.0000 - val_loss: 1.3402 - val_acc: 0.5000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0835 - acc: 1.0000 - val_loss: 1.3328 - val_acc: 0.5000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0737 - acc: 1.0000 - val_loss: 1.3362 - val_acc: 0.5000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0827 - acc: 1.0000 - val_loss: 1.3419 - val_acc: 0.5000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0734 - acc: 1.0000 - val_loss: 1.3451 - val_acc: 0.5000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0826 - acc: 1.0000 - val_loss: 1.3395 - val_acc: 0.5000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0802 - acc: 1.0000 - val_loss: 1.3425 - val_acc: 0.5000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0787 - acc: 1.0000 - val_loss: 1.3446 - val_acc: 0.5000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1094 - acc: 0.9844 - val_loss: 1.3484 - val_acc: 0.5000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0764 - acc: 1.0000 - val_loss: 1.3514 - val_acc: 0.5000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0724 - acc: 1.0000 - val_loss: 1.3569 - val_acc: 0.5000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0919 - acc: 1.0000 - val_loss: 1.3606 - val_acc: 0.5000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0699 - acc: 1.0000 - val_loss: 1.3575 - val_acc: 0.5000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0744 - acc: 1.0000 - val_loss: 1.3577 - val_acc: 0.5000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0819 - acc: 1.0000 - val_loss: 1.3600 - val_acc: 0.5000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0802 - acc: 1.0000 - val_loss: 1.3607 - val_acc: 0.5000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0850 - acc: 1.0000 - val_loss: 1.3591 - val_acc: 0.5000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1150 - acc: 0.9844 - val_loss: 1.3509 - val_acc: 0.5000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0696 - acc: 1.0000 - val_loss: 1.3442 - val_acc: 0.5000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0781 - acc: 1.0000 - val_loss: 1.3394 - val_acc: 0.5000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0814 - acc: 1.0000 - val_loss: 1.3394 - val_acc: 0.5000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0719 - acc: 1.0000 - val_loss: 1.3507 - val_acc: 0.5000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0894 - acc: 1.0000 - val_loss: 1.3764 - val_acc: 0.5000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.1037 - acc: 0.9844 - val_loss: 1.4036 - val_acc: 0.5000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0753 - acc: 1.0000 - val_loss: 1.4343 - val_acc: 0.5000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0839 - acc: 1.0000 - val_loss: 1.4537 - val_acc: 0.5000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0729 - acc: 1.0000 - val_loss: 1.4643 - val_acc: 0.5000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0838 - acc: 1.0000 - val_loss: 1.4737 - val_acc: 0.5000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0702 - acc: 1.0000 - val_loss: 1.4818 - val_acc: 0.5000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0786 - acc: 1.0000 - val_loss: 1.4873 - val_acc: 0.5000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0722 - acc: 1.0000 - val_loss: 1.4822 - val_acc: 0.5000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0838 - acc: 1.0000 - val_loss: 1.4778 - val_acc: 0.5000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0695 - acc: 1.0000 - val_loss: 1.4625 - val_acc: 0.5000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0838 - acc: 1.0000 - val_loss: 1.4669 - val_acc: 0.5000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0768 - acc: 1.0000 - val_loss: 1.4673 - val_acc: 0.5000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0728 - acc: 1.0000 - val_loss: 1.4640 - val_acc: 0.5000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0724 - acc: 1.0000 - val_loss: 1.4560 - val_acc: 0.5000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0741 - acc: 1.0000 - val_loss: 1.4465 - val_acc: 0.5000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0740 - acc: 1.0000 - val_loss: 1.4375 - val_acc: 0.5000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0702 - acc: 1.0000 - val_loss: 1.4261 - val_acc: 0.5000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0641 - acc: 1.0000 - val_loss: 1.4197 - val_acc: 0.5000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0788 - acc: 1.0000 - val_loss: 1.4213 - val_acc: 0.5000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0970 - acc: 1.0000 - val_loss: 1.4200 - val_acc: 0.5000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0670 - acc: 1.0000 - val_loss: 1.4289 - val_acc: 0.5000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1264 - acc: 0.9844 - val_loss: 1.4449 - val_acc: 0.5000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0743 - acc: 1.0000 - val_loss: 1.4596 - val_acc: 0.5000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0743 - acc: 1.0000 - val_loss: 1.4688 - val_acc: 0.5000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0669 - acc: 1.0000 - val_loss: 1.4740 - val_acc: 0.5000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0737 - acc: 1.0000 - val_loss: 1.4793 - val_acc: 0.5000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0997 - acc: 1.0000 - val_loss: 1.4806 - val_acc: 0.5000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0710 - acc: 1.0000 - val_loss: 1.4813 - val_acc: 0.5000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0748 - acc: 1.0000 - val_loss: 1.4756 - val_acc: 0.5000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0763 - acc: 1.0000 - val_loss: 1.4748 - val_acc: 0.5000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0697 - acc: 1.0000 - val_loss: 1.4733 - val_acc: 0.5000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0707 - acc: 1.0000 - val_loss: 1.4671 - val_acc: 0.5000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0719 - acc: 1.0000 - val_loss: 1.4655 - val_acc: 0.5000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0644 - acc: 1.0000 - val_loss: 1.4716 - val_acc: 0.5000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0715 - acc: 1.0000 - val_loss: 1.4782 - val_acc: 0.5000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0675 - acc: 1.0000 - val_loss: 1.4887 - val_acc: 0.5000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0671 - acc: 1.0000 - val_loss: 1.4941 - val_acc: 0.5000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0639 - acc: 1.0000 - val_loss: 1.5016 - val_acc: 0.5000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0650 - acc: 1.0000 - val_loss: 1.5099 - val_acc: 0.5000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0649 - acc: 1.0000 - val_loss: 1.5179 - val_acc: 0.5000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0661 - acc: 1.0000 - val_loss: 1.5190 - val_acc: 0.5000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0674 - acc: 1.0000 - val_loss: 1.5162 - val_acc: 0.5000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0762 - acc: 1.0000 - val_loss: 1.5158 - val_acc: 0.5000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0644 - acc: 1.0000 - val_loss: 1.5172 - val_acc: 0.5000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0653 - acc: 1.0000 - val_loss: 1.5200 - val_acc: 0.5000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0642 - acc: 1.0000 - val_loss: 1.5248 - val_acc: 0.5000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0695 - acc: 1.0000 - val_loss: 1.5354 - val_acc: 0.5000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0627 - acc: 1.0000 - val_loss: 1.5438 - val_acc: 0.5000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0645 - acc: 1.0000 - val_loss: 1.5530 - val_acc: 0.5000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0605 - acc: 1.0000 - val_loss: 1.5525 - val_acc: 0.5000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0629 - acc: 1.0000 - val_loss: 1.5550 - val_acc: 0.5000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0660 - acc: 1.0000 - val_loss: 1.5649 - val_acc: 0.5000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0648 - acc: 1.0000 - val_loss: 1.5779 - val_acc: 0.5000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0665 - acc: 1.0000 - val_loss: 1.5946 - val_acc: 0.5000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0538 - acc: 1.0000 - val_loss: 1.6020 - val_acc: 0.5000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0642 - acc: 1.0000 - val_loss: 1.6081 - val_acc: 0.5000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0690 - acc: 1.0000 - val_loss: 1.6073 - val_acc: 0.5000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0678 - acc: 1.0000 - val_loss: 1.6142 - val_acc: 0.5000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0574 - acc: 1.0000 - val_loss: 1.6170 - val_acc: 0.5000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0627 - acc: 1.0000 - val_loss: 1.6183 - val_acc: 0.5000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0682 - acc: 1.0000 - val_loss: 1.6273 - val_acc: 0.5000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0582 - acc: 1.0000 - val_loss: 1.6340 - val_acc: 0.5000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0585 - acc: 1.0000 - val_loss: 1.6396 - val_acc: 0.5000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0652 - acc: 1.0000 - val_loss: 1.6438 - val_acc: 0.5000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0680 - acc: 1.0000 - val_loss: 1.6512 - val_acc: 0.5000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0617 - acc: 1.0000 - val_loss: 1.6419 - val_acc: 0.5000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0679 - acc: 1.0000 - val_loss: 1.6305 - val_acc: 0.5000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0627 - acc: 1.0000 - val_loss: 1.6107 - val_acc: 0.5000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0680 - acc: 1.0000 - val_loss: 1.5995 - val_acc: 0.5000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0613 - acc: 1.0000 - val_loss: 1.5887 - val_acc: 0.5000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0662 - acc: 1.0000 - val_loss: 1.5834 - val_acc: 0.5000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0631 - acc: 1.0000 - val_loss: 1.5734 - val_acc: 0.5000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0593 - acc: 1.0000 - val_loss: 1.5674 - val_acc: 0.5000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0714 - acc: 1.0000 - val_loss: 1.5569 - val_acc: 0.5000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0690 - acc: 1.0000 - val_loss: 1.5553 - val_acc: 0.5000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0545 - acc: 1.0000 - val_loss: 1.5624 - val_acc: 0.5000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0557 - acc: 1.0000 - val_loss: 1.5718 - val_acc: 0.5000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0645 - acc: 1.0000 - val_loss: 1.5812 - val_acc: 0.5000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0559 - acc: 1.0000 - val_loss: 1.5931 - val_acc: 0.5000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0581 - acc: 1.0000 - val_loss: 1.6147 - val_acc: 0.5000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0570 - acc: 1.0000 - val_loss: 1.6330 - val_acc: 0.5000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0740 - acc: 1.0000 - val_loss: 1.6531 - val_acc: 0.5000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0610 - acc: 1.0000 - val_loss: 1.6720 - val_acc: 0.5000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0621 - acc: 1.0000 - val_loss: 1.6872 - val_acc: 0.5000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0581 - acc: 1.0000 - val_loss: 1.6976 - val_acc: 0.5000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0543 - acc: 1.0000 - val_loss: 1.7015 - val_acc: 0.5000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0526 - acc: 1.0000 - val_loss: 1.7046 - val_acc: 0.5000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0567 - acc: 1.0000 - val_loss: 1.6963 - val_acc: 0.5000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0523 - acc: 1.0000 - val_loss: 1.6843 - val_acc: 0.5000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0637 - acc: 1.0000 - val_loss: 1.6744 - val_acc: 0.5000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0592 - acc: 1.0000 - val_loss: 1.6659 - val_acc: 0.5000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0616 - acc: 1.0000 - val_loss: 1.6628 - val_acc: 0.5000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0686 - acc: 1.0000 - val_loss: 1.6580 - val_acc: 0.5000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0491 - acc: 1.0000 - val_loss: 1.6538 - val_acc: 0.5000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0542 - acc: 1.0000 - val_loss: 1.6464 - val_acc: 0.5000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0603 - acc: 1.0000 - val_loss: 1.6376 - val_acc: 0.5000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0547 - acc: 1.0000 - val_loss: 1.6266 - val_acc: 0.5000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0586 - acc: 1.0000 - val_loss: 1.6184 - val_acc: 0.5000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0496 - acc: 1.0000 - val_loss: 1.6128 - val_acc: 0.5000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0641 - acc: 1.0000 - val_loss: 1.6068 - val_acc: 0.5000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0591 - acc: 1.0000 - val_loss: 1.6043 - val_acc: 0.5000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0516 - acc: 1.0000 - val_loss: 1.6023 - val_acc: 0.5000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0609 - acc: 1.0000 - val_loss: 1.5983 - val_acc: 0.5000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0611 - acc: 1.0000 - val_loss: 1.5989 - val_acc: 0.5000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0772 - acc: 1.0000 - val_loss: 1.6010 - val_acc: 0.5000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.6084 - val_acc: 0.5000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0592 - acc: 1.0000 - val_loss: 1.6156 - val_acc: 0.5000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0511 - acc: 1.0000 - val_loss: 1.6296 - val_acc: 0.5000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1149 - acc: 0.9844 - val_loss: 1.6292 - val_acc: 0.5000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0532 - acc: 1.0000 - val_loss: 1.6345 - val_acc: 0.5000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0526 - acc: 1.0000 - val_loss: 1.6397 - val_acc: 0.5000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0506 - acc: 1.0000 - val_loss: 1.6509 - val_acc: 0.5000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0602 - acc: 1.0000 - val_loss: 1.6647 - val_acc: 0.5000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0810 - acc: 1.0000 - val_loss: 1.6652 - val_acc: 0.5000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0939 - acc: 0.9844 - val_loss: 1.6749 - val_acc: 0.5000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0515 - acc: 1.0000 - val_loss: 1.6779 - val_acc: 0.5000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0583 - acc: 1.0000 - val_loss: 1.6741 - val_acc: 0.5000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0622 - acc: 1.0000 - val_loss: 1.6698 - val_acc: 0.5000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0522 - acc: 1.0000 - val_loss: 1.6519 - val_acc: 0.5000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0558 - acc: 1.0000 - val_loss: 1.6309 - val_acc: 0.5000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0514 - acc: 1.0000 - val_loss: 1.6089 - val_acc: 0.5000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0530 - acc: 1.0000 - val_loss: 1.5864 - val_acc: 0.5000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0481 - acc: 1.0000 - val_loss: 1.5685 - val_acc: 0.5000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0548 - acc: 1.0000 - val_loss: 1.5553 - val_acc: 0.5000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0449 - acc: 1.0000 - val_loss: 1.5472 - val_acc: 0.5000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.1070 - acc: 0.9844 - val_loss: 1.5525 - val_acc: 0.5000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0494 - acc: 1.0000 - val_loss: 1.5602 - val_acc: 0.5000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0565 - acc: 1.0000 - val_loss: 1.5687 - val_acc: 0.5000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0497 - acc: 1.0000 - val_loss: 1.5924 - val_acc: 0.5000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 22s 22s/step - loss: 0.0537 - acc: 1.0000 - val_loss: 1.6175 - val_acc: 0.5000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0547 - acc: 1.0000 - val_loss: 1.6495 - val_acc: 0.5000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0658 - acc: 1.0000 - val_loss: 1.6828 - val_acc: 0.5000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0529 - acc: 1.0000 - val_loss: 1.7095 - val_acc: 0.5000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0498 - acc: 1.0000 - val_loss: 1.7346 - val_acc: 0.5000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0529 - acc: 1.0000 - val_loss: 1.7512 - val_acc: 0.5000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0470 - acc: 1.0000 - val_loss: 1.7569 - val_acc: 0.5000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0443 - acc: 1.0000 - val_loss: 1.7474 - val_acc: 0.5000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0519 - acc: 1.0000 - val_loss: 1.7347 - val_acc: 0.5000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0485 - acc: 1.0000 - val_loss: 1.7149 - val_acc: 0.5000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0583 - acc: 1.0000 - val_loss: 1.6868 - val_acc: 0.5000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0560 - acc: 1.0000 - val_loss: 1.6613 - val_acc: 0.5000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0539 - acc: 1.0000 - val_loss: 1.6347 - val_acc: 0.5000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0457 - acc: 1.0000 - val_loss: 1.6133 - val_acc: 0.5000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0442 - acc: 1.0000 - val_loss: 1.5968 - val_acc: 0.5000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0521 - acc: 1.0000 - val_loss: 1.5870 - val_acc: 0.5000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0525 - acc: 1.0000 - val_loss: 1.5807 - val_acc: 0.5000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0473 - acc: 1.0000 - val_loss: 1.5763 - val_acc: 0.5000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0566 - acc: 1.0000 - val_loss: 1.5791 - val_acc: 0.5000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0487 - acc: 1.0000 - val_loss: 1.5800 - val_acc: 0.5000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0477 - acc: 1.0000 - val_loss: 1.5790 - val_acc: 0.5000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0466 - acc: 1.0000 - val_loss: 1.5792 - val_acc: 0.5000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0502 - acc: 1.0000 - val_loss: 1.5815 - val_acc: 0.5000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0452 - acc: 1.0000 - val_loss: 1.5857 - val_acc: 0.5000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0520 - acc: 1.0000 - val_loss: 1.5881 - val_acc: 0.5000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0440 - acc: 1.0000 - val_loss: 1.5893 - val_acc: 0.5000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0412 - acc: 1.0000 - val_loss: 1.5931 - val_acc: 0.5000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0531 - acc: 1.0000 - val_loss: 1.6003 - val_acc: 0.5000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0558 - acc: 1.0000 - val_loss: 1.6037 - val_acc: 0.5000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0428 - acc: 1.0000 - val_loss: 1.6103 - val_acc: 0.5000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0530 - acc: 1.0000 - val_loss: 1.6107 - val_acc: 0.5000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 23s 23s/step - loss: 0.0511 - acc: 1.0000 - val_loss: 1.6132 - val_acc: 0.5000\n",
            "Runtime : 11254.704264 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAMECAYAAABqtvueAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gy4zg_iEyept",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "PyErI2SYBeqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1258
        },
        "outputId": "a7ec9a30-6cd2-47a0-f8fc-44a9e193a0b7"
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(64, 64, 1))  \n",
        "\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same', name='encoded')(x)\n",
        "\n",
        "encoder = Model(input_img,encoded)\n",
        "encoder.summary()\n",
        "\n",
        "latent_inputs = Input(shape=(512,))\n",
        "r = Dense(8*8*8, activation='relu')(latent_inputs)\n",
        "r = Reshape(target_shape=(8,8,8))(r)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(r)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='output')(x)\n",
        "\n",
        "decoder = Model(latent_inputs,decoded)\n",
        "\n",
        "decoder.summary()\n",
        "\n",
        "\n",
        "output = decoder(encoder(input_img))\n",
        "autoencoder = Model(input_img, output)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy',metrics=['accuracy'])\n",
        "autoencoder.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "encoded (MaxPooling2D)       (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 1,572,480\n",
            "Trainable params: 1,572,480\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2 (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "output (Conv2D)              (None, 64, 64, 1)         145       \n",
            "=================================================================\n",
            "Total params: 265,137\n",
            "Trainable params: 265,137\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "model_7 (Model)              (None, 1, 1, 512)         1572480   \n",
            "_________________________________________________________________\n",
            "model_8 (Model)              (None, 64, 64, 1)         265137    \n",
            "=================================================================\n",
            "Total params: 1,837,617\n",
            "Trainable params: 1,837,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AxFLdbS3bBtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "735470df-cdb7-4519-d1c0-43d93204ab9f"
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(autoencoder, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"221pt\" viewBox=\"0.00 0.00 316.00 221.00\" width=\"316pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 312,-217 312,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140023510062640 -->\n<g class=\"node\" id=\"node1\">\n<title>140023510062640</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 308,-212.5 308,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-185.8\">input_5: InputLayer</text>\n<polyline fill=\"none\" points=\"133,-166.5 133,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"133,-189.5 191,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"191,-166.5 191,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-197.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"191,-189.5 308,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-174.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023509570672 -->\n<g class=\"node\" id=\"node2\">\n<title>140023509570672</title>\n<polygon fill=\"none\" points=\"10,-83.5 10,-129.5 298,-129.5 298,-83.5 10,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-102.8\">model_7: Model</text>\n<polyline fill=\"none\" points=\"123,-83.5 123,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"123,-106.5 181,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"181,-83.5 181,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-114.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"181,-106.5 298,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-91.3\">(None, 1, 1, 512)</text>\n</g>\n<!-- 140023510062640&#45;&gt;140023509570672 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140023510062640-&gt;140023509570672</title>\n<path d=\"M154,-166.3799C154,-158.1745 154,-148.7679 154,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"157.5001,-139.784 154,-129.784 150.5001,-139.784 157.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023508826432 -->\n<g class=\"node\" id=\"node3\">\n<title>140023508826432</title>\n<polygon fill=\"none\" points=\"10,-.5 10,-46.5 298,-46.5 298,-.5 10,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66.5\" y=\"-19.8\">model_8: Model</text>\n<polyline fill=\"none\" points=\"123,-.5 123,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"123,-23.5 181,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"181,-.5 181,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-31.3\">multiple</text>\n<polyline fill=\"none\" points=\"181,-23.5 298,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-8.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023509570672&#45;&gt;140023508826432 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140023509570672-&gt;140023508826432</title>\n<path d=\"M154,-83.3799C154,-75.1745 154,-65.7679 154,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"157.5001,-56.784 154,-46.784 150.5001,-56.784 157.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "rWhi_aRVbuBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1422
        },
        "outputId": "b931e707-c38a-4923-dcf5-5d28396a6ce8"
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(encoder, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"1051pt\" viewBox=\"0.00 0.00 420.00 1051.00\" width=\"420pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1047)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1047 416,-1047 416,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140023510062640 -->\n<g class=\"node\" id=\"node1\">\n<title>140023510062640</title>\n<polygon fill=\"none\" points=\"52,-996.5 52,-1042.5 360,-1042.5 360,-996.5 52,-996.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-1015.8\">input_5: InputLayer</text>\n<polyline fill=\"none\" points=\"185,-996.5 185,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-1027.3\">input:</text>\n<polyline fill=\"none\" points=\"185,-1019.5 243,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-1004.3\">output:</text>\n<polyline fill=\"none\" points=\"243,-996.5 243,-1042.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-1027.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"243,-1019.5 360,-1019.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301.5\" y=\"-1004.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023510062584 -->\n<g class=\"node\" id=\"node2\">\n<title>140023510062584</title>\n<polygon fill=\"none\" points=\"44.5,-913.5 44.5,-959.5 367.5,-959.5 367.5,-913.5 44.5,-913.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-932.8\">conv2d_24: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-913.5 184.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-944.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-936.5 242.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-921.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-913.5 242.5,-959.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-944.3\">(None, 64, 64, 1)</text>\n<polyline fill=\"none\" points=\"242.5,-936.5 367.5,-936.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-921.3\">(None, 64, 64, 16)</text>\n</g>\n<!-- 140023510062640&#45;&gt;140023510062584 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140023510062640-&gt;140023510062584</title>\n<path d=\"M206,-996.3799C206,-988.1745 206,-978.7679 206,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-969.784 206,-959.784 202.5001,-969.784 209.5001,-969.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510063480 -->\n<g class=\"node\" id=\"node3\">\n<title>140023510063480</title>\n<polygon fill=\"none\" points=\"0,-830.5 0,-876.5 412,-876.5 412,-830.5 0,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-849.8\">max_pooling2d_15: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"229,-830.5 229,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"229,-853.5 287,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"287,-830.5 287,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-861.3\">(None, 64, 64, 16)</text>\n<polyline fill=\"none\" points=\"287,-853.5 412,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-838.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 140023510062584&#45;&gt;140023510063480 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140023510062584-&gt;140023510063480</title>\n<path d=\"M206,-913.3799C206,-905.1745 206,-895.7679 206,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-886.784 206,-876.784 202.5001,-886.784 209.5001,-886.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510063648 -->\n<g class=\"node\" id=\"node4\">\n<title>140023510063648</title>\n<polygon fill=\"none\" points=\"44.5,-747.5 44.5,-793.5 367.5,-793.5 367.5,-747.5 44.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-766.8\">conv2d_25: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-747.5 184.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-770.5 242.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-747.5 242.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-778.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"242.5,-770.5 367.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-755.3\">(None, 32, 32, 32)</text>\n</g>\n<!-- 140023510063480&#45;&gt;140023510063648 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140023510063480-&gt;140023510063648</title>\n<path d=\"M206,-830.3799C206,-822.1745 206,-812.7679 206,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-803.784 206,-793.784 202.5001,-803.784 209.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510063368 -->\n<g class=\"node\" id=\"node5\">\n<title>140023510063368</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 412,-710.5 412,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-683.8\">max_pooling2d_16: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"229,-664.5 229,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"229,-687.5 287,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"287,-664.5 287,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-695.3\">(None, 32, 32, 32)</text>\n<polyline fill=\"none\" points=\"287,-687.5 412,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-672.3\">(None, 16, 16, 32)</text>\n</g>\n<!-- 140023510063648&#45;&gt;140023510063368 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140023510063648-&gt;140023510063368</title>\n<path d=\"M206,-747.3799C206,-739.1745 206,-729.7679 206,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-720.784 206,-710.784 202.5001,-720.784 209.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510148096 -->\n<g class=\"node\" id=\"node6\">\n<title>140023510148096</title>\n<polygon fill=\"none\" points=\"44.5,-581.5 44.5,-627.5 367.5,-627.5 367.5,-581.5 44.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-600.8\">conv2d_26: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-581.5 184.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-604.5 242.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-581.5 242.5,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-612.3\">(None, 16, 16, 32)</text>\n<polyline fill=\"none\" points=\"242.5,-604.5 367.5,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-589.3\">(None, 16, 16, 64)</text>\n</g>\n<!-- 140023510063368&#45;&gt;140023510148096 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140023510063368-&gt;140023510148096</title>\n<path d=\"M206,-664.3799C206,-656.1745 206,-646.7679 206,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-637.784 206,-627.784 202.5001,-637.784 209.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510148040 -->\n<g class=\"node\" id=\"node7\">\n<title>140023510148040</title>\n<polygon fill=\"none\" points=\"0,-498.5 0,-544.5 412,-544.5 412,-498.5 0,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-517.8\">max_pooling2d_17: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"229,-498.5 229,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"229,-521.5 287,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"287,-498.5 287,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-529.3\">(None, 16, 16, 64)</text>\n<polyline fill=\"none\" points=\"287,-521.5 412,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-506.3\">(None, 8, 8, 64)</text>\n</g>\n<!-- 140023510148096&#45;&gt;140023510148040 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140023510148096-&gt;140023510148040</title>\n<path d=\"M206,-581.3799C206,-573.1745 206,-563.7679 206,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-554.784 206,-544.784 202.5001,-554.784 209.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510269568 -->\n<g class=\"node\" id=\"node8\">\n<title>140023510269568</title>\n<polygon fill=\"none\" points=\"48.5,-415.5 48.5,-461.5 363.5,-461.5 363.5,-415.5 48.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-434.8\">conv2d_27: Conv2D</text>\n<polyline fill=\"none\" points=\"188.5,-415.5 188.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"188.5,-438.5 246.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"246.5,-415.5 246.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-446.3\">(None, 8, 8, 64)</text>\n<polyline fill=\"none\" points=\"246.5,-438.5 363.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-423.3\">(None, 8, 8, 128)</text>\n</g>\n<!-- 140023510148040&#45;&gt;140023510269568 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140023510148040-&gt;140023510269568</title>\n<path d=\"M206,-498.3799C206,-490.1745 206,-480.7679 206,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-471.784 206,-461.784 202.5001,-471.784 209.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023510269904 -->\n<g class=\"node\" id=\"node9\">\n<title>140023510269904</title>\n<polygon fill=\"none\" points=\"4,-332.5 4,-378.5 408,-378.5 408,-332.5 4,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-351.8\">max_pooling2d_18: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"233,-332.5 233,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"233,-355.5 291,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"291,-332.5 291,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-363.3\">(None, 8, 8, 128)</text>\n<polyline fill=\"none\" points=\"291,-355.5 408,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-340.3\">(None, 4, 4, 128)</text>\n</g>\n<!-- 140023510269568&#45;&gt;140023510269904 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140023510269568-&gt;140023510269904</title>\n<path d=\"M206,-415.3799C206,-407.1745 206,-397.7679 206,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-388.784 206,-378.784 202.5001,-388.784 209.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509911984 -->\n<g class=\"node\" id=\"node10\">\n<title>140023509911984</title>\n<polygon fill=\"none\" points=\"48.5,-249.5 48.5,-295.5 363.5,-295.5 363.5,-249.5 48.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-268.8\">conv2d_28: Conv2D</text>\n<polyline fill=\"none\" points=\"188.5,-249.5 188.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"188.5,-272.5 246.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"246.5,-249.5 246.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-280.3\">(None, 4, 4, 128)</text>\n<polyline fill=\"none\" points=\"246.5,-272.5 363.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-257.3\">(None, 4, 4, 256)</text>\n</g>\n<!-- 140023510269904&#45;&gt;140023509911984 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140023510269904-&gt;140023509911984</title>\n<path d=\"M206,-332.3799C206,-324.1745 206,-314.7679 206,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-305.784 206,-295.784 202.5001,-305.784 209.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509911928 -->\n<g class=\"node\" id=\"node11\">\n<title>140023509911928</title>\n<polygon fill=\"none\" points=\"4,-166.5 4,-212.5 408,-212.5 408,-166.5 4,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-185.8\">max_pooling2d_19: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"233,-166.5 233,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"233,-189.5 291,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"262\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"291,-166.5 291,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-197.3\">(None, 4, 4, 256)</text>\n<polyline fill=\"none\" points=\"291,-189.5 408,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.5\" y=\"-174.3\">(None, 2, 2, 256)</text>\n</g>\n<!-- 140023509911984&#45;&gt;140023509911928 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140023509911984-&gt;140023509911928</title>\n<path d=\"M206,-249.3799C206,-241.1745 206,-231.7679 206,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-222.784 206,-212.784 202.5001,-222.784 209.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509570728 -->\n<g class=\"node\" id=\"node12\">\n<title>140023509570728</title>\n<polygon fill=\"none\" points=\"48.5,-83.5 48.5,-129.5 363.5,-129.5 363.5,-83.5 48.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-102.8\">conv2d_29: Conv2D</text>\n<polyline fill=\"none\" points=\"188.5,-83.5 188.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"188.5,-106.5 246.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"217.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"246.5,-83.5 246.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-114.3\">(None, 2, 2, 256)</text>\n<polyline fill=\"none\" points=\"246.5,-106.5 363.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"305\" y=\"-91.3\">(None, 2, 2, 512)</text>\n</g>\n<!-- 140023509911928&#45;&gt;140023509570728 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140023509911928-&gt;140023509570728</title>\n<path d=\"M206,-166.3799C206,-158.1745 206,-148.7679 206,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-139.784 206,-129.784 202.5001,-139.784 209.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509663640 -->\n<g class=\"node\" id=\"node13\">\n<title>140023509663640</title>\n<polygon fill=\"none\" points=\"37.5,-.5 37.5,-46.5 374.5,-46.5 374.5,-.5 37.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118.5\" y=\"-19.8\">encoded: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"199.5,-.5 199.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"199.5,-23.5 257.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"228.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"257.5,-.5 257.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-31.3\">(None, 2, 2, 512)</text>\n<polyline fill=\"none\" points=\"257.5,-23.5 374.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-8.3\">(None, 1, 1, 512)</text>\n</g>\n<!-- 140023509570728&#45;&gt;140023509663640 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140023509570728-&gt;140023509663640</title>\n<path d=\"M206,-83.3799C206,-75.1745 206,-65.7679 206,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"209.5001,-56.784 206,-46.784 202.5001,-56.784 209.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "RaLjtY_Ebump",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1090
        },
        "outputId": "eedc7167-1033-4a96-cb36-752ee0ef9462"
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(decoder, show_layer_names=True, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"802pt\" viewBox=\"0.00 0.00 412.00 802.00\" width=\"412pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-798 408,-798 408,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140023509660560 -->\n<g class=\"node\" id=\"node1\">\n<title>140023509660560</title>\n<polygon fill=\"none\" points=\"63,-747.5 63,-793.5 341,-793.5 341,-747.5 63,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-766.8\">input_6: InputLayer</text>\n<polyline fill=\"none\" points=\"196,-747.5 196,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"196,-770.5 254,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"254,-747.5 254,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-778.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"254,-770.5 341,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"297.5\" y=\"-755.3\">(None, 512)</text>\n</g>\n<!-- 140023509301736 -->\n<g class=\"node\" id=\"node2\">\n<title>140023509301736</title>\n<polygon fill=\"none\" points=\"76,-664.5 76,-710.5 328,-710.5 328,-664.5 76,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-683.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"183,-664.5 183,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"183,-687.5 241,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"241,-664.5 241,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-695.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"241,-687.5 328,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-672.3\">(None, 512)</text>\n</g>\n<!-- 140023509660560&#45;&gt;140023509301736 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140023509660560-&gt;140023509301736</title>\n<path d=\"M202,-747.3799C202,-739.1745 202,-729.7679 202,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-720.784 202,-710.784 198.5001,-720.784 205.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509299944 -->\n<g class=\"node\" id=\"node3\">\n<title>140023509299944</title>\n<polygon fill=\"none\" points=\"57,-581.5 57,-627.5 347,-627.5 347,-581.5 57,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-600.8\">reshape_3: Reshape</text>\n<polyline fill=\"none\" points=\"187,-581.5 187,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"187,-604.5 245,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"245,-581.5 245,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-612.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"245,-604.5 347,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296\" y=\"-589.3\">(None, 8, 8, 8)</text>\n</g>\n<!-- 140023509301736&#45;&gt;140023509299944 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140023509301736-&gt;140023509299944</title>\n<path d=\"M202,-664.3799C202,-656.1745 202,-646.7679 202,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-637.784 202,-627.784 198.5001,-637.784 205.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509301120 -->\n<g class=\"node\" id=\"node4\">\n<title>140023509301120</title>\n<polygon fill=\"none\" points=\"52,-498.5 52,-544.5 352,-544.5 352,-498.5 52,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"122\" y=\"-517.8\">conv2d_30: Conv2D</text>\n<polyline fill=\"none\" points=\"192,-498.5 192,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"192,-521.5 250,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"221\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"250,-498.5 250,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-529.3\">(None, 8, 8, 8)</text>\n<polyline fill=\"none\" points=\"250,-521.5 352,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-506.3\">(None, 8, 8, 8)</text>\n</g>\n<!-- 140023509299944&#45;&gt;140023509301120 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140023509299944-&gt;140023509301120</title>\n<path d=\"M202,-581.3799C202,-573.1745 202,-563.7679 202,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-554.784 202,-544.784 198.5001,-554.784 205.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509302128 -->\n<g class=\"node\" id=\"node5\">\n<title>140023509302128</title>\n<polygon fill=\"none\" points=\"4,-415.5 4,-461.5 400,-461.5 400,-415.5 4,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-434.8\">up_sampling2d_7: UpSampling2D</text>\n<polyline fill=\"none\" points=\"225,-415.5 225,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"225,-438.5 283,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"283,-415.5 283,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-446.3\">(None, 8, 8, 8)</text>\n<polyline fill=\"none\" points=\"283,-438.5 400,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-423.3\">(None, 16, 16, 8)</text>\n</g>\n<!-- 140023509301120&#45;&gt;140023509302128 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140023509301120-&gt;140023509302128</title>\n<path d=\"M202,-498.3799C202,-490.1745 202,-480.7679 202,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-471.784 202,-461.784 198.5001,-471.784 205.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509498008 -->\n<g class=\"node\" id=\"node6\">\n<title>140023509498008</title>\n<polygon fill=\"none\" points=\"44.5,-332.5 44.5,-378.5 359.5,-378.5 359.5,-332.5 44.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-351.8\">conv2d_31: Conv2D</text>\n<polyline fill=\"none\" points=\"184.5,-332.5 184.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"184.5,-355.5 242.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"242.5,-332.5 242.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-363.3\">(None, 16, 16, 8)</text>\n<polyline fill=\"none\" points=\"242.5,-355.5 359.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-340.3\">(None, 16, 16, 8)</text>\n</g>\n<!-- 140023509302128&#45;&gt;140023509498008 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140023509302128-&gt;140023509498008</title>\n<path d=\"M202,-415.3799C202,-407.1745 202,-397.7679 202,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-388.784 202,-378.784 198.5001,-388.784 205.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509399648 -->\n<g class=\"node\" id=\"node7\">\n<title>140023509399648</title>\n<polygon fill=\"none\" points=\"4,-249.5 4,-295.5 400,-295.5 400,-249.5 4,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114.5\" y=\"-268.8\">up_sampling2d_8: UpSampling2D</text>\n<polyline fill=\"none\" points=\"225,-249.5 225,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"225,-272.5 283,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"283,-249.5 283,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-280.3\">(None, 16, 16, 8)</text>\n<polyline fill=\"none\" points=\"283,-272.5 400,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-257.3\">(None, 32, 32, 8)</text>\n</g>\n<!-- 140023509498008&#45;&gt;140023509399648 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140023509498008-&gt;140023509399648</title>\n<path d=\"M202,-332.3799C202,-324.1745 202,-314.7679 202,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-305.784 202,-295.784 198.5001,-305.784 205.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509170384 -->\n<g class=\"node\" id=\"node8\">\n<title>140023509170384</title>\n<polygon fill=\"none\" points=\"40.5,-166.5 40.5,-212.5 363.5,-212.5 363.5,-166.5 40.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-185.8\">conv2d_32: Conv2D</text>\n<polyline fill=\"none\" points=\"180.5,-166.5 180.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"180.5,-189.5 238.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"209.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"238.5,-166.5 238.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-197.3\">(None, 32, 32, 8)</text>\n<polyline fill=\"none\" points=\"238.5,-189.5 363.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"301\" y=\"-174.3\">(None, 32, 32, 16)</text>\n</g>\n<!-- 140023509399648&#45;&gt;140023509170384 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140023509399648-&gt;140023509170384</title>\n<path d=\"M202,-249.3799C202,-241.1745 202,-231.7679 202,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-222.784 202,-212.784 198.5001,-222.784 205.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023509170776 -->\n<g class=\"node\" id=\"node9\">\n<title>140023509170776</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 404,-129.5 404,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-102.8\">up_sampling2d_9: UpSampling2D</text>\n<polyline fill=\"none\" points=\"221,-83.5 221,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"221,-106.5 279,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"279,-83.5 279,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-114.3\">(None, 32, 32, 16)</text>\n<polyline fill=\"none\" points=\"279,-106.5 404,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"341.5\" y=\"-91.3\">(None, 64, 64, 16)</text>\n</g>\n<!-- 140023509170384&#45;&gt;140023509170776 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140023509170384-&gt;140023509170776</title>\n<path d=\"M202,-166.3799C202,-158.1745 202,-148.7679 202,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-139.784 202,-129.784 198.5001,-139.784 205.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140023508824584 -->\n<g class=\"node\" id=\"node10\">\n<title>140023508824584</title>\n<polygon fill=\"none\" points=\"54.5,-.5 54.5,-46.5 349.5,-46.5 349.5,-.5 54.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-19.8\">output: Conv2D</text>\n<polyline fill=\"none\" points=\"166.5,-.5 166.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"166.5,-23.5 224.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"224.5,-.5 224.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287\" y=\"-31.3\">(None, 64, 64, 16)</text>\n<polyline fill=\"none\" points=\"224.5,-23.5 349.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"287\" y=\"-8.3\">(None, 64, 64, 1)</text>\n</g>\n<!-- 140023509170776&#45;&gt;140023508824584 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140023509170776-&gt;140023508824584</title>\n<path d=\"M202,-83.3799C202,-75.1745 202,-65.7679 202,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"205.5001,-56.784 202,-46.784 198.5001,-56.784 205.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "7t9MJN1j0HUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_accuracy(dataset,encoder,threshold=0.6):\n",
        "    left = dataset['val_left']\n",
        "    right = dataset['val_right']\n",
        "    \n",
        "    left_latent = encoder.predict(left/255.0)\n",
        "    right_latent = encoder.predict(right/255.0)\n",
        "    #display(left_latent.shape) , display(right_latent.shape)\n",
        "    op = np.array([cosine_similarity(left_latent[i].reshape(-1,512), right_latent[i].reshape(-1,512))[0][0] for i in range(len(left))])\n",
        "    op = (op-np.min(op))/(np.max(op)-np.min(op))\n",
        "\n",
        "    index = np.where(op>threshold)\n",
        "    pred = np.zeros(len(op))\n",
        "    pred[index] = 1\n",
        "    total = np.sum((pred==dataset['val_target']).astype(int))\n",
        "\n",
        "    return total/len(left)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "znNOE9yRImDu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def shift(arr):\n",
        "    for i in range(len(arr)):\n",
        "        arr[i] = np.roll(arr[i],random.randint(-12,12),axis=0)\n",
        "    return arr\n",
        "\n",
        "def img_generator(data, batch_size):\n",
        "    keys = [*data]\n",
        "    index = np.random.permutation(len(keys))\n",
        "    batch_data = np.zeros((batch_size, 64, 64, 1))\n",
        "    batch_labels = np.zeros((batch_size, 64, 64, 1))\n",
        "    counter = 0\n",
        "    while True:\n",
        "        if counter+batch_size<=len(keys):\n",
        "            batch_index = index[counter:batch_size+counter]\n",
        "            counter+=batch_size\n",
        "            k=0\n",
        "            for i in batch_index:\n",
        "                batch_data[k] = data[keys[i]].astype('float32') /255.\n",
        "                batch_labels[k] = data[keys[i]].astype('float32') /255.\n",
        "                k+=1\n",
        "            yield (batch_data), batch_labels\n",
        "        else:\n",
        "            batch_index = index[counter:]\n",
        "            counter=0\n",
        "            k=0\n",
        "            for i in batch_index:\n",
        "                batch_data[k] = data[keys[i]].astype('float32') /255.\n",
        "                batch_labels[k] = data[keys[i]].astype('float32') /255.\n",
        "                k+=1\n",
        "            yield (batch_data[:k]), batch_labels[:k]\n",
        "            \n",
        "            \n",
        "def img_generator_val(data):\n",
        "    keys = [*data]\n",
        "    batch_labels = np.zeros((len(data), 64, 64, 1))\n",
        "    while True:\n",
        "        for i in range(len(keys)):\n",
        "            batch_labels[i] = data[keys[i]].astype('float32') /255.\n",
        "        yield batch_labels, batch_labels\n",
        "\n",
        "def custom_activation(x):\n",
        "    return K.sigmoid(x)*255\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
        "\n",
        "        \n",
        "def train_encoder(dataset,epochs=1000):\n",
        "    input_img = Input(shape=(64, 64, 1))  # adapt this if using `channels_first` image data format\n",
        "    # x = CoordinateChannel2D()(input_img)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    # x = CoordinateChannel2D()(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    # x = CoordinateChannel2D()(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "    encoded = Flatten()(x)\n",
        "    encoded = Dense(8*8*8, activation='relu', name='latent')(encoded)\n",
        "    encoder = Model(input_img,encoded)\n",
        "\n",
        "    r = Reshape(target_shape=(8,8,8))(encoded)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(r)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = UpSampling2D((2, 2))(x)\n",
        "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='output')(x)\n",
        "\n",
        "\n",
        "    tb_batch_size = 64\n",
        "\n",
        "    tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
        "\n",
        "    autoencoder = Model(input_img, decoded)\n",
        "\n",
        "    autoencoder.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    history = autoencoder.fit_generator(img_generator(dataset['train_imgs'],batch_size=32),\n",
        "                                        epochs=epochs,\n",
        "                                        verbose = 1,\n",
        "                                        steps_per_epoch = 1,\n",
        "                                        validation_data=img_generator_val(dataset['val_imgs']),\n",
        "                                        validation_steps = 1,\n",
        "                                        shuffle= True,\n",
        "                                        callbacks = [tensorboard_cb])\n",
        "\n",
        "    autoencoder.summary()\n",
        "\n",
        "    historydf = pd.DataFrame(history.history)\n",
        "    historydf.plot(subplots=True, grid=True, figsize=(10,15))\n",
        "\n",
        "    n = 10 \n",
        "    plt.figure(figsize=(24, 24))\n",
        "    keys = [*seen_dataset['train_imgs']]\n",
        "    dic = seen_dataset['train_imgs']\n",
        "\n",
        "    for i in range(n):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(dic[keys[i]].reshape((64,64)))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # display reconstruction\n",
        "        ax = plt.subplot(2, n, i + n)\n",
        "        #plt.imshow(autoencoder.predict((dic[keys[i]].astype('float64')).reshape((1,64,64,1))).reshape((64,64)))\n",
        "        plt.imshow(255*autoencoder.predict((dic[keys[i]].astype('float64')/255.).reshape((1,64,64,1))).reshape((64,64)))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "    return encoder, autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jBHZsA5yGBIu",
        "colab_type": "code",
        "outputId": "cb9f28f4-e269-40ee-b1c3-e4fc7da5b95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104399
        }
      },
      "cell_type": "code",
      "source": [
        "seen_encoder,seen_autoencoder = train_encoder(seen_dataset,epochs=3000)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/3000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6885 - val_acc: 0.8392\n",
            "Epoch 2/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6885 - acc: 0.8436 - val_loss: 0.6823 - val_acc: 0.8815\n",
            "Epoch 3/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6826 - acc: 0.8856 - val_loss: 0.6730 - val_acc: 0.8864\n",
            "Epoch 4/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6730 - acc: 0.8882 - val_loss: 0.6596 - val_acc: 0.8880\n",
            "Epoch 5/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6594 - acc: 0.8880 - val_loss: 0.6408 - val_acc: 0.8887\n",
            "Epoch 6/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6404 - acc: 0.8887 - val_loss: 0.6148 - val_acc: 0.8892\n",
            "Epoch 7/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6140 - acc: 0.8856 - val_loss: 0.5801 - val_acc: 0.8893\n",
            "Epoch 8/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5803 - acc: 0.8908 - val_loss: 0.5354 - val_acc: 0.8895\n",
            "Epoch 9/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5348 - acc: 0.8890 - val_loss: 0.4811 - val_acc: 0.8895\n",
            "Epoch 10/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4835 - acc: 0.8952 - val_loss: 0.4195 - val_acc: 0.8895\n",
            "Epoch 11/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4185 - acc: 0.8882 - val_loss: 0.3576 - val_acc: 0.8896\n",
            "Epoch 12/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3558 - acc: 0.8906 - val_loss: 0.3067 - val_acc: 0.8897\n",
            "Epoch 13/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3015 - acc: 0.8877 - val_loss: 0.2789 - val_acc: 0.8899\n",
            "Epoch 14/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2790 - acc: 0.8879 - val_loss: 0.2771 - val_acc: 0.8900\n",
            "Epoch 15/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2801 - acc: 0.8907 - val_loss: 0.2892 - val_acc: 0.8900\n",
            "Epoch 16/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2745 - acc: 0.8942 - val_loss: 0.3002 - val_acc: 0.8900\n",
            "Epoch 17/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3086 - acc: 0.8894 - val_loss: 0.2986 - val_acc: 0.8900\n",
            "Epoch 18/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3068 - acc: 0.8894 - val_loss: 0.2852 - val_acc: 0.8900\n",
            "Epoch 19/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2417 - acc: 0.8991 - val_loss: 0.2675 - val_acc: 0.8900\n",
            "Epoch 20/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2271 - acc: 0.8991 - val_loss: 0.2492 - val_acc: 0.8900\n",
            "Epoch 21/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2972 - acc: 0.8807 - val_loss: 0.2311 - val_acc: 0.8900\n",
            "Epoch 22/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2363 - acc: 0.8866 - val_loss: 0.2182 - val_acc: 0.8900\n",
            "Epoch 23/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2338 - acc: 0.8866 - val_loss: 0.2109 - val_acc: 0.8900\n",
            "Epoch 24/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2124 - acc: 0.8912 - val_loss: 0.2079 - val_acc: 0.8900\n",
            "Epoch 25/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2229 - acc: 0.8856 - val_loss: 0.2078 - val_acc: 0.8900\n",
            "Epoch 26/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2285 - acc: 0.8801 - val_loss: 0.2093 - val_acc: 0.8900\n",
            "Epoch 27/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1976 - acc: 0.8978 - val_loss: 0.2104 - val_acc: 0.8900\n",
            "Epoch 28/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1998 - acc: 0.8978 - val_loss: 0.2098 - val_acc: 0.8899\n",
            "Epoch 29/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2160 - acc: 0.8821 - val_loss: 0.2082 - val_acc: 0.8899\n",
            "Epoch 30/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2043 - acc: 0.8909 - val_loss: 0.2052 - val_acc: 0.8899\n",
            "Epoch 31/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2000 - acc: 0.8896 - val_loss: 0.2016 - val_acc: 0.8899\n",
            "Epoch 32/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1964 - acc: 0.8896 - val_loss: 0.1979 - val_acc: 0.8899\n",
            "Epoch 33/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1913 - acc: 0.8959 - val_loss: 0.1948 - val_acc: 0.8899\n",
            "Epoch 34/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1874 - acc: 0.8959 - val_loss: 0.1929 - val_acc: 0.8899\n",
            "Epoch 35/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1983 - acc: 0.8871 - val_loss: 0.1923 - val_acc: 0.8899\n",
            "Epoch 36/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1830 - acc: 0.8907 - val_loss: 0.1925 - val_acc: 0.8900\n",
            "Epoch 37/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1826 - acc: 0.8907 - val_loss: 0.1929 - val_acc: 0.8900\n",
            "Epoch 38/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1981 - acc: 0.8872 - val_loss: 0.1925 - val_acc: 0.8900\n",
            "Epoch 39/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1979 - acc: 0.8872 - val_loss: 0.1912 - val_acc: 0.8900\n",
            "Epoch 40/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1689 - acc: 0.8991 - val_loss: 0.1897 - val_acc: 0.8900\n",
            "Epoch 41/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1973 - acc: 0.8889 - val_loss: 0.1879 - val_acc: 0.8900\n",
            "Epoch 42/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1946 - acc: 0.8889 - val_loss: 0.1864 - val_acc: 0.8900\n",
            "Epoch 43/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1936 - acc: 0.8886 - val_loss: 0.1855 - val_acc: 0.8900\n",
            "Epoch 44/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2042 - acc: 0.8779 - val_loss: 0.1852 - val_acc: 0.8900\n",
            "Epoch 45/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1981 - acc: 0.8797 - val_loss: 0.1856 - val_acc: 0.8900\n",
            "Epoch 46/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2108 - acc: 0.8802 - val_loss: 0.1864 - val_acc: 0.8900\n",
            "Epoch 47/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2117 - acc: 0.8802 - val_loss: 0.1874 - val_acc: 0.8899\n",
            "Epoch 48/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1756 - acc: 0.8965 - val_loss: 0.1874 - val_acc: 0.8899\n",
            "Epoch 49/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1905 - acc: 0.8859 - val_loss: 0.1865 - val_acc: 0.8899\n",
            "Epoch 50/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2014 - acc: 0.8836 - val_loss: 0.1851 - val_acc: 0.8899\n",
            "Epoch 51/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1768 - acc: 0.8932 - val_loss: 0.1831 - val_acc: 0.8899\n",
            "Epoch 52/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1825 - acc: 0.8937 - val_loss: 0.1810 - val_acc: 0.8900\n",
            "Epoch 53/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1799 - acc: 0.8937 - val_loss: 0.1795 - val_acc: 0.8900\n",
            "Epoch 54/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1777 - acc: 0.8904 - val_loss: 0.1789 - val_acc: 0.8900\n",
            "Epoch 55/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1580 - acc: 0.8999 - val_loss: 0.1794 - val_acc: 0.8900\n",
            "Epoch 56/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1677 - acc: 0.8942 - val_loss: 0.1806 - val_acc: 0.8900\n",
            "Epoch 57/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1729 - acc: 0.8936 - val_loss: 0.1814 - val_acc: 0.8900\n",
            "Epoch 58/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1698 - acc: 0.8936 - val_loss: 0.1814 - val_acc: 0.8900\n",
            "Epoch 59/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1672 - acc: 0.8939 - val_loss: 0.1805 - val_acc: 0.8900\n",
            "Epoch 60/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1920 - acc: 0.8862 - val_loss: 0.1785 - val_acc: 0.8900\n",
            "Epoch 61/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1893 - acc: 0.8862 - val_loss: 0.1764 - val_acc: 0.8900\n",
            "Epoch 62/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1731 - acc: 0.8913 - val_loss: 0.1752 - val_acc: 0.8900\n",
            "Epoch 63/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1883 - acc: 0.8800 - val_loss: 0.1748 - val_acc: 0.8900\n",
            "Epoch 64/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1854 - acc: 0.8819 - val_loss: 0.1755 - val_acc: 0.8900\n",
            "Epoch 65/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1646 - acc: 0.8963 - val_loss: 0.1762 - val_acc: 0.8900\n",
            "Epoch 66/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1957 - acc: 0.8924 - val_loss: 0.1765 - val_acc: 0.8900\n",
            "Epoch 67/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1729 - acc: 0.8893 - val_loss: 0.1763 - val_acc: 0.8900\n",
            "Epoch 68/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1627 - acc: 0.8982 - val_loss: 0.1752 - val_acc: 0.8900\n",
            "Epoch 69/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1790 - acc: 0.8884 - val_loss: 0.1740 - val_acc: 0.8900\n",
            "Epoch 70/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1948 - acc: 0.8827 - val_loss: 0.1730 - val_acc: 0.8900\n",
            "Epoch 71/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1680 - acc: 0.8926 - val_loss: 0.1721 - val_acc: 0.8900\n",
            "Epoch 72/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1904 - acc: 0.8837 - val_loss: 0.1716 - val_acc: 0.8900\n",
            "Epoch 73/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1818 - acc: 0.8837 - val_loss: 0.1713 - val_acc: 0.8900\n",
            "Epoch 74/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2105 - acc: 0.8807 - val_loss: 0.1710 - val_acc: 0.8900\n",
            "Epoch 75/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1551 - acc: 0.8997 - val_loss: 0.1707 - val_acc: 0.8900\n",
            "Epoch 76/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1650 - acc: 0.8968 - val_loss: 0.1705 - val_acc: 0.8900\n",
            "Epoch 77/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1658 - acc: 0.8942 - val_loss: 0.1704 - val_acc: 0.8900\n",
            "Epoch 78/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1801 - acc: 0.8865 - val_loss: 0.1700 - val_acc: 0.8900\n",
            "Epoch 79/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1910 - acc: 0.8858 - val_loss: 0.1695 - val_acc: 0.8900\n",
            "Epoch 80/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1844 - acc: 0.8858 - val_loss: 0.1691 - val_acc: 0.8900\n",
            "Epoch 81/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1840 - acc: 0.8886 - val_loss: 0.1688 - val_acc: 0.8900\n",
            "Epoch 82/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1664 - acc: 0.8903 - val_loss: 0.1687 - val_acc: 0.8900\n",
            "Epoch 83/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1795 - acc: 0.8837 - val_loss: 0.1686 - val_acc: 0.8900\n",
            "Epoch 84/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1635 - acc: 0.8942 - val_loss: 0.1683 - val_acc: 0.8900\n",
            "Epoch 85/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1739 - acc: 0.8885 - val_loss: 0.1679 - val_acc: 0.8900\n",
            "Epoch 86/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1705 - acc: 0.8874 - val_loss: 0.1674 - val_acc: 0.8900\n",
            "Epoch 87/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1639 - acc: 0.8925 - val_loss: 0.1668 - val_acc: 0.8900\n",
            "Epoch 88/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1700 - acc: 0.8893 - val_loss: 0.1663 - val_acc: 0.8900\n",
            "Epoch 89/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1809 - acc: 0.8826 - val_loss: 0.1659 - val_acc: 0.8900\n",
            "Epoch 90/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1695 - acc: 0.8868 - val_loss: 0.1655 - val_acc: 0.8900\n",
            "Epoch 91/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1872 - acc: 0.8895 - val_loss: 0.1652 - val_acc: 0.8900\n",
            "Epoch 92/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1668 - acc: 0.8895 - val_loss: 0.1649 - val_acc: 0.8900\n",
            "Epoch 93/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1548 - acc: 0.8969 - val_loss: 0.1646 - val_acc: 0.8900\n",
            "Epoch 94/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1807 - acc: 0.8864 - val_loss: 0.1642 - val_acc: 0.8900\n",
            "Epoch 95/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1705 - acc: 0.8857 - val_loss: 0.1638 - val_acc: 0.8900\n",
            "Epoch 96/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1567 - acc: 0.8929 - val_loss: 0.1634 - val_acc: 0.8900\n",
            "Epoch 97/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1798 - acc: 0.8828 - val_loss: 0.1630 - val_acc: 0.8900\n",
            "Epoch 98/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1650 - acc: 0.8912 - val_loss: 0.1626 - val_acc: 0.8900\n",
            "Epoch 99/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1605 - acc: 0.8891 - val_loss: 0.1622 - val_acc: 0.8900\n",
            "Epoch 100/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1594 - acc: 0.8937 - val_loss: 0.1619 - val_acc: 0.8900\n",
            "Epoch 101/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1640 - acc: 0.8921 - val_loss: 0.1615 - val_acc: 0.8900\n",
            "Epoch 102/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1679 - acc: 0.8890 - val_loss: 0.1612 - val_acc: 0.8900\n",
            "Epoch 103/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1831 - acc: 0.8911 - val_loss: 0.1610 - val_acc: 0.8900\n",
            "Epoch 104/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1904 - acc: 0.8914 - val_loss: 0.1611 - val_acc: 0.8900\n",
            "Epoch 105/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1750 - acc: 0.8823 - val_loss: 0.1612 - val_acc: 0.8900\n",
            "Epoch 106/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1537 - acc: 0.8911 - val_loss: 0.1612 - val_acc: 0.8900\n",
            "Epoch 107/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1536 - acc: 0.8911 - val_loss: 0.1609 - val_acc: 0.8900\n",
            "Epoch 108/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1680 - acc: 0.8912 - val_loss: 0.1604 - val_acc: 0.8900\n",
            "Epoch 109/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1784 - acc: 0.8790 - val_loss: 0.1600 - val_acc: 0.8900\n",
            "Epoch 110/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1666 - acc: 0.8851 - val_loss: 0.1597 - val_acc: 0.8900\n",
            "Epoch 111/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1542 - acc: 0.8943 - val_loss: 0.1592 - val_acc: 0.8900\n",
            "Epoch 112/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1637 - acc: 0.8938 - val_loss: 0.1588 - val_acc: 0.8900\n",
            "Epoch 113/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1630 - acc: 0.8938 - val_loss: 0.1586 - val_acc: 0.8900\n",
            "Epoch 114/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1529 - acc: 0.8918 - val_loss: 0.1585 - val_acc: 0.8900\n",
            "Epoch 115/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1599 - acc: 0.8888 - val_loss: 0.1581 - val_acc: 0.8900\n",
            "Epoch 116/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1778 - acc: 0.8801 - val_loss: 0.1576 - val_acc: 0.8900\n",
            "Epoch 117/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1717 - acc: 0.8856 - val_loss: 0.1573 - val_acc: 0.8900\n",
            "Epoch 118/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1699 - acc: 0.8837 - val_loss: 0.1574 - val_acc: 0.8900\n",
            "Epoch 119/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1520 - acc: 0.8908 - val_loss: 0.1574 - val_acc: 0.8900\n",
            "Epoch 120/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1519 - acc: 0.8908 - val_loss: 0.1573 - val_acc: 0.8900\n",
            "Epoch 121/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1545 - acc: 0.8909 - val_loss: 0.1570 - val_acc: 0.8900\n",
            "Epoch 122/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1539 - acc: 0.8909 - val_loss: 0.1568 - val_acc: 0.8900\n",
            "Epoch 123/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1512 - acc: 0.8909 - val_loss: 0.1566 - val_acc: 0.8900\n",
            "Epoch 124/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1627 - acc: 0.8887 - val_loss: 0.1560 - val_acc: 0.8900\n",
            "Epoch 125/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1618 - acc: 0.8887 - val_loss: 0.1553 - val_acc: 0.8900\n",
            "Epoch 126/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1660 - acc: 0.8804 - val_loss: 0.1550 - val_acc: 0.8900\n",
            "Epoch 127/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8888 - val_loss: 0.1549 - val_acc: 0.8899\n",
            "Epoch 128/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1546 - acc: 0.8918 - val_loss: 0.1547 - val_acc: 0.8899\n",
            "Epoch 129/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1459 - acc: 0.8995 - val_loss: 0.1544 - val_acc: 0.8899\n",
            "Epoch 130/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1468 - acc: 0.8947 - val_loss: 0.1540 - val_acc: 0.8899\n",
            "Epoch 131/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8958 - val_loss: 0.1536 - val_acc: 0.8899\n",
            "Epoch 132/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1505 - acc: 0.8916 - val_loss: 0.1534 - val_acc: 0.8899\n",
            "Epoch 133/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1660 - acc: 0.8839 - val_loss: 0.1531 - val_acc: 0.8899\n",
            "Epoch 134/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1607 - acc: 0.8867 - val_loss: 0.1529 - val_acc: 0.8899\n",
            "Epoch 135/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1400 - acc: 0.8991 - val_loss: 0.1528 - val_acc: 0.8899\n",
            "Epoch 136/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565 - acc: 0.8918 - val_loss: 0.1526 - val_acc: 0.8899\n",
            "Epoch 137/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1448 - acc: 0.8992 - val_loss: 0.1522 - val_acc: 0.8899\n",
            "Epoch 138/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.9000 - val_loss: 0.1519 - val_acc: 0.8899\n",
            "Epoch 139/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1500 - acc: 0.8881 - val_loss: 0.1515 - val_acc: 0.8899\n",
            "Epoch 140/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1740 - acc: 0.8884 - val_loss: 0.1516 - val_acc: 0.8899\n",
            "Epoch 141/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1490 - acc: 0.8900 - val_loss: 0.1516 - val_acc: 0.8899\n",
            "Epoch 142/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1414 - acc: 0.8967 - val_loss: 0.1514 - val_acc: 0.8900\n",
            "Epoch 143/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1615 - acc: 0.8830 - val_loss: 0.1511 - val_acc: 0.8900\n",
            "Epoch 144/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1600 - acc: 0.8851 - val_loss: 0.1507 - val_acc: 0.8900\n",
            "Epoch 145/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1592 - acc: 0.8851 - val_loss: 0.1505 - val_acc: 0.8899\n",
            "Epoch 146/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1653 - acc: 0.8803 - val_loss: 0.1503 - val_acc: 0.8899\n",
            "Epoch 147/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1643 - acc: 0.8803 - val_loss: 0.1502 - val_acc: 0.8899\n",
            "Epoch 148/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8953 - val_loss: 0.1502 - val_acc: 0.8899\n",
            "Epoch 149/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1617 - acc: 0.8804 - val_loss: 0.1503 - val_acc: 0.8899\n",
            "Epoch 150/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1479 - acc: 0.8913 - val_loss: 0.1500 - val_acc: 0.8899\n",
            "Epoch 151/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1474 - acc: 0.8913 - val_loss: 0.1497 - val_acc: 0.8899\n",
            "Epoch 152/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1586 - acc: 0.8855 - val_loss: 0.1496 - val_acc: 0.8899\n",
            "Epoch 153/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1576 - acc: 0.8855 - val_loss: 0.1496 - val_acc: 0.8899\n",
            "Epoch 154/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1491 - acc: 0.8907 - val_loss: 0.1494 - val_acc: 0.8899\n",
            "Epoch 155/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1459 - acc: 0.8930 - val_loss: 0.1489 - val_acc: 0.8899\n",
            "Epoch 156/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1631 - acc: 0.8818 - val_loss: 0.1484 - val_acc: 0.8899\n",
            "Epoch 157/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8959 - val_loss: 0.1484 - val_acc: 0.8899\n",
            "Epoch 158/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1404 - acc: 0.8940 - val_loss: 0.1481 - val_acc: 0.8899\n",
            "Epoch 159/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1448 - acc: 0.8907 - val_loss: 0.1477 - val_acc: 0.8899\n",
            "Epoch 160/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1763 - acc: 0.8830 - val_loss: 0.1478 - val_acc: 0.8899\n",
            "Epoch 161/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565 - acc: 0.8861 - val_loss: 0.1480 - val_acc: 0.8899\n",
            "Epoch 162/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2005 - acc: 0.8907 - val_loss: 0.1495 - val_acc: 0.8899\n",
            "Epoch 163/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1500 - acc: 0.8912 - val_loss: 0.1499 - val_acc: 0.8899\n",
            "Epoch 164/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1564 - acc: 0.8873 - val_loss: 0.1491 - val_acc: 0.8899\n",
            "Epoch 165/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1633 - acc: 0.8755 - val_loss: 0.1482 - val_acc: 0.8899\n",
            "Epoch 166/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565 - acc: 0.8839 - val_loss: 0.1472 - val_acc: 0.8899\n",
            "Epoch 167/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1552 - acc: 0.8839 - val_loss: 0.1468 - val_acc: 0.8899\n",
            "Epoch 168/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1663 - acc: 0.8741 - val_loss: 0.1467 - val_acc: 0.8899\n",
            "Epoch 169/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - acc: 0.8741 - val_loss: 0.1466 - val_acc: 0.8899\n",
            "Epoch 170/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8924 - val_loss: 0.1464 - val_acc: 0.8899\n",
            "Epoch 171/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8965 - val_loss: 0.1461 - val_acc: 0.8899\n",
            "Epoch 172/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1508 - acc: 0.8843 - val_loss: 0.1458 - val_acc: 0.8899\n",
            "Epoch 173/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1426 - acc: 0.8968 - val_loss: 0.1454 - val_acc: 0.8899\n",
            "Epoch 174/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1425 - acc: 0.8909 - val_loss: 0.1452 - val_acc: 0.8899\n",
            "Epoch 175/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8909 - val_loss: 0.1449 - val_acc: 0.8899\n",
            "Epoch 176/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2126 - acc: 0.8891 - val_loss: 0.1456 - val_acc: 0.8899\n",
            "Epoch 177/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1445 - acc: 0.8909 - val_loss: 0.1465 - val_acc: 0.8899\n",
            "Epoch 178/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1452 - acc: 0.8909 - val_loss: 0.1463 - val_acc: 0.8899\n",
            "Epoch 179/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1434 - acc: 0.8928 - val_loss: 0.1456 - val_acc: 0.8899\n",
            "Epoch 180/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8929 - val_loss: 0.1452 - val_acc: 0.8899\n",
            "Epoch 181/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1625 - acc: 0.8801 - val_loss: 0.1451 - val_acc: 0.8899\n",
            "Epoch 182/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1620 - acc: 0.8801 - val_loss: 0.1448 - val_acc: 0.8899\n",
            "Epoch 183/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1431 - acc: 0.8911 - val_loss: 0.1446 - val_acc: 0.8899\n",
            "Epoch 184/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2121 - acc: 0.8836 - val_loss: 0.1458 - val_acc: 0.8899\n",
            "Epoch 185/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1517 - acc: 0.8863 - val_loss: 0.1476 - val_acc: 0.8899\n",
            "Epoch 186/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1516 - acc: 0.8855 - val_loss: 0.1480 - val_acc: 0.8899\n",
            "Epoch 187/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1504 - acc: 0.8896 - val_loss: 0.1469 - val_acc: 0.8899\n",
            "Epoch 188/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1527 - acc: 0.8892 - val_loss: 0.1455 - val_acc: 0.8899\n",
            "Epoch 189/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1589 - acc: 0.8798 - val_loss: 0.1448 - val_acc: 0.8899\n",
            "Epoch 190/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8877 - val_loss: 0.1449 - val_acc: 0.8899\n",
            "Epoch 191/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8877 - val_loss: 0.1448 - val_acc: 0.8899\n",
            "Epoch 192/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1526 - acc: 0.8854 - val_loss: 0.1443 - val_acc: 0.8899\n",
            "Epoch 193/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1510 - acc: 0.8923 - val_loss: 0.1441 - val_acc: 0.8899\n",
            "Epoch 194/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8846 - val_loss: 0.1442 - val_acc: 0.8899\n",
            "Epoch 195/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8846 - val_loss: 0.1443 - val_acc: 0.8899\n",
            "Epoch 196/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1613 - acc: 0.8927 - val_loss: 0.1445 - val_acc: 0.8899\n",
            "Epoch 197/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1387 - acc: 0.8927 - val_loss: 0.1442 - val_acc: 0.8899\n",
            "Epoch 198/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - acc: 0.8857 - val_loss: 0.1438 - val_acc: 0.8899\n",
            "Epoch 199/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1958 - acc: 0.8900 - val_loss: 0.1439 - val_acc: 0.8899\n",
            "Epoch 200/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1430 - acc: 0.8901 - val_loss: 0.1437 - val_acc: 0.8899\n",
            "Epoch 201/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8983 - val_loss: 0.1436 - val_acc: 0.8899\n",
            "Epoch 202/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1763 - acc: 0.8764 - val_loss: 0.1431 - val_acc: 0.8899\n",
            "Epoch 203/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1486 - acc: 0.8860 - val_loss: 0.1429 - val_acc: 0.8899\n",
            "Epoch 204/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1481 - acc: 0.8860 - val_loss: 0.1427 - val_acc: 0.8899\n",
            "Epoch 205/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1484 - acc: 0.8863 - val_loss: 0.1425 - val_acc: 0.8899\n",
            "Epoch 206/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1480 - acc: 0.8863 - val_loss: 0.1423 - val_acc: 0.8899\n",
            "Epoch 207/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1407 - acc: 0.8946 - val_loss: 0.1422 - val_acc: 0.8899\n",
            "Epoch 208/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1403 - acc: 0.8946 - val_loss: 0.1421 - val_acc: 0.8899\n",
            "Epoch 209/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1445 - acc: 0.8903 - val_loss: 0.1419 - val_acc: 0.8899\n",
            "Epoch 210/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1772 - acc: 0.8911 - val_loss: 0.1426 - val_acc: 0.8899\n",
            "Epoch 211/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1480 - acc: 0.8859 - val_loss: 0.1435 - val_acc: 0.8899\n",
            "Epoch 212/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1564 - acc: 0.8801 - val_loss: 0.1435 - val_acc: 0.8899\n",
            "Epoch 213/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1465 - acc: 0.8871 - val_loss: 0.1426 - val_acc: 0.8899\n",
            "Epoch 214/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1454 - acc: 0.8871 - val_loss: 0.1421 - val_acc: 0.8899\n",
            "Epoch 215/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8921 - val_loss: 0.1422 - val_acc: 0.8899\n",
            "Epoch 216/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1486 - acc: 0.8843 - val_loss: 0.1418 - val_acc: 0.8899\n",
            "Epoch 217/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1484 - acc: 0.8846 - val_loss: 0.1407 - val_acc: 0.8899\n",
            "Epoch 218/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1616 - acc: 0.8778 - val_loss: 0.1406 - val_acc: 0.8899\n",
            "Epoch 219/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1489 - acc: 0.8825 - val_loss: 0.1409 - val_acc: 0.8899\n",
            "Epoch 220/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1555 - acc: 0.8795 - val_loss: 0.1408 - val_acc: 0.8899\n",
            "Epoch 221/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1441 - acc: 0.8907 - val_loss: 0.1403 - val_acc: 0.8899\n",
            "Epoch 222/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1434 - acc: 0.8907 - val_loss: 0.1401 - val_acc: 0.8899\n",
            "Epoch 223/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1387 - acc: 0.8890 - val_loss: 0.1402 - val_acc: 0.8899\n",
            "Epoch 224/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8994 - val_loss: 0.1401 - val_acc: 0.8899\n",
            "Epoch 225/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1446 - acc: 0.8886 - val_loss: 0.1395 - val_acc: 0.8899\n",
            "Epoch 226/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1454 - acc: 0.8884 - val_loss: 0.1392 - val_acc: 0.8899\n",
            "Epoch 227/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1353 - acc: 0.8960 - val_loss: 0.1391 - val_acc: 0.8899\n",
            "Epoch 228/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1571 - acc: 0.8805 - val_loss: 0.1391 - val_acc: 0.8898\n",
            "Epoch 229/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1596 - acc: 0.8820 - val_loss: 0.1390 - val_acc: 0.8898\n",
            "Epoch 230/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1392 - acc: 0.8877 - val_loss: 0.1388 - val_acc: 0.8898\n",
            "Epoch 231/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1428 - acc: 0.8865 - val_loss: 0.1387 - val_acc: 0.8899\n",
            "Epoch 232/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1613 - acc: 0.8854 - val_loss: 0.1389 - val_acc: 0.8899\n",
            "Epoch 233/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1421 - acc: 0.8897 - val_loss: 0.1389 - val_acc: 0.8899\n",
            "Epoch 234/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1457 - acc: 0.8853 - val_loss: 0.1388 - val_acc: 0.8898\n",
            "Epoch 235/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1417 - acc: 0.8881 - val_loss: 0.1384 - val_acc: 0.8898\n",
            "Epoch 236/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1412 - acc: 0.8881 - val_loss: 0.1380 - val_acc: 0.8899\n",
            "Epoch 237/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8939 - val_loss: 0.1381 - val_acc: 0.8899\n",
            "Epoch 238/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8939 - val_loss: 0.1388 - val_acc: 0.8899\n",
            "Epoch 239/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8969 - val_loss: 0.1385 - val_acc: 0.8899\n",
            "Epoch 240/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8965 - val_loss: 0.1377 - val_acc: 0.8899\n",
            "Epoch 241/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1419 - acc: 0.8888 - val_loss: 0.1377 - val_acc: 0.8898\n",
            "Epoch 242/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8964 - val_loss: 0.1376 - val_acc: 0.8898\n",
            "Epoch 243/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8951 - val_loss: 0.1373 - val_acc: 0.8898\n",
            "Epoch 244/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1503 - acc: 0.8824 - val_loss: 0.1374 - val_acc: 0.8899\n",
            "Epoch 245/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1487 - acc: 0.8806 - val_loss: 0.1375 - val_acc: 0.8898\n",
            "Epoch 246/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8870 - val_loss: 0.1373 - val_acc: 0.8898\n",
            "Epoch 247/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1413 - acc: 0.8847 - val_loss: 0.1368 - val_acc: 0.8898\n",
            "Epoch 248/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1404 - acc: 0.8847 - val_loss: 0.1368 - val_acc: 0.8898\n",
            "Epoch 249/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2703 - acc: 0.8755 - val_loss: 0.1435 - val_acc: 0.8894\n",
            "Epoch 250/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1575 - acc: 0.8752 - val_loss: 0.1490 - val_acc: 0.8892\n",
            "Epoch 251/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1592 - acc: 0.8853 - val_loss: 0.1474 - val_acc: 0.8895\n",
            "Epoch 252/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1571 - acc: 0.8856 - val_loss: 0.1423 - val_acc: 0.8898\n",
            "Epoch 253/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1840 - acc: 0.8815 - val_loss: 0.1413 - val_acc: 0.8899\n",
            "Epoch 254/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1725 - acc: 0.8945 - val_loss: 0.1426 - val_acc: 0.8899\n",
            "Epoch 255/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1607 - acc: 0.8780 - val_loss: 0.1418 - val_acc: 0.8899\n",
            "Epoch 256/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1596 - acc: 0.8780 - val_loss: 0.1408 - val_acc: 0.8899\n",
            "Epoch 257/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8940 - val_loss: 0.1409 - val_acc: 0.8899\n",
            "Epoch 258/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1497 - acc: 0.8846 - val_loss: 0.1410 - val_acc: 0.8899\n",
            "Epoch 259/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1447 - acc: 0.8865 - val_loss: 0.1408 - val_acc: 0.8899\n",
            "Epoch 260/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1481 - acc: 0.8871 - val_loss: 0.1403 - val_acc: 0.8899\n",
            "Epoch 261/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1393 - acc: 0.8902 - val_loss: 0.1400 - val_acc: 0.8899\n",
            "Epoch 262/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8910 - val_loss: 0.1398 - val_acc: 0.8899\n",
            "Epoch 263/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - acc: 0.8774 - val_loss: 0.1394 - val_acc: 0.8899\n",
            "Epoch 264/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1447 - acc: 0.8887 - val_loss: 0.1391 - val_acc: 0.8899\n",
            "Epoch 265/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8868 - val_loss: 0.1390 - val_acc: 0.8899\n",
            "Epoch 266/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1449 - acc: 0.8868 - val_loss: 0.1388 - val_acc: 0.8899\n",
            "Epoch 267/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1457 - acc: 0.8841 - val_loss: 0.1385 - val_acc: 0.8899\n",
            "Epoch 268/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1452 - acc: 0.8840 - val_loss: 0.1381 - val_acc: 0.8899\n",
            "Epoch 269/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1501 - acc: 0.8821 - val_loss: 0.1377 - val_acc: 0.8899\n",
            "Epoch 270/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1355 - acc: 0.8918 - val_loss: 0.1376 - val_acc: 0.8899\n",
            "Epoch 271/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8855 - val_loss: 0.1375 - val_acc: 0.8899\n",
            "Epoch 272/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1442 - acc: 0.8824 - val_loss: 0.1370 - val_acc: 0.8899\n",
            "Epoch 273/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8847 - val_loss: 0.1366 - val_acc: 0.8899\n",
            "Epoch 274/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - acc: 0.8899 - val_loss: 0.1363 - val_acc: 0.8899\n",
            "Epoch 275/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1510 - acc: 0.8793 - val_loss: 0.1361 - val_acc: 0.8899\n",
            "Epoch 276/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1504 - acc: 0.8773 - val_loss: 0.1361 - val_acc: 0.8899\n",
            "Epoch 277/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1393 - acc: 0.8862 - val_loss: 0.1359 - val_acc: 0.8898\n",
            "Epoch 278/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2013 - acc: 0.8905 - val_loss: 0.1369 - val_acc: 0.8898\n",
            "Epoch 279/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1415 - acc: 0.8866 - val_loss: 0.1374 - val_acc: 0.8898\n",
            "Epoch 280/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8912 - val_loss: 0.1368 - val_acc: 0.8898\n",
            "Epoch 281/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8910 - val_loss: 0.1361 - val_acc: 0.8898\n",
            "Epoch 282/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1420 - acc: 0.8905 - val_loss: 0.1359 - val_acc: 0.8898\n",
            "Epoch 283/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8884 - val_loss: 0.1358 - val_acc: 0.8899\n",
            "Epoch 284/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2239 - acc: 0.8864 - val_loss: 0.1365 - val_acc: 0.8898\n",
            "Epoch 285/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1391 - acc: 0.8867 - val_loss: 0.1387 - val_acc: 0.8898\n",
            "Epoch 286/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8915 - val_loss: 0.1391 - val_acc: 0.8898\n",
            "Epoch 287/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8773 - val_loss: 0.1377 - val_acc: 0.8898\n",
            "Epoch 288/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1463 - acc: 0.8853 - val_loss: 0.1368 - val_acc: 0.8898\n",
            "Epoch 289/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1361 - acc: 0.8885 - val_loss: 0.1371 - val_acc: 0.8899\n",
            "Epoch 290/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2149 - acc: 0.8873 - val_loss: 0.1369 - val_acc: 0.8899\n",
            "Epoch 291/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8876 - val_loss: 0.1369 - val_acc: 0.8898\n",
            "Epoch 292/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1412 - acc: 0.8887 - val_loss: 0.1373 - val_acc: 0.8898\n",
            "Epoch 293/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8901 - val_loss: 0.1373 - val_acc: 0.8898\n",
            "Epoch 294/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1469 - acc: 0.8806 - val_loss: 0.1369 - val_acc: 0.8898\n",
            "Epoch 295/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1463 - acc: 0.8806 - val_loss: 0.1364 - val_acc: 0.8898\n",
            "Epoch 296/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8885 - val_loss: 0.1363 - val_acc: 0.8898\n",
            "Epoch 297/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8854 - val_loss: 0.1363 - val_acc: 0.8898\n",
            "Epoch 298/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8921 - val_loss: 0.1362 - val_acc: 0.8898\n",
            "Epoch 299/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8898 - val_loss: 0.1357 - val_acc: 0.8898\n",
            "Epoch 300/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8868 - val_loss: 0.1353 - val_acc: 0.8898\n",
            "Epoch 301/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8891 - val_loss: 0.1351 - val_acc: 0.8898\n",
            "Epoch 302/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8876 - val_loss: 0.1348 - val_acc: 0.8898\n",
            "Epoch 303/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1658 - acc: 0.8810 - val_loss: 0.1351 - val_acc: 0.8898\n",
            "Epoch 304/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8932 - val_loss: 0.1352 - val_acc: 0.8898\n",
            "Epoch 305/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8872 - val_loss: 0.1349 - val_acc: 0.8898\n",
            "Epoch 306/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1386 - acc: 0.8832 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 307/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1378 - acc: 0.8832 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 308/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8948 - val_loss: 0.1347 - val_acc: 0.8898\n",
            "Epoch 309/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2410 - acc: 0.8918 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 310/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1511 - acc: 0.8885 - val_loss: 0.1367 - val_acc: 0.8897\n",
            "Epoch 311/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1414 - acc: 0.8854 - val_loss: 0.1382 - val_acc: 0.8897\n",
            "Epoch 312/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8854 - val_loss: 0.1375 - val_acc: 0.8897\n",
            "Epoch 313/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8906 - val_loss: 0.1359 - val_acc: 0.8898\n",
            "Epoch 314/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1399 - acc: 0.8858 - val_loss: 0.1355 - val_acc: 0.8898\n",
            "Epoch 315/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8853 - val_loss: 0.1359 - val_acc: 0.8899\n",
            "Epoch 316/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1541 - acc: 0.8932 - val_loss: 0.1352 - val_acc: 0.8899\n",
            "Epoch 317/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8898 - val_loss: 0.1346 - val_acc: 0.8899\n",
            "Epoch 318/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1486 - acc: 0.8814 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 319/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1506 - acc: 0.8771 - val_loss: 0.1347 - val_acc: 0.8898\n",
            "Epoch 320/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8889 - val_loss: 0.1347 - val_acc: 0.8898\n",
            "Epoch 321/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2116 - acc: 0.8912 - val_loss: 0.1360 - val_acc: 0.8897\n",
            "Epoch 322/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8915 - val_loss: 0.1362 - val_acc: 0.8897\n",
            "Epoch 323/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8983 - val_loss: 0.1352 - val_acc: 0.8898\n",
            "Epoch 324/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8914 - val_loss: 0.1348 - val_acc: 0.8898\n",
            "Epoch 325/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8899 - val_loss: 0.1357 - val_acc: 0.8898\n",
            "Epoch 326/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1491 - acc: 0.8920 - val_loss: 0.1357 - val_acc: 0.8898\n",
            "Epoch 327/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1435 - acc: 0.8824 - val_loss: 0.1348 - val_acc: 0.8898\n",
            "Epoch 328/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1425 - acc: 0.8852 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 329/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8899 - val_loss: 0.1348 - val_acc: 0.8897\n",
            "Epoch 330/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8898 - val_loss: 0.1348 - val_acc: 0.8897\n",
            "Epoch 331/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1457 - acc: 0.8842 - val_loss: 0.1343 - val_acc: 0.8897\n",
            "Epoch 332/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1417 - acc: 0.8827 - val_loss: 0.1337 - val_acc: 0.8898\n",
            "Epoch 333/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8870 - val_loss: 0.1334 - val_acc: 0.8898\n",
            "Epoch 334/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1413 - acc: 0.8848 - val_loss: 0.1334 - val_acc: 0.8898\n",
            "Epoch 335/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8849 - val_loss: 0.1333 - val_acc: 0.8898\n",
            "Epoch 336/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1356 - acc: 0.8857 - val_loss: 0.1329 - val_acc: 0.8898\n",
            "Epoch 337/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8857 - val_loss: 0.1328 - val_acc: 0.8897\n",
            "Epoch 338/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2292 - acc: 0.8886 - val_loss: 0.1358 - val_acc: 0.8896\n",
            "Epoch 339/3000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1346 - acc: 0.8892 - val_loss: 0.1388 - val_acc: 0.8894\n",
            "Epoch 340/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1455 - acc: 0.8852 - val_loss: 0.1380 - val_acc: 0.8895\n",
            "Epoch 341/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8793 - val_loss: 0.1352 - val_acc: 0.8897\n",
            "Epoch 342/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1530 - acc: 0.8758 - val_loss: 0.1339 - val_acc: 0.8897\n",
            "Epoch 343/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1516 - acc: 0.8759 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 344/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1395 - acc: 0.8849 - val_loss: 0.1345 - val_acc: 0.8898\n",
            "Epoch 345/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8943 - val_loss: 0.1340 - val_acc: 0.8898\n",
            "Epoch 346/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8906 - val_loss: 0.1335 - val_acc: 0.8897\n",
            "Epoch 347/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8905 - val_loss: 0.1335 - val_acc: 0.8896\n",
            "Epoch 348/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8920 - val_loss: 0.1338 - val_acc: 0.8896\n",
            "Epoch 349/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8837 - val_loss: 0.1336 - val_acc: 0.8895\n",
            "Epoch 350/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1622 - acc: 0.8956 - val_loss: 0.1335 - val_acc: 0.8895\n",
            "Epoch 351/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8965 - val_loss: 0.1330 - val_acc: 0.8896\n",
            "Epoch 352/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8922 - val_loss: 0.1329 - val_acc: 0.8896\n",
            "Epoch 353/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1385 - acc: 0.8846 - val_loss: 0.1332 - val_acc: 0.8897\n",
            "Epoch 354/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1356 - acc: 0.8859 - val_loss: 0.1329 - val_acc: 0.8897\n",
            "Epoch 355/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8943 - val_loss: 0.1323 - val_acc: 0.8896\n",
            "Epoch 356/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1487 - acc: 0.8852 - val_loss: 0.1319 - val_acc: 0.8896\n",
            "Epoch 357/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8907 - val_loss: 0.1319 - val_acc: 0.8896\n",
            "Epoch 358/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8884 - val_loss: 0.1320 - val_acc: 0.8895\n",
            "Epoch 359/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8775 - val_loss: 0.1318 - val_acc: 0.8896\n",
            "Epoch 360/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1328 - acc: 0.8867 - val_loss: 0.1314 - val_acc: 0.8896\n",
            "Epoch 361/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8847 - val_loss: 0.1310 - val_acc: 0.8896\n",
            "Epoch 362/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8847 - val_loss: 0.1310 - val_acc: 0.8896\n",
            "Epoch 363/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.8908 - val_loss: 0.1310 - val_acc: 0.8896\n",
            "Epoch 364/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1340 - acc: 0.8850 - val_loss: 0.1309 - val_acc: 0.8895\n",
            "Epoch 365/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8849 - val_loss: 0.1307 - val_acc: 0.8894\n",
            "Epoch 366/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8854 - val_loss: 0.1306 - val_acc: 0.8893\n",
            "Epoch 367/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1371 - acc: 0.8857 - val_loss: 0.1306 - val_acc: 0.8891\n",
            "Epoch 368/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8855 - val_loss: 0.1305 - val_acc: 0.8890\n",
            "Epoch 369/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8846 - val_loss: 0.1304 - val_acc: 0.8889\n",
            "Epoch 370/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1406 - acc: 0.8866 - val_loss: 0.1302 - val_acc: 0.8888\n",
            "Epoch 371/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1452 - acc: 0.8778 - val_loss: 0.1301 - val_acc: 0.8887\n",
            "Epoch 372/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8923 - val_loss: 0.1299 - val_acc: 0.8887\n",
            "Epoch 373/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8931 - val_loss: 0.1299 - val_acc: 0.8886\n",
            "Epoch 374/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8838 - val_loss: 0.1297 - val_acc: 0.8887\n",
            "Epoch 375/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.9012 - val_loss: 0.1296 - val_acc: 0.8888\n",
            "Epoch 376/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1562 - acc: 0.8913 - val_loss: 0.1297 - val_acc: 0.8888\n",
            "Epoch 377/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8864 - val_loss: 0.1297 - val_acc: 0.8889\n",
            "Epoch 378/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8929 - val_loss: 0.1297 - val_acc: 0.8889\n",
            "Epoch 379/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8930 - val_loss: 0.1296 - val_acc: 0.8889\n",
            "Epoch 380/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298 - acc: 0.8878 - val_loss: 0.1295 - val_acc: 0.8890\n",
            "Epoch 381/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2518 - acc: 0.8828 - val_loss: 0.1317 - val_acc: 0.8886\n",
            "Epoch 382/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1417 - acc: 0.8853 - val_loss: 0.1345 - val_acc: 0.8884\n",
            "Epoch 383/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8925 - val_loss: 0.1341 - val_acc: 0.8887\n",
            "Epoch 384/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8928 - val_loss: 0.1321 - val_acc: 0.8891\n",
            "Epoch 385/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1595 - acc: 0.8803 - val_loss: 0.1318 - val_acc: 0.8894\n",
            "Epoch 386/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8882 - val_loss: 0.1321 - val_acc: 0.8896\n",
            "Epoch 387/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1323 - acc: 0.8894 - val_loss: 0.1319 - val_acc: 0.8897\n",
            "Epoch 388/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1505 - acc: 0.8798 - val_loss: 0.1314 - val_acc: 0.8897\n",
            "Epoch 389/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1496 - acc: 0.8798 - val_loss: 0.1311 - val_acc: 0.8897\n",
            "Epoch 390/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1383 - acc: 0.8838 - val_loss: 0.1309 - val_acc: 0.8897\n",
            "Epoch 391/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1471 - acc: 0.8780 - val_loss: 0.1310 - val_acc: 0.8896\n",
            "Epoch 392/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1490 - acc: 0.8771 - val_loss: 0.1310 - val_acc: 0.8896\n",
            "Epoch 393/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2000 - acc: 0.9006 - val_loss: 0.1329 - val_acc: 0.8895\n",
            "Epoch 394/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8894 - val_loss: 0.1331 - val_acc: 0.8895\n",
            "Epoch 395/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8895 - val_loss: 0.1316 - val_acc: 0.8896\n",
            "Epoch 396/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8856 - val_loss: 0.1311 - val_acc: 0.8897\n",
            "Epoch 397/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8923 - val_loss: 0.1321 - val_acc: 0.8898\n",
            "Epoch 398/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8910 - val_loss: 0.1320 - val_acc: 0.8898\n",
            "Epoch 399/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8880 - val_loss: 0.1308 - val_acc: 0.8897\n",
            "Epoch 400/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8879 - val_loss: 0.1307 - val_acc: 0.8895\n",
            "Epoch 401/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8907 - val_loss: 0.1312 - val_acc: 0.8894\n",
            "Epoch 402/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8871 - val_loss: 0.1312 - val_acc: 0.8894\n",
            "Epoch 403/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1450 - acc: 0.8883 - val_loss: 0.1309 - val_acc: 0.8894\n",
            "Epoch 404/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2486 - acc: 0.8764 - val_loss: 0.1354 - val_acc: 0.8890\n",
            "Epoch 405/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8778 - val_loss: 0.1383 - val_acc: 0.8888\n",
            "Epoch 406/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1393 - acc: 0.8912 - val_loss: 0.1364 - val_acc: 0.8891\n",
            "Epoch 407/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1384 - acc: 0.8891 - val_loss: 0.1330 - val_acc: 0.8894\n",
            "Epoch 408/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8896 - val_loss: 0.1334 - val_acc: 0.8897\n",
            "Epoch 409/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1308 - acc: 0.8913 - val_loss: 0.1363 - val_acc: 0.8898\n",
            "Epoch 410/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1354 - acc: 0.8891 - val_loss: 0.1353 - val_acc: 0.8898\n",
            "Epoch 411/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1440 - acc: 0.8871 - val_loss: 0.1319 - val_acc: 0.8897\n",
            "Epoch 412/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8953 - val_loss: 0.1314 - val_acc: 0.8895\n",
            "Epoch 413/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1354 - acc: 0.8850 - val_loss: 0.1324 - val_acc: 0.8893\n",
            "Epoch 414/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8903 - val_loss: 0.1329 - val_acc: 0.8892\n",
            "Epoch 415/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8876 - val_loss: 0.1322 - val_acc: 0.8892\n",
            "Epoch 416/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8873 - val_loss: 0.1312 - val_acc: 0.8892\n",
            "Epoch 417/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8898 - val_loss: 0.1307 - val_acc: 0.8893\n",
            "Epoch 418/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8932 - val_loss: 0.1312 - val_acc: 0.8894\n",
            "Epoch 419/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8886 - val_loss: 0.1312 - val_acc: 0.8894\n",
            "Epoch 420/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1308 - acc: 0.8886 - val_loss: 0.1301 - val_acc: 0.8893\n",
            "Epoch 421/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8965 - val_loss: 0.1294 - val_acc: 0.8891\n",
            "Epoch 422/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8983 - val_loss: 0.1293 - val_acc: 0.8890\n",
            "Epoch 423/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8793 - val_loss: 0.1294 - val_acc: 0.8888\n",
            "Epoch 424/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8851 - val_loss: 0.1292 - val_acc: 0.8889\n",
            "Epoch 425/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8851 - val_loss: 0.1288 - val_acc: 0.8890\n",
            "Epoch 426/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8848 - val_loss: 0.1286 - val_acc: 0.8891\n",
            "Epoch 427/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8848 - val_loss: 0.1285 - val_acc: 0.8891\n",
            "Epoch 428/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8899 - val_loss: 0.1285 - val_acc: 0.8890\n",
            "Epoch 429/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8969 - val_loss: 0.1284 - val_acc: 0.8890\n",
            "Epoch 430/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8828 - val_loss: 0.1281 - val_acc: 0.8889\n",
            "Epoch 431/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8897 - val_loss: 0.1278 - val_acc: 0.8887\n",
            "Epoch 432/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8902 - val_loss: 0.1278 - val_acc: 0.8884\n",
            "Epoch 433/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8877 - val_loss: 0.1279 - val_acc: 0.8882\n",
            "Epoch 434/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8900 - val_loss: 0.1277 - val_acc: 0.8881\n",
            "Epoch 435/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8941 - val_loss: 0.1274 - val_acc: 0.8881\n",
            "Epoch 436/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8748 - val_loss: 0.1271 - val_acc: 0.8883\n",
            "Epoch 437/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1902 - acc: 0.8829 - val_loss: 0.1276 - val_acc: 0.8881\n",
            "Epoch 438/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8854 - val_loss: 0.1282 - val_acc: 0.8880\n",
            "Epoch 439/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8906 - val_loss: 0.1282 - val_acc: 0.8882\n",
            "Epoch 440/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1443 - acc: 0.8891 - val_loss: 0.1280 - val_acc: 0.8884\n",
            "Epoch 441/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8979 - val_loss: 0.1276 - val_acc: 0.8888\n",
            "Epoch 442/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8982 - val_loss: 0.1280 - val_acc: 0.8892\n",
            "Epoch 443/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8914 - val_loss: 0.1283 - val_acc: 0.8893\n",
            "Epoch 444/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1447 - acc: 0.8919 - val_loss: 0.1277 - val_acc: 0.8892\n",
            "Epoch 445/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8882 - val_loss: 0.1276 - val_acc: 0.8890\n",
            "Epoch 446/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1399 - acc: 0.8761 - val_loss: 0.1278 - val_acc: 0.8888\n",
            "Epoch 447/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1396 - acc: 0.8782 - val_loss: 0.1281 - val_acc: 0.8887\n",
            "Epoch 448/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1790 - acc: 0.8770 - val_loss: 0.1293 - val_acc: 0.8884\n",
            "Epoch 449/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8785 - val_loss: 0.1296 - val_acc: 0.8884\n",
            "Epoch 450/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8860 - val_loss: 0.1282 - val_acc: 0.8888\n",
            "Epoch 451/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1744 - acc: 0.8829 - val_loss: 0.1283 - val_acc: 0.8889\n",
            "Epoch 452/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8843 - val_loss: 0.1282 - val_acc: 0.8890\n",
            "Epoch 453/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8919 - val_loss: 0.1281 - val_acc: 0.8892\n",
            "Epoch 454/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8922 - val_loss: 0.1282 - val_acc: 0.8894\n",
            "Epoch 455/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8901 - val_loss: 0.1282 - val_acc: 0.8895\n",
            "Epoch 456/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8901 - val_loss: 0.1282 - val_acc: 0.8895\n",
            "Epoch 457/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1894 - acc: 0.8974 - val_loss: 0.1286 - val_acc: 0.8893\n",
            "Epoch 458/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8994 - val_loss: 0.1299 - val_acc: 0.8891\n",
            "Epoch 459/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8866 - val_loss: 0.1306 - val_acc: 0.8890\n",
            "Epoch 460/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8926 - val_loss: 0.1300 - val_acc: 0.8891\n",
            "Epoch 461/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1396 - acc: 0.8803 - val_loss: 0.1288 - val_acc: 0.8893\n",
            "Epoch 462/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8804 - val_loss: 0.1281 - val_acc: 0.8894\n",
            "Epoch 463/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1730 - acc: 0.8900 - val_loss: 0.1282 - val_acc: 0.8894\n",
            "Epoch 464/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8908 - val_loss: 0.1285 - val_acc: 0.8894\n",
            "Epoch 465/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8796 - val_loss: 0.1286 - val_acc: 0.8893\n",
            "Epoch 466/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8814 - val_loss: 0.1284 - val_acc: 0.8893\n",
            "Epoch 467/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8956 - val_loss: 0.1282 - val_acc: 0.8893\n",
            "Epoch 468/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8887 - val_loss: 0.1279 - val_acc: 0.8893\n",
            "Epoch 469/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8917 - val_loss: 0.1277 - val_acc: 0.8894\n",
            "Epoch 470/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8918 - val_loss: 0.1276 - val_acc: 0.8894\n",
            "Epoch 471/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8975 - val_loss: 0.1274 - val_acc: 0.8893\n",
            "Epoch 472/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1297 - acc: 0.8878 - val_loss: 0.1272 - val_acc: 0.8892\n",
            "Epoch 473/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1357 - acc: 0.8816 - val_loss: 0.1270 - val_acc: 0.8890\n",
            "Epoch 474/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1372 - acc: 0.8819 - val_loss: 0.1269 - val_acc: 0.8888\n",
            "Epoch 475/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8817 - val_loss: 0.1268 - val_acc: 0.8887\n",
            "Epoch 476/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8986 - val_loss: 0.1265 - val_acc: 0.8887\n",
            "Epoch 477/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1716 - acc: 0.8964 - val_loss: 0.1269 - val_acc: 0.8885\n",
            "Epoch 478/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8946 - val_loss: 0.1273 - val_acc: 0.8884\n",
            "Epoch 479/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8847 - val_loss: 0.1271 - val_acc: 0.8884\n",
            "Epoch 480/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8825 - val_loss: 0.1267 - val_acc: 0.8886\n",
            "Epoch 481/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1328 - acc: 0.8827 - val_loss: 0.1266 - val_acc: 0.8886\n",
            "Epoch 482/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8842 - val_loss: 0.1266 - val_acc: 0.8886\n",
            "Epoch 483/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1614 - acc: 0.8882 - val_loss: 0.1264 - val_acc: 0.8884\n",
            "Epoch 484/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8821 - val_loss: 0.1268 - val_acc: 0.8882\n",
            "Epoch 485/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8820 - val_loss: 0.1269 - val_acc: 0.8881\n",
            "Epoch 486/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8849 - val_loss: 0.1265 - val_acc: 0.8883\n",
            "Epoch 487/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8850 - val_loss: 0.1263 - val_acc: 0.8886\n",
            "Epoch 488/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1591 - acc: 0.8789 - val_loss: 0.1260 - val_acc: 0.8885\n",
            "Epoch 489/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8906 - val_loss: 0.1261 - val_acc: 0.8884\n",
            "Epoch 490/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8878 - val_loss: 0.1261 - val_acc: 0.8884\n",
            "Epoch 491/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8810 - val_loss: 0.1261 - val_acc: 0.8882\n",
            "Epoch 492/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8778 - val_loss: 0.1261 - val_acc: 0.8881\n",
            "Epoch 493/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8874 - val_loss: 0.1259 - val_acc: 0.8881\n",
            "Epoch 494/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8947 - val_loss: 0.1257 - val_acc: 0.8882\n",
            "Epoch 495/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8949 - val_loss: 0.1258 - val_acc: 0.8884\n",
            "Epoch 496/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8843 - val_loss: 0.1257 - val_acc: 0.8882\n",
            "Epoch 497/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1380 - acc: 0.8858 - val_loss: 0.1254 - val_acc: 0.8878\n",
            "Epoch 498/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8805 - val_loss: 0.1252 - val_acc: 0.8873\n",
            "Epoch 499/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8882 - val_loss: 0.1252 - val_acc: 0.8870\n",
            "Epoch 500/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.8880 - val_loss: 0.1251 - val_acc: 0.8869\n",
            "Epoch 501/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8855 - val_loss: 0.1249 - val_acc: 0.8872\n",
            "Epoch 502/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8909 - val_loss: 0.1249 - val_acc: 0.8876\n",
            "Epoch 503/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8902 - val_loss: 0.1250 - val_acc: 0.8879\n",
            "Epoch 504/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8867 - val_loss: 0.1249 - val_acc: 0.8879\n",
            "Epoch 505/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8900 - val_loss: 0.1245 - val_acc: 0.8877\n",
            "Epoch 506/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8889 - val_loss: 0.1244 - val_acc: 0.8875\n",
            "Epoch 507/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8900 - val_loss: 0.1243 - val_acc: 0.8873\n",
            "Epoch 508/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8781 - val_loss: 0.1242 - val_acc: 0.8873\n",
            "Epoch 509/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8882 - val_loss: 0.1241 - val_acc: 0.8875\n",
            "Epoch 510/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8878 - val_loss: 0.1241 - val_acc: 0.8876\n",
            "Epoch 511/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8764 - val_loss: 0.1239 - val_acc: 0.8874\n",
            "Epoch 512/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8762 - val_loss: 0.1239 - val_acc: 0.8869\n",
            "Epoch 513/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2141 - acc: 0.8779 - val_loss: 0.1273 - val_acc: 0.8856\n",
            "Epoch 514/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8910 - val_loss: 0.1292 - val_acc: 0.8857\n",
            "Epoch 515/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8874 - val_loss: 0.1271 - val_acc: 0.8871\n",
            "Epoch 516/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8859 - val_loss: 0.1256 - val_acc: 0.8884\n",
            "Epoch 517/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1393 - acc: 0.8778 - val_loss: 0.1264 - val_acc: 0.8890\n",
            "Epoch 518/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1400 - acc: 0.8786 - val_loss: 0.1262 - val_acc: 0.8891\n",
            "Epoch 519/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8845 - val_loss: 0.1250 - val_acc: 0.8887\n",
            "Epoch 520/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8836 - val_loss: 0.1252 - val_acc: 0.8881\n",
            "Epoch 521/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8816 - val_loss: 0.1265 - val_acc: 0.8875\n",
            "Epoch 522/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8880 - val_loss: 0.1263 - val_acc: 0.8875\n",
            "Epoch 523/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8879 - val_loss: 0.1250 - val_acc: 0.8881\n",
            "Epoch 524/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8888 - val_loss: 0.1248 - val_acc: 0.8887\n",
            "Epoch 525/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8892 - val_loss: 0.1263 - val_acc: 0.8890\n",
            "Epoch 526/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8895 - val_loss: 0.1263 - val_acc: 0.8890\n",
            "Epoch 527/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1419 - acc: 0.8815 - val_loss: 0.1243 - val_acc: 0.8886\n",
            "Epoch 528/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8789 - val_loss: 0.1251 - val_acc: 0.8880\n",
            "Epoch 529/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8864 - val_loss: 0.1261 - val_acc: 0.8876\n",
            "Epoch 530/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8893 - val_loss: 0.1253 - val_acc: 0.8878\n",
            "Epoch 531/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1922 - acc: 0.8903 - val_loss: 0.1267 - val_acc: 0.8876\n",
            "Epoch 532/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8921 - val_loss: 0.1261 - val_acc: 0.8879\n",
            "Epoch 533/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8940 - val_loss: 0.1248 - val_acc: 0.8886\n",
            "Epoch 534/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8896 - val_loss: 0.1254 - val_acc: 0.8890\n",
            "Epoch 535/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8854 - val_loss: 0.1265 - val_acc: 0.8892\n",
            "Epoch 536/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8981 - val_loss: 0.1257 - val_acc: 0.8891\n",
            "Epoch 537/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8986 - val_loss: 0.1242 - val_acc: 0.8888\n",
            "Epoch 538/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8906 - val_loss: 0.1243 - val_acc: 0.8883\n",
            "Epoch 539/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8982 - val_loss: 0.1251 - val_acc: 0.8879\n",
            "Epoch 540/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8986 - val_loss: 0.1250 - val_acc: 0.8879\n",
            "Epoch 541/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8846 - val_loss: 0.1244 - val_acc: 0.8882\n",
            "Epoch 542/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8902 - val_loss: 0.1240 - val_acc: 0.8885\n",
            "Epoch 543/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8887 - val_loss: 0.1240 - val_acc: 0.8886\n",
            "Epoch 544/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8813 - val_loss: 0.1238 - val_acc: 0.8886\n",
            "Epoch 545/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8812 - val_loss: 0.1234 - val_acc: 0.8883\n",
            "Epoch 546/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8844 - val_loss: 0.1232 - val_acc: 0.8879\n",
            "Epoch 547/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8829 - val_loss: 0.1233 - val_acc: 0.8876\n",
            "Epoch 548/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 0.8785 - val_loss: 0.1232 - val_acc: 0.8874\n",
            "Epoch 549/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8927 - val_loss: 0.1230 - val_acc: 0.8874\n",
            "Epoch 550/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8808 - val_loss: 0.1229 - val_acc: 0.8876\n",
            "Epoch 551/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8810 - val_loss: 0.1228 - val_acc: 0.8877\n",
            "Epoch 552/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8890 - val_loss: 0.1226 - val_acc: 0.8876\n",
            "Epoch 553/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8894 - val_loss: 0.1225 - val_acc: 0.8875\n",
            "Epoch 554/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8881 - val_loss: 0.1224 - val_acc: 0.8871\n",
            "Epoch 555/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8825 - val_loss: 0.1225 - val_acc: 0.8868\n",
            "Epoch 556/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8878 - val_loss: 0.1225 - val_acc: 0.8867\n",
            "Epoch 557/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8890 - val_loss: 0.1223 - val_acc: 0.8869\n",
            "Epoch 558/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 0.8783 - val_loss: 0.1223 - val_acc: 0.8872\n",
            "Epoch 559/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8935 - val_loss: 0.1223 - val_acc: 0.8874\n",
            "Epoch 560/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8884 - val_loss: 0.1223 - val_acc: 0.8874\n",
            "Epoch 561/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8884 - val_loss: 0.1222 - val_acc: 0.8872\n",
            "Epoch 562/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2861 - acc: 0.8734 - val_loss: 0.1302 - val_acc: 0.8850\n",
            "Epoch 563/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1405 - acc: 0.8788 - val_loss: 0.1374 - val_acc: 0.8845\n",
            "Epoch 564/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1576 - acc: 0.8812 - val_loss: 0.1379 - val_acc: 0.8859\n",
            "Epoch 565/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1861 - acc: 0.8722 - val_loss: 0.1355 - val_acc: 0.8874\n",
            "Epoch 566/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1468 - acc: 0.8767 - val_loss: 0.1303 - val_acc: 0.8887\n",
            "Epoch 567/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1439 - acc: 0.8745 - val_loss: 0.1292 - val_acc: 0.8894\n",
            "Epoch 568/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - acc: 0.8833 - val_loss: 0.1310 - val_acc: 0.8897\n",
            "Epoch 569/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8837 - val_loss: 0.1294 - val_acc: 0.8897\n",
            "Epoch 570/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1468 - acc: 0.8737 - val_loss: 0.1263 - val_acc: 0.8896\n",
            "Epoch 571/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8739 - val_loss: 0.1267 - val_acc: 0.8894\n",
            "Epoch 572/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8949 - val_loss: 0.1287 - val_acc: 0.8892\n",
            "Epoch 573/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8961 - val_loss: 0.1295 - val_acc: 0.8892\n",
            "Epoch 574/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8960 - val_loss: 0.1290 - val_acc: 0.8892\n",
            "Epoch 575/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1320 - acc: 0.8836 - val_loss: 0.1282 - val_acc: 0.8894\n",
            "Epoch 576/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8905 - val_loss: 0.1279 - val_acc: 0.8894\n",
            "Epoch 577/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2119 - acc: 0.8864 - val_loss: 0.1272 - val_acc: 0.8894\n",
            "Epoch 578/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8886 - val_loss: 0.1275 - val_acc: 0.8894\n",
            "Epoch 579/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8885 - val_loss: 0.1280 - val_acc: 0.8894\n",
            "Epoch 580/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8905 - val_loss: 0.1277 - val_acc: 0.8894\n",
            "Epoch 581/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1932 - acc: 0.8893 - val_loss: 0.1287 - val_acc: 0.8895\n",
            "Epoch 582/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8925 - val_loss: 0.1289 - val_acc: 0.8895\n",
            "Epoch 583/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1297 - acc: 0.8924 - val_loss: 0.1287 - val_acc: 0.8896\n",
            "Epoch 584/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1403 - acc: 0.8798 - val_loss: 0.1284 - val_acc: 0.8897\n",
            "Epoch 585/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8906 - val_loss: 0.1281 - val_acc: 0.8897\n",
            "Epoch 586/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8933 - val_loss: 0.1272 - val_acc: 0.8896\n",
            "Epoch 587/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1707 - acc: 0.8839 - val_loss: 0.1263 - val_acc: 0.8895\n",
            "Epoch 588/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1292 - acc: 0.8852 - val_loss: 0.1265 - val_acc: 0.8892\n",
            "Epoch 589/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8891 - val_loss: 0.1269 - val_acc: 0.8890\n",
            "Epoch 590/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8887 - val_loss: 0.1269 - val_acc: 0.8888\n",
            "Epoch 591/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8783 - val_loss: 0.1266 - val_acc: 0.8888\n",
            "Epoch 592/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1918 - acc: 0.8804 - val_loss: 0.1268 - val_acc: 0.8888\n",
            "Epoch 593/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1354 - acc: 0.8862 - val_loss: 0.1264 - val_acc: 0.8889\n",
            "Epoch 594/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8841 - val_loss: 0.1259 - val_acc: 0.8889\n",
            "Epoch 595/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8842 - val_loss: 0.1254 - val_acc: 0.8890\n",
            "Epoch 596/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8913 - val_loss: 0.1251 - val_acc: 0.8891\n",
            "Epoch 597/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8837 - val_loss: 0.1248 - val_acc: 0.8891\n",
            "Epoch 598/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8874 - val_loss: 0.1246 - val_acc: 0.8892\n",
            "Epoch 599/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2430 - acc: 0.8811 - val_loss: 0.1264 - val_acc: 0.8889\n",
            "Epoch 600/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8848 - val_loss: 0.1289 - val_acc: 0.8887\n",
            "Epoch 601/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8851 - val_loss: 0.1293 - val_acc: 0.8887\n",
            "Epoch 602/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8882 - val_loss: 0.1276 - val_acc: 0.8891\n",
            "Epoch 603/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1969 - acc: 0.8847 - val_loss: 0.1280 - val_acc: 0.8891\n",
            "Epoch 604/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1248 - acc: 0.8939 - val_loss: 0.1275 - val_acc: 0.8893\n",
            "Epoch 605/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1313 - acc: 0.8854 - val_loss: 0.1271 - val_acc: 0.8894\n",
            "Epoch 606/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8884 - val_loss: 0.1270 - val_acc: 0.8895\n",
            "Epoch 607/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8884 - val_loss: 0.1265 - val_acc: 0.8895\n",
            "Epoch 608/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8791 - val_loss: 0.1256 - val_acc: 0.8893\n",
            "Epoch 609/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8939 - val_loss: 0.1251 - val_acc: 0.8890\n",
            "Epoch 610/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8937 - val_loss: 0.1253 - val_acc: 0.8887\n",
            "Epoch 611/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8884 - val_loss: 0.1254 - val_acc: 0.8885\n",
            "Epoch 612/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8880 - val_loss: 0.1252 - val_acc: 0.8884\n",
            "Epoch 613/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8844 - val_loss: 0.1247 - val_acc: 0.8885\n",
            "Epoch 614/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1365 - acc: 0.8782 - val_loss: 0.1242 - val_acc: 0.8886\n",
            "Epoch 615/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8880 - val_loss: 0.1239 - val_acc: 0.8886\n",
            "Epoch 616/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8862 - val_loss: 0.1237 - val_acc: 0.8887\n",
            "Epoch 617/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8910 - val_loss: 0.1233 - val_acc: 0.8886\n",
            "Epoch 618/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8828 - val_loss: 0.1229 - val_acc: 0.8885\n",
            "Epoch 619/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8869 - val_loss: 0.1228 - val_acc: 0.8882\n",
            "Epoch 620/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3027 - acc: 0.8671 - val_loss: 0.1282 - val_acc: 0.8871\n",
            "Epoch 621/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1425 - acc: 0.8750 - val_loss: 0.1344 - val_acc: 0.8864\n",
            "Epoch 622/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1460 - acc: 0.8755 - val_loss: 0.1343 - val_acc: 0.8868\n",
            "Epoch 623/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1455 - acc: 0.8761 - val_loss: 0.1292 - val_acc: 0.8880\n",
            "Epoch 624/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8876 - val_loss: 0.1252 - val_acc: 0.8890\n",
            "Epoch 625/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8983 - val_loss: 0.1271 - val_acc: 0.8895\n",
            "Epoch 626/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8880 - val_loss: 0.1303 - val_acc: 0.8896\n",
            "Epoch 627/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1347 - acc: 0.8882 - val_loss: 0.1284 - val_acc: 0.8895\n",
            "Epoch 628/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8881 - val_loss: 0.1249 - val_acc: 0.8892\n",
            "Epoch 629/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8953 - val_loss: 0.1244 - val_acc: 0.8887\n",
            "Epoch 630/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1395 - acc: 0.8785 - val_loss: 0.1259 - val_acc: 0.8880\n",
            "Epoch 631/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8854 - val_loss: 0.1272 - val_acc: 0.8877\n",
            "Epoch 632/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8860 - val_loss: 0.1268 - val_acc: 0.8877\n",
            "Epoch 633/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8843 - val_loss: 0.1253 - val_acc: 0.8879\n",
            "Epoch 634/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1421 - acc: 0.8838 - val_loss: 0.1242 - val_acc: 0.8882\n",
            "Epoch 635/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8879 - val_loss: 0.1239 - val_acc: 0.8886\n",
            "Epoch 636/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8831 - val_loss: 0.1238 - val_acc: 0.8888\n",
            "Epoch 637/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8889 - val_loss: 0.1237 - val_acc: 0.8889\n",
            "Epoch 638/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8890 - val_loss: 0.1232 - val_acc: 0.8888\n",
            "Epoch 639/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8929 - val_loss: 0.1229 - val_acc: 0.8887\n",
            "Epoch 640/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8926 - val_loss: 0.1227 - val_acc: 0.8885\n",
            "Epoch 641/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8956 - val_loss: 0.1226 - val_acc: 0.8882\n",
            "Epoch 642/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8904 - val_loss: 0.1224 - val_acc: 0.8881\n",
            "Epoch 643/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8870 - val_loss: 0.1221 - val_acc: 0.8880\n",
            "Epoch 644/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8870 - val_loss: 0.1218 - val_acc: 0.8879\n",
            "Epoch 645/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1651 - acc: 0.8910 - val_loss: 0.1222 - val_acc: 0.8876\n",
            "Epoch 646/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8933 - val_loss: 0.1224 - val_acc: 0.8874\n",
            "Epoch 647/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8796 - val_loss: 0.1223 - val_acc: 0.8874\n",
            "Epoch 648/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8841 - val_loss: 0.1219 - val_acc: 0.8875\n",
            "Epoch 649/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8826 - val_loss: 0.1216 - val_acc: 0.8876\n",
            "Epoch 650/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8827 - val_loss: 0.1215 - val_acc: 0.8876\n",
            "Epoch 651/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8941 - val_loss: 0.1215 - val_acc: 0.8876\n",
            "Epoch 652/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8735 - val_loss: 0.1212 - val_acc: 0.8874\n",
            "Epoch 653/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1859 - acc: 0.8822 - val_loss: 0.1221 - val_acc: 0.8865\n",
            "Epoch 654/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8738 - val_loss: 0.1235 - val_acc: 0.8860\n",
            "Epoch 655/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8730 - val_loss: 0.1235 - val_acc: 0.8861\n",
            "Epoch 656/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8892 - val_loss: 0.1221 - val_acc: 0.8869\n",
            "Epoch 657/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8744 - val_loss: 0.1215 - val_acc: 0.8876\n",
            "Epoch 658/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8916 - val_loss: 0.1220 - val_acc: 0.8882\n",
            "Epoch 659/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8922 - val_loss: 0.1225 - val_acc: 0.8885\n",
            "Epoch 660/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8876 - val_loss: 0.1218 - val_acc: 0.8884\n",
            "Epoch 661/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8854 - val_loss: 0.1209 - val_acc: 0.8879\n",
            "Epoch 662/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8852 - val_loss: 0.1211 - val_acc: 0.8872\n",
            "Epoch 663/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8866 - val_loss: 0.1218 - val_acc: 0.8867\n",
            "Epoch 664/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8871 - val_loss: 0.1220 - val_acc: 0.8865\n",
            "Epoch 665/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8874 - val_loss: 0.1213 - val_acc: 0.8868\n",
            "Epoch 666/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8737 - val_loss: 0.1206 - val_acc: 0.8874\n",
            "Epoch 667/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8862 - val_loss: 0.1206 - val_acc: 0.8879\n",
            "Epoch 668/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2758 - acc: 0.8732 - val_loss: 0.1220 - val_acc: 0.8873\n",
            "Epoch 669/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8815 - val_loss: 0.1250 - val_acc: 0.8869\n",
            "Epoch 670/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8812 - val_loss: 0.1260 - val_acc: 0.8872\n",
            "Epoch 671/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8889 - val_loss: 0.1245 - val_acc: 0.8880\n",
            "Epoch 672/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1514 - acc: 0.8856 - val_loss: 0.1235 - val_acc: 0.8885\n",
            "Epoch 673/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1518 - acc: 0.8816 - val_loss: 0.1231 - val_acc: 0.8888\n",
            "Epoch 674/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8813 - val_loss: 0.1231 - val_acc: 0.8891\n",
            "Epoch 675/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8837 - val_loss: 0.1232 - val_acc: 0.8893\n",
            "Epoch 676/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8882 - val_loss: 0.1232 - val_acc: 0.8893\n",
            "Epoch 677/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8870 - val_loss: 0.1229 - val_acc: 0.8893\n",
            "Epoch 678/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2082 - acc: 0.8764 - val_loss: 0.1233 - val_acc: 0.8890\n",
            "Epoch 679/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8766 - val_loss: 0.1251 - val_acc: 0.8887\n",
            "Epoch 680/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8859 - val_loss: 0.1260 - val_acc: 0.8886\n",
            "Epoch 681/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8858 - val_loss: 0.1255 - val_acc: 0.8886\n",
            "Epoch 682/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8907 - val_loss: 0.1245 - val_acc: 0.8889\n",
            "Epoch 683/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8901 - val_loss: 0.1239 - val_acc: 0.8891\n",
            "Epoch 684/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8952 - val_loss: 0.1241 - val_acc: 0.8893\n",
            "Epoch 685/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8878 - val_loss: 0.1242 - val_acc: 0.8893\n",
            "Epoch 686/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8862 - val_loss: 0.1235 - val_acc: 0.8892\n",
            "Epoch 687/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8860 - val_loss: 0.1228 - val_acc: 0.8889\n",
            "Epoch 688/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2516 - acc: 0.8760 - val_loss: 0.1252 - val_acc: 0.8881\n",
            "Epoch 689/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1400 - acc: 0.8753 - val_loss: 0.1297 - val_acc: 0.8874\n",
            "Epoch 690/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8836 - val_loss: 0.1314 - val_acc: 0.8872\n",
            "Epoch 691/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8825 - val_loss: 0.1291 - val_acc: 0.8876\n",
            "Epoch 692/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8867 - val_loss: 0.1255 - val_acc: 0.8882\n",
            "Epoch 693/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8873 - val_loss: 0.1239 - val_acc: 0.8888\n",
            "Epoch 694/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8880 - val_loss: 0.1249 - val_acc: 0.8891\n",
            "Epoch 695/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8895 - val_loss: 0.1261 - val_acc: 0.8892\n",
            "Epoch 696/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8903 - val_loss: 0.1248 - val_acc: 0.8891\n",
            "Epoch 697/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8796 - val_loss: 0.1226 - val_acc: 0.8886\n",
            "Epoch 698/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8871 - val_loss: 0.1222 - val_acc: 0.8880\n",
            "Epoch 699/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8821 - val_loss: 0.1232 - val_acc: 0.8873\n",
            "Epoch 700/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1347 - acc: 0.8893 - val_loss: 0.1244 - val_acc: 0.8869\n",
            "Epoch 701/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8891 - val_loss: 0.1244 - val_acc: 0.8868\n",
            "Epoch 702/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8863 - val_loss: 0.1232 - val_acc: 0.8872\n",
            "Epoch 703/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8835 - val_loss: 0.1220 - val_acc: 0.8878\n",
            "Epoch 704/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8849 - val_loss: 0.1217 - val_acc: 0.8883\n",
            "Epoch 705/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8853 - val_loss: 0.1224 - val_acc: 0.8886\n",
            "Epoch 706/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8925 - val_loss: 0.1229 - val_acc: 0.8887\n",
            "Epoch 707/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8859 - val_loss: 0.1219 - val_acc: 0.8884\n",
            "Epoch 708/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8859 - val_loss: 0.1208 - val_acc: 0.8878\n",
            "Epoch 709/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2044 - acc: 0.8833 - val_loss: 0.1231 - val_acc: 0.8867\n",
            "Epoch 710/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8914 - val_loss: 0.1265 - val_acc: 0.8860\n",
            "Epoch 711/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8882 - val_loss: 0.1272 - val_acc: 0.8862\n",
            "Epoch 712/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8723 - val_loss: 0.1252 - val_acc: 0.8869\n",
            "Epoch 713/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8822 - val_loss: 0.1224 - val_acc: 0.8879\n",
            "Epoch 714/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8895 - val_loss: 0.1214 - val_acc: 0.8886\n",
            "Epoch 715/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8901 - val_loss: 0.1224 - val_acc: 0.8891\n",
            "Epoch 716/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8844 - val_loss: 0.1230 - val_acc: 0.8891\n",
            "Epoch 717/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8970 - val_loss: 0.1225 - val_acc: 0.8890\n",
            "Epoch 718/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8968 - val_loss: 0.1214 - val_acc: 0.8887\n",
            "Epoch 719/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8773 - val_loss: 0.1207 - val_acc: 0.8882\n",
            "Epoch 720/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8794 - val_loss: 0.1213 - val_acc: 0.8877\n",
            "Epoch 721/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8787 - val_loss: 0.1220 - val_acc: 0.8873\n",
            "Epoch 722/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8860 - val_loss: 0.1219 - val_acc: 0.8873\n",
            "Epoch 723/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8860 - val_loss: 0.1211 - val_acc: 0.8875\n",
            "Epoch 724/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8958 - val_loss: 0.1205 - val_acc: 0.8880\n",
            "Epoch 725/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8963 - val_loss: 0.1208 - val_acc: 0.8883\n",
            "Epoch 726/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8902 - val_loss: 0.1214 - val_acc: 0.8885\n",
            "Epoch 727/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8892 - val_loss: 0.1208 - val_acc: 0.8884\n",
            "Epoch 728/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8812 - val_loss: 0.1198 - val_acc: 0.8879\n",
            "Epoch 729/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8937 - val_loss: 0.1194 - val_acc: 0.8873\n",
            "Epoch 730/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8932 - val_loss: 0.1195 - val_acc: 0.8869\n",
            "Epoch 731/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8874 - val_loss: 0.1197 - val_acc: 0.8866\n",
            "Epoch 732/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8870 - val_loss: 0.1194 - val_acc: 0.8867\n",
            "Epoch 733/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2362 - acc: 0.8685 - val_loss: 0.1217 - val_acc: 0.8861\n",
            "Epoch 734/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8789 - val_loss: 0.1234 - val_acc: 0.8860\n",
            "Epoch 735/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8909 - val_loss: 0.1228 - val_acc: 0.8866\n",
            "Epoch 736/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8836 - val_loss: 0.1212 - val_acc: 0.8876\n",
            "Epoch 737/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8823 - val_loss: 0.1206 - val_acc: 0.8883\n",
            "Epoch 738/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1831 - acc: 0.8810 - val_loss: 0.1207 - val_acc: 0.8885\n",
            "Epoch 739/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8840 - val_loss: 0.1208 - val_acc: 0.8885\n",
            "Epoch 740/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8882 - val_loss: 0.1207 - val_acc: 0.8884\n",
            "Epoch 741/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8882 - val_loss: 0.1206 - val_acc: 0.8884\n",
            "Epoch 742/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8872 - val_loss: 0.1208 - val_acc: 0.8883\n",
            "Epoch 743/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8838 - val_loss: 0.1209 - val_acc: 0.8882\n",
            "Epoch 744/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8741 - val_loss: 0.1209 - val_acc: 0.8882\n",
            "Epoch 745/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8741 - val_loss: 0.1208 - val_acc: 0.8883\n",
            "Epoch 746/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1349 - acc: 0.8871 - val_loss: 0.1207 - val_acc: 0.8884\n",
            "Epoch 747/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8837 - val_loss: 0.1204 - val_acc: 0.8884\n",
            "Epoch 748/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8930 - val_loss: 0.1201 - val_acc: 0.8884\n",
            "Epoch 749/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8887 - val_loss: 0.1200 - val_acc: 0.8884\n",
            "Epoch 750/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8901 - val_loss: 0.1199 - val_acc: 0.8883\n",
            "Epoch 751/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8824 - val_loss: 0.1197 - val_acc: 0.8881\n",
            "Epoch 752/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8920 - val_loss: 0.1194 - val_acc: 0.8880\n",
            "Epoch 753/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8947 - val_loss: 0.1191 - val_acc: 0.8880\n",
            "Epoch 754/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8906 - val_loss: 0.1189 - val_acc: 0.8879\n",
            "Epoch 755/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1447 - acc: 0.8834 - val_loss: 0.1189 - val_acc: 0.8877\n",
            "Epoch 756/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8928 - val_loss: 0.1191 - val_acc: 0.8875\n",
            "Epoch 757/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8831 - val_loss: 0.1192 - val_acc: 0.8873\n",
            "Epoch 758/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8863 - val_loss: 0.1190 - val_acc: 0.8872\n",
            "Epoch 759/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8860 - val_loss: 0.1188 - val_acc: 0.8869\n",
            "Epoch 760/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8861 - val_loss: 0.1186 - val_acc: 0.8868\n",
            "Epoch 761/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8744 - val_loss: 0.1184 - val_acc: 0.8869\n",
            "Epoch 762/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8840 - val_loss: 0.1184 - val_acc: 0.8869\n",
            "Epoch 763/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8841 - val_loss: 0.1185 - val_acc: 0.8869\n",
            "Epoch 764/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8853 - val_loss: 0.1184 - val_acc: 0.8868\n",
            "Epoch 765/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8883 - val_loss: 0.1181 - val_acc: 0.8866\n",
            "Epoch 766/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1698 - acc: 0.8795 - val_loss: 0.1185 - val_acc: 0.8860\n",
            "Epoch 767/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8816 - val_loss: 0.1193 - val_acc: 0.8857\n",
            "Epoch 768/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8797 - val_loss: 0.1192 - val_acc: 0.8861\n",
            "Epoch 769/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8944 - val_loss: 0.1187 - val_acc: 0.8868\n",
            "Epoch 770/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8826 - val_loss: 0.1183 - val_acc: 0.8873\n",
            "Epoch 771/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1585 - acc: 0.8794 - val_loss: 0.1184 - val_acc: 0.8874\n",
            "Epoch 772/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8841 - val_loss: 0.1183 - val_acc: 0.8874\n",
            "Epoch 773/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8759 - val_loss: 0.1182 - val_acc: 0.8871\n",
            "Epoch 774/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8757 - val_loss: 0.1183 - val_acc: 0.8868\n",
            "Epoch 775/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8905 - val_loss: 0.1184 - val_acc: 0.8867\n",
            "Epoch 776/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1361 - acc: 0.8819 - val_loss: 0.1183 - val_acc: 0.8870\n",
            "Epoch 777/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8992 - val_loss: 0.1182 - val_acc: 0.8873\n",
            "Epoch 778/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8863 - val_loss: 0.1181 - val_acc: 0.8876\n",
            "Epoch 779/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1401 - acc: 0.8853 - val_loss: 0.1180 - val_acc: 0.8876\n",
            "Epoch 780/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8854 - val_loss: 0.1180 - val_acc: 0.8876\n",
            "Epoch 781/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8922 - val_loss: 0.1180 - val_acc: 0.8876\n",
            "Epoch 782/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8866 - val_loss: 0.1180 - val_acc: 0.8876\n",
            "Epoch 783/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8832 - val_loss: 0.1178 - val_acc: 0.8876\n",
            "Epoch 784/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8833 - val_loss: 0.1176 - val_acc: 0.8876\n",
            "Epoch 785/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8839 - val_loss: 0.1176 - val_acc: 0.8876\n",
            "Epoch 786/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8917 - val_loss: 0.1176 - val_acc: 0.8874\n",
            "Epoch 787/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8781 - val_loss: 0.1176 - val_acc: 0.8872\n",
            "Epoch 788/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8870 - val_loss: 0.1175 - val_acc: 0.8870\n",
            "Epoch 789/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8866 - val_loss: 0.1173 - val_acc: 0.8869\n",
            "Epoch 790/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8761 - val_loss: 0.1172 - val_acc: 0.8870\n",
            "Epoch 791/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8764 - val_loss: 0.1172 - val_acc: 0.8871\n",
            "Epoch 792/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8813 - val_loss: 0.1172 - val_acc: 0.8871\n",
            "Epoch 793/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8747 - val_loss: 0.1170 - val_acc: 0.8866\n",
            "Epoch 794/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1404 - acc: 0.8767 - val_loss: 0.1172 - val_acc: 0.8861\n",
            "Epoch 795/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8988 - val_loss: 0.1174 - val_acc: 0.8857\n",
            "Epoch 796/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8859 - val_loss: 0.1173 - val_acc: 0.8858\n",
            "Epoch 797/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8822 - val_loss: 0.1169 - val_acc: 0.8863\n",
            "Epoch 798/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8828 - val_loss: 0.1169 - val_acc: 0.8867\n",
            "Epoch 799/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8834 - val_loss: 0.1171 - val_acc: 0.8870\n",
            "Epoch 800/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8898 - val_loss: 0.1171 - val_acc: 0.8868\n",
            "Epoch 801/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8859 - val_loss: 0.1166 - val_acc: 0.8862\n",
            "Epoch 802/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8853 - val_loss: 0.1168 - val_acc: 0.8856\n",
            "Epoch 803/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8878 - val_loss: 0.1169 - val_acc: 0.8853\n",
            "Epoch 804/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8983 - val_loss: 0.1167 - val_acc: 0.8857\n",
            "Epoch 805/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8848 - val_loss: 0.1165 - val_acc: 0.8861\n",
            "Epoch 806/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8753 - val_loss: 0.1164 - val_acc: 0.8863\n",
            "Epoch 807/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8901 - val_loss: 0.1163 - val_acc: 0.8865\n",
            "Epoch 808/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8903 - val_loss: 0.1161 - val_acc: 0.8865\n",
            "Epoch 809/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8865 - val_loss: 0.1161 - val_acc: 0.8865\n",
            "Epoch 810/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8866 - val_loss: 0.1162 - val_acc: 0.8865\n",
            "Epoch 811/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8823 - val_loss: 0.1162 - val_acc: 0.8865\n",
            "Epoch 812/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8884 - val_loss: 0.1161 - val_acc: 0.8864\n",
            "Epoch 813/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8916 - val_loss: 0.1160 - val_acc: 0.8866\n",
            "Epoch 814/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2393 - acc: 0.8810 - val_loss: 0.1195 - val_acc: 0.8851\n",
            "Epoch 815/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8860 - val_loss: 0.1232 - val_acc: 0.8846\n",
            "Epoch 816/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8858 - val_loss: 0.1221 - val_acc: 0.8858\n",
            "Epoch 817/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2181 - acc: 0.8707 - val_loss: 0.1257 - val_acc: 0.8859\n",
            "Epoch 818/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8871 - val_loss: 0.1251 - val_acc: 0.8869\n",
            "Epoch 819/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8902 - val_loss: 0.1228 - val_acc: 0.8881\n",
            "Epoch 820/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8926 - val_loss: 0.1226 - val_acc: 0.8890\n",
            "Epoch 821/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8918 - val_loss: 0.1239 - val_acc: 0.8895\n",
            "Epoch 822/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8967 - val_loss: 0.1240 - val_acc: 0.8896\n",
            "Epoch 823/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8969 - val_loss: 0.1226 - val_acc: 0.8897\n",
            "Epoch 824/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8988 - val_loss: 0.1213 - val_acc: 0.8896\n",
            "Epoch 825/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8803 - val_loss: 0.1208 - val_acc: 0.8894\n",
            "Epoch 826/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8860 - val_loss: 0.1214 - val_acc: 0.8893\n",
            "Epoch 827/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8908 - val_loss: 0.1217 - val_acc: 0.8892\n",
            "Epoch 828/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8908 - val_loss: 0.1212 - val_acc: 0.8892\n",
            "Epoch 829/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8849 - val_loss: 0.1202 - val_acc: 0.8893\n",
            "Epoch 830/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8902 - val_loss: 0.1195 - val_acc: 0.8894\n",
            "Epoch 831/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8794 - val_loss: 0.1195 - val_acc: 0.8895\n",
            "Epoch 832/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8839 - val_loss: 0.1195 - val_acc: 0.8895\n",
            "Epoch 833/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8904 - val_loss: 0.1189 - val_acc: 0.8894\n",
            "Epoch 834/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8911 - val_loss: 0.1185 - val_acc: 0.8891\n",
            "Epoch 835/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8907 - val_loss: 0.1183 - val_acc: 0.8889\n",
            "Epoch 836/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8883 - val_loss: 0.1182 - val_acc: 0.8887\n",
            "Epoch 837/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8903 - val_loss: 0.1180 - val_acc: 0.8884\n",
            "Epoch 838/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8944 - val_loss: 0.1176 - val_acc: 0.8883\n",
            "Epoch 839/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1308 - acc: 0.8754 - val_loss: 0.1173 - val_acc: 0.8882\n",
            "Epoch 840/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8889 - val_loss: 0.1170 - val_acc: 0.8881\n",
            "Epoch 841/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8904 - val_loss: 0.1168 - val_acc: 0.8879\n",
            "Epoch 842/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8909 - val_loss: 0.1167 - val_acc: 0.8875\n",
            "Epoch 843/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8839 - val_loss: 0.1167 - val_acc: 0.8872\n",
            "Epoch 844/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8968 - val_loss: 0.1165 - val_acc: 0.8871\n",
            "Epoch 845/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8898 - val_loss: 0.1164 - val_acc: 0.8869\n",
            "Epoch 846/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8848 - val_loss: 0.1162 - val_acc: 0.8869\n",
            "Epoch 847/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8853 - val_loss: 0.1161 - val_acc: 0.8869\n",
            "Epoch 848/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8743 - val_loss: 0.1159 - val_acc: 0.8869\n",
            "Epoch 849/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8760 - val_loss: 0.1158 - val_acc: 0.8868\n",
            "Epoch 850/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8760 - val_loss: 0.1157 - val_acc: 0.8868\n",
            "Epoch 851/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8845 - val_loss: 0.1157 - val_acc: 0.8867\n",
            "Epoch 852/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8845 - val_loss: 0.1157 - val_acc: 0.8867\n",
            "Epoch 853/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8935 - val_loss: 0.1157 - val_acc: 0.8864\n",
            "Epoch 854/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8822 - val_loss: 0.1155 - val_acc: 0.8861\n",
            "Epoch 855/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8798 - val_loss: 0.1155 - val_acc: 0.8858\n",
            "Epoch 856/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8885 - val_loss: 0.1155 - val_acc: 0.8857\n",
            "Epoch 857/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8892 - val_loss: 0.1153 - val_acc: 0.8860\n",
            "Epoch 858/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8876 - val_loss: 0.1152 - val_acc: 0.8864\n",
            "Epoch 859/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8967 - val_loss: 0.1152 - val_acc: 0.8868\n",
            "Epoch 860/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8844 - val_loss: 0.1153 - val_acc: 0.8869\n",
            "Epoch 861/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2055 - acc: 0.8820 - val_loss: 0.1160 - val_acc: 0.8861\n",
            "Epoch 862/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8892 - val_loss: 0.1177 - val_acc: 0.8858\n",
            "Epoch 863/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8894 - val_loss: 0.1177 - val_acc: 0.8865\n",
            "Epoch 864/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8766 - val_loss: 0.1164 - val_acc: 0.8874\n",
            "Epoch 865/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8839 - val_loss: 0.1160 - val_acc: 0.8882\n",
            "Epoch 866/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8899 - val_loss: 0.1169 - val_acc: 0.8886\n",
            "Epoch 867/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8788 - val_loss: 0.1166 - val_acc: 0.8886\n",
            "Epoch 868/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8802 - val_loss: 0.1158 - val_acc: 0.8883\n",
            "Epoch 869/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8950 - val_loss: 0.1160 - val_acc: 0.8879\n",
            "Epoch 870/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8896 - val_loss: 0.1165 - val_acc: 0.8876\n",
            "Epoch 871/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2483 - acc: 0.8798 - val_loss: 0.1230 - val_acc: 0.8863\n",
            "Epoch 872/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8890 - val_loss: 0.1271 - val_acc: 0.8859\n",
            "Epoch 873/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1292 - acc: 0.8845 - val_loss: 0.1247 - val_acc: 0.8867\n",
            "Epoch 874/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8855 - val_loss: 0.1195 - val_acc: 0.8880\n",
            "Epoch 875/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8804 - val_loss: 0.1183 - val_acc: 0.8890\n",
            "Epoch 876/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8822 - val_loss: 0.1216 - val_acc: 0.8893\n",
            "Epoch 877/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1320 - acc: 0.8829 - val_loss: 0.1216 - val_acc: 0.8894\n",
            "Epoch 878/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8799 - val_loss: 0.1183 - val_acc: 0.8891\n",
            "Epoch 879/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8988 - val_loss: 0.1176 - val_acc: 0.8887\n",
            "Epoch 880/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8950 - val_loss: 0.1188 - val_acc: 0.8882\n",
            "Epoch 881/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8930 - val_loss: 0.1201 - val_acc: 0.8878\n",
            "Epoch 882/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8822 - val_loss: 0.1199 - val_acc: 0.8878\n",
            "Epoch 883/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8836 - val_loss: 0.1186 - val_acc: 0.8881\n",
            "Epoch 884/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8867 - val_loss: 0.1174 - val_acc: 0.8885\n",
            "Epoch 885/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2159 - acc: 0.8811 - val_loss: 0.1176 - val_acc: 0.8886\n",
            "Epoch 886/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8901 - val_loss: 0.1180 - val_acc: 0.8887\n",
            "Epoch 887/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8823 - val_loss: 0.1180 - val_acc: 0.8888\n",
            "Epoch 888/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8927 - val_loss: 0.1178 - val_acc: 0.8890\n",
            "Epoch 889/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8859 - val_loss: 0.1176 - val_acc: 0.8891\n",
            "Epoch 890/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2408 - acc: 0.8775 - val_loss: 0.1191 - val_acc: 0.8889\n",
            "Epoch 891/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8862 - val_loss: 0.1211 - val_acc: 0.8886\n",
            "Epoch 892/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8880 - val_loss: 0.1217 - val_acc: 0.8886\n",
            "Epoch 893/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8813 - val_loss: 0.1205 - val_acc: 0.8888\n",
            "Epoch 894/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8815 - val_loss: 0.1190 - val_acc: 0.8890\n",
            "Epoch 895/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8883 - val_loss: 0.1188 - val_acc: 0.8892\n",
            "Epoch 896/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8958 - val_loss: 0.1197 - val_acc: 0.8893\n",
            "Epoch 897/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8959 - val_loss: 0.1202 - val_acc: 0.8893\n",
            "Epoch 898/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8856 - val_loss: 0.1192 - val_acc: 0.8891\n",
            "Epoch 899/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8849 - val_loss: 0.1180 - val_acc: 0.8887\n",
            "Epoch 900/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8918 - val_loss: 0.1181 - val_acc: 0.8881\n",
            "Epoch 901/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8804 - val_loss: 0.1188 - val_acc: 0.8875\n",
            "Epoch 902/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8867 - val_loss: 0.1189 - val_acc: 0.8872\n",
            "Epoch 903/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8911 - val_loss: 0.1180 - val_acc: 0.8873\n",
            "Epoch 904/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8900 - val_loss: 0.1169 - val_acc: 0.8877\n",
            "Epoch 905/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8904 - val_loss: 0.1165 - val_acc: 0.8881\n",
            "Epoch 906/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8864 - val_loss: 0.1170 - val_acc: 0.8884\n",
            "Epoch 907/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8908 - val_loss: 0.1172 - val_acc: 0.8883\n",
            "Epoch 908/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8892 - val_loss: 0.1166 - val_acc: 0.8881\n",
            "Epoch 909/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8886 - val_loss: 0.1156 - val_acc: 0.8874\n",
            "Epoch 910/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8882 - val_loss: 0.1159 - val_acc: 0.8865\n",
            "Epoch 911/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8875 - val_loss: 0.1164 - val_acc: 0.8859\n",
            "Epoch 912/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8866 - val_loss: 0.1163 - val_acc: 0.8858\n",
            "Epoch 913/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8746 - val_loss: 0.1157 - val_acc: 0.8860\n",
            "Epoch 914/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8806 - val_loss: 0.1151 - val_acc: 0.8865\n",
            "Epoch 915/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8813 - val_loss: 0.1151 - val_acc: 0.8869\n",
            "Epoch 916/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8919 - val_loss: 0.1154 - val_acc: 0.8869\n",
            "Epoch 917/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8906 - val_loss: 0.1153 - val_acc: 0.8868\n",
            "Epoch 918/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2185 - acc: 0.8801 - val_loss: 0.1159 - val_acc: 0.8855\n",
            "Epoch 919/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1828 - acc: 0.8738 - val_loss: 0.1217 - val_acc: 0.8837\n",
            "Epoch 920/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8702 - val_loss: 0.1254 - val_acc: 0.8836\n",
            "Epoch 921/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8700 - val_loss: 0.1235 - val_acc: 0.8852\n",
            "Epoch 922/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8804 - val_loss: 0.1192 - val_acc: 0.8872\n",
            "Epoch 923/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8809 - val_loss: 0.1175 - val_acc: 0.8885\n",
            "Epoch 924/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298 - acc: 0.8886 - val_loss: 0.1192 - val_acc: 0.8891\n",
            "Epoch 925/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8898 - val_loss: 0.1205 - val_acc: 0.8893\n",
            "Epoch 926/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1860 - acc: 0.8903 - val_loss: 0.1184 - val_acc: 0.8891\n",
            "Epoch 927/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8896 - val_loss: 0.1184 - val_acc: 0.8887\n",
            "Epoch 928/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8892 - val_loss: 0.1199 - val_acc: 0.8883\n",
            "Epoch 929/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8790 - val_loss: 0.1210 - val_acc: 0.8880\n",
            "Epoch 930/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8787 - val_loss: 0.1210 - val_acc: 0.8880\n",
            "Epoch 931/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1334 - acc: 0.8882 - val_loss: 0.1204 - val_acc: 0.8881\n",
            "Epoch 932/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8901 - val_loss: 0.1190 - val_acc: 0.8885\n",
            "Epoch 933/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8930 - val_loss: 0.1189 - val_acc: 0.8887\n",
            "Epoch 934/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8936 - val_loss: 0.1197 - val_acc: 0.8889\n",
            "Epoch 935/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8947 - val_loss: 0.1203 - val_acc: 0.8891\n",
            "Epoch 936/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8905 - val_loss: 0.1197 - val_acc: 0.8892\n",
            "Epoch 937/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8860 - val_loss: 0.1185 - val_acc: 0.8891\n",
            "Epoch 938/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8982 - val_loss: 0.1178 - val_acc: 0.8890\n",
            "Epoch 939/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8910 - val_loss: 0.1176 - val_acc: 0.8887\n",
            "Epoch 940/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8907 - val_loss: 0.1178 - val_acc: 0.8884\n",
            "Epoch 941/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8983 - val_loss: 0.1176 - val_acc: 0.8882\n",
            "Epoch 942/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8858 - val_loss: 0.1172 - val_acc: 0.8881\n",
            "Epoch 943/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8899 - val_loss: 0.1166 - val_acc: 0.8880\n",
            "Epoch 944/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8899 - val_loss: 0.1163 - val_acc: 0.8880\n",
            "Epoch 945/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8883 - val_loss: 0.1164 - val_acc: 0.8880\n",
            "Epoch 946/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - acc: 0.8777 - val_loss: 0.1167 - val_acc: 0.8877\n",
            "Epoch 947/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8841 - val_loss: 0.1168 - val_acc: 0.8874\n",
            "Epoch 948/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8821 - val_loss: 0.1165 - val_acc: 0.8873\n",
            "Epoch 949/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8887 - val_loss: 0.1158 - val_acc: 0.8873\n",
            "Epoch 950/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8887 - val_loss: 0.1155 - val_acc: 0.8873\n",
            "Epoch 951/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8783 - val_loss: 0.1155 - val_acc: 0.8873\n",
            "Epoch 952/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8931 - val_loss: 0.1156 - val_acc: 0.8873\n",
            "Epoch 953/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2191 - acc: 0.8732 - val_loss: 0.1158 - val_acc: 0.8865\n",
            "Epoch 954/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8768 - val_loss: 0.1169 - val_acc: 0.8860\n",
            "Epoch 955/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8881 - val_loss: 0.1174 - val_acc: 0.8861\n",
            "Epoch 956/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8883 - val_loss: 0.1167 - val_acc: 0.8866\n",
            "Epoch 957/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2393 - acc: 0.8714 - val_loss: 0.1190 - val_acc: 0.8867\n",
            "Epoch 958/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8875 - val_loss: 0.1198 - val_acc: 0.8872\n",
            "Epoch 959/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8896 - val_loss: 0.1189 - val_acc: 0.8880\n",
            "Epoch 960/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8943 - val_loss: 0.1178 - val_acc: 0.8886\n",
            "Epoch 961/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8948 - val_loss: 0.1178 - val_acc: 0.8890\n",
            "Epoch 962/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8931 - val_loss: 0.1183 - val_acc: 0.8891\n",
            "Epoch 963/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1844 - acc: 0.8885 - val_loss: 0.1181 - val_acc: 0.8890\n",
            "Epoch 964/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8848 - val_loss: 0.1180 - val_acc: 0.8887\n",
            "Epoch 965/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2634 - acc: 0.8736 - val_loss: 0.1220 - val_acc: 0.8880\n",
            "Epoch 966/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8886 - val_loss: 0.1267 - val_acc: 0.8876\n",
            "Epoch 967/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1366 - acc: 0.8772 - val_loss: 0.1285 - val_acc: 0.8878\n",
            "Epoch 968/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1380 - acc: 0.8773 - val_loss: 0.1265 - val_acc: 0.8883\n",
            "Epoch 969/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8856 - val_loss: 0.1230 - val_acc: 0.8890\n",
            "Epoch 970/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8747 - val_loss: 0.1215 - val_acc: 0.8894\n",
            "Epoch 971/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8833 - val_loss: 0.1224 - val_acc: 0.8896\n",
            "Epoch 972/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8739 - val_loss: 0.1229 - val_acc: 0.8897\n",
            "Epoch 973/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1436 - acc: 0.8797 - val_loss: 0.1215 - val_acc: 0.8896\n",
            "Epoch 974/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8950 - val_loss: 0.1201 - val_acc: 0.8893\n",
            "Epoch 975/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8918 - val_loss: 0.1196 - val_acc: 0.8890\n",
            "Epoch 976/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8957 - val_loss: 0.1198 - val_acc: 0.8886\n",
            "Epoch 977/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8956 - val_loss: 0.1198 - val_acc: 0.8884\n",
            "Epoch 978/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8954 - val_loss: 0.1192 - val_acc: 0.8884\n",
            "Epoch 979/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8900 - val_loss: 0.1183 - val_acc: 0.8884\n",
            "Epoch 980/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8855 - val_loss: 0.1176 - val_acc: 0.8885\n",
            "Epoch 981/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2288 - acc: 0.8805 - val_loss: 0.1182 - val_acc: 0.8883\n",
            "Epoch 982/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8895 - val_loss: 0.1190 - val_acc: 0.8882\n",
            "Epoch 983/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8911 - val_loss: 0.1193 - val_acc: 0.8882\n",
            "Epoch 984/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8912 - val_loss: 0.1189 - val_acc: 0.8884\n",
            "Epoch 985/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8914 - val_loss: 0.1182 - val_acc: 0.8886\n",
            "Epoch 986/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8783 - val_loss: 0.1174 - val_acc: 0.8888\n",
            "Epoch 987/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1826 - acc: 0.8875 - val_loss: 0.1172 - val_acc: 0.8888\n",
            "Epoch 988/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8921 - val_loss: 0.1169 - val_acc: 0.8888\n",
            "Epoch 989/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8843 - val_loss: 0.1168 - val_acc: 0.8886\n",
            "Epoch 990/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8843 - val_loss: 0.1167 - val_acc: 0.8884\n",
            "Epoch 991/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8882 - val_loss: 0.1167 - val_acc: 0.8882\n",
            "Epoch 992/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8879 - val_loss: 0.1165 - val_acc: 0.8880\n",
            "Epoch 993/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8772 - val_loss: 0.1162 - val_acc: 0.8879\n",
            "Epoch 994/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8863 - val_loss: 0.1160 - val_acc: 0.8878\n",
            "Epoch 995/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8830 - val_loss: 0.1158 - val_acc: 0.8875\n",
            "Epoch 996/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8844 - val_loss: 0.1157 - val_acc: 0.8873\n",
            "Epoch 997/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8825 - val_loss: 0.1155 - val_acc: 0.8870\n",
            "Epoch 998/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8813 - val_loss: 0.1152 - val_acc: 0.8870\n",
            "Epoch 999/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8812 - val_loss: 0.1150 - val_acc: 0.8871\n",
            "Epoch 1000/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8862 - val_loss: 0.1149 - val_acc: 0.8872\n",
            "Epoch 1001/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8897 - val_loss: 0.1149 - val_acc: 0.8871\n",
            "Epoch 1002/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8825 - val_loss: 0.1150 - val_acc: 0.8870\n",
            "Epoch 1003/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8837 - val_loss: 0.1148 - val_acc: 0.8868\n",
            "Epoch 1004/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8949 - val_loss: 0.1146 - val_acc: 0.8867\n",
            "Epoch 1005/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1961 - acc: 0.8804 - val_loss: 0.1156 - val_acc: 0.8860\n",
            "Epoch 1006/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1376 - acc: 0.8710 - val_loss: 0.1173 - val_acc: 0.8853\n",
            "Epoch 1007/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8904 - val_loss: 0.1175 - val_acc: 0.8855\n",
            "Epoch 1008/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2389 - acc: 0.8664 - val_loss: 0.1205 - val_acc: 0.8853\n",
            "Epoch 1009/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8807 - val_loss: 0.1205 - val_acc: 0.8863\n",
            "Epoch 1010/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8754 - val_loss: 0.1187 - val_acc: 0.8875\n",
            "Epoch 1011/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8769 - val_loss: 0.1175 - val_acc: 0.8884\n",
            "Epoch 1012/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8883 - val_loss: 0.1180 - val_acc: 0.8890\n",
            "Epoch 1013/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8889 - val_loss: 0.1190 - val_acc: 0.8893\n",
            "Epoch 1014/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8851 - val_loss: 0.1188 - val_acc: 0.8894\n",
            "Epoch 1015/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8851 - val_loss: 0.1177 - val_acc: 0.8892\n",
            "Epoch 1016/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8797 - val_loss: 0.1170 - val_acc: 0.8889\n",
            "Epoch 1017/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8879 - val_loss: 0.1174 - val_acc: 0.8886\n",
            "Epoch 1018/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1220 - acc: 0.8856 - val_loss: 0.1180 - val_acc: 0.8883\n",
            "Epoch 1019/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2137 - acc: 0.8814 - val_loss: 0.1207 - val_acc: 0.8879\n",
            "Epoch 1020/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8822 - val_loss: 0.1218 - val_acc: 0.8879\n",
            "Epoch 1021/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8864 - val_loss: 0.1206 - val_acc: 0.8883\n",
            "Epoch 1022/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8827 - val_loss: 0.1184 - val_acc: 0.8888\n",
            "Epoch 1023/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8767 - val_loss: 0.1173 - val_acc: 0.8891\n",
            "Epoch 1024/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8789 - val_loss: 0.1175 - val_acc: 0.8893\n",
            "Epoch 1025/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1654 - acc: 0.8830 - val_loss: 0.1175 - val_acc: 0.8893\n",
            "Epoch 1026/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8867 - val_loss: 0.1169 - val_acc: 0.8890\n",
            "Epoch 1027/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8867 - val_loss: 0.1166 - val_acc: 0.8887\n",
            "Epoch 1028/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8870 - val_loss: 0.1168 - val_acc: 0.8883\n",
            "Epoch 1029/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8870 - val_loss: 0.1169 - val_acc: 0.8881\n",
            "Epoch 1030/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8901 - val_loss: 0.1166 - val_acc: 0.8880\n",
            "Epoch 1031/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8936 - val_loss: 0.1160 - val_acc: 0.8882\n",
            "Epoch 1032/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8939 - val_loss: 0.1155 - val_acc: 0.8884\n",
            "Epoch 1033/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8858 - val_loss: 0.1153 - val_acc: 0.8886\n",
            "Epoch 1034/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8889 - val_loss: 0.1151 - val_acc: 0.8885\n",
            "Epoch 1035/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8866 - val_loss: 0.1148 - val_acc: 0.8883\n",
            "Epoch 1036/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8877 - val_loss: 0.1146 - val_acc: 0.8879\n",
            "Epoch 1037/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8872 - val_loss: 0.1145 - val_acc: 0.8874\n",
            "Epoch 1038/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8876 - val_loss: 0.1144 - val_acc: 0.8870\n",
            "Epoch 1039/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8854 - val_loss: 0.1142 - val_acc: 0.8868\n",
            "Epoch 1040/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8865 - val_loss: 0.1139 - val_acc: 0.8867\n",
            "Epoch 1041/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2375 - acc: 0.8761 - val_loss: 0.1156 - val_acc: 0.8860\n",
            "Epoch 1042/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8896 - val_loss: 0.1170 - val_acc: 0.8859\n",
            "Epoch 1043/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8932 - val_loss: 0.1170 - val_acc: 0.8864\n",
            "Epoch 1044/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8938 - val_loss: 0.1159 - val_acc: 0.8872\n",
            "Epoch 1045/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8891 - val_loss: 0.1150 - val_acc: 0.8880\n",
            "Epoch 1046/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8872 - val_loss: 0.1152 - val_acc: 0.8885\n",
            "Epoch 1047/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8944 - val_loss: 0.1160 - val_acc: 0.8887\n",
            "Epoch 1048/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8928 - val_loss: 0.1157 - val_acc: 0.8886\n",
            "Epoch 1049/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8809 - val_loss: 0.1147 - val_acc: 0.8882\n",
            "Epoch 1050/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8781 - val_loss: 0.1144 - val_acc: 0.8876\n",
            "Epoch 1051/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8843 - val_loss: 0.1150 - val_acc: 0.8871\n",
            "Epoch 1052/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8933 - val_loss: 0.1153 - val_acc: 0.8869\n",
            "Epoch 1053/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8903 - val_loss: 0.1151 - val_acc: 0.8870\n",
            "Epoch 1054/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8733 - val_loss: 0.1144 - val_acc: 0.8874\n",
            "Epoch 1055/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8791 - val_loss: 0.1139 - val_acc: 0.8878\n",
            "Epoch 1056/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2299 - acc: 0.8681 - val_loss: 0.1148 - val_acc: 0.8874\n",
            "Epoch 1057/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8740 - val_loss: 0.1163 - val_acc: 0.8870\n",
            "Epoch 1058/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8897 - val_loss: 0.1165 - val_acc: 0.8872\n",
            "Epoch 1059/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8897 - val_loss: 0.1157 - val_acc: 0.8876\n",
            "Epoch 1060/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8917 - val_loss: 0.1148 - val_acc: 0.8881\n",
            "Epoch 1061/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8901 - val_loss: 0.1149 - val_acc: 0.8885\n",
            "Epoch 1062/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8880 - val_loss: 0.1152 - val_acc: 0.8887\n",
            "Epoch 1063/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8856 - val_loss: 0.1152 - val_acc: 0.8886\n",
            "Epoch 1064/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8857 - val_loss: 0.1147 - val_acc: 0.8883\n",
            "Epoch 1065/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8847 - val_loss: 0.1142 - val_acc: 0.8879\n",
            "Epoch 1066/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8875 - val_loss: 0.1143 - val_acc: 0.8875\n",
            "Epoch 1067/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8883 - val_loss: 0.1144 - val_acc: 0.8872\n",
            "Epoch 1068/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1470 - acc: 0.8723 - val_loss: 0.1146 - val_acc: 0.8871\n",
            "Epoch 1069/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8861 - val_loss: 0.1142 - val_acc: 0.8874\n",
            "Epoch 1070/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8840 - val_loss: 0.1139 - val_acc: 0.8877\n",
            "Epoch 1071/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2655 - acc: 0.8683 - val_loss: 0.1159 - val_acc: 0.8873\n",
            "Epoch 1072/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8814 - val_loss: 0.1178 - val_acc: 0.8871\n",
            "Epoch 1073/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8781 - val_loss: 0.1180 - val_acc: 0.8874\n",
            "Epoch 1074/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1914 - acc: 0.8745 - val_loss: 0.1193 - val_acc: 0.8875\n",
            "Epoch 1075/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8801 - val_loss: 0.1188 - val_acc: 0.8880\n",
            "Epoch 1076/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8805 - val_loss: 0.1175 - val_acc: 0.8886\n",
            "Epoch 1077/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8870 - val_loss: 0.1169 - val_acc: 0.8890\n",
            "Epoch 1078/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8876 - val_loss: 0.1176 - val_acc: 0.8892\n",
            "Epoch 1079/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8786 - val_loss: 0.1179 - val_acc: 0.8892\n",
            "Epoch 1080/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8787 - val_loss: 0.1172 - val_acc: 0.8890\n",
            "Epoch 1081/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8853 - val_loss: 0.1165 - val_acc: 0.8886\n",
            "Epoch 1082/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8850 - val_loss: 0.1164 - val_acc: 0.8882\n",
            "Epoch 1083/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8894 - val_loss: 0.1164 - val_acc: 0.8878\n",
            "Epoch 1084/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8903 - val_loss: 0.1164 - val_acc: 0.8876\n",
            "Epoch 1085/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8902 - val_loss: 0.1160 - val_acc: 0.8876\n",
            "Epoch 1086/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8887 - val_loss: 0.1154 - val_acc: 0.8877\n",
            "Epoch 1087/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8934 - val_loss: 0.1149 - val_acc: 0.8880\n",
            "Epoch 1088/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8862 - val_loss: 0.1145 - val_acc: 0.8881\n",
            "Epoch 1089/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8849 - val_loss: 0.1142 - val_acc: 0.8880\n",
            "Epoch 1090/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8750 - val_loss: 0.1139 - val_acc: 0.8878\n",
            "Epoch 1091/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1525 - acc: 0.8748 - val_loss: 0.1138 - val_acc: 0.8872\n",
            "Epoch 1092/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2347 - acc: 0.8749 - val_loss: 0.1164 - val_acc: 0.8860\n",
            "Epoch 1093/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1225 - acc: 0.8808 - val_loss: 0.1192 - val_acc: 0.8853\n",
            "Epoch 1094/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8847 - val_loss: 0.1191 - val_acc: 0.8857\n",
            "Epoch 1095/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8845 - val_loss: 0.1168 - val_acc: 0.8868\n",
            "Epoch 1096/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8871 - val_loss: 0.1150 - val_acc: 0.8880\n",
            "Epoch 1097/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8882 - val_loss: 0.1156 - val_acc: 0.8887\n",
            "Epoch 1098/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8794 - val_loss: 0.1164 - val_acc: 0.8889\n",
            "Epoch 1099/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8871 - val_loss: 0.1156 - val_acc: 0.8887\n",
            "Epoch 1100/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8872 - val_loss: 0.1143 - val_acc: 0.8881\n",
            "Epoch 1101/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8826 - val_loss: 0.1143 - val_acc: 0.8872\n",
            "Epoch 1102/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8903 - val_loss: 0.1150 - val_acc: 0.8865\n",
            "Epoch 1103/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8885 - val_loss: 0.1152 - val_acc: 0.8861\n",
            "Epoch 1104/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8820 - val_loss: 0.1145 - val_acc: 0.8863\n",
            "Epoch 1105/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8849 - val_loss: 0.1135 - val_acc: 0.8869\n",
            "Epoch 1106/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8857 - val_loss: 0.1131 - val_acc: 0.8874\n",
            "Epoch 1107/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8842 - val_loss: 0.1135 - val_acc: 0.8878\n",
            "Epoch 1108/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8906 - val_loss: 0.1137 - val_acc: 0.8879\n",
            "Epoch 1109/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8916 - val_loss: 0.1131 - val_acc: 0.8875\n",
            "Epoch 1110/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8847 - val_loss: 0.1125 - val_acc: 0.8869\n",
            "Epoch 1111/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8800 - val_loss: 0.1126 - val_acc: 0.8860\n",
            "Epoch 1112/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8830 - val_loss: 0.1127 - val_acc: 0.8855\n",
            "Epoch 1113/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8803 - val_loss: 0.1131 - val_acc: 0.8850\n",
            "Epoch 1114/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8874 - val_loss: 0.1129 - val_acc: 0.8851\n",
            "Epoch 1115/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8712 - val_loss: 0.1123 - val_acc: 0.8858\n",
            "Epoch 1116/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8810 - val_loss: 0.1123 - val_acc: 0.8865\n",
            "Epoch 1117/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8881 - val_loss: 0.1124 - val_acc: 0.8868\n",
            "Epoch 1118/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8825 - val_loss: 0.1122 - val_acc: 0.8867\n",
            "Epoch 1119/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8941 - val_loss: 0.1119 - val_acc: 0.8863\n",
            "Epoch 1120/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8938 - val_loss: 0.1120 - val_acc: 0.8858\n",
            "Epoch 1121/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8860 - val_loss: 0.1122 - val_acc: 0.8856\n",
            "Epoch 1122/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8761 - val_loss: 0.1119 - val_acc: 0.8859\n",
            "Epoch 1123/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8766 - val_loss: 0.1116 - val_acc: 0.8865\n",
            "Epoch 1124/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8731 - val_loss: 0.1117 - val_acc: 0.8869\n",
            "Epoch 1125/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8858 - val_loss: 0.1117 - val_acc: 0.8869\n",
            "Epoch 1126/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8894 - val_loss: 0.1116 - val_acc: 0.8865\n",
            "Epoch 1127/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8949 - val_loss: 0.1117 - val_acc: 0.8862\n",
            "Epoch 1128/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8881 - val_loss: 0.1116 - val_acc: 0.8861\n",
            "Epoch 1129/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8867 - val_loss: 0.1114 - val_acc: 0.8861\n",
            "Epoch 1130/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8788 - val_loss: 0.1113 - val_acc: 0.8862\n",
            "Epoch 1131/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8789 - val_loss: 0.1112 - val_acc: 0.8864\n",
            "Epoch 1132/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8927 - val_loss: 0.1113 - val_acc: 0.8867\n",
            "Epoch 1133/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8827 - val_loss: 0.1112 - val_acc: 0.8865\n",
            "Epoch 1134/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8871 - val_loss: 0.1111 - val_acc: 0.8863\n",
            "Epoch 1135/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8805 - val_loss: 0.1111 - val_acc: 0.8861\n",
            "Epoch 1136/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8785 - val_loss: 0.1111 - val_acc: 0.8859\n",
            "Epoch 1137/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8911 - val_loss: 0.1110 - val_acc: 0.8859\n",
            "Epoch 1138/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2255 - acc: 0.8696 - val_loss: 0.1130 - val_acc: 0.8848\n",
            "Epoch 1139/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8788 - val_loss: 0.1145 - val_acc: 0.8847\n",
            "Epoch 1140/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8879 - val_loss: 0.1135 - val_acc: 0.8858\n",
            "Epoch 1141/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8808 - val_loss: 0.1123 - val_acc: 0.8871\n",
            "Epoch 1142/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1600 - acc: 0.8813 - val_loss: 0.1124 - val_acc: 0.8877\n",
            "Epoch 1143/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2743 - acc: 0.8736 - val_loss: 0.1161 - val_acc: 0.8867\n",
            "Epoch 1144/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8847 - val_loss: 0.1203 - val_acc: 0.8863\n",
            "Epoch 1145/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8816 - val_loss: 0.1205 - val_acc: 0.8869\n",
            "Epoch 1146/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8761 - val_loss: 0.1182 - val_acc: 0.8881\n",
            "Epoch 1147/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2502 - acc: 0.8721 - val_loss: 0.1194 - val_acc: 0.8887\n",
            "Epoch 1148/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8892 - val_loss: 0.1193 - val_acc: 0.8893\n",
            "Epoch 1149/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8847 - val_loss: 0.1190 - val_acc: 0.8896\n",
            "Epoch 1150/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8901 - val_loss: 0.1194 - val_acc: 0.8898\n",
            "Epoch 1151/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8912 - val_loss: 0.1201 - val_acc: 0.8899\n",
            "Epoch 1152/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8845 - val_loss: 0.1202 - val_acc: 0.8898\n",
            "Epoch 1153/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8844 - val_loss: 0.1198 - val_acc: 0.8898\n",
            "Epoch 1154/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8969 - val_loss: 0.1196 - val_acc: 0.8897\n",
            "Epoch 1155/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8923 - val_loss: 0.1194 - val_acc: 0.8896\n",
            "Epoch 1156/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8845 - val_loss: 0.1190 - val_acc: 0.8895\n",
            "Epoch 1157/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8843 - val_loss: 0.1184 - val_acc: 0.8895\n",
            "Epoch 1158/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8944 - val_loss: 0.1178 - val_acc: 0.8895\n",
            "Epoch 1159/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8943 - val_loss: 0.1174 - val_acc: 0.8894\n",
            "Epoch 1160/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8857 - val_loss: 0.1170 - val_acc: 0.8894\n",
            "Epoch 1161/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8881 - val_loss: 0.1167 - val_acc: 0.8894\n",
            "Epoch 1162/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8904 - val_loss: 0.1161 - val_acc: 0.8893\n",
            "Epoch 1163/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8880 - val_loss: 0.1154 - val_acc: 0.8891\n",
            "Epoch 1164/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2302 - acc: 0.8777 - val_loss: 0.1162 - val_acc: 0.8887\n",
            "Epoch 1165/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8857 - val_loss: 0.1180 - val_acc: 0.8882\n",
            "Epoch 1166/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8831 - val_loss: 0.1184 - val_acc: 0.8881\n",
            "Epoch 1167/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8867 - val_loss: 0.1173 - val_acc: 0.8883\n",
            "Epoch 1168/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8896 - val_loss: 0.1159 - val_acc: 0.8886\n",
            "Epoch 1169/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8834 - val_loss: 0.1153 - val_acc: 0.8890\n",
            "Epoch 1170/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1248 - acc: 0.8850 - val_loss: 0.1153 - val_acc: 0.8891\n",
            "Epoch 1171/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8859 - val_loss: 0.1151 - val_acc: 0.8890\n",
            "Epoch 1172/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8858 - val_loss: 0.1143 - val_acc: 0.8887\n",
            "Epoch 1173/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8842 - val_loss: 0.1138 - val_acc: 0.8882\n",
            "Epoch 1174/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8853 - val_loss: 0.1138 - val_acc: 0.8876\n",
            "Epoch 1175/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8764 - val_loss: 0.1140 - val_acc: 0.8870\n",
            "Epoch 1176/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1431 - acc: 0.8875 - val_loss: 0.1145 - val_acc: 0.8864\n",
            "Epoch 1177/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8889 - val_loss: 0.1149 - val_acc: 0.8862\n",
            "Epoch 1178/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8987 - val_loss: 0.1140 - val_acc: 0.8866\n",
            "Epoch 1179/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8990 - val_loss: 0.1129 - val_acc: 0.8873\n",
            "Epoch 1180/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8859 - val_loss: 0.1126 - val_acc: 0.8879\n",
            "Epoch 1181/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8912 - val_loss: 0.1132 - val_acc: 0.8882\n",
            "Epoch 1182/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8860 - val_loss: 0.1133 - val_acc: 0.8882\n",
            "Epoch 1183/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8927 - val_loss: 0.1125 - val_acc: 0.8878\n",
            "Epoch 1184/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8866 - val_loss: 0.1117 - val_acc: 0.8871\n",
            "Epoch 1185/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8877 - val_loss: 0.1117 - val_acc: 0.8863\n",
            "Epoch 1186/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8816 - val_loss: 0.1120 - val_acc: 0.8856\n",
            "Epoch 1187/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8814 - val_loss: 0.1119 - val_acc: 0.8855\n",
            "Epoch 1188/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8895 - val_loss: 0.1115 - val_acc: 0.8858\n",
            "Epoch 1189/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8758 - val_loss: 0.1113 - val_acc: 0.8861\n",
            "Epoch 1190/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8860 - val_loss: 0.1113 - val_acc: 0.8865\n",
            "Epoch 1191/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8862 - val_loss: 0.1114 - val_acc: 0.8869\n",
            "Epoch 1192/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8890 - val_loss: 0.1112 - val_acc: 0.8870\n",
            "Epoch 1193/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8771 - val_loss: 0.1109 - val_acc: 0.8869\n",
            "Epoch 1194/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8808 - val_loss: 0.1107 - val_acc: 0.8866\n",
            "Epoch 1195/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1809 - acc: 0.8666 - val_loss: 0.1118 - val_acc: 0.8856\n",
            "Epoch 1196/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2916 - acc: 0.8664 - val_loss: 0.1189 - val_acc: 0.8837\n",
            "Epoch 1197/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8968 - val_loss: 0.1241 - val_acc: 0.8834\n",
            "Epoch 1198/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8965 - val_loss: 0.1238 - val_acc: 0.8849\n",
            "Epoch 1199/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8849 - val_loss: 0.1196 - val_acc: 0.8870\n",
            "Epoch 1200/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8830 - val_loss: 0.1167 - val_acc: 0.8886\n",
            "Epoch 1201/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8909 - val_loss: 0.1181 - val_acc: 0.8894\n",
            "Epoch 1202/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8918 - val_loss: 0.1209 - val_acc: 0.8896\n",
            "Epoch 1203/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8877 - val_loss: 0.1195 - val_acc: 0.8896\n",
            "Epoch 1204/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8916 - val_loss: 0.1168 - val_acc: 0.8893\n",
            "Epoch 1205/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8906 - val_loss: 0.1162 - val_acc: 0.8888\n",
            "Epoch 1206/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8866 - val_loss: 0.1172 - val_acc: 0.8882\n",
            "Epoch 1207/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8916 - val_loss: 0.1181 - val_acc: 0.8877\n",
            "Epoch 1208/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8773 - val_loss: 0.1177 - val_acc: 0.8876\n",
            "Epoch 1209/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1433 - acc: 0.8879 - val_loss: 0.1171 - val_acc: 0.8876\n",
            "Epoch 1210/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8916 - val_loss: 0.1160 - val_acc: 0.8880\n",
            "Epoch 1211/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8897 - val_loss: 0.1156 - val_acc: 0.8885\n",
            "Epoch 1212/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8887 - val_loss: 0.1159 - val_acc: 0.8889\n",
            "Epoch 1213/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8850 - val_loss: 0.1161 - val_acc: 0.8891\n",
            "Epoch 1214/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8884 - val_loss: 0.1152 - val_acc: 0.8891\n",
            "Epoch 1215/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8883 - val_loss: 0.1139 - val_acc: 0.8889\n",
            "Epoch 1216/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8947 - val_loss: 0.1133 - val_acc: 0.8885\n",
            "Epoch 1217/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8841 - val_loss: 0.1134 - val_acc: 0.8880\n",
            "Epoch 1218/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8893 - val_loss: 0.1137 - val_acc: 0.8875\n",
            "Epoch 1219/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8864 - val_loss: 0.1134 - val_acc: 0.8872\n",
            "Epoch 1220/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8891 - val_loss: 0.1128 - val_acc: 0.8871\n",
            "Epoch 1221/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8897 - val_loss: 0.1124 - val_acc: 0.8871\n",
            "Epoch 1222/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8910 - val_loss: 0.1123 - val_acc: 0.8873\n",
            "Epoch 1223/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8919 - val_loss: 0.1124 - val_acc: 0.8875\n",
            "Epoch 1224/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8943 - val_loss: 0.1122 - val_acc: 0.8875\n",
            "Epoch 1225/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8943 - val_loss: 0.1117 - val_acc: 0.8874\n",
            "Epoch 1226/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8773 - val_loss: 0.1111 - val_acc: 0.8870\n",
            "Epoch 1227/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8949 - val_loss: 0.1110 - val_acc: 0.8865\n",
            "Epoch 1228/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8825 - val_loss: 0.1113 - val_acc: 0.8860\n",
            "Epoch 1229/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8820 - val_loss: 0.1114 - val_acc: 0.8858\n",
            "Epoch 1230/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8819 - val_loss: 0.1113 - val_acc: 0.8858\n",
            "Epoch 1231/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8857 - val_loss: 0.1109 - val_acc: 0.8860\n",
            "Epoch 1232/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8859 - val_loss: 0.1106 - val_acc: 0.8863\n",
            "Epoch 1233/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8753 - val_loss: 0.1106 - val_acc: 0.8864\n",
            "Epoch 1234/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1802 - acc: 0.8880 - val_loss: 0.1109 - val_acc: 0.8860\n",
            "Epoch 1235/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8799 - val_loss: 0.1115 - val_acc: 0.8856\n",
            "Epoch 1236/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8864 - val_loss: 0.1118 - val_acc: 0.8857\n",
            "Epoch 1237/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8848 - val_loss: 0.1113 - val_acc: 0.8864\n",
            "Epoch 1238/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8854 - val_loss: 0.1108 - val_acc: 0.8871\n",
            "Epoch 1239/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298 - acc: 0.8852 - val_loss: 0.1108 - val_acc: 0.8874\n",
            "Epoch 1240/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8933 - val_loss: 0.1110 - val_acc: 0.8877\n",
            "Epoch 1241/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8743 - val_loss: 0.1111 - val_acc: 0.8877\n",
            "Epoch 1242/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2545 - acc: 0.8742 - val_loss: 0.1132 - val_acc: 0.8865\n",
            "Epoch 1243/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8885 - val_loss: 0.1170 - val_acc: 0.8855\n",
            "Epoch 1244/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2456 - acc: 0.8650 - val_loss: 0.1272 - val_acc: 0.8833\n",
            "Epoch 1245/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8796 - val_loss: 0.1319 - val_acc: 0.8832\n",
            "Epoch 1246/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8864 - val_loss: 0.1297 - val_acc: 0.8849\n",
            "Epoch 1247/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8880 - val_loss: 0.1240 - val_acc: 0.8872\n",
            "Epoch 1248/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1447 - acc: 0.8821 - val_loss: 0.1196 - val_acc: 0.8888\n",
            "Epoch 1249/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8874 - val_loss: 0.1189 - val_acc: 0.8896\n",
            "Epoch 1250/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8774 - val_loss: 0.1207 - val_acc: 0.8898\n",
            "Epoch 1251/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1328 - acc: 0.8793 - val_loss: 0.1207 - val_acc: 0.8898\n",
            "Epoch 1252/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8871 - val_loss: 0.1190 - val_acc: 0.8896\n",
            "Epoch 1253/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8793 - val_loss: 0.1179 - val_acc: 0.8894\n",
            "Epoch 1254/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8869 - val_loss: 0.1183 - val_acc: 0.8890\n",
            "Epoch 1255/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8946 - val_loss: 0.1191 - val_acc: 0.8888\n",
            "Epoch 1256/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8849 - val_loss: 0.1192 - val_acc: 0.8886\n",
            "Epoch 1257/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8915 - val_loss: 0.1181 - val_acc: 0.8887\n",
            "Epoch 1258/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8925 - val_loss: 0.1166 - val_acc: 0.8889\n",
            "Epoch 1259/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8897 - val_loss: 0.1157 - val_acc: 0.8892\n",
            "Epoch 1260/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8899 - val_loss: 0.1157 - val_acc: 0.8894\n",
            "Epoch 1261/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8872 - val_loss: 0.1162 - val_acc: 0.8895\n",
            "Epoch 1262/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8995 - val_loss: 0.1161 - val_acc: 0.8895\n",
            "Epoch 1263/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8869 - val_loss: 0.1150 - val_acc: 0.8894\n",
            "Epoch 1264/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8932 - val_loss: 0.1139 - val_acc: 0.8891\n",
            "Epoch 1265/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8926 - val_loss: 0.1133 - val_acc: 0.8887\n",
            "Epoch 1266/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8798 - val_loss: 0.1133 - val_acc: 0.8882\n",
            "Epoch 1267/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8846 - val_loss: 0.1134 - val_acc: 0.8878\n",
            "Epoch 1268/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8895 - val_loss: 0.1132 - val_acc: 0.8875\n",
            "Epoch 1269/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2495 - acc: 0.8672 - val_loss: 0.1159 - val_acc: 0.8866\n",
            "Epoch 1270/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8786 - val_loss: 0.1178 - val_acc: 0.8863\n",
            "Epoch 1271/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8930 - val_loss: 0.1173 - val_acc: 0.8865\n",
            "Epoch 1272/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8848 - val_loss: 0.1157 - val_acc: 0.8871\n",
            "Epoch 1273/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8862 - val_loss: 0.1135 - val_acc: 0.8879\n",
            "Epoch 1274/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8904 - val_loss: 0.1127 - val_acc: 0.8886\n",
            "Epoch 1275/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8873 - val_loss: 0.1137 - val_acc: 0.8890\n",
            "Epoch 1276/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8812 - val_loss: 0.1145 - val_acc: 0.8890\n",
            "Epoch 1277/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8812 - val_loss: 0.1137 - val_acc: 0.8889\n",
            "Epoch 1278/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8821 - val_loss: 0.1123 - val_acc: 0.8884\n",
            "Epoch 1279/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8817 - val_loss: 0.1120 - val_acc: 0.8877\n",
            "Epoch 1280/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8785 - val_loss: 0.1128 - val_acc: 0.8869\n",
            "Epoch 1281/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8967 - val_loss: 0.1135 - val_acc: 0.8863\n",
            "Epoch 1282/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8902 - val_loss: 0.1132 - val_acc: 0.8861\n",
            "Epoch 1283/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1995 - acc: 0.8788 - val_loss: 0.1139 - val_acc: 0.8858\n",
            "Epoch 1284/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8824 - val_loss: 0.1135 - val_acc: 0.8862\n",
            "Epoch 1285/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8811 - val_loss: 0.1126 - val_acc: 0.8868\n",
            "Epoch 1286/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8840 - val_loss: 0.1119 - val_acc: 0.8875\n",
            "Epoch 1287/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8860 - val_loss: 0.1122 - val_acc: 0.8881\n",
            "Epoch 1288/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8895 - val_loss: 0.1128 - val_acc: 0.8883\n",
            "Epoch 1289/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8919 - val_loss: 0.1130 - val_acc: 0.8884\n",
            "Epoch 1290/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8922 - val_loss: 0.1123 - val_acc: 0.8882\n",
            "Epoch 1291/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8853 - val_loss: 0.1114 - val_acc: 0.8879\n",
            "Epoch 1292/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8865 - val_loss: 0.1110 - val_acc: 0.8874\n",
            "Epoch 1293/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8845 - val_loss: 0.1113 - val_acc: 0.8869\n",
            "Epoch 1294/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8894 - val_loss: 0.1115 - val_acc: 0.8866\n",
            "Epoch 1295/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8864 - val_loss: 0.1114 - val_acc: 0.8865\n",
            "Epoch 1296/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8754 - val_loss: 0.1109 - val_acc: 0.8868\n",
            "Epoch 1297/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8757 - val_loss: 0.1106 - val_acc: 0.8872\n",
            "Epoch 1298/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8862 - val_loss: 0.1105 - val_acc: 0.8875\n",
            "Epoch 1299/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8937 - val_loss: 0.1106 - val_acc: 0.8877\n",
            "Epoch 1300/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8835 - val_loss: 0.1106 - val_acc: 0.8877\n",
            "Epoch 1301/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8834 - val_loss: 0.1101 - val_acc: 0.8874\n",
            "Epoch 1302/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8912 - val_loss: 0.1099 - val_acc: 0.8868\n",
            "Epoch 1303/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8797 - val_loss: 0.1100 - val_acc: 0.8862\n",
            "Epoch 1304/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8865 - val_loss: 0.1102 - val_acc: 0.8856\n",
            "Epoch 1305/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8900 - val_loss: 0.1101 - val_acc: 0.8855\n",
            "Epoch 1306/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8900 - val_loss: 0.1096 - val_acc: 0.8858\n",
            "Epoch 1307/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8881 - val_loss: 0.1094 - val_acc: 0.8862\n",
            "Epoch 1308/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8884 - val_loss: 0.1095 - val_acc: 0.8866\n",
            "Epoch 1309/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8875 - val_loss: 0.1097 - val_acc: 0.8869\n",
            "Epoch 1310/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8896 - val_loss: 0.1096 - val_acc: 0.8869\n",
            "Epoch 1311/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8898 - val_loss: 0.1092 - val_acc: 0.8865\n",
            "Epoch 1312/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8878 - val_loss: 0.1091 - val_acc: 0.8859\n",
            "Epoch 1313/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8874 - val_loss: 0.1092 - val_acc: 0.8854\n",
            "Epoch 1314/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8862 - val_loss: 0.1092 - val_acc: 0.8852\n",
            "Epoch 1315/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8739 - val_loss: 0.1093 - val_acc: 0.8850\n",
            "Epoch 1316/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8738 - val_loss: 0.1092 - val_acc: 0.8849\n",
            "Epoch 1317/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8800 - val_loss: 0.1091 - val_acc: 0.8851\n",
            "Epoch 1318/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8900 - val_loss: 0.1089 - val_acc: 0.8855\n",
            "Epoch 1319/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8890 - val_loss: 0.1090 - val_acc: 0.8860\n",
            "Epoch 1320/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8879 - val_loss: 0.1090 - val_acc: 0.8862\n",
            "Epoch 1321/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8770 - val_loss: 0.1087 - val_acc: 0.8860\n",
            "Epoch 1322/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8769 - val_loss: 0.1087 - val_acc: 0.8855\n",
            "Epoch 1323/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8723 - val_loss: 0.1090 - val_acc: 0.8850\n",
            "Epoch 1324/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8801 - val_loss: 0.1091 - val_acc: 0.8848\n",
            "Epoch 1325/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8857 - val_loss: 0.1087 - val_acc: 0.8854\n",
            "Epoch 1326/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8863 - val_loss: 0.1086 - val_acc: 0.8861\n",
            "Epoch 1327/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2145 - acc: 0.8758 - val_loss: 0.1092 - val_acc: 0.8855\n",
            "Epoch 1328/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8827 - val_loss: 0.1107 - val_acc: 0.8850\n",
            "Epoch 1329/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8850 - val_loss: 0.1111 - val_acc: 0.8854\n",
            "Epoch 1330/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8847 - val_loss: 0.1107 - val_acc: 0.8862\n",
            "Epoch 1331/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8855 - val_loss: 0.1101 - val_acc: 0.8871\n",
            "Epoch 1332/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1636 - acc: 0.8803 - val_loss: 0.1103 - val_acc: 0.8872\n",
            "Epoch 1333/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8861 - val_loss: 0.1104 - val_acc: 0.8873\n",
            "Epoch 1334/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1450 - acc: 0.8876 - val_loss: 0.1109 - val_acc: 0.8873\n",
            "Epoch 1335/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1383 - acc: 0.8913 - val_loss: 0.1118 - val_acc: 0.8873\n",
            "Epoch 1336/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8935 - val_loss: 0.1120 - val_acc: 0.8876\n",
            "Epoch 1337/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8886 - val_loss: 0.1117 - val_acc: 0.8881\n",
            "Epoch 1338/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8891 - val_loss: 0.1116 - val_acc: 0.8886\n",
            "Epoch 1339/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8852 - val_loss: 0.1118 - val_acc: 0.8888\n",
            "Epoch 1340/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8983 - val_loss: 0.1119 - val_acc: 0.8889\n",
            "Epoch 1341/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8984 - val_loss: 0.1117 - val_acc: 0.8888\n",
            "Epoch 1342/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8905 - val_loss: 0.1112 - val_acc: 0.8885\n",
            "Epoch 1343/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8980 - val_loss: 0.1109 - val_acc: 0.8881\n",
            "Epoch 1344/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8989 - val_loss: 0.1109 - val_acc: 0.8878\n",
            "Epoch 1345/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2152 - acc: 0.8761 - val_loss: 0.1128 - val_acc: 0.8871\n",
            "Epoch 1346/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8887 - val_loss: 0.1145 - val_acc: 0.8869\n",
            "Epoch 1347/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8873 - val_loss: 0.1143 - val_acc: 0.8871\n",
            "Epoch 1348/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8938 - val_loss: 0.1129 - val_acc: 0.8878\n",
            "Epoch 1349/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8811 - val_loss: 0.1119 - val_acc: 0.8886\n",
            "Epoch 1350/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8829 - val_loss: 0.1120 - val_acc: 0.8890\n",
            "Epoch 1351/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8857 - val_loss: 0.1123 - val_acc: 0.8891\n",
            "Epoch 1352/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1313 - acc: 0.8874 - val_loss: 0.1113 - val_acc: 0.8888\n",
            "Epoch 1353/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2176 - acc: 0.8829 - val_loss: 0.1117 - val_acc: 0.8881\n",
            "Epoch 1354/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8942 - val_loss: 0.1139 - val_acc: 0.8873\n",
            "Epoch 1355/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2723 - acc: 0.8616 - val_loss: 0.1224 - val_acc: 0.8856\n",
            "Epoch 1356/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2198 - acc: 0.8659 - val_loss: 0.1352 - val_acc: 0.8837\n",
            "Epoch 1357/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8853 - val_loss: 0.1399 - val_acc: 0.8840\n",
            "Epoch 1358/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1899 - acc: 0.8651 - val_loss: 0.1405 - val_acc: 0.8851\n",
            "Epoch 1359/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1428 - acc: 0.8815 - val_loss: 0.1336 - val_acc: 0.8869\n",
            "Epoch 1360/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1340 - acc: 0.8880 - val_loss: 0.1247 - val_acc: 0.8886\n",
            "Epoch 1361/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8916 - val_loss: 0.1206 - val_acc: 0.8895\n",
            "Epoch 1362/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8810 - val_loss: 0.1228 - val_acc: 0.8899\n",
            "Epoch 1363/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8957 - val_loss: 0.1279 - val_acc: 0.8900\n",
            "Epoch 1364/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8939 - val_loss: 0.1297 - val_acc: 0.8900\n",
            "Epoch 1365/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1450 - acc: 0.8827 - val_loss: 0.1250 - val_acc: 0.8900\n",
            "Epoch 1366/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8859 - val_loss: 0.1202 - val_acc: 0.8899\n",
            "Epoch 1367/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8859 - val_loss: 0.1189 - val_acc: 0.8898\n",
            "Epoch 1368/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8841 - val_loss: 0.1206 - val_acc: 0.8895\n",
            "Epoch 1369/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8790 - val_loss: 0.1227 - val_acc: 0.8893\n",
            "Epoch 1370/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8866 - val_loss: 0.1235 - val_acc: 0.8892\n",
            "Epoch 1371/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8751 - val_loss: 0.1223 - val_acc: 0.8892\n",
            "Epoch 1372/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8831 - val_loss: 0.1199 - val_acc: 0.8893\n",
            "Epoch 1373/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8903 - val_loss: 0.1174 - val_acc: 0.8894\n",
            "Epoch 1374/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8905 - val_loss: 0.1160 - val_acc: 0.8896\n",
            "Epoch 1375/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8737 - val_loss: 0.1159 - val_acc: 0.8897\n",
            "Epoch 1376/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8950 - val_loss: 0.1165 - val_acc: 0.8897\n",
            "Epoch 1377/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8924 - val_loss: 0.1166 - val_acc: 0.8897\n",
            "Epoch 1378/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8963 - val_loss: 0.1158 - val_acc: 0.8896\n",
            "Epoch 1379/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8836 - val_loss: 0.1141 - val_acc: 0.8893\n",
            "Epoch 1380/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8963 - val_loss: 0.1129 - val_acc: 0.8890\n",
            "Epoch 1381/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8905 - val_loss: 0.1125 - val_acc: 0.8885\n",
            "Epoch 1382/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8857 - val_loss: 0.1127 - val_acc: 0.8880\n",
            "Epoch 1383/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8872 - val_loss: 0.1130 - val_acc: 0.8875\n",
            "Epoch 1384/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8879 - val_loss: 0.1128 - val_acc: 0.8872\n",
            "Epoch 1385/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8906 - val_loss: 0.1122 - val_acc: 0.8872\n",
            "Epoch 1386/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8906 - val_loss: 0.1113 - val_acc: 0.8874\n",
            "Epoch 1387/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8903 - val_loss: 0.1108 - val_acc: 0.8877\n",
            "Epoch 1388/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8886 - val_loss: 0.1107 - val_acc: 0.8879\n",
            "Epoch 1389/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8914 - val_loss: 0.1109 - val_acc: 0.8880\n",
            "Epoch 1390/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8914 - val_loss: 0.1108 - val_acc: 0.8879\n",
            "Epoch 1391/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8842 - val_loss: 0.1103 - val_acc: 0.8875\n",
            "Epoch 1392/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8840 - val_loss: 0.1096 - val_acc: 0.8868\n",
            "Epoch 1393/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8845 - val_loss: 0.1095 - val_acc: 0.8860\n",
            "Epoch 1394/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8863 - val_loss: 0.1098 - val_acc: 0.8852\n",
            "Epoch 1395/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8741 - val_loss: 0.1100 - val_acc: 0.8848\n",
            "Epoch 1396/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1549 - acc: 0.8697 - val_loss: 0.1101 - val_acc: 0.8845\n",
            "Epoch 1397/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8816 - val_loss: 0.1098 - val_acc: 0.8849\n",
            "Epoch 1398/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3186 - acc: 0.8584 - val_loss: 0.1138 - val_acc: 0.8834\n",
            "Epoch 1399/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1605 - acc: 0.8725 - val_loss: 0.1195 - val_acc: 0.8823\n",
            "Epoch 1400/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2278 - acc: 0.8559 - val_loss: 0.1293 - val_acc: 0.8807\n",
            "Epoch 1401/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8804 - val_loss: 0.1326 - val_acc: 0.8819\n",
            "Epoch 1402/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8855 - val_loss: 0.1293 - val_acc: 0.8845\n",
            "Epoch 1403/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8879 - val_loss: 0.1231 - val_acc: 0.8870\n",
            "Epoch 1404/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1376 - acc: 0.8809 - val_loss: 0.1192 - val_acc: 0.8886\n",
            "Epoch 1405/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8881 - val_loss: 0.1190 - val_acc: 0.8893\n",
            "Epoch 1406/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8976 - val_loss: 0.1213 - val_acc: 0.8897\n",
            "Epoch 1407/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8760 - val_loss: 0.1218 - val_acc: 0.8898\n",
            "Epoch 1408/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2130 - acc: 0.8832 - val_loss: 0.1192 - val_acc: 0.8897\n",
            "Epoch 1409/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8948 - val_loss: 0.1178 - val_acc: 0.8895\n",
            "Epoch 1410/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8857 - val_loss: 0.1178 - val_acc: 0.8893\n",
            "Epoch 1411/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8883 - val_loss: 0.1189 - val_acc: 0.8890\n",
            "Epoch 1412/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8853 - val_loss: 0.1200 - val_acc: 0.8889\n",
            "Epoch 1413/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8935 - val_loss: 0.1204 - val_acc: 0.8888\n",
            "Epoch 1414/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8895 - val_loss: 0.1199 - val_acc: 0.8889\n",
            "Epoch 1415/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8895 - val_loss: 0.1188 - val_acc: 0.8891\n",
            "Epoch 1416/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8891 - val_loss: 0.1175 - val_acc: 0.8893\n",
            "Epoch 1417/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8853 - val_loss: 0.1167 - val_acc: 0.8895\n",
            "Epoch 1418/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1920 - acc: 0.8862 - val_loss: 0.1163 - val_acc: 0.8896\n",
            "Epoch 1419/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8888 - val_loss: 0.1161 - val_acc: 0.8897\n",
            "Epoch 1420/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8918 - val_loss: 0.1159 - val_acc: 0.8897\n",
            "Epoch 1421/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8843 - val_loss: 0.1157 - val_acc: 0.8897\n",
            "Epoch 1422/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8883 - val_loss: 0.1154 - val_acc: 0.8897\n",
            "Epoch 1423/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8840 - val_loss: 0.1150 - val_acc: 0.8896\n",
            "Epoch 1424/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8775 - val_loss: 0.1146 - val_acc: 0.8895\n",
            "Epoch 1425/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8823 - val_loss: 0.1143 - val_acc: 0.8894\n",
            "Epoch 1426/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8792 - val_loss: 0.1139 - val_acc: 0.8893\n",
            "Epoch 1427/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8840 - val_loss: 0.1135 - val_acc: 0.8892\n",
            "Epoch 1428/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8869 - val_loss: 0.1131 - val_acc: 0.8890\n",
            "Epoch 1429/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8983 - val_loss: 0.1126 - val_acc: 0.8890\n",
            "Epoch 1430/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8982 - val_loss: 0.1121 - val_acc: 0.8889\n",
            "Epoch 1431/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8875 - val_loss: 0.1117 - val_acc: 0.8889\n",
            "Epoch 1432/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8916 - val_loss: 0.1114 - val_acc: 0.8888\n",
            "Epoch 1433/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8945 - val_loss: 0.1112 - val_acc: 0.8888\n",
            "Epoch 1434/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8944 - val_loss: 0.1110 - val_acc: 0.8887\n",
            "Epoch 1435/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8791 - val_loss: 0.1106 - val_acc: 0.8885\n",
            "Epoch 1436/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2433 - acc: 0.8752 - val_loss: 0.1112 - val_acc: 0.8878\n",
            "Epoch 1437/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1861 - acc: 0.8807 - val_loss: 0.1156 - val_acc: 0.8868\n",
            "Epoch 1438/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8831 - val_loss: 0.1198 - val_acc: 0.8860\n",
            "Epoch 1439/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8810 - val_loss: 0.1211 - val_acc: 0.8858\n",
            "Epoch 1440/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8866 - val_loss: 0.1190 - val_acc: 0.8864\n",
            "Epoch 1441/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8872 - val_loss: 0.1153 - val_acc: 0.8874\n",
            "Epoch 1442/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1414 - acc: 0.8847 - val_loss: 0.1131 - val_acc: 0.8882\n",
            "Epoch 1443/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8883 - val_loss: 0.1126 - val_acc: 0.8888\n",
            "Epoch 1444/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8926 - val_loss: 0.1138 - val_acc: 0.8892\n",
            "Epoch 1445/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1530 - acc: 0.8864 - val_loss: 0.1145 - val_acc: 0.8894\n",
            "Epoch 1446/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8962 - val_loss: 0.1141 - val_acc: 0.8893\n",
            "Epoch 1447/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8914 - val_loss: 0.1132 - val_acc: 0.8891\n",
            "Epoch 1448/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2025 - acc: 0.8829 - val_loss: 0.1125 - val_acc: 0.8886\n",
            "Epoch 1449/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8945 - val_loss: 0.1136 - val_acc: 0.8881\n",
            "Epoch 1450/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8941 - val_loss: 0.1148 - val_acc: 0.8877\n",
            "Epoch 1451/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8796 - val_loss: 0.1152 - val_acc: 0.8875\n",
            "Epoch 1452/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8846 - val_loss: 0.1148 - val_acc: 0.8877\n",
            "Epoch 1453/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8847 - val_loss: 0.1137 - val_acc: 0.8880\n",
            "Epoch 1454/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1220 - acc: 0.8829 - val_loss: 0.1127 - val_acc: 0.8883\n",
            "Epoch 1455/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8946 - val_loss: 0.1123 - val_acc: 0.8887\n",
            "Epoch 1456/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8806 - val_loss: 0.1125 - val_acc: 0.8889\n",
            "Epoch 1457/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8809 - val_loss: 0.1127 - val_acc: 0.8890\n",
            "Epoch 1458/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8851 - val_loss: 0.1124 - val_acc: 0.8889\n",
            "Epoch 1459/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8773 - val_loss: 0.1115 - val_acc: 0.8887\n",
            "Epoch 1460/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8913 - val_loss: 0.1109 - val_acc: 0.8884\n",
            "Epoch 1461/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8760 - val_loss: 0.1107 - val_acc: 0.8880\n",
            "Epoch 1462/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8921 - val_loss: 0.1107 - val_acc: 0.8876\n",
            "Epoch 1463/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8822 - val_loss: 0.1107 - val_acc: 0.8873\n",
            "Epoch 1464/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8858 - val_loss: 0.1108 - val_acc: 0.8871\n",
            "Epoch 1465/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8870 - val_loss: 0.1106 - val_acc: 0.8870\n",
            "Epoch 1466/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8841 - val_loss: 0.1102 - val_acc: 0.8871\n",
            "Epoch 1467/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8842 - val_loss: 0.1098 - val_acc: 0.8874\n",
            "Epoch 1468/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2154 - acc: 0.8775 - val_loss: 0.1100 - val_acc: 0.8872\n",
            "Epoch 1469/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8826 - val_loss: 0.1111 - val_acc: 0.8870\n",
            "Epoch 1470/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8859 - val_loss: 0.1120 - val_acc: 0.8870\n",
            "Epoch 1471/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8841 - val_loss: 0.1121 - val_acc: 0.8872\n",
            "Epoch 1472/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8808 - val_loss: 0.1116 - val_acc: 0.8875\n",
            "Epoch 1473/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8812 - val_loss: 0.1109 - val_acc: 0.8877\n",
            "Epoch 1474/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8794 - val_loss: 0.1103 - val_acc: 0.8880\n",
            "Epoch 1475/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8797 - val_loss: 0.1102 - val_acc: 0.8882\n",
            "Epoch 1476/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8827 - val_loss: 0.1102 - val_acc: 0.8881\n",
            "Epoch 1477/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8828 - val_loss: 0.1100 - val_acc: 0.8880\n",
            "Epoch 1478/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8804 - val_loss: 0.1098 - val_acc: 0.8876\n",
            "Epoch 1479/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8822 - val_loss: 0.1096 - val_acc: 0.8872\n",
            "Epoch 1480/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8854 - val_loss: 0.1095 - val_acc: 0.8869\n",
            "Epoch 1481/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8870 - val_loss: 0.1095 - val_acc: 0.8867\n",
            "Epoch 1482/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8756 - val_loss: 0.1093 - val_acc: 0.8866\n",
            "Epoch 1483/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8747 - val_loss: 0.1091 - val_acc: 0.8865\n",
            "Epoch 1484/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2822 - acc: 0.8622 - val_loss: 0.1111 - val_acc: 0.8856\n",
            "Epoch 1485/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8832 - val_loss: 0.1133 - val_acc: 0.8850\n",
            "Epoch 1486/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8881 - val_loss: 0.1140 - val_acc: 0.8852\n",
            "Epoch 1487/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8883 - val_loss: 0.1129 - val_acc: 0.8861\n",
            "Epoch 1488/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8918 - val_loss: 0.1114 - val_acc: 0.8872\n",
            "Epoch 1489/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8858 - val_loss: 0.1107 - val_acc: 0.8881\n",
            "Epoch 1490/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8850 - val_loss: 0.1112 - val_acc: 0.8886\n",
            "Epoch 1491/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8902 - val_loss: 0.1118 - val_acc: 0.8887\n",
            "Epoch 1492/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8763 - val_loss: 0.1115 - val_acc: 0.8885\n",
            "Epoch 1493/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8854 - val_loss: 0.1108 - val_acc: 0.8881\n",
            "Epoch 1494/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8836 - val_loss: 0.1105 - val_acc: 0.8875\n",
            "Epoch 1495/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8830 - val_loss: 0.1109 - val_acc: 0.8868\n",
            "Epoch 1496/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8861 - val_loss: 0.1111 - val_acc: 0.8862\n",
            "Epoch 1497/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2445 - acc: 0.8669 - val_loss: 0.1137 - val_acc: 0.8854\n",
            "Epoch 1498/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8843 - val_loss: 0.1155 - val_acc: 0.8852\n",
            "Epoch 1499/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8854 - val_loss: 0.1152 - val_acc: 0.8858\n",
            "Epoch 1500/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8848 - val_loss: 0.1133 - val_acc: 0.8869\n",
            "Epoch 1501/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8779 - val_loss: 0.1116 - val_acc: 0.8879\n",
            "Epoch 1502/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8863 - val_loss: 0.1112 - val_acc: 0.8887\n",
            "Epoch 1503/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8827 - val_loss: 0.1119 - val_acc: 0.8890\n",
            "Epoch 1504/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8924 - val_loss: 0.1123 - val_acc: 0.8891\n",
            "Epoch 1505/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8887 - val_loss: 0.1116 - val_acc: 0.8889\n",
            "Epoch 1506/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8885 - val_loss: 0.1107 - val_acc: 0.8885\n",
            "Epoch 1507/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2030 - acc: 0.8787 - val_loss: 0.1112 - val_acc: 0.8875\n",
            "Epoch 1508/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8844 - val_loss: 0.1129 - val_acc: 0.8867\n",
            "Epoch 1509/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8835 - val_loss: 0.1140 - val_acc: 0.8863\n",
            "Epoch 1510/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8895 - val_loss: 0.1137 - val_acc: 0.8864\n",
            "Epoch 1511/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1389 - acc: 0.8802 - val_loss: 0.1130 - val_acc: 0.8868\n",
            "Epoch 1512/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8837 - val_loss: 0.1116 - val_acc: 0.8874\n",
            "Epoch 1513/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8797 - val_loss: 0.1105 - val_acc: 0.8879\n",
            "Epoch 1514/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8851 - val_loss: 0.1104 - val_acc: 0.8883\n",
            "Epoch 1515/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8908 - val_loss: 0.1110 - val_acc: 0.8886\n",
            "Epoch 1516/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8754 - val_loss: 0.1113 - val_acc: 0.8887\n",
            "Epoch 1517/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8847 - val_loss: 0.1106 - val_acc: 0.8885\n",
            "Epoch 1518/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8845 - val_loss: 0.1097 - val_acc: 0.8881\n",
            "Epoch 1519/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8894 - val_loss: 0.1093 - val_acc: 0.8875\n",
            "Epoch 1520/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8840 - val_loss: 0.1096 - val_acc: 0.8868\n",
            "Epoch 1521/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8824 - val_loss: 0.1099 - val_acc: 0.8862\n",
            "Epoch 1522/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8942 - val_loss: 0.1098 - val_acc: 0.8860\n",
            "Epoch 1523/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8742 - val_loss: 0.1093 - val_acc: 0.8861\n",
            "Epoch 1524/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8859 - val_loss: 0.1086 - val_acc: 0.8864\n",
            "Epoch 1525/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8777 - val_loss: 0.1081 - val_acc: 0.8869\n",
            "Epoch 1526/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8858 - val_loss: 0.1081 - val_acc: 0.8872\n",
            "Epoch 1527/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8867 - val_loss: 0.1084 - val_acc: 0.8873\n",
            "Epoch 1528/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8894 - val_loss: 0.1085 - val_acc: 0.8872\n",
            "Epoch 1529/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8951 - val_loss: 0.1083 - val_acc: 0.8870\n",
            "Epoch 1530/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8887 - val_loss: 0.1080 - val_acc: 0.8866\n",
            "Epoch 1531/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8876 - val_loss: 0.1075 - val_acc: 0.8861\n",
            "Epoch 1532/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8789 - val_loss: 0.1075 - val_acc: 0.8854\n",
            "Epoch 1533/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8913 - val_loss: 0.1075 - val_acc: 0.8851\n",
            "Epoch 1534/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8813 - val_loss: 0.1075 - val_acc: 0.8850\n",
            "Epoch 1535/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8813 - val_loss: 0.1073 - val_acc: 0.8852\n",
            "Epoch 1536/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8850 - val_loss: 0.1071 - val_acc: 0.8857\n",
            "Epoch 1537/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8804 - val_loss: 0.1071 - val_acc: 0.8861\n",
            "Epoch 1538/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8785 - val_loss: 0.1071 - val_acc: 0.8862\n",
            "Epoch 1539/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8915 - val_loss: 0.1071 - val_acc: 0.8861\n",
            "Epoch 1540/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8836 - val_loss: 0.1069 - val_acc: 0.8858\n",
            "Epoch 1541/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8891 - val_loss: 0.1069 - val_acc: 0.8855\n",
            "Epoch 1542/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8870 - val_loss: 0.1070 - val_acc: 0.8853\n",
            "Epoch 1543/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8798 - val_loss: 0.1069 - val_acc: 0.8853\n",
            "Epoch 1544/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8847 - val_loss: 0.1068 - val_acc: 0.8855\n",
            "Epoch 1545/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8853 - val_loss: 0.1067 - val_acc: 0.8858\n",
            "Epoch 1546/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8817 - val_loss: 0.1067 - val_acc: 0.8861\n",
            "Epoch 1547/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8755 - val_loss: 0.1067 - val_acc: 0.8862\n",
            "Epoch 1548/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8714 - val_loss: 0.1066 - val_acc: 0.8862\n",
            "Epoch 1549/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8873 - val_loss: 0.1065 - val_acc: 0.8861\n",
            "Epoch 1550/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8872 - val_loss: 0.1064 - val_acc: 0.8859\n",
            "Epoch 1551/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8813 - val_loss: 0.1063 - val_acc: 0.8857\n",
            "Epoch 1552/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8908 - val_loss: 0.1065 - val_acc: 0.8855\n",
            "Epoch 1553/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8860 - val_loss: 0.1065 - val_acc: 0.8855\n",
            "Epoch 1554/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8805 - val_loss: 0.1064 - val_acc: 0.8855\n",
            "Epoch 1555/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8893 - val_loss: 0.1062 - val_acc: 0.8857\n",
            "Epoch 1556/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8896 - val_loss: 0.1062 - val_acc: 0.8860\n",
            "Epoch 1557/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2370 - acc: 0.8762 - val_loss: 0.1073 - val_acc: 0.8847\n",
            "Epoch 1558/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8788 - val_loss: 0.1092 - val_acc: 0.8840\n",
            "Epoch 1559/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8783 - val_loss: 0.1094 - val_acc: 0.8845\n",
            "Epoch 1560/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8909 - val_loss: 0.1083 - val_acc: 0.8857\n",
            "Epoch 1561/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8919 - val_loss: 0.1075 - val_acc: 0.8870\n",
            "Epoch 1562/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8827 - val_loss: 0.1077 - val_acc: 0.8879\n",
            "Epoch 1563/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8866 - val_loss: 0.1084 - val_acc: 0.8883\n",
            "Epoch 1564/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8875 - val_loss: 0.1080 - val_acc: 0.8882\n",
            "Epoch 1565/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8760 - val_loss: 0.1073 - val_acc: 0.8877\n",
            "Epoch 1566/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8756 - val_loss: 0.1074 - val_acc: 0.8870\n",
            "Epoch 1567/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8837 - val_loss: 0.1080 - val_acc: 0.8863\n",
            "Epoch 1568/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8850 - val_loss: 0.1083 - val_acc: 0.8860\n",
            "Epoch 1569/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8848 - val_loss: 0.1080 - val_acc: 0.8862\n",
            "Epoch 1570/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8877 - val_loss: 0.1074 - val_acc: 0.8867\n",
            "Epoch 1571/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2450 - acc: 0.8695 - val_loss: 0.1086 - val_acc: 0.8865\n",
            "Epoch 1572/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8821 - val_loss: 0.1097 - val_acc: 0.8866\n",
            "Epoch 1573/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8943 - val_loss: 0.1099 - val_acc: 0.8870\n",
            "Epoch 1574/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8831 - val_loss: 0.1094 - val_acc: 0.8877\n",
            "Epoch 1575/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8846 - val_loss: 0.1089 - val_acc: 0.8884\n",
            "Epoch 1576/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8856 - val_loss: 0.1089 - val_acc: 0.8888\n",
            "Epoch 1577/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8860 - val_loss: 0.1092 - val_acc: 0.8889\n",
            "Epoch 1578/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8779 - val_loss: 0.1091 - val_acc: 0.8887\n",
            "Epoch 1579/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8921 - val_loss: 0.1087 - val_acc: 0.8883\n",
            "Epoch 1580/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8830 - val_loss: 0.1086 - val_acc: 0.8879\n",
            "Epoch 1581/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.9000 - val_loss: 0.1086 - val_acc: 0.8874\n",
            "Epoch 1582/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8862 - val_loss: 0.1086 - val_acc: 0.8871\n",
            "Epoch 1583/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8906 - val_loss: 0.1084 - val_acc: 0.8871\n",
            "Epoch 1584/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8918 - val_loss: 0.1079 - val_acc: 0.8872\n",
            "Epoch 1585/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8859 - val_loss: 0.1075 - val_acc: 0.8874\n",
            "Epoch 1586/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1620 - acc: 0.8801 - val_loss: 0.1076 - val_acc: 0.8874\n",
            "Epoch 1587/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8863 - val_loss: 0.1078 - val_acc: 0.8873\n",
            "Epoch 1588/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1899 - acc: 0.8728 - val_loss: 0.1086 - val_acc: 0.8869\n",
            "Epoch 1589/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8828 - val_loss: 0.1092 - val_acc: 0.8869\n",
            "Epoch 1590/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8906 - val_loss: 0.1091 - val_acc: 0.8872\n",
            "Epoch 1591/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8777 - val_loss: 0.1086 - val_acc: 0.8876\n",
            "Epoch 1592/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8867 - val_loss: 0.1082 - val_acc: 0.8880\n",
            "Epoch 1593/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8873 - val_loss: 0.1082 - val_acc: 0.8883\n",
            "Epoch 1594/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2511 - acc: 0.8704 - val_loss: 0.1087 - val_acc: 0.8880\n",
            "Epoch 1595/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8772 - val_loss: 0.1101 - val_acc: 0.8876\n",
            "Epoch 1596/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8763 - val_loss: 0.1111 - val_acc: 0.8874\n",
            "Epoch 1597/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8754 - val_loss: 0.1111 - val_acc: 0.8876\n",
            "Epoch 1598/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8944 - val_loss: 0.1103 - val_acc: 0.8880\n",
            "Epoch 1599/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.9007 - val_loss: 0.1096 - val_acc: 0.8884\n",
            "Epoch 1600/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.9010 - val_loss: 0.1095 - val_acc: 0.8886\n",
            "Epoch 1601/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8881 - val_loss: 0.1098 - val_acc: 0.8886\n",
            "Epoch 1602/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8849 - val_loss: 0.1097 - val_acc: 0.8884\n",
            "Epoch 1603/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8864 - val_loss: 0.1092 - val_acc: 0.8880\n",
            "Epoch 1604/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8906 - val_loss: 0.1087 - val_acc: 0.8876\n",
            "Epoch 1605/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8889 - val_loss: 0.1084 - val_acc: 0.8871\n",
            "Epoch 1606/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8855 - val_loss: 0.1083 - val_acc: 0.8866\n",
            "Epoch 1607/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8869 - val_loss: 0.1083 - val_acc: 0.8863\n",
            "Epoch 1608/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8992 - val_loss: 0.1079 - val_acc: 0.8865\n",
            "Epoch 1609/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8858 - val_loss: 0.1074 - val_acc: 0.8868\n",
            "Epoch 1610/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8901 - val_loss: 0.1071 - val_acc: 0.8870\n",
            "Epoch 1611/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8766 - val_loss: 0.1069 - val_acc: 0.8869\n",
            "Epoch 1612/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8908 - val_loss: 0.1067 - val_acc: 0.8868\n",
            "Epoch 1613/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8881 - val_loss: 0.1066 - val_acc: 0.8867\n",
            "Epoch 1614/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3037 - acc: 0.8612 - val_loss: 0.1086 - val_acc: 0.8850\n",
            "Epoch 1615/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8807 - val_loss: 0.1119 - val_acc: 0.8839\n",
            "Epoch 1616/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8817 - val_loss: 0.1139 - val_acc: 0.8838\n",
            "Epoch 1617/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8895 - val_loss: 0.1128 - val_acc: 0.8852\n",
            "Epoch 1618/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8810 - val_loss: 0.1103 - val_acc: 0.8869\n",
            "Epoch 1619/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8835 - val_loss: 0.1092 - val_acc: 0.8882\n",
            "Epoch 1620/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8898 - val_loss: 0.1101 - val_acc: 0.8889\n",
            "Epoch 1621/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1431 - acc: 0.8839 - val_loss: 0.1107 - val_acc: 0.8890\n",
            "Epoch 1622/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8904 - val_loss: 0.1100 - val_acc: 0.8888\n",
            "Epoch 1623/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8925 - val_loss: 0.1093 - val_acc: 0.8883\n",
            "Epoch 1624/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8922 - val_loss: 0.1093 - val_acc: 0.8875\n",
            "Epoch 1625/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8921 - val_loss: 0.1098 - val_acc: 0.8867\n",
            "Epoch 1626/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1956 - acc: 0.8759 - val_loss: 0.1112 - val_acc: 0.8859\n",
            "Epoch 1627/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8961 - val_loss: 0.1118 - val_acc: 0.8857\n",
            "Epoch 1628/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1901 - acc: 0.8675 - val_loss: 0.1139 - val_acc: 0.8855\n",
            "Epoch 1629/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8745 - val_loss: 0.1140 - val_acc: 0.8861\n",
            "Epoch 1630/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1425 - acc: 0.8785 - val_loss: 0.1132 - val_acc: 0.8871\n",
            "Epoch 1631/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8830 - val_loss: 0.1118 - val_acc: 0.8882\n",
            "Epoch 1632/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8893 - val_loss: 0.1113 - val_acc: 0.8889\n",
            "Epoch 1633/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8847 - val_loss: 0.1118 - val_acc: 0.8892\n",
            "Epoch 1634/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8894 - val_loss: 0.1121 - val_acc: 0.8894\n",
            "Epoch 1635/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8791 - val_loss: 0.1114 - val_acc: 0.8892\n",
            "Epoch 1636/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1518 - acc: 0.8871 - val_loss: 0.1103 - val_acc: 0.8888\n",
            "Epoch 1637/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8829 - val_loss: 0.1103 - val_acc: 0.8881\n",
            "Epoch 1638/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8908 - val_loss: 0.1112 - val_acc: 0.8874\n",
            "Epoch 1639/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8896 - val_loss: 0.1116 - val_acc: 0.8871\n",
            "Epoch 1640/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8865 - val_loss: 0.1112 - val_acc: 0.8872\n",
            "Epoch 1641/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8887 - val_loss: 0.1102 - val_acc: 0.8875\n",
            "Epoch 1642/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8930 - val_loss: 0.1094 - val_acc: 0.8880\n",
            "Epoch 1643/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8851 - val_loss: 0.1091 - val_acc: 0.8884\n",
            "Epoch 1644/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8857 - val_loss: 0.1093 - val_acc: 0.8886\n",
            "Epoch 1645/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8901 - val_loss: 0.1092 - val_acc: 0.8886\n",
            "Epoch 1646/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8901 - val_loss: 0.1086 - val_acc: 0.8883\n",
            "Epoch 1647/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8830 - val_loss: 0.1079 - val_acc: 0.8878\n",
            "Epoch 1648/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8908 - val_loss: 0.1078 - val_acc: 0.8870\n",
            "Epoch 1649/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8858 - val_loss: 0.1080 - val_acc: 0.8863\n",
            "Epoch 1650/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8848 - val_loss: 0.1078 - val_acc: 0.8860\n",
            "Epoch 1651/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8845 - val_loss: 0.1074 - val_acc: 0.8860\n",
            "Epoch 1652/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8752 - val_loss: 0.1068 - val_acc: 0.8863\n",
            "Epoch 1653/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8839 - val_loss: 0.1067 - val_acc: 0.8867\n",
            "Epoch 1654/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8759 - val_loss: 0.1068 - val_acc: 0.8869\n",
            "Epoch 1655/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8763 - val_loss: 0.1067 - val_acc: 0.8869\n",
            "Epoch 1656/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8841 - val_loss: 0.1064 - val_acc: 0.8867\n",
            "Epoch 1657/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8934 - val_loss: 0.1061 - val_acc: 0.8862\n",
            "Epoch 1658/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8799 - val_loss: 0.1061 - val_acc: 0.8854\n",
            "Epoch 1659/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8792 - val_loss: 0.1065 - val_acc: 0.8845\n",
            "Epoch 1660/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8877 - val_loss: 0.1066 - val_acc: 0.8843\n",
            "Epoch 1661/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8877 - val_loss: 0.1063 - val_acc: 0.8847\n",
            "Epoch 1662/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8861 - val_loss: 0.1060 - val_acc: 0.8855\n",
            "Epoch 1663/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8957 - val_loss: 0.1061 - val_acc: 0.8862\n",
            "Epoch 1664/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8964 - val_loss: 0.1062 - val_acc: 0.8865\n",
            "Epoch 1665/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8839 - val_loss: 0.1060 - val_acc: 0.8864\n",
            "Epoch 1666/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8888 - val_loss: 0.1056 - val_acc: 0.8859\n",
            "Epoch 1667/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8847 - val_loss: 0.1057 - val_acc: 0.8853\n",
            "Epoch 1668/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8764 - val_loss: 0.1061 - val_acc: 0.8847\n",
            "Epoch 1669/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2253 - acc: 0.8672 - val_loss: 0.1085 - val_acc: 0.8834\n",
            "Epoch 1670/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8745 - val_loss: 0.1096 - val_acc: 0.8834\n",
            "Epoch 1671/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1697 - acc: 0.8656 - val_loss: 0.1104 - val_acc: 0.8842\n",
            "Epoch 1672/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8756 - val_loss: 0.1097 - val_acc: 0.8858\n",
            "Epoch 1673/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8924 - val_loss: 0.1088 - val_acc: 0.8873\n",
            "Epoch 1674/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8893 - val_loss: 0.1088 - val_acc: 0.8884\n",
            "Epoch 1675/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2489 - acc: 0.8741 - val_loss: 0.1098 - val_acc: 0.8885\n",
            "Epoch 1676/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8906 - val_loss: 0.1108 - val_acc: 0.8886\n",
            "Epoch 1677/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8918 - val_loss: 0.1121 - val_acc: 0.8886\n",
            "Epoch 1678/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8865 - val_loss: 0.1131 - val_acc: 0.8887\n",
            "Epoch 1679/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8809 - val_loss: 0.1134 - val_acc: 0.8889\n",
            "Epoch 1680/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8824 - val_loss: 0.1130 - val_acc: 0.8891\n",
            "Epoch 1681/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8795 - val_loss: 0.1127 - val_acc: 0.8893\n",
            "Epoch 1682/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8993 - val_loss: 0.1127 - val_acc: 0.8894\n",
            "Epoch 1683/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8912 - val_loss: 0.1132 - val_acc: 0.8894\n",
            "Epoch 1684/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8952 - val_loss: 0.1135 - val_acc: 0.8894\n",
            "Epoch 1685/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8862 - val_loss: 0.1133 - val_acc: 0.8894\n",
            "Epoch 1686/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2450 - acc: 0.8766 - val_loss: 0.1142 - val_acc: 0.8891\n",
            "Epoch 1687/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8836 - val_loss: 0.1163 - val_acc: 0.8888\n",
            "Epoch 1688/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8851 - val_loss: 0.1177 - val_acc: 0.8886\n",
            "Epoch 1689/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8874 - val_loss: 0.1174 - val_acc: 0.8888\n",
            "Epoch 1690/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8828 - val_loss: 0.1158 - val_acc: 0.8891\n",
            "Epoch 1691/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8930 - val_loss: 0.1142 - val_acc: 0.8894\n",
            "Epoch 1692/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8933 - val_loss: 0.1138 - val_acc: 0.8896\n",
            "Epoch 1693/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8883 - val_loss: 0.1142 - val_acc: 0.8897\n",
            "Epoch 1694/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8870 - val_loss: 0.1140 - val_acc: 0.8897\n",
            "Epoch 1695/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8870 - val_loss: 0.1127 - val_acc: 0.8896\n",
            "Epoch 1696/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8890 - val_loss: 0.1112 - val_acc: 0.8893\n",
            "Epoch 1697/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8822 - val_loss: 0.1104 - val_acc: 0.8888\n",
            "Epoch 1698/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8819 - val_loss: 0.1104 - val_acc: 0.8881\n",
            "Epoch 1699/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8875 - val_loss: 0.1105 - val_acc: 0.8875\n",
            "Epoch 1700/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8871 - val_loss: 0.1102 - val_acc: 0.8873\n",
            "Epoch 1701/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8832 - val_loss: 0.1092 - val_acc: 0.8873\n",
            "Epoch 1702/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8845 - val_loss: 0.1084 - val_acc: 0.8876\n",
            "Epoch 1703/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8837 - val_loss: 0.1078 - val_acc: 0.8880\n",
            "Epoch 1704/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8914 - val_loss: 0.1076 - val_acc: 0.8881\n",
            "Epoch 1705/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8895 - val_loss: 0.1075 - val_acc: 0.8881\n",
            "Epoch 1706/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8893 - val_loss: 0.1072 - val_acc: 0.8878\n",
            "Epoch 1707/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8868 - val_loss: 0.1068 - val_acc: 0.8871\n",
            "Epoch 1708/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8911 - val_loss: 0.1066 - val_acc: 0.8862\n",
            "Epoch 1709/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8884 - val_loss: 0.1066 - val_acc: 0.8853\n",
            "Epoch 1710/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8879 - val_loss: 0.1066 - val_acc: 0.8848\n",
            "Epoch 1711/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2053 - acc: 0.8719 - val_loss: 0.1081 - val_acc: 0.8840\n",
            "Epoch 1712/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8852 - val_loss: 0.1085 - val_acc: 0.8842\n",
            "Epoch 1713/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8871 - val_loss: 0.1080 - val_acc: 0.8852\n",
            "Epoch 1714/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8762 - val_loss: 0.1071 - val_acc: 0.8864\n",
            "Epoch 1715/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8814 - val_loss: 0.1069 - val_acc: 0.8871\n",
            "Epoch 1716/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8877 - val_loss: 0.1066 - val_acc: 0.8875\n",
            "Epoch 1717/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8764 - val_loss: 0.1063 - val_acc: 0.8874\n",
            "Epoch 1718/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2022 - acc: 0.8676 - val_loss: 0.1067 - val_acc: 0.8864\n",
            "Epoch 1719/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8821 - val_loss: 0.1080 - val_acc: 0.8854\n",
            "Epoch 1720/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2472 - acc: 0.8681 - val_loss: 0.1124 - val_acc: 0.8836\n",
            "Epoch 1721/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8867 - val_loss: 0.1153 - val_acc: 0.8833\n",
            "Epoch 1722/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8858 - val_loss: 0.1147 - val_acc: 0.8848\n",
            "Epoch 1723/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8846 - val_loss: 0.1118 - val_acc: 0.8869\n",
            "Epoch 1724/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8775 - val_loss: 0.1098 - val_acc: 0.8884\n",
            "Epoch 1725/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8755 - val_loss: 0.1105 - val_acc: 0.8892\n",
            "Epoch 1726/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8846 - val_loss: 0.1126 - val_acc: 0.8895\n",
            "Epoch 1727/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8831 - val_loss: 0.1129 - val_acc: 0.8895\n",
            "Epoch 1728/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8905 - val_loss: 0.1115 - val_acc: 0.8893\n",
            "Epoch 1729/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8898 - val_loss: 0.1100 - val_acc: 0.8889\n",
            "Epoch 1730/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8876 - val_loss: 0.1100 - val_acc: 0.8883\n",
            "Epoch 1731/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8884 - val_loss: 0.1113 - val_acc: 0.8876\n",
            "Epoch 1732/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8879 - val_loss: 0.1122 - val_acc: 0.8871\n",
            "Epoch 1733/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8865 - val_loss: 0.1119 - val_acc: 0.8871\n",
            "Epoch 1734/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2257 - acc: 0.8641 - val_loss: 0.1136 - val_acc: 0.8868\n",
            "Epoch 1735/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8858 - val_loss: 0.1134 - val_acc: 0.8871\n",
            "Epoch 1736/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8895 - val_loss: 0.1118 - val_acc: 0.8878\n",
            "Epoch 1737/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8974 - val_loss: 0.1102 - val_acc: 0.8886\n",
            "Epoch 1738/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2260 - acc: 0.8803 - val_loss: 0.1109 - val_acc: 0.8889\n",
            "Epoch 1739/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8911 - val_loss: 0.1116 - val_acc: 0.8890\n",
            "Epoch 1740/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8902 - val_loss: 0.1117 - val_acc: 0.8892\n",
            "Epoch 1741/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8835 - val_loss: 0.1115 - val_acc: 0.8893\n",
            "Epoch 1742/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8858 - val_loss: 0.1112 - val_acc: 0.8893\n",
            "Epoch 1743/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8987 - val_loss: 0.1111 - val_acc: 0.8893\n",
            "Epoch 1744/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8911 - val_loss: 0.1111 - val_acc: 0.8892\n",
            "Epoch 1745/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8985 - val_loss: 0.1110 - val_acc: 0.8891\n",
            "Epoch 1746/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8993 - val_loss: 0.1107 - val_acc: 0.8890\n",
            "Epoch 1747/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8868 - val_loss: 0.1102 - val_acc: 0.8888\n",
            "Epoch 1748/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8895 - val_loss: 0.1097 - val_acc: 0.8887\n",
            "Epoch 1749/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8894 - val_loss: 0.1094 - val_acc: 0.8885\n",
            "Epoch 1750/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8812 - val_loss: 0.1091 - val_acc: 0.8884\n",
            "Epoch 1751/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1819 - acc: 0.8715 - val_loss: 0.1095 - val_acc: 0.8880\n",
            "Epoch 1752/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8851 - val_loss: 0.1098 - val_acc: 0.8879\n",
            "Epoch 1753/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1859 - acc: 0.8743 - val_loss: 0.1113 - val_acc: 0.8876\n",
            "Epoch 1754/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8885 - val_loss: 0.1117 - val_acc: 0.8876\n",
            "Epoch 1755/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8936 - val_loss: 0.1109 - val_acc: 0.8880\n",
            "Epoch 1756/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8941 - val_loss: 0.1096 - val_acc: 0.8885\n",
            "Epoch 1757/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8824 - val_loss: 0.1089 - val_acc: 0.8888\n",
            "Epoch 1758/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8900 - val_loss: 0.1089 - val_acc: 0.8890\n",
            "Epoch 1759/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8919 - val_loss: 0.1092 - val_acc: 0.8889\n",
            "Epoch 1760/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8918 - val_loss: 0.1092 - val_acc: 0.8887\n",
            "Epoch 1761/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8841 - val_loss: 0.1084 - val_acc: 0.8882\n",
            "Epoch 1762/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8892 - val_loss: 0.1078 - val_acc: 0.8875\n",
            "Epoch 1763/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8909 - val_loss: 0.1075 - val_acc: 0.8869\n",
            "Epoch 1764/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8783 - val_loss: 0.1075 - val_acc: 0.8863\n",
            "Epoch 1765/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8929 - val_loss: 0.1072 - val_acc: 0.8862\n",
            "Epoch 1766/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8898 - val_loss: 0.1067 - val_acc: 0.8865\n",
            "Epoch 1767/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8870 - val_loss: 0.1062 - val_acc: 0.8869\n",
            "Epoch 1768/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2781 - acc: 0.8583 - val_loss: 0.1075 - val_acc: 0.8864\n",
            "Epoch 1769/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8813 - val_loss: 0.1087 - val_acc: 0.8864\n",
            "Epoch 1770/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8813 - val_loss: 0.1095 - val_acc: 0.8867\n",
            "Epoch 1771/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8865 - val_loss: 0.1091 - val_acc: 0.8873\n",
            "Epoch 1772/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8770 - val_loss: 0.1084 - val_acc: 0.8878\n",
            "Epoch 1773/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8852 - val_loss: 0.1077 - val_acc: 0.8883\n",
            "Epoch 1774/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8823 - val_loss: 0.1076 - val_acc: 0.8885\n",
            "Epoch 1775/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2638 - acc: 0.8700 - val_loss: 0.1082 - val_acc: 0.8883\n",
            "Epoch 1776/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2296 - acc: 0.8610 - val_loss: 0.1115 - val_acc: 0.8875\n",
            "Epoch 1777/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8710 - val_loss: 0.1152 - val_acc: 0.8870\n",
            "Epoch 1778/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8928 - val_loss: 0.1169 - val_acc: 0.8871\n",
            "Epoch 1779/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8903 - val_loss: 0.1160 - val_acc: 0.8878\n",
            "Epoch 1780/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8950 - val_loss: 0.1141 - val_acc: 0.8886\n",
            "Epoch 1781/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8828 - val_loss: 0.1130 - val_acc: 0.8892\n",
            "Epoch 1782/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8961 - val_loss: 0.1135 - val_acc: 0.8896\n",
            "Epoch 1783/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8909 - val_loss: 0.1145 - val_acc: 0.8897\n",
            "Epoch 1784/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8870 - val_loss: 0.1143 - val_acc: 0.8897\n",
            "Epoch 1785/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2222 - acc: 0.8847 - val_loss: 0.1129 - val_acc: 0.8895\n",
            "Epoch 1786/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2225 - acc: 0.8817 - val_loss: 0.1136 - val_acc: 0.8891\n",
            "Epoch 1787/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8900 - val_loss: 0.1164 - val_acc: 0.8885\n",
            "Epoch 1788/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8918 - val_loss: 0.1187 - val_acc: 0.8883\n",
            "Epoch 1789/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8777 - val_loss: 0.1193 - val_acc: 0.8884\n",
            "Epoch 1790/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8780 - val_loss: 0.1180 - val_acc: 0.8887\n",
            "Epoch 1791/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8895 - val_loss: 0.1159 - val_acc: 0.8892\n",
            "Epoch 1792/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8925 - val_loss: 0.1145 - val_acc: 0.8895\n",
            "Epoch 1793/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8830 - val_loss: 0.1144 - val_acc: 0.8897\n",
            "Epoch 1794/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8855 - val_loss: 0.1147 - val_acc: 0.8898\n",
            "Epoch 1795/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8894 - val_loss: 0.1145 - val_acc: 0.8897\n",
            "Epoch 1796/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8869 - val_loss: 0.1134 - val_acc: 0.8896\n",
            "Epoch 1797/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8790 - val_loss: 0.1118 - val_acc: 0.8893\n",
            "Epoch 1798/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8786 - val_loss: 0.1108 - val_acc: 0.8887\n",
            "Epoch 1799/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8865 - val_loss: 0.1104 - val_acc: 0.8880\n",
            "Epoch 1800/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8831 - val_loss: 0.1106 - val_acc: 0.8873\n",
            "Epoch 1801/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8893 - val_loss: 0.1105 - val_acc: 0.8868\n",
            "Epoch 1802/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8818 - val_loss: 0.1099 - val_acc: 0.8867\n",
            "Epoch 1803/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8864 - val_loss: 0.1087 - val_acc: 0.8871\n",
            "Epoch 1804/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8906 - val_loss: 0.1078 - val_acc: 0.8875\n",
            "Epoch 1805/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8837 - val_loss: 0.1074 - val_acc: 0.8880\n",
            "Epoch 1806/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8840 - val_loss: 0.1075 - val_acc: 0.8881\n",
            "Epoch 1807/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8848 - val_loss: 0.1073 - val_acc: 0.8880\n",
            "Epoch 1808/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8875 - val_loss: 0.1069 - val_acc: 0.8877\n",
            "Epoch 1809/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8733 - val_loss: 0.1062 - val_acc: 0.8869\n",
            "Epoch 1810/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8726 - val_loss: 0.1061 - val_acc: 0.8858\n",
            "Epoch 1811/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8906 - val_loss: 0.1066 - val_acc: 0.8847\n",
            "Epoch 1812/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8837 - val_loss: 0.1068 - val_acc: 0.8842\n",
            "Epoch 1813/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8793 - val_loss: 0.1063 - val_acc: 0.8844\n",
            "Epoch 1814/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8796 - val_loss: 0.1056 - val_acc: 0.8853\n",
            "Epoch 1815/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8748 - val_loss: 0.1054 - val_acc: 0.8860\n",
            "Epoch 1816/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8902 - val_loss: 0.1057 - val_acc: 0.8863\n",
            "Epoch 1817/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1486 - acc: 0.8811 - val_loss: 0.1060 - val_acc: 0.8860\n",
            "Epoch 1818/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8855 - val_loss: 0.1060 - val_acc: 0.8857\n",
            "Epoch 1819/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8815 - val_loss: 0.1057 - val_acc: 0.8855\n",
            "Epoch 1820/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8837 - val_loss: 0.1056 - val_acc: 0.8854\n",
            "Epoch 1821/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8838 - val_loss: 0.1056 - val_acc: 0.8855\n",
            "Epoch 1822/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8876 - val_loss: 0.1055 - val_acc: 0.8859\n",
            "Epoch 1823/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8881 - val_loss: 0.1054 - val_acc: 0.8863\n",
            "Epoch 1824/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8810 - val_loss: 0.1053 - val_acc: 0.8866\n",
            "Epoch 1825/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8857 - val_loss: 0.1051 - val_acc: 0.8866\n",
            "Epoch 1826/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8797 - val_loss: 0.1049 - val_acc: 0.8864\n",
            "Epoch 1827/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8739 - val_loss: 0.1048 - val_acc: 0.8861\n",
            "Epoch 1828/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8791 - val_loss: 0.1049 - val_acc: 0.8859\n",
            "Epoch 1829/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2409 - acc: 0.8584 - val_loss: 0.1069 - val_acc: 0.8849\n",
            "Epoch 1830/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8835 - val_loss: 0.1088 - val_acc: 0.8845\n",
            "Epoch 1831/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8941 - val_loss: 0.1087 - val_acc: 0.8852\n",
            "Epoch 1832/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8825 - val_loss: 0.1073 - val_acc: 0.8865\n",
            "Epoch 1833/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8841 - val_loss: 0.1064 - val_acc: 0.8877\n",
            "Epoch 1834/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8903 - val_loss: 0.1066 - val_acc: 0.8884\n",
            "Epoch 1835/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8911 - val_loss: 0.1072 - val_acc: 0.8886\n",
            "Epoch 1836/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1896 - acc: 0.8754 - val_loss: 0.1068 - val_acc: 0.8882\n",
            "Epoch 1837/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2820 - acc: 0.8666 - val_loss: 0.1091 - val_acc: 0.8870\n",
            "Epoch 1838/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8804 - val_loss: 0.1136 - val_acc: 0.8860\n",
            "Epoch 1839/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8843 - val_loss: 0.1166 - val_acc: 0.8857\n",
            "Epoch 1840/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8851 - val_loss: 0.1165 - val_acc: 0.8865\n",
            "Epoch 1841/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1750 - acc: 0.8743 - val_loss: 0.1168 - val_acc: 0.8871\n",
            "Epoch 1842/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8875 - val_loss: 0.1153 - val_acc: 0.8880\n",
            "Epoch 1843/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8868 - val_loss: 0.1135 - val_acc: 0.8889\n",
            "Epoch 1844/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8891 - val_loss: 0.1129 - val_acc: 0.8894\n",
            "Epoch 1845/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8897 - val_loss: 0.1136 - val_acc: 0.8897\n",
            "Epoch 1846/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8938 - val_loss: 0.1149 - val_acc: 0.8898\n",
            "Epoch 1847/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1552 - acc: 0.8879 - val_loss: 0.1152 - val_acc: 0.8898\n",
            "Epoch 1848/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8968 - val_loss: 0.1144 - val_acc: 0.8897\n",
            "Epoch 1849/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8887 - val_loss: 0.1130 - val_acc: 0.8896\n",
            "Epoch 1850/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8955 - val_loss: 0.1123 - val_acc: 0.8893\n",
            "Epoch 1851/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8952 - val_loss: 0.1121 - val_acc: 0.8891\n",
            "Epoch 1852/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8949 - val_loss: 0.1119 - val_acc: 0.8888\n",
            "Epoch 1853/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8808 - val_loss: 0.1116 - val_acc: 0.8886\n",
            "Epoch 1854/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8788 - val_loss: 0.1110 - val_acc: 0.8886\n",
            "Epoch 1855/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8853 - val_loss: 0.1102 - val_acc: 0.8886\n",
            "Epoch 1856/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8837 - val_loss: 0.1094 - val_acc: 0.8887\n",
            "Epoch 1857/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8948 - val_loss: 0.1088 - val_acc: 0.8888\n",
            "Epoch 1858/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8808 - val_loss: 0.1083 - val_acc: 0.8889\n",
            "Epoch 1859/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8809 - val_loss: 0.1079 - val_acc: 0.8888\n",
            "Epoch 1860/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8847 - val_loss: 0.1076 - val_acc: 0.8886\n",
            "Epoch 1861/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8767 - val_loss: 0.1070 - val_acc: 0.8883\n",
            "Epoch 1862/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8908 - val_loss: 0.1065 - val_acc: 0.8879\n",
            "Epoch 1863/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8908 - val_loss: 0.1062 - val_acc: 0.8873\n",
            "Epoch 1864/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8751 - val_loss: 0.1060 - val_acc: 0.8868\n",
            "Epoch 1865/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8913 - val_loss: 0.1058 - val_acc: 0.8864\n",
            "Epoch 1866/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8824 - val_loss: 0.1056 - val_acc: 0.8863\n",
            "Epoch 1867/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8837 - val_loss: 0.1053 - val_acc: 0.8863\n",
            "Epoch 1868/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8838 - val_loss: 0.1050 - val_acc: 0.8864\n",
            "Epoch 1869/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8827 - val_loss: 0.1048 - val_acc: 0.8865\n",
            "Epoch 1870/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8860 - val_loss: 0.1048 - val_acc: 0.8864\n",
            "Epoch 1871/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8872 - val_loss: 0.1047 - val_acc: 0.8863\n",
            "Epoch 1872/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8845 - val_loss: 0.1047 - val_acc: 0.8860\n",
            "Epoch 1873/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8830 - val_loss: 0.1046 - val_acc: 0.8858\n",
            "Epoch 1874/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8828 - val_loss: 0.1046 - val_acc: 0.8856\n",
            "Epoch 1875/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8803 - val_loss: 0.1044 - val_acc: 0.8856\n",
            "Epoch 1876/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1533 - acc: 0.8724 - val_loss: 0.1046 - val_acc: 0.8853\n",
            "Epoch 1877/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8872 - val_loss: 0.1048 - val_acc: 0.8852\n",
            "Epoch 1878/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8873 - val_loss: 0.1049 - val_acc: 0.8854\n",
            "Epoch 1879/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8803 - val_loss: 0.1047 - val_acc: 0.8858\n",
            "Epoch 1880/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8801 - val_loss: 0.1045 - val_acc: 0.8862\n",
            "Epoch 1881/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8759 - val_loss: 0.1044 - val_acc: 0.8860\n",
            "Epoch 1882/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8837 - val_loss: 0.1046 - val_acc: 0.8859\n",
            "Epoch 1883/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1960 - acc: 0.8708 - val_loss: 0.1061 - val_acc: 0.8851\n",
            "Epoch 1884/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8737 - val_loss: 0.1072 - val_acc: 0.8849\n",
            "Epoch 1885/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8731 - val_loss: 0.1068 - val_acc: 0.8856\n",
            "Epoch 1886/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8812 - val_loss: 0.1058 - val_acc: 0.8868\n",
            "Epoch 1887/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1398 - acc: 0.8785 - val_loss: 0.1059 - val_acc: 0.8875\n",
            "Epoch 1888/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8886 - val_loss: 0.1063 - val_acc: 0.8881\n",
            "Epoch 1889/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8910 - val_loss: 0.1064 - val_acc: 0.8883\n",
            "Epoch 1890/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2306 - acc: 0.8793 - val_loss: 0.1069 - val_acc: 0.8879\n",
            "Epoch 1891/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8938 - val_loss: 0.1081 - val_acc: 0.8875\n",
            "Epoch 1892/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8849 - val_loss: 0.1090 - val_acc: 0.8874\n",
            "Epoch 1893/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1945 - acc: 0.8672 - val_loss: 0.1113 - val_acc: 0.8871\n",
            "Epoch 1894/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8739 - val_loss: 0.1122 - val_acc: 0.8874\n",
            "Epoch 1895/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8744 - val_loss: 0.1117 - val_acc: 0.8880\n",
            "Epoch 1896/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8852 - val_loss: 0.1108 - val_acc: 0.8886\n",
            "Epoch 1897/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1591 - acc: 0.8801 - val_loss: 0.1108 - val_acc: 0.8890\n",
            "Epoch 1898/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8880 - val_loss: 0.1112 - val_acc: 0.8892\n",
            "Epoch 1899/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8873 - val_loss: 0.1116 - val_acc: 0.8893\n",
            "Epoch 1900/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8888 - val_loss: 0.1114 - val_acc: 0.8893\n",
            "Epoch 1901/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8892 - val_loss: 0.1109 - val_acc: 0.8892\n",
            "Epoch 1902/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8894 - val_loss: 0.1104 - val_acc: 0.8890\n",
            "Epoch 1903/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8874 - val_loss: 0.1100 - val_acc: 0.8887\n",
            "Epoch 1904/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8829 - val_loss: 0.1098 - val_acc: 0.8884\n",
            "Epoch 1905/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8916 - val_loss: 0.1096 - val_acc: 0.8882\n",
            "Epoch 1906/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8913 - val_loss: 0.1091 - val_acc: 0.8881\n",
            "Epoch 1907/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8907 - val_loss: 0.1083 - val_acc: 0.8881\n",
            "Epoch 1908/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8876 - val_loss: 0.1076 - val_acc: 0.8883\n",
            "Epoch 1909/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8848 - val_loss: 0.1070 - val_acc: 0.8884\n",
            "Epoch 1910/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8878 - val_loss: 0.1067 - val_acc: 0.8884\n",
            "Epoch 1911/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1897 - acc: 0.8812 - val_loss: 0.1065 - val_acc: 0.8881\n",
            "Epoch 1912/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8913 - val_loss: 0.1066 - val_acc: 0.8877\n",
            "Epoch 1913/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8917 - val_loss: 0.1067 - val_acc: 0.8874\n",
            "Epoch 1914/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8847 - val_loss: 0.1067 - val_acc: 0.8871\n",
            "Epoch 1915/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8923 - val_loss: 0.1063 - val_acc: 0.8871\n",
            "Epoch 1916/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8924 - val_loss: 0.1057 - val_acc: 0.8872\n",
            "Epoch 1917/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8894 - val_loss: 0.1054 - val_acc: 0.8874\n",
            "Epoch 1918/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8737 - val_loss: 0.1052 - val_acc: 0.8875\n",
            "Epoch 1919/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8742 - val_loss: 0.1053 - val_acc: 0.8874\n",
            "Epoch 1920/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8833 - val_loss: 0.1052 - val_acc: 0.8871\n",
            "Epoch 1921/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8886 - val_loss: 0.1048 - val_acc: 0.8867\n",
            "Epoch 1922/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8827 - val_loss: 0.1044 - val_acc: 0.8862\n",
            "Epoch 1923/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8814 - val_loss: 0.1045 - val_acc: 0.8856\n",
            "Epoch 1924/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8936 - val_loss: 0.1046 - val_acc: 0.8853\n",
            "Epoch 1925/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8850 - val_loss: 0.1045 - val_acc: 0.8855\n",
            "Epoch 1926/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8854 - val_loss: 0.1042 - val_acc: 0.8860\n",
            "Epoch 1927/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8760 - val_loss: 0.1040 - val_acc: 0.8865\n",
            "Epoch 1928/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8855 - val_loss: 0.1040 - val_acc: 0.8867\n",
            "Epoch 1929/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8829 - val_loss: 0.1038 - val_acc: 0.8865\n",
            "Epoch 1930/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8891 - val_loss: 0.1038 - val_acc: 0.8862\n",
            "Epoch 1931/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8937 - val_loss: 0.1039 - val_acc: 0.8859\n",
            "Epoch 1932/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8864 - val_loss: 0.1039 - val_acc: 0.8858\n",
            "Epoch 1933/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8862 - val_loss: 0.1038 - val_acc: 0.8858\n",
            "Epoch 1934/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8862 - val_loss: 0.1036 - val_acc: 0.8861\n",
            "Epoch 1935/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8923 - val_loss: 0.1034 - val_acc: 0.8863\n",
            "Epoch 1936/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8925 - val_loss: 0.1034 - val_acc: 0.8865\n",
            "Epoch 1937/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8824 - val_loss: 0.1034 - val_acc: 0.8865\n",
            "Epoch 1938/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8814 - val_loss: 0.1034 - val_acc: 0.8863\n",
            "Epoch 1939/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8784 - val_loss: 0.1034 - val_acc: 0.8861\n",
            "Epoch 1940/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8783 - val_loss: 0.1034 - val_acc: 0.8860\n",
            "Epoch 1941/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8905 - val_loss: 0.1034 - val_acc: 0.8860\n",
            "Epoch 1942/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8798 - val_loss: 0.1033 - val_acc: 0.8862\n",
            "Epoch 1943/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8899 - val_loss: 0.1032 - val_acc: 0.8865\n",
            "Epoch 1944/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2211 - acc: 0.8712 - val_loss: 0.1040 - val_acc: 0.8857\n",
            "Epoch 1945/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8804 - val_loss: 0.1052 - val_acc: 0.8852\n",
            "Epoch 1946/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8852 - val_loss: 0.1052 - val_acc: 0.8856\n",
            "Epoch 1947/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8832 - val_loss: 0.1046 - val_acc: 0.8865\n",
            "Epoch 1948/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8835 - val_loss: 0.1042 - val_acc: 0.8874\n",
            "Epoch 1949/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8834 - val_loss: 0.1046 - val_acc: 0.8880\n",
            "Epoch 1950/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8778 - val_loss: 0.1049 - val_acc: 0.8883\n",
            "Epoch 1951/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8738 - val_loss: 0.1048 - val_acc: 0.8882\n",
            "Epoch 1952/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8887 - val_loss: 0.1045 - val_acc: 0.8878\n",
            "Epoch 1953/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8835 - val_loss: 0.1043 - val_acc: 0.8873\n",
            "Epoch 1954/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8920 - val_loss: 0.1044 - val_acc: 0.8868\n",
            "Epoch 1955/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8876 - val_loss: 0.1046 - val_acc: 0.8865\n",
            "Epoch 1956/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8886 - val_loss: 0.1044 - val_acc: 0.8864\n",
            "Epoch 1957/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8903 - val_loss: 0.1041 - val_acc: 0.8867\n",
            "Epoch 1958/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8939 - val_loss: 0.1038 - val_acc: 0.8872\n",
            "Epoch 1959/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8903 - val_loss: 0.1038 - val_acc: 0.8876\n",
            "Epoch 1960/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8817 - val_loss: 0.1036 - val_acc: 0.8876\n",
            "Epoch 1961/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8818 - val_loss: 0.1034 - val_acc: 0.8873\n",
            "Epoch 1962/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8839 - val_loss: 0.1033 - val_acc: 0.8867\n",
            "Epoch 1963/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8820 - val_loss: 0.1033 - val_acc: 0.8863\n",
            "Epoch 1964/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8848 - val_loss: 0.1033 - val_acc: 0.8861\n",
            "Epoch 1965/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8874 - val_loss: 0.1031 - val_acc: 0.8863\n",
            "Epoch 1966/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8857 - val_loss: 0.1029 - val_acc: 0.8865\n",
            "Epoch 1967/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8742 - val_loss: 0.1027 - val_acc: 0.8867\n",
            "Epoch 1968/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8749 - val_loss: 0.1028 - val_acc: 0.8867\n",
            "Epoch 1969/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8814 - val_loss: 0.1030 - val_acc: 0.8864\n",
            "Epoch 1970/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8847 - val_loss: 0.1030 - val_acc: 0.8861\n",
            "Epoch 1971/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8847 - val_loss: 0.1030 - val_acc: 0.8860\n",
            "Epoch 1972/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8822 - val_loss: 0.1027 - val_acc: 0.8859\n",
            "Epoch 1973/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8812 - val_loss: 0.1025 - val_acc: 0.8860\n",
            "Epoch 1974/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3046 - acc: 0.8610 - val_loss: 0.1039 - val_acc: 0.8853\n",
            "Epoch 1975/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8930 - val_loss: 0.1056 - val_acc: 0.8851\n",
            "Epoch 1976/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8809 - val_loss: 0.1059 - val_acc: 0.8860\n",
            "Epoch 1977/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8817 - val_loss: 0.1056 - val_acc: 0.8872\n",
            "Epoch 1978/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8840 - val_loss: 0.1054 - val_acc: 0.8881\n",
            "Epoch 1979/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8772 - val_loss: 0.1054 - val_acc: 0.8886\n",
            "Epoch 1980/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8919 - val_loss: 0.1054 - val_acc: 0.8887\n",
            "Epoch 1981/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8835 - val_loss: 0.1054 - val_acc: 0.8886\n",
            "Epoch 1982/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.9006 - val_loss: 0.1055 - val_acc: 0.8883\n",
            "Epoch 1983/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.9005 - val_loss: 0.1056 - val_acc: 0.8880\n",
            "Epoch 1984/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8884 - val_loss: 0.1057 - val_acc: 0.8877\n",
            "Epoch 1985/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8911 - val_loss: 0.1056 - val_acc: 0.8875\n",
            "Epoch 1986/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8854 - val_loss: 0.1054 - val_acc: 0.8875\n",
            "Epoch 1987/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8923 - val_loss: 0.1051 - val_acc: 0.8877\n",
            "Epoch 1988/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8863 - val_loss: 0.1048 - val_acc: 0.8878\n",
            "Epoch 1989/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8885 - val_loss: 0.1045 - val_acc: 0.8880\n",
            "Epoch 1990/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8846 - val_loss: 0.1043 - val_acc: 0.8881\n",
            "Epoch 1991/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8921 - val_loss: 0.1041 - val_acc: 0.8881\n",
            "Epoch 1992/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8789 - val_loss: 0.1038 - val_acc: 0.8878\n",
            "Epoch 1993/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8869 - val_loss: 0.1036 - val_acc: 0.8875\n",
            "Epoch 1994/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8871 - val_loss: 0.1035 - val_acc: 0.8871\n",
            "Epoch 1995/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8865 - val_loss: 0.1034 - val_acc: 0.8868\n",
            "Epoch 1996/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8890 - val_loss: 0.1032 - val_acc: 0.8868\n",
            "Epoch 1997/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8755 - val_loss: 0.1029 - val_acc: 0.8869\n",
            "Epoch 1998/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8808 - val_loss: 0.1027 - val_acc: 0.8869\n",
            "Epoch 1999/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8757 - val_loss: 0.1025 - val_acc: 0.8868\n",
            "Epoch 2000/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8747 - val_loss: 0.1025 - val_acc: 0.8865\n",
            "Epoch 2001/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8921 - val_loss: 0.1026 - val_acc: 0.8862\n",
            "Epoch 2002/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8994 - val_loss: 0.1027 - val_acc: 0.8859\n",
            "Epoch 2003/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8855 - val_loss: 0.1025 - val_acc: 0.8859\n",
            "Epoch 2004/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8817 - val_loss: 0.1024 - val_acc: 0.8858\n",
            "Epoch 2005/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8838 - val_loss: 0.1024 - val_acc: 0.8860\n",
            "Epoch 2006/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8885 - val_loss: 0.1027 - val_acc: 0.8862\n",
            "Epoch 2007/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8847 - val_loss: 0.1026 - val_acc: 0.8863\n",
            "Epoch 2008/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8850 - val_loss: 0.1024 - val_acc: 0.8862\n",
            "Epoch 2009/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8882 - val_loss: 0.1023 - val_acc: 0.8859\n",
            "Epoch 2010/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8993 - val_loss: 0.1023 - val_acc: 0.8857\n",
            "Epoch 2011/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8892 - val_loss: 0.1024 - val_acc: 0.8856\n",
            "Epoch 2012/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8891 - val_loss: 0.1023 - val_acc: 0.8856\n",
            "Epoch 2013/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1426 - acc: 0.8745 - val_loss: 0.1026 - val_acc: 0.8851\n",
            "Epoch 2014/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8887 - val_loss: 0.1030 - val_acc: 0.8853\n",
            "Epoch 2015/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8824 - val_loss: 0.1033 - val_acc: 0.8856\n",
            "Epoch 2016/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8817 - val_loss: 0.1030 - val_acc: 0.8864\n",
            "Epoch 2017/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8880 - val_loss: 0.1027 - val_acc: 0.8871\n",
            "Epoch 2018/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8862 - val_loss: 0.1028 - val_acc: 0.8873\n",
            "Epoch 2019/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8929 - val_loss: 0.1029 - val_acc: 0.8872\n",
            "Epoch 2020/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8912 - val_loss: 0.1029 - val_acc: 0.8868\n",
            "Epoch 2021/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8882 - val_loss: 0.1032 - val_acc: 0.8863\n",
            "Epoch 2022/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8854 - val_loss: 0.1033 - val_acc: 0.8862\n",
            "Epoch 2023/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8853 - val_loss: 0.1029 - val_acc: 0.8863\n",
            "Epoch 2024/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8881 - val_loss: 0.1025 - val_acc: 0.8866\n",
            "Epoch 2025/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1564 - acc: 0.8815 - val_loss: 0.1027 - val_acc: 0.8863\n",
            "Epoch 2026/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8905 - val_loss: 0.1032 - val_acc: 0.8862\n",
            "Epoch 2027/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8903 - val_loss: 0.1032 - val_acc: 0.8866\n",
            "Epoch 2028/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8860 - val_loss: 0.1030 - val_acc: 0.8873\n",
            "Epoch 2029/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2634 - acc: 0.8734 - val_loss: 0.1051 - val_acc: 0.8864\n",
            "Epoch 2030/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2499 - acc: 0.8596 - val_loss: 0.1150 - val_acc: 0.8829\n",
            "Epoch 2031/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8717 - val_loss: 0.1217 - val_acc: 0.8816\n",
            "Epoch 2032/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2249 - acc: 0.8531 - val_loss: 0.1309 - val_acc: 0.8804\n",
            "Epoch 2033/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2088 - acc: 0.8536 - val_loss: 0.1363 - val_acc: 0.8819\n",
            "Epoch 2034/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1358 - acc: 0.8842 - val_loss: 0.1307 - val_acc: 0.8860\n",
            "Epoch 2035/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8819 - val_loss: 0.1223 - val_acc: 0.8888\n",
            "Epoch 2036/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1666 - acc: 0.8804 - val_loss: 0.1196 - val_acc: 0.8898\n",
            "Epoch 2037/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8978 - val_loss: 0.1203 - val_acc: 0.8900\n",
            "Epoch 2038/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8979 - val_loss: 0.1230 - val_acc: 0.8900\n",
            "Epoch 2039/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1567 - acc: 0.8863 - val_loss: 0.1242 - val_acc: 0.8900\n",
            "Epoch 2040/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8909 - val_loss: 0.1232 - val_acc: 0.8900\n",
            "Epoch 2041/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8898 - val_loss: 0.1217 - val_acc: 0.8899\n",
            "Epoch 2042/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8917 - val_loss: 0.1209 - val_acc: 0.8898\n",
            "Epoch 2043/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8957 - val_loss: 0.1209 - val_acc: 0.8897\n",
            "Epoch 2044/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8958 - val_loss: 0.1211 - val_acc: 0.8896\n",
            "Epoch 2045/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8870 - val_loss: 0.1208 - val_acc: 0.8896\n",
            "Epoch 2046/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8885 - val_loss: 0.1202 - val_acc: 0.8897\n",
            "Epoch 2047/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8916 - val_loss: 0.1190 - val_acc: 0.8897\n",
            "Epoch 2048/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8870 - val_loss: 0.1175 - val_acc: 0.8898\n",
            "Epoch 2049/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8991 - val_loss: 0.1162 - val_acc: 0.8899\n",
            "Epoch 2050/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8922 - val_loss: 0.1154 - val_acc: 0.8899\n",
            "Epoch 2051/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2331 - acc: 0.8847 - val_loss: 0.1155 - val_acc: 0.8900\n",
            "Epoch 2052/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8890 - val_loss: 0.1156 - val_acc: 0.8900\n",
            "Epoch 2053/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8887 - val_loss: 0.1153 - val_acc: 0.8900\n",
            "Epoch 2054/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8797 - val_loss: 0.1147 - val_acc: 0.8900\n",
            "Epoch 2055/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2231 - acc: 0.8815 - val_loss: 0.1156 - val_acc: 0.8899\n",
            "Epoch 2056/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8801 - val_loss: 0.1162 - val_acc: 0.8899\n",
            "Epoch 2057/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1508 - acc: 0.8751 - val_loss: 0.1168 - val_acc: 0.8899\n",
            "Epoch 2058/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8875 - val_loss: 0.1165 - val_acc: 0.8898\n",
            "Epoch 2059/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8964 - val_loss: 0.1154 - val_acc: 0.8898\n",
            "Epoch 2060/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8857 - val_loss: 0.1142 - val_acc: 0.8898\n",
            "Epoch 2061/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8833 - val_loss: 0.1132 - val_acc: 0.8898\n",
            "Epoch 2062/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8928 - val_loss: 0.1125 - val_acc: 0.8898\n",
            "Epoch 2063/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8906 - val_loss: 0.1122 - val_acc: 0.8898\n",
            "Epoch 2064/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8926 - val_loss: 0.1117 - val_acc: 0.8898\n",
            "Epoch 2065/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8998 - val_loss: 0.1110 - val_acc: 0.8897\n",
            "Epoch 2066/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8874 - val_loss: 0.1102 - val_acc: 0.8897\n",
            "Epoch 2067/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8917 - val_loss: 0.1095 - val_acc: 0.8895\n",
            "Epoch 2068/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8928 - val_loss: 0.1091 - val_acc: 0.8894\n",
            "Epoch 2069/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8928 - val_loss: 0.1088 - val_acc: 0.8892\n",
            "Epoch 2070/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8856 - val_loss: 0.1085 - val_acc: 0.8891\n",
            "Epoch 2071/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8856 - val_loss: 0.1081 - val_acc: 0.8891\n",
            "Epoch 2072/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2409 - acc: 0.8706 - val_loss: 0.1095 - val_acc: 0.8887\n",
            "Epoch 2073/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8790 - val_loss: 0.1112 - val_acc: 0.8883\n",
            "Epoch 2074/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8800 - val_loss: 0.1120 - val_acc: 0.8881\n",
            "Epoch 2075/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8905 - val_loss: 0.1112 - val_acc: 0.8882\n",
            "Epoch 2076/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8905 - val_loss: 0.1095 - val_acc: 0.8885\n",
            "Epoch 2077/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8906 - val_loss: 0.1080 - val_acc: 0.8889\n",
            "Epoch 2078/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8910 - val_loss: 0.1075 - val_acc: 0.8892\n",
            "Epoch 2079/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8877 - val_loss: 0.1078 - val_acc: 0.8892\n",
            "Epoch 2080/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8876 - val_loss: 0.1079 - val_acc: 0.8892\n",
            "Epoch 2081/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8813 - val_loss: 0.1072 - val_acc: 0.8888\n",
            "Epoch 2082/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8821 - val_loss: 0.1062 - val_acc: 0.8883\n",
            "Epoch 2083/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8790 - val_loss: 0.1055 - val_acc: 0.8876\n",
            "Epoch 2084/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8975 - val_loss: 0.1055 - val_acc: 0.8869\n",
            "Epoch 2085/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2232 - acc: 0.8731 - val_loss: 0.1081 - val_acc: 0.8856\n",
            "Epoch 2086/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8913 - val_loss: 0.1100 - val_acc: 0.8850\n",
            "Epoch 2087/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8823 - val_loss: 0.1096 - val_acc: 0.8854\n",
            "Epoch 2088/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8804 - val_loss: 0.1077 - val_acc: 0.8866\n",
            "Epoch 2089/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8814 - val_loss: 0.1060 - val_acc: 0.8877\n",
            "Epoch 2090/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8863 - val_loss: 0.1057 - val_acc: 0.8885\n",
            "Epoch 2091/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8863 - val_loss: 0.1065 - val_acc: 0.8889\n",
            "Epoch 2092/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8894 - val_loss: 0.1067 - val_acc: 0.8889\n",
            "Epoch 2093/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8925 - val_loss: 0.1062 - val_acc: 0.8886\n",
            "Epoch 2094/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8858 - val_loss: 0.1054 - val_acc: 0.8882\n",
            "Epoch 2095/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8853 - val_loss: 0.1049 - val_acc: 0.8875\n",
            "Epoch 2096/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8857 - val_loss: 0.1050 - val_acc: 0.8868\n",
            "Epoch 2097/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8839 - val_loss: 0.1051 - val_acc: 0.8864\n",
            "Epoch 2098/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8890 - val_loss: 0.1047 - val_acc: 0.8864\n",
            "Epoch 2099/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8857 - val_loss: 0.1041 - val_acc: 0.8868\n",
            "Epoch 2100/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8752 - val_loss: 0.1037 - val_acc: 0.8873\n",
            "Epoch 2101/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8759 - val_loss: 0.1036 - val_acc: 0.8877\n",
            "Epoch 2102/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8873 - val_loss: 0.1037 - val_acc: 0.8878\n",
            "Epoch 2103/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8834 - val_loss: 0.1035 - val_acc: 0.8878\n",
            "Epoch 2104/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8833 - val_loss: 0.1032 - val_acc: 0.8875\n",
            "Epoch 2105/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8913 - val_loss: 0.1030 - val_acc: 0.8870\n",
            "Epoch 2106/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8797 - val_loss: 0.1029 - val_acc: 0.8865\n",
            "Epoch 2107/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8882 - val_loss: 0.1029 - val_acc: 0.8860\n",
            "Epoch 2108/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8837 - val_loss: 0.1034 - val_acc: 0.8856\n",
            "Epoch 2109/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8801 - val_loss: 0.1038 - val_acc: 0.8853\n",
            "Epoch 2110/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1902 - acc: 0.8745 - val_loss: 0.1054 - val_acc: 0.8846\n",
            "Epoch 2111/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8814 - val_loss: 0.1068 - val_acc: 0.8844\n",
            "Epoch 2112/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8820 - val_loss: 0.1061 - val_acc: 0.8853\n",
            "Epoch 2113/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8872 - val_loss: 0.1047 - val_acc: 0.8867\n",
            "Epoch 2114/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8877 - val_loss: 0.1042 - val_acc: 0.8878\n",
            "Epoch 2115/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8903 - val_loss: 0.1047 - val_acc: 0.8884\n",
            "Epoch 2116/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8804 - val_loss: 0.1049 - val_acc: 0.8886\n",
            "Epoch 2117/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1496 - acc: 0.8865 - val_loss: 0.1045 - val_acc: 0.8883\n",
            "Epoch 2118/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8891 - val_loss: 0.1044 - val_acc: 0.8879\n",
            "Epoch 2119/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8887 - val_loss: 0.1047 - val_acc: 0.8875\n",
            "Epoch 2120/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8766 - val_loss: 0.1050 - val_acc: 0.8872\n",
            "Epoch 2121/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8925 - val_loss: 0.1050 - val_acc: 0.8872\n",
            "Epoch 2122/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8903 - val_loss: 0.1045 - val_acc: 0.8874\n",
            "Epoch 2123/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8844 - val_loss: 0.1043 - val_acc: 0.8877\n",
            "Epoch 2124/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2380 - acc: 0.8667 - val_loss: 0.1057 - val_acc: 0.8874\n",
            "Epoch 2125/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8782 - val_loss: 0.1071 - val_acc: 0.8873\n",
            "Epoch 2126/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8745 - val_loss: 0.1074 - val_acc: 0.8876\n",
            "Epoch 2127/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8831 - val_loss: 0.1069 - val_acc: 0.8881\n",
            "Epoch 2128/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8835 - val_loss: 0.1063 - val_acc: 0.8886\n",
            "Epoch 2129/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8821 - val_loss: 0.1060 - val_acc: 0.8888\n",
            "Epoch 2130/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8901 - val_loss: 0.1062 - val_acc: 0.8890\n",
            "Epoch 2131/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8892 - val_loss: 0.1064 - val_acc: 0.8889\n",
            "Epoch 2132/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8872 - val_loss: 0.1062 - val_acc: 0.8887\n",
            "Epoch 2133/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8890 - val_loss: 0.1058 - val_acc: 0.8883\n",
            "Epoch 2134/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8877 - val_loss: 0.1054 - val_acc: 0.8878\n",
            "Epoch 2135/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8793 - val_loss: 0.1053 - val_acc: 0.8875\n",
            "Epoch 2136/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8767 - val_loss: 0.1055 - val_acc: 0.8872\n",
            "Epoch 2137/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8899 - val_loss: 0.1056 - val_acc: 0.8872\n",
            "Epoch 2138/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8969 - val_loss: 0.1052 - val_acc: 0.8875\n",
            "Epoch 2139/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8974 - val_loss: 0.1046 - val_acc: 0.8880\n",
            "Epoch 2140/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8923 - val_loss: 0.1043 - val_acc: 0.8883\n",
            "Epoch 2141/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8945 - val_loss: 0.1042 - val_acc: 0.8884\n",
            "Epoch 2142/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1417 - acc: 0.8853 - val_loss: 0.1039 - val_acc: 0.8883\n",
            "Epoch 2143/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8828 - val_loss: 0.1035 - val_acc: 0.8878\n",
            "Epoch 2144/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8842 - val_loss: 0.1033 - val_acc: 0.8873\n",
            "Epoch 2145/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8886 - val_loss: 0.1034 - val_acc: 0.8868\n",
            "Epoch 2146/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8882 - val_loss: 0.1035 - val_acc: 0.8865\n",
            "Epoch 2147/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1779 - acc: 0.8833 - val_loss: 0.1042 - val_acc: 0.8860\n",
            "Epoch 2148/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8966 - val_loss: 0.1041 - val_acc: 0.8862\n",
            "Epoch 2149/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1597 - acc: 0.8746 - val_loss: 0.1041 - val_acc: 0.8867\n",
            "Epoch 2150/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8863 - val_loss: 0.1040 - val_acc: 0.8873\n",
            "Epoch 2151/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8882 - val_loss: 0.1041 - val_acc: 0.8878\n",
            "Epoch 2152/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8947 - val_loss: 0.1042 - val_acc: 0.8882\n",
            "Epoch 2153/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8850 - val_loss: 0.1042 - val_acc: 0.8885\n",
            "Epoch 2154/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8854 - val_loss: 0.1040 - val_acc: 0.8886\n",
            "Epoch 2155/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8892 - val_loss: 0.1037 - val_acc: 0.8884\n",
            "Epoch 2156/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8799 - val_loss: 0.1034 - val_acc: 0.8878\n",
            "Epoch 2157/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8943 - val_loss: 0.1035 - val_acc: 0.8872\n",
            "Epoch 2158/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8938 - val_loss: 0.1037 - val_acc: 0.8866\n",
            "Epoch 2159/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2976 - acc: 0.8504 - val_loss: 0.1078 - val_acc: 0.8848\n",
            "Epoch 2160/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8745 - val_loss: 0.1114 - val_acc: 0.8838\n",
            "Epoch 2161/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8849 - val_loss: 0.1115 - val_acc: 0.8846\n",
            "Epoch 2162/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8799 - val_loss: 0.1089 - val_acc: 0.8864\n",
            "Epoch 2163/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8874 - val_loss: 0.1065 - val_acc: 0.8880\n",
            "Epoch 2164/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8889 - val_loss: 0.1066 - val_acc: 0.8889\n",
            "Epoch 2165/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8918 - val_loss: 0.1082 - val_acc: 0.8893\n",
            "Epoch 2166/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8811 - val_loss: 0.1083 - val_acc: 0.8894\n",
            "Epoch 2167/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8929 - val_loss: 0.1071 - val_acc: 0.8891\n",
            "Epoch 2168/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8892 - val_loss: 0.1057 - val_acc: 0.8885\n",
            "Epoch 2169/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8817 - val_loss: 0.1055 - val_acc: 0.8877\n",
            "Epoch 2170/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8830 - val_loss: 0.1062 - val_acc: 0.8869\n",
            "Epoch 2171/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8816 - val_loss: 0.1067 - val_acc: 0.8864\n",
            "Epoch 2172/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8864 - val_loss: 0.1062 - val_acc: 0.8867\n",
            "Epoch 2173/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8866 - val_loss: 0.1049 - val_acc: 0.8873\n",
            "Epoch 2174/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8750 - val_loss: 0.1041 - val_acc: 0.8879\n",
            "Epoch 2175/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8737 - val_loss: 0.1036 - val_acc: 0.8881\n",
            "Epoch 2176/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8817 - val_loss: 0.1034 - val_acc: 0.8881\n",
            "Epoch 2177/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8824 - val_loss: 0.1032 - val_acc: 0.8879\n",
            "Epoch 2178/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8722 - val_loss: 0.1029 - val_acc: 0.8876\n",
            "Epoch 2179/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8928 - val_loss: 0.1026 - val_acc: 0.8870\n",
            "Epoch 2180/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8897 - val_loss: 0.1026 - val_acc: 0.8865\n",
            "Epoch 2181/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8895 - val_loss: 0.1026 - val_acc: 0.8861\n",
            "Epoch 2182/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8938 - val_loss: 0.1026 - val_acc: 0.8860\n",
            "Epoch 2183/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8801 - val_loss: 0.1021 - val_acc: 0.8864\n",
            "Epoch 2184/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8932 - val_loss: 0.1018 - val_acc: 0.8868\n",
            "Epoch 2185/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8834 - val_loss: 0.1018 - val_acc: 0.8870\n",
            "Epoch 2186/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8839 - val_loss: 0.1019 - val_acc: 0.8870\n",
            "Epoch 2187/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8886 - val_loss: 0.1017 - val_acc: 0.8867\n",
            "Epoch 2188/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8885 - val_loss: 0.1016 - val_acc: 0.8863\n",
            "Epoch 2189/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8870 - val_loss: 0.1017 - val_acc: 0.8859\n",
            "Epoch 2190/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8885 - val_loss: 0.1018 - val_acc: 0.8856\n",
            "Epoch 2191/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8883 - val_loss: 0.1018 - val_acc: 0.8855\n",
            "Epoch 2192/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8745 - val_loss: 0.1015 - val_acc: 0.8857\n",
            "Epoch 2193/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8880 - val_loss: 0.1015 - val_acc: 0.8861\n",
            "Epoch 2194/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1548 - acc: 0.8748 - val_loss: 0.1023 - val_acc: 0.8855\n",
            "Epoch 2195/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8781 - val_loss: 0.1029 - val_acc: 0.8855\n",
            "Epoch 2196/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8821 - val_loss: 0.1025 - val_acc: 0.8860\n",
            "Epoch 2197/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8849 - val_loss: 0.1017 - val_acc: 0.8867\n",
            "Epoch 2198/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8874 - val_loss: 0.1017 - val_acc: 0.8869\n",
            "Epoch 2199/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8756 - val_loss: 0.1020 - val_acc: 0.8871\n",
            "Epoch 2200/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8761 - val_loss: 0.1020 - val_acc: 0.8872\n",
            "Epoch 2201/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8852 - val_loss: 0.1016 - val_acc: 0.8870\n",
            "Epoch 2202/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8836 - val_loss: 0.1015 - val_acc: 0.8866\n",
            "Epoch 2203/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8887 - val_loss: 0.1018 - val_acc: 0.8862\n",
            "Epoch 2204/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2959 - acc: 0.8563 - val_loss: 0.1066 - val_acc: 0.8833\n",
            "Epoch 2205/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8704 - val_loss: 0.1125 - val_acc: 0.8813\n",
            "Epoch 2206/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8860 - val_loss: 0.1133 - val_acc: 0.8825\n",
            "Epoch 2207/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8790 - val_loss: 0.1095 - val_acc: 0.8856\n",
            "Epoch 2208/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2309 - acc: 0.8549 - val_loss: 0.1099 - val_acc: 0.8872\n",
            "Epoch 2209/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8836 - val_loss: 0.1095 - val_acc: 0.8886\n",
            "Epoch 2210/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8967 - val_loss: 0.1093 - val_acc: 0.8893\n",
            "Epoch 2211/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1356 - acc: 0.8924 - val_loss: 0.1100 - val_acc: 0.8896\n",
            "Epoch 2212/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8947 - val_loss: 0.1104 - val_acc: 0.8897\n",
            "Epoch 2213/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8857 - val_loss: 0.1104 - val_acc: 0.8896\n",
            "Epoch 2214/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8885 - val_loss: 0.1101 - val_acc: 0.8895\n",
            "Epoch 2215/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8882 - val_loss: 0.1099 - val_acc: 0.8893\n",
            "Epoch 2216/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1480 - acc: 0.8842 - val_loss: 0.1101 - val_acc: 0.8891\n",
            "Epoch 2217/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8789 - val_loss: 0.1105 - val_acc: 0.8888\n",
            "Epoch 2218/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8934 - val_loss: 0.1106 - val_acc: 0.8888\n",
            "Epoch 2219/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8893 - val_loss: 0.1102 - val_acc: 0.8888\n",
            "Epoch 2220/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1361 - acc: 0.8814 - val_loss: 0.1098 - val_acc: 0.8889\n",
            "Epoch 2221/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8794 - val_loss: 0.1091 - val_acc: 0.8891\n",
            "Epoch 2222/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8796 - val_loss: 0.1085 - val_acc: 0.8892\n",
            "Epoch 2223/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8882 - val_loss: 0.1079 - val_acc: 0.8893\n",
            "Epoch 2224/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8865 - val_loss: 0.1075 - val_acc: 0.8894\n",
            "Epoch 2225/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8914 - val_loss: 0.1069 - val_acc: 0.8894\n",
            "Epoch 2226/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8861 - val_loss: 0.1062 - val_acc: 0.8892\n",
            "Epoch 2227/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8835 - val_loss: 0.1056 - val_acc: 0.8889\n",
            "Epoch 2228/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8833 - val_loss: 0.1051 - val_acc: 0.8885\n",
            "Epoch 2229/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8756 - val_loss: 0.1047 - val_acc: 0.8880\n",
            "Epoch 2230/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8810 - val_loss: 0.1045 - val_acc: 0.8876\n",
            "Epoch 2231/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8782 - val_loss: 0.1041 - val_acc: 0.8873\n",
            "Epoch 2232/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8882 - val_loss: 0.1036 - val_acc: 0.8873\n",
            "Epoch 2233/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8859 - val_loss: 0.1031 - val_acc: 0.8874\n",
            "Epoch 2234/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8971 - val_loss: 0.1028 - val_acc: 0.8876\n",
            "Epoch 2235/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8864 - val_loss: 0.1026 - val_acc: 0.8877\n",
            "Epoch 2236/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8865 - val_loss: 0.1023 - val_acc: 0.8877\n",
            "Epoch 2237/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8903 - val_loss: 0.1020 - val_acc: 0.8874\n",
            "Epoch 2238/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8775 - val_loss: 0.1016 - val_acc: 0.8868\n",
            "Epoch 2239/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8767 - val_loss: 0.1016 - val_acc: 0.8861\n",
            "Epoch 2240/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8832 - val_loss: 0.1017 - val_acc: 0.8855\n",
            "Epoch 2241/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8841 - val_loss: 0.1018 - val_acc: 0.8853\n",
            "Epoch 2242/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8841 - val_loss: 0.1016 - val_acc: 0.8854\n",
            "Epoch 2243/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8806 - val_loss: 0.1014 - val_acc: 0.8858\n",
            "Epoch 2244/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8809 - val_loss: 0.1012 - val_acc: 0.8861\n",
            "Epoch 2245/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8812 - val_loss: 0.1012 - val_acc: 0.8859\n",
            "Epoch 2246/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8847 - val_loss: 0.1013 - val_acc: 0.8859\n",
            "Epoch 2247/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8858 - val_loss: 0.1013 - val_acc: 0.8860\n",
            "Epoch 2248/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8894 - val_loss: 0.1012 - val_acc: 0.8863\n",
            "Epoch 2249/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8777 - val_loss: 0.1011 - val_acc: 0.8865\n",
            "Epoch 2250/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3265 - acc: 0.8625 - val_loss: 0.1037 - val_acc: 0.8848\n",
            "Epoch 2251/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8839 - val_loss: 0.1077 - val_acc: 0.8834\n",
            "Epoch 2252/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8879 - val_loss: 0.1084 - val_acc: 0.8842\n",
            "Epoch 2253/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8909 - val_loss: 0.1064 - val_acc: 0.8863\n",
            "Epoch 2254/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8902 - val_loss: 0.1049 - val_acc: 0.8880\n",
            "Epoch 2255/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8780 - val_loss: 0.1049 - val_acc: 0.8888\n",
            "Epoch 2256/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8856 - val_loss: 0.1058 - val_acc: 0.8891\n",
            "Epoch 2257/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8860 - val_loss: 0.1061 - val_acc: 0.8890\n",
            "Epoch 2258/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8846 - val_loss: 0.1053 - val_acc: 0.8887\n",
            "Epoch 2259/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8947 - val_loss: 0.1048 - val_acc: 0.8883\n",
            "Epoch 2260/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8746 - val_loss: 0.1048 - val_acc: 0.8877\n",
            "Epoch 2261/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1821 - acc: 0.8685 - val_loss: 0.1063 - val_acc: 0.8869\n",
            "Epoch 2262/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1331 - acc: 0.8794 - val_loss: 0.1079 - val_acc: 0.8865\n",
            "Epoch 2263/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2049 - acc: 0.8614 - val_loss: 0.1106 - val_acc: 0.8863\n",
            "Epoch 2264/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8888 - val_loss: 0.1110 - val_acc: 0.8868\n",
            "Epoch 2265/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8743 - val_loss: 0.1095 - val_acc: 0.8879\n",
            "Epoch 2266/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2249 - acc: 0.8648 - val_loss: 0.1100 - val_acc: 0.8884\n",
            "Epoch 2267/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8928 - val_loss: 0.1098 - val_acc: 0.8890\n",
            "Epoch 2268/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8865 - val_loss: 0.1097 - val_acc: 0.8894\n",
            "Epoch 2269/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8889 - val_loss: 0.1098 - val_acc: 0.8896\n",
            "Epoch 2270/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8864 - val_loss: 0.1100 - val_acc: 0.8897\n",
            "Epoch 2271/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1860 - acc: 0.8834 - val_loss: 0.1105 - val_acc: 0.8896\n",
            "Epoch 2272/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8895 - val_loss: 0.1107 - val_acc: 0.8894\n",
            "Epoch 2273/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8905 - val_loss: 0.1107 - val_acc: 0.8893\n",
            "Epoch 2274/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8766 - val_loss: 0.1106 - val_acc: 0.8891\n",
            "Epoch 2275/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8880 - val_loss: 0.1104 - val_acc: 0.8891\n",
            "Epoch 2276/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8862 - val_loss: 0.1101 - val_acc: 0.8892\n",
            "Epoch 2277/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8837 - val_loss: 0.1097 - val_acc: 0.8893\n",
            "Epoch 2278/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8838 - val_loss: 0.1091 - val_acc: 0.8894\n",
            "Epoch 2279/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8814 - val_loss: 0.1085 - val_acc: 0.8895\n",
            "Epoch 2280/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2377 - acc: 0.8728 - val_loss: 0.1097 - val_acc: 0.8892\n",
            "Epoch 2281/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8845 - val_loss: 0.1109 - val_acc: 0.8890\n",
            "Epoch 2282/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8838 - val_loss: 0.1111 - val_acc: 0.8889\n",
            "Epoch 2283/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1515 - acc: 0.8783 - val_loss: 0.1112 - val_acc: 0.8888\n",
            "Epoch 2284/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8872 - val_loss: 0.1103 - val_acc: 0.8889\n",
            "Epoch 2285/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8893 - val_loss: 0.1090 - val_acc: 0.8890\n",
            "Epoch 2286/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8781 - val_loss: 0.1080 - val_acc: 0.8892\n",
            "Epoch 2287/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8856 - val_loss: 0.1076 - val_acc: 0.8893\n",
            "Epoch 2288/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8857 - val_loss: 0.1075 - val_acc: 0.8893\n",
            "Epoch 2289/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2459 - acc: 0.8789 - val_loss: 0.1070 - val_acc: 0.8892\n",
            "Epoch 2290/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8906 - val_loss: 0.1069 - val_acc: 0.8891\n",
            "Epoch 2291/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8921 - val_loss: 0.1073 - val_acc: 0.8888\n",
            "Epoch 2292/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8903 - val_loss: 0.1076 - val_acc: 0.8886\n",
            "Epoch 2293/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8945 - val_loss: 0.1076 - val_acc: 0.8885\n",
            "Epoch 2294/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8871 - val_loss: 0.1070 - val_acc: 0.8885\n",
            "Epoch 2295/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8859 - val_loss: 0.1061 - val_acc: 0.8886\n",
            "Epoch 2296/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8904 - val_loss: 0.1054 - val_acc: 0.8888\n",
            "Epoch 2297/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1789 - acc: 0.8748 - val_loss: 0.1054 - val_acc: 0.8888\n",
            "Epoch 2298/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8854 - val_loss: 0.1054 - val_acc: 0.8887\n",
            "Epoch 2299/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8837 - val_loss: 0.1053 - val_acc: 0.8886\n",
            "Epoch 2300/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8876 - val_loss: 0.1050 - val_acc: 0.8884\n",
            "Epoch 2301/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8859 - val_loss: 0.1046 - val_acc: 0.8883\n",
            "Epoch 2302/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2433 - acc: 0.8708 - val_loss: 0.1055 - val_acc: 0.8878\n",
            "Epoch 2303/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8879 - val_loss: 0.1066 - val_acc: 0.8874\n",
            "Epoch 2304/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8880 - val_loss: 0.1069 - val_acc: 0.8875\n",
            "Epoch 2305/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8785 - val_loss: 0.1064 - val_acc: 0.8879\n",
            "Epoch 2306/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8867 - val_loss: 0.1055 - val_acc: 0.8885\n",
            "Epoch 2307/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8825 - val_loss: 0.1051 - val_acc: 0.8888\n",
            "Epoch 2308/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8907 - val_loss: 0.1051 - val_acc: 0.8890\n",
            "Epoch 2309/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8888 - val_loss: 0.1050 - val_acc: 0.8890\n",
            "Epoch 2310/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8888 - val_loss: 0.1045 - val_acc: 0.8889\n",
            "Epoch 2311/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1333 - acc: 0.8826 - val_loss: 0.1039 - val_acc: 0.8886\n",
            "Epoch 2312/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8857 - val_loss: 0.1035 - val_acc: 0.8880\n",
            "Epoch 2313/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2444 - acc: 0.8666 - val_loss: 0.1053 - val_acc: 0.8871\n",
            "Epoch 2314/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8910 - val_loss: 0.1073 - val_acc: 0.8863\n",
            "Epoch 2315/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8835 - val_loss: 0.1076 - val_acc: 0.8864\n",
            "Epoch 2316/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8837 - val_loss: 0.1063 - val_acc: 0.8872\n",
            "Epoch 2317/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8783 - val_loss: 0.1049 - val_acc: 0.8881\n",
            "Epoch 2318/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8933 - val_loss: 0.1044 - val_acc: 0.8888\n",
            "Epoch 2319/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8860 - val_loss: 0.1051 - val_acc: 0.8891\n",
            "Epoch 2320/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8912 - val_loss: 0.1055 - val_acc: 0.8892\n",
            "Epoch 2321/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8759 - val_loss: 0.1046 - val_acc: 0.8889\n",
            "Epoch 2322/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8849 - val_loss: 0.1036 - val_acc: 0.8883\n",
            "Epoch 2323/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8848 - val_loss: 0.1033 - val_acc: 0.8874\n",
            "Epoch 2324/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8837 - val_loss: 0.1038 - val_acc: 0.8865\n",
            "Epoch 2325/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8820 - val_loss: 0.1040 - val_acc: 0.8860\n",
            "Epoch 2326/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8894 - val_loss: 0.1038 - val_acc: 0.8860\n",
            "Epoch 2327/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8857 - val_loss: 0.1030 - val_acc: 0.8866\n",
            "Epoch 2328/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8778 - val_loss: 0.1023 - val_acc: 0.8874\n",
            "Epoch 2329/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8743 - val_loss: 0.1023 - val_acc: 0.8880\n",
            "Epoch 2330/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8750 - val_loss: 0.1025 - val_acc: 0.8882\n",
            "Epoch 2331/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8867 - val_loss: 0.1022 - val_acc: 0.8880\n",
            "Epoch 2332/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8962 - val_loss: 0.1018 - val_acc: 0.8876\n",
            "Epoch 2333/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8894 - val_loss: 0.1015 - val_acc: 0.8870\n",
            "Epoch 2334/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8873 - val_loss: 0.1016 - val_acc: 0.8864\n",
            "Epoch 2335/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8868 - val_loss: 0.1017 - val_acc: 0.8861\n",
            "Epoch 2336/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8866 - val_loss: 0.1015 - val_acc: 0.8860\n",
            "Epoch 2337/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8790 - val_loss: 0.1011 - val_acc: 0.8863\n",
            "Epoch 2338/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8923 - val_loss: 0.1009 - val_acc: 0.8867\n",
            "Epoch 2339/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8825 - val_loss: 0.1008 - val_acc: 0.8869\n",
            "Epoch 2340/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8842 - val_loss: 0.1009 - val_acc: 0.8870\n",
            "Epoch 2341/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8792 - val_loss: 0.1009 - val_acc: 0.8868\n",
            "Epoch 2342/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8920 - val_loss: 0.1008 - val_acc: 0.8866\n",
            "Epoch 2343/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8918 - val_loss: 0.1007 - val_acc: 0.8863\n",
            "Epoch 2344/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8829 - val_loss: 0.1007 - val_acc: 0.8862\n",
            "Epoch 2345/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8800 - val_loss: 0.1006 - val_acc: 0.8863\n",
            "Epoch 2346/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8896 - val_loss: 0.1006 - val_acc: 0.8866\n",
            "Epoch 2347/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8868 - val_loss: 0.1007 - val_acc: 0.8869\n",
            "Epoch 2348/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8871 - val_loss: 0.1006 - val_acc: 0.8870\n",
            "Epoch 2349/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8871 - val_loss: 0.1004 - val_acc: 0.8869\n",
            "Epoch 2350/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8831 - val_loss: 0.1003 - val_acc: 0.8867\n",
            "Epoch 2351/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8830 - val_loss: 0.1002 - val_acc: 0.8865\n",
            "Epoch 2352/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8761 - val_loss: 0.1001 - val_acc: 0.8865\n",
            "Epoch 2353/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8875 - val_loss: 0.1001 - val_acc: 0.8865\n",
            "Epoch 2354/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8876 - val_loss: 0.1001 - val_acc: 0.8867\n",
            "Epoch 2355/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8823 - val_loss: 0.1001 - val_acc: 0.8868\n",
            "Epoch 2356/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8882 - val_loss: 0.1001 - val_acc: 0.8867\n",
            "Epoch 2357/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8880 - val_loss: 0.1003 - val_acc: 0.8866\n",
            "Epoch 2358/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8888 - val_loss: 0.1004 - val_acc: 0.8863\n",
            "Epoch 2359/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8903 - val_loss: 0.1004 - val_acc: 0.8862\n",
            "Epoch 2360/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8937 - val_loss: 0.1002 - val_acc: 0.8863\n",
            "Epoch 2361/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8895 - val_loss: 0.1001 - val_acc: 0.8864\n",
            "Epoch 2362/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8897 - val_loss: 0.1001 - val_acc: 0.8864\n",
            "Epoch 2363/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8810 - val_loss: 0.1001 - val_acc: 0.8865\n",
            "Epoch 2364/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8929 - val_loss: 0.1000 - val_acc: 0.8866\n",
            "Epoch 2365/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8919 - val_loss: 0.1000 - val_acc: 0.8865\n",
            "Epoch 2366/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8835 - val_loss: 0.1000 - val_acc: 0.8864\n",
            "Epoch 2367/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8846 - val_loss: 0.0998 - val_acc: 0.8865\n",
            "Epoch 2368/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8861 - val_loss: 0.0998 - val_acc: 0.8866\n",
            "Epoch 2369/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8864 - val_loss: 0.0998 - val_acc: 0.8867\n",
            "Epoch 2370/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8747 - val_loss: 0.0999 - val_acc: 0.8868\n",
            "Epoch 2371/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8833 - val_loss: 0.0998 - val_acc: 0.8868\n",
            "Epoch 2372/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8853 - val_loss: 0.0997 - val_acc: 0.8869\n",
            "Epoch 2373/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8854 - val_loss: 0.0997 - val_acc: 0.8869\n",
            "Epoch 2374/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2231 - acc: 0.8618 - val_loss: 0.1010 - val_acc: 0.8860\n",
            "Epoch 2375/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8815 - val_loss: 0.1026 - val_acc: 0.8855\n",
            "Epoch 2376/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8810 - val_loss: 0.1026 - val_acc: 0.8861\n",
            "Epoch 2377/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8909 - val_loss: 0.1022 - val_acc: 0.8869\n",
            "Epoch 2378/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8826 - val_loss: 0.1017 - val_acc: 0.8877\n",
            "Epoch 2379/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8835 - val_loss: 0.1017 - val_acc: 0.8882\n",
            "Epoch 2380/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2675 - acc: 0.8660 - val_loss: 0.1029 - val_acc: 0.8875\n",
            "Epoch 2381/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8851 - val_loss: 0.1048 - val_acc: 0.8871\n",
            "Epoch 2382/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8759 - val_loss: 0.1057 - val_acc: 0.8872\n",
            "Epoch 2383/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8910 - val_loss: 0.1053 - val_acc: 0.8878\n",
            "Epoch 2384/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.9002 - val_loss: 0.1047 - val_acc: 0.8885\n",
            "Epoch 2385/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.9008 - val_loss: 0.1049 - val_acc: 0.8890\n",
            "Epoch 2386/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8925 - val_loss: 0.1056 - val_acc: 0.8893\n",
            "Epoch 2387/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8874 - val_loss: 0.1057 - val_acc: 0.8893\n",
            "Epoch 2388/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8936 - val_loss: 0.1051 - val_acc: 0.8892\n",
            "Epoch 2389/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8876 - val_loss: 0.1043 - val_acc: 0.8889\n",
            "Epoch 2390/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8874 - val_loss: 0.1040 - val_acc: 0.8884\n",
            "Epoch 2391/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8833 - val_loss: 0.1038 - val_acc: 0.8880\n",
            "Epoch 2392/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8846 - val_loss: 0.1035 - val_acc: 0.8878\n",
            "Epoch 2393/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2389 - acc: 0.8667 - val_loss: 0.1054 - val_acc: 0.8872\n",
            "Epoch 2394/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8869 - val_loss: 0.1074 - val_acc: 0.8867\n",
            "Epoch 2395/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8862 - val_loss: 0.1074 - val_acc: 0.8871\n",
            "Epoch 2396/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8867 - val_loss: 0.1060 - val_acc: 0.8879\n",
            "Epoch 2397/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8901 - val_loss: 0.1048 - val_acc: 0.8888\n",
            "Epoch 2398/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8777 - val_loss: 0.1048 - val_acc: 0.8893\n",
            "Epoch 2399/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1746 - acc: 0.8717 - val_loss: 0.1048 - val_acc: 0.8894\n",
            "Epoch 2400/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8778 - val_loss: 0.1044 - val_acc: 0.8893\n",
            "Epoch 2401/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8778 - val_loss: 0.1041 - val_acc: 0.8890\n",
            "Epoch 2402/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8767 - val_loss: 0.1040 - val_acc: 0.8886\n",
            "Epoch 2403/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1376 - acc: 0.8966 - val_loss: 0.1046 - val_acc: 0.8880\n",
            "Epoch 2404/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8872 - val_loss: 0.1050 - val_acc: 0.8877\n",
            "Epoch 2405/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8838 - val_loss: 0.1048 - val_acc: 0.8876\n",
            "Epoch 2406/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - acc: 0.8783 - val_loss: 0.1048 - val_acc: 0.8877\n",
            "Epoch 2407/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8861 - val_loss: 0.1045 - val_acc: 0.8880\n",
            "Epoch 2408/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8882 - val_loss: 0.1041 - val_acc: 0.8883\n",
            "Epoch 2409/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1970 - acc: 0.8732 - val_loss: 0.1045 - val_acc: 0.8884\n",
            "Epoch 2410/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8871 - val_loss: 0.1050 - val_acc: 0.8883\n",
            "Epoch 2411/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8906 - val_loss: 0.1051 - val_acc: 0.8884\n",
            "Epoch 2412/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.9017 - val_loss: 0.1047 - val_acc: 0.8886\n",
            "Epoch 2413/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8922 - val_loss: 0.1042 - val_acc: 0.8887\n",
            "Epoch 2414/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8785 - val_loss: 0.1038 - val_acc: 0.8887\n",
            "Epoch 2415/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8929 - val_loss: 0.1036 - val_acc: 0.8886\n",
            "Epoch 2416/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2577 - acc: 0.8732 - val_loss: 0.1046 - val_acc: 0.8880\n",
            "Epoch 2417/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8887 - val_loss: 0.1059 - val_acc: 0.8876\n",
            "Epoch 2418/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8841 - val_loss: 0.1064 - val_acc: 0.8876\n",
            "Epoch 2419/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8840 - val_loss: 0.1059 - val_acc: 0.8880\n",
            "Epoch 2420/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8897 - val_loss: 0.1049 - val_acc: 0.8885\n",
            "Epoch 2421/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8878 - val_loss: 0.1045 - val_acc: 0.8889\n",
            "Epoch 2422/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1736 - acc: 0.8783 - val_loss: 0.1046 - val_acc: 0.8889\n",
            "Epoch 2423/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8902 - val_loss: 0.1045 - val_acc: 0.8888\n",
            "Epoch 2424/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8877 - val_loss: 0.1043 - val_acc: 0.8886\n",
            "Epoch 2425/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2204 - acc: 0.8673 - val_loss: 0.1056 - val_acc: 0.8879\n",
            "Epoch 2426/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8895 - val_loss: 0.1071 - val_acc: 0.8873\n",
            "Epoch 2427/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8915 - val_loss: 0.1075 - val_acc: 0.8871\n",
            "Epoch 2428/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8913 - val_loss: 0.1067 - val_acc: 0.8876\n",
            "Epoch 2429/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8920 - val_loss: 0.1056 - val_acc: 0.8883\n",
            "Epoch 2430/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8876 - val_loss: 0.1053 - val_acc: 0.8888\n",
            "Epoch 2431/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8956 - val_loss: 0.1057 - val_acc: 0.8892\n",
            "Epoch 2432/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8988 - val_loss: 0.1060 - val_acc: 0.8892\n",
            "Epoch 2433/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8792 - val_loss: 0.1050 - val_acc: 0.8890\n",
            "Epoch 2434/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2661 - acc: 0.8717 - val_loss: 0.1048 - val_acc: 0.8883\n",
            "Epoch 2435/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2174 - acc: 0.8673 - val_loss: 0.1094 - val_acc: 0.8870\n",
            "Epoch 2436/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1550 - acc: 0.8763 - val_loss: 0.1165 - val_acc: 0.8854\n",
            "Epoch 2437/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1460 - acc: 0.8755 - val_loss: 0.1204 - val_acc: 0.8852\n",
            "Epoch 2438/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8858 - val_loss: 0.1187 - val_acc: 0.8867\n",
            "Epoch 2439/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8759 - val_loss: 0.1142 - val_acc: 0.8884\n",
            "Epoch 2440/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8824 - val_loss: 0.1113 - val_acc: 0.8894\n",
            "Epoch 2441/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8836 - val_loss: 0.1116 - val_acc: 0.8898\n",
            "Epoch 2442/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8915 - val_loss: 0.1137 - val_acc: 0.8899\n",
            "Epoch 2443/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8883 - val_loss: 0.1146 - val_acc: 0.8899\n",
            "Epoch 2444/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8914 - val_loss: 0.1131 - val_acc: 0.8898\n",
            "Epoch 2445/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8911 - val_loss: 0.1109 - val_acc: 0.8895\n",
            "Epoch 2446/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8951 - val_loss: 0.1095 - val_acc: 0.8889\n",
            "Epoch 2447/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8861 - val_loss: 0.1092 - val_acc: 0.8883\n",
            "Epoch 2448/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1881 - acc: 0.8752 - val_loss: 0.1107 - val_acc: 0.8876\n",
            "Epoch 2449/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8894 - val_loss: 0.1121 - val_acc: 0.8871\n",
            "Epoch 2450/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8888 - val_loss: 0.1121 - val_acc: 0.8870\n",
            "Epoch 2451/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8842 - val_loss: 0.1108 - val_acc: 0.8875\n",
            "Epoch 2452/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1566 - acc: 0.8808 - val_loss: 0.1100 - val_acc: 0.8880\n",
            "Epoch 2453/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8913 - val_loss: 0.1089 - val_acc: 0.8886\n",
            "Epoch 2454/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8875 - val_loss: 0.1080 - val_acc: 0.8892\n",
            "Epoch 2455/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8880 - val_loss: 0.1075 - val_acc: 0.8895\n",
            "Epoch 2456/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8778 - val_loss: 0.1070 - val_acc: 0.8896\n",
            "Epoch 2457/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8795 - val_loss: 0.1063 - val_acc: 0.8894\n",
            "Epoch 2458/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8869 - val_loss: 0.1055 - val_acc: 0.8891\n",
            "Epoch 2459/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8791 - val_loss: 0.1048 - val_acc: 0.8887\n",
            "Epoch 2460/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8859 - val_loss: 0.1045 - val_acc: 0.8881\n",
            "Epoch 2461/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8841 - val_loss: 0.1044 - val_acc: 0.8876\n",
            "Epoch 2462/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8837 - val_loss: 0.1042 - val_acc: 0.8872\n",
            "Epoch 2463/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8900 - val_loss: 0.1037 - val_acc: 0.8871\n",
            "Epoch 2464/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8906 - val_loss: 0.1030 - val_acc: 0.8873\n",
            "Epoch 2465/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8909 - val_loss: 0.1025 - val_acc: 0.8876\n",
            "Epoch 2466/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8854 - val_loss: 0.1022 - val_acc: 0.8879\n",
            "Epoch 2467/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8981 - val_loss: 0.1022 - val_acc: 0.8880\n",
            "Epoch 2468/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8983 - val_loss: 0.1021 - val_acc: 0.8880\n",
            "Epoch 2469/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8835 - val_loss: 0.1016 - val_acc: 0.8878\n",
            "Epoch 2470/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1589 - acc: 0.8832 - val_loss: 0.1012 - val_acc: 0.8872\n",
            "Epoch 2471/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8787 - val_loss: 0.1016 - val_acc: 0.8863\n",
            "Epoch 2472/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8830 - val_loss: 0.1020 - val_acc: 0.8858\n",
            "Epoch 2473/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8825 - val_loss: 0.1017 - val_acc: 0.8859\n",
            "Epoch 2474/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8770 - val_loss: 0.1011 - val_acc: 0.8863\n",
            "Epoch 2475/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8781 - val_loss: 0.1006 - val_acc: 0.8868\n",
            "Epoch 2476/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8870 - val_loss: 0.1007 - val_acc: 0.8873\n",
            "Epoch 2477/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8888 - val_loss: 0.1010 - val_acc: 0.8875\n",
            "Epoch 2478/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8892 - val_loss: 0.1012 - val_acc: 0.8876\n",
            "Epoch 2479/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8902 - val_loss: 0.1009 - val_acc: 0.8874\n",
            "Epoch 2480/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8901 - val_loss: 0.1007 - val_acc: 0.8870\n",
            "Epoch 2481/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8950 - val_loss: 0.1007 - val_acc: 0.8867\n",
            "Epoch 2482/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8778 - val_loss: 0.1006 - val_acc: 0.8866\n",
            "Epoch 2483/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1665 - acc: 0.8665 - val_loss: 0.1010 - val_acc: 0.8863\n",
            "Epoch 2484/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1953 - acc: 0.8688 - val_loss: 0.1031 - val_acc: 0.8855\n",
            "Epoch 2485/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8753 - val_loss: 0.1044 - val_acc: 0.8856\n",
            "Epoch 2486/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8758 - val_loss: 0.1041 - val_acc: 0.8865\n",
            "Epoch 2487/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8970 - val_loss: 0.1031 - val_acc: 0.8876\n",
            "Epoch 2488/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8938 - val_loss: 0.1027 - val_acc: 0.8884\n",
            "Epoch 2489/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1797 - acc: 0.8781 - val_loss: 0.1031 - val_acc: 0.8886\n",
            "Epoch 2490/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8865 - val_loss: 0.1034 - val_acc: 0.8885\n",
            "Epoch 2491/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8844 - val_loss: 0.1037 - val_acc: 0.8883\n",
            "Epoch 2492/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8868 - val_loss: 0.1039 - val_acc: 0.8881\n",
            "Epoch 2493/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8890 - val_loss: 0.1039 - val_acc: 0.8880\n",
            "Epoch 2494/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8817 - val_loss: 0.1037 - val_acc: 0.8880\n",
            "Epoch 2495/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8919 - val_loss: 0.1035 - val_acc: 0.8881\n",
            "Epoch 2496/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2359 - acc: 0.8681 - val_loss: 0.1045 - val_acc: 0.8879\n",
            "Epoch 2497/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8856 - val_loss: 0.1055 - val_acc: 0.8879\n",
            "Epoch 2498/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8854 - val_loss: 0.1058 - val_acc: 0.8882\n",
            "Epoch 2499/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8856 - val_loss: 0.1056 - val_acc: 0.8886\n",
            "Epoch 2500/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8910 - val_loss: 0.1051 - val_acc: 0.8889\n",
            "Epoch 2501/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8819 - val_loss: 0.1048 - val_acc: 0.8890\n",
            "Epoch 2502/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8821 - val_loss: 0.1045 - val_acc: 0.8890\n",
            "Epoch 2503/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8779 - val_loss: 0.1042 - val_acc: 0.8888\n",
            "Epoch 2504/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8882 - val_loss: 0.1038 - val_acc: 0.8886\n",
            "Epoch 2505/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8844 - val_loss: 0.1033 - val_acc: 0.8883\n",
            "Epoch 2506/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8839 - val_loss: 0.1029 - val_acc: 0.8880\n",
            "Epoch 2507/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8919 - val_loss: 0.1026 - val_acc: 0.8878\n",
            "Epoch 2508/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2614 - acc: 0.8603 - val_loss: 0.1041 - val_acc: 0.8872\n",
            "Epoch 2509/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8802 - val_loss: 0.1059 - val_acc: 0.8867\n",
            "Epoch 2510/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8856 - val_loss: 0.1062 - val_acc: 0.8870\n",
            "Epoch 2511/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8910 - val_loss: 0.1051 - val_acc: 0.8877\n",
            "Epoch 2512/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8896 - val_loss: 0.1040 - val_acc: 0.8885\n",
            "Epoch 2513/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8865 - val_loss: 0.1036 - val_acc: 0.8889\n",
            "Epoch 2514/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8871 - val_loss: 0.1040 - val_acc: 0.8890\n",
            "Epoch 2515/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2618 - acc: 0.8707 - val_loss: 0.1044 - val_acc: 0.8888\n",
            "Epoch 2516/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8910 - val_loss: 0.1051 - val_acc: 0.8884\n",
            "Epoch 2517/3000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1037 - acc: 0.8907 - val_loss: 0.1058 - val_acc: 0.8880\n",
            "Epoch 2518/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1888 - acc: 0.8631 - val_loss: 0.1078 - val_acc: 0.8874\n",
            "Epoch 2519/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8898 - val_loss: 0.1087 - val_acc: 0.8874\n",
            "Epoch 2520/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8880 - val_loss: 0.1080 - val_acc: 0.8878\n",
            "Epoch 2521/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8765 - val_loss: 0.1066 - val_acc: 0.8883\n",
            "Epoch 2522/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8838 - val_loss: 0.1058 - val_acc: 0.8888\n",
            "Epoch 2523/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8939 - val_loss: 0.1061 - val_acc: 0.8891\n",
            "Epoch 2524/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8951 - val_loss: 0.1065 - val_acc: 0.8892\n",
            "Epoch 2525/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8928 - val_loss: 0.1064 - val_acc: 0.8892\n",
            "Epoch 2526/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8892 - val_loss: 0.1053 - val_acc: 0.8890\n",
            "Epoch 2527/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8890 - val_loss: 0.1041 - val_acc: 0.8885\n",
            "Epoch 2528/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8792 - val_loss: 0.1034 - val_acc: 0.8879\n",
            "Epoch 2529/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8758 - val_loss: 0.1036 - val_acc: 0.8871\n",
            "Epoch 2530/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1878 - acc: 0.8657 - val_loss: 0.1054 - val_acc: 0.8860\n",
            "Epoch 2531/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8802 - val_loss: 0.1061 - val_acc: 0.8857\n",
            "Epoch 2532/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8865 - val_loss: 0.1048 - val_acc: 0.8865\n",
            "Epoch 2533/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8871 - val_loss: 0.1030 - val_acc: 0.8877\n",
            "Epoch 2534/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8882 - val_loss: 0.1024 - val_acc: 0.8885\n",
            "Epoch 2535/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8882 - val_loss: 0.1031 - val_acc: 0.8890\n",
            "Epoch 2536/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1727 - acc: 0.8815 - val_loss: 0.1033 - val_acc: 0.8891\n",
            "Epoch 2537/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2847 - acc: 0.8610 - val_loss: 0.1035 - val_acc: 0.8886\n",
            "Epoch 2538/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1546 - acc: 0.8789 - val_loss: 0.1069 - val_acc: 0.8876\n",
            "Epoch 2539/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8901 - val_loss: 0.1106 - val_acc: 0.8869\n",
            "Epoch 2540/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8896 - val_loss: 0.1118 - val_acc: 0.8870\n",
            "Epoch 2541/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8972 - val_loss: 0.1104 - val_acc: 0.8878\n",
            "Epoch 2542/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8921 - val_loss: 0.1081 - val_acc: 0.8887\n",
            "Epoch 2543/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8945 - val_loss: 0.1072 - val_acc: 0.8892\n",
            "Epoch 2544/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8904 - val_loss: 0.1079 - val_acc: 0.8895\n",
            "Epoch 2545/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8838 - val_loss: 0.1087 - val_acc: 0.8896\n",
            "Epoch 2546/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2190 - acc: 0.8843 - val_loss: 0.1092 - val_acc: 0.8896\n",
            "Epoch 2547/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2415 - acc: 0.8810 - val_loss: 0.1090 - val_acc: 0.8896\n",
            "Epoch 2548/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8913 - val_loss: 0.1096 - val_acc: 0.8895\n",
            "Epoch 2549/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8989 - val_loss: 0.1110 - val_acc: 0.8893\n",
            "Epoch 2550/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8995 - val_loss: 0.1122 - val_acc: 0.8892\n",
            "Epoch 2551/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8872 - val_loss: 0.1127 - val_acc: 0.8891\n",
            "Epoch 2552/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8907 - val_loss: 0.1121 - val_acc: 0.8891\n",
            "Epoch 2553/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8889 - val_loss: 0.1109 - val_acc: 0.8892\n",
            "Epoch 2554/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8818 - val_loss: 0.1097 - val_acc: 0.8893\n",
            "Epoch 2555/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8819 - val_loss: 0.1087 - val_acc: 0.8894\n",
            "Epoch 2556/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8862 - val_loss: 0.1080 - val_acc: 0.8895\n",
            "Epoch 2557/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8907 - val_loss: 0.1073 - val_acc: 0.8895\n",
            "Epoch 2558/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8906 - val_loss: 0.1065 - val_acc: 0.8893\n",
            "Epoch 2559/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2024 - acc: 0.8792 - val_loss: 0.1060 - val_acc: 0.8892\n",
            "Epoch 2560/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8952 - val_loss: 0.1057 - val_acc: 0.8890\n",
            "Epoch 2561/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8804 - val_loss: 0.1057 - val_acc: 0.8887\n",
            "Epoch 2562/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8790 - val_loss: 0.1057 - val_acc: 0.8884\n",
            "Epoch 2563/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8893 - val_loss: 0.1056 - val_acc: 0.8883\n",
            "Epoch 2564/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8850 - val_loss: 0.1053 - val_acc: 0.8882\n",
            "Epoch 2565/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8837 - val_loss: 0.1046 - val_acc: 0.8883\n",
            "Epoch 2566/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8917 - val_loss: 0.1038 - val_acc: 0.8886\n",
            "Epoch 2567/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8920 - val_loss: 0.1033 - val_acc: 0.8888\n",
            "Epoch 2568/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8951 - val_loss: 0.1029 - val_acc: 0.8890\n",
            "Epoch 2569/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8954 - val_loss: 0.1028 - val_acc: 0.8889\n",
            "Epoch 2570/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8926 - val_loss: 0.1024 - val_acc: 0.8887\n",
            "Epoch 2571/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8814 - val_loss: 0.1018 - val_acc: 0.8882\n",
            "Epoch 2572/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8808 - val_loss: 0.1013 - val_acc: 0.8875\n",
            "Epoch 2573/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8829 - val_loss: 0.1012 - val_acc: 0.8869\n",
            "Epoch 2574/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8871 - val_loss: 0.1011 - val_acc: 0.8865\n",
            "Epoch 2575/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8832 - val_loss: 0.1009 - val_acc: 0.8865\n",
            "Epoch 2576/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8768 - val_loss: 0.1007 - val_acc: 0.8867\n",
            "Epoch 2577/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8728 - val_loss: 0.1005 - val_acc: 0.8869\n",
            "Epoch 2578/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1988 - acc: 0.8599 - val_loss: 0.1008 - val_acc: 0.8868\n",
            "Epoch 2579/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8870 - val_loss: 0.1010 - val_acc: 0.8870\n",
            "Epoch 2580/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8709 - val_loss: 0.1009 - val_acc: 0.8873\n",
            "Epoch 2581/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8928 - val_loss: 0.1007 - val_acc: 0.8876\n",
            "Epoch 2582/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8899 - val_loss: 0.1005 - val_acc: 0.8876\n",
            "Epoch 2583/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8874 - val_loss: 0.1008 - val_acc: 0.8876\n",
            "Epoch 2584/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8816 - val_loss: 0.1009 - val_acc: 0.8875\n",
            "Epoch 2585/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2761 - acc: 0.8626 - val_loss: 0.1017 - val_acc: 0.8874\n",
            "Epoch 2586/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1614 - acc: 0.8792 - val_loss: 0.1038 - val_acc: 0.8872\n",
            "Epoch 2587/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8839 - val_loss: 0.1053 - val_acc: 0.8875\n",
            "Epoch 2588/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8875 - val_loss: 0.1058 - val_acc: 0.8880\n",
            "Epoch 2589/3000\n",
            "Epoch 2590/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8897 - val_loss: 0.1075 - val_acc: 0.8889\n",
            "Epoch 2591/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8904 - val_loss: 0.1078 - val_acc: 0.8893\n",
            "Epoch 2592/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8917 - val_loss: 0.1079 - val_acc: 0.8895\n",
            "Epoch 2593/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8794 - val_loss: 0.1079 - val_acc: 0.8896\n",
            "Epoch 2594/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8796 - val_loss: 0.1075 - val_acc: 0.8895\n",
            "Epoch 2595/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8929 - val_loss: 0.1072 - val_acc: 0.8893\n",
            "Epoch 2596/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8827 - val_loss: 0.1068 - val_acc: 0.8890\n",
            "Epoch 2597/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8823 - val_loss: 0.1065 - val_acc: 0.8887\n",
            "Epoch 2598/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8851 - val_loss: 0.1061 - val_acc: 0.8884\n",
            "Epoch 2599/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8878 - val_loss: 0.1055 - val_acc: 0.8882\n",
            "Epoch 2600/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8854 - val_loss: 0.1047 - val_acc: 0.8882\n",
            "Epoch 2601/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8886 - val_loss: 0.1039 - val_acc: 0.8883\n",
            "Epoch 2602/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8772 - val_loss: 0.1033 - val_acc: 0.8884\n",
            "Epoch 2603/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8862 - val_loss: 0.1029 - val_acc: 0.8886\n",
            "Epoch 2604/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8851 - val_loss: 0.1026 - val_acc: 0.8886\n",
            "Epoch 2605/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8909 - val_loss: 0.1020 - val_acc: 0.8886\n",
            "Epoch 2606/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - acc: 0.8645 - val_loss: 0.1024 - val_acc: 0.8878\n",
            "Epoch 2607/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8871 - val_loss: 0.1041 - val_acc: 0.8870\n",
            "Epoch 2608/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8865 - val_loss: 0.1051 - val_acc: 0.8866\n",
            "Epoch 2609/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2112 - acc: 0.8704 - val_loss: 0.1084 - val_acc: 0.8857\n",
            "Epoch 2610/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8823 - val_loss: 0.1092 - val_acc: 0.8861\n",
            "Epoch 2611/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8823 - val_loss: 0.1077 - val_acc: 0.8874\n",
            "Epoch 2612/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8959 - val_loss: 0.1058 - val_acc: 0.8886\n",
            "Epoch 2613/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8971 - val_loss: 0.1050 - val_acc: 0.8892\n",
            "Epoch 2614/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8748 - val_loss: 0.1050 - val_acc: 0.8894\n",
            "Epoch 2615/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8852 - val_loss: 0.1050 - val_acc: 0.8892\n",
            "Epoch 2616/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8884 - val_loss: 0.1044 - val_acc: 0.8888\n",
            "Epoch 2617/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8878 - val_loss: 0.1037 - val_acc: 0.8882\n",
            "Epoch 2618/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8835 - val_loss: 0.1034 - val_acc: 0.8874\n",
            "Epoch 2619/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8923 - val_loss: 0.1034 - val_acc: 0.8868\n",
            "Epoch 2620/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8874 - val_loss: 0.1033 - val_acc: 0.8865\n",
            "Epoch 2621/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8868 - val_loss: 0.1028 - val_acc: 0.8866\n",
            "Epoch 2622/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8870 - val_loss: 0.1021 - val_acc: 0.8871\n",
            "Epoch 2623/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2797 - acc: 0.8484 - val_loss: 0.1035 - val_acc: 0.8869\n",
            "Epoch 2624/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8860 - val_loss: 0.1048 - val_acc: 0.8870\n",
            "Epoch 2625/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8860 - val_loss: 0.1052 - val_acc: 0.8874\n",
            "Epoch 2626/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8842 - val_loss: 0.1047 - val_acc: 0.8881\n",
            "Epoch 2627/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8827 - val_loss: 0.1039 - val_acc: 0.8886\n",
            "Epoch 2628/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8872 - val_loss: 0.1034 - val_acc: 0.8889\n",
            "Epoch 2629/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8835 - val_loss: 0.1031 - val_acc: 0.8889\n",
            "Epoch 2630/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8833 - val_loss: 0.1029 - val_acc: 0.8887\n",
            "Epoch 2631/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8764 - val_loss: 0.1025 - val_acc: 0.8883\n",
            "Epoch 2632/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8816 - val_loss: 0.1024 - val_acc: 0.8878\n",
            "Epoch 2633/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8779 - val_loss: 0.1023 - val_acc: 0.8874\n",
            "Epoch 2634/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8862 - val_loss: 0.1021 - val_acc: 0.8871\n",
            "Epoch 2635/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8858 - val_loss: 0.1018 - val_acc: 0.8871\n",
            "Epoch 2636/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8848 - val_loss: 0.1014 - val_acc: 0.8873\n",
            "Epoch 2637/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2544 - acc: 0.8610 - val_loss: 0.1023 - val_acc: 0.8872\n",
            "Epoch 2638/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8849 - val_loss: 0.1032 - val_acc: 0.8872\n",
            "Epoch 2639/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8903 - val_loss: 0.1031 - val_acc: 0.8876\n",
            "Epoch 2640/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8931 - val_loss: 0.1026 - val_acc: 0.8882\n",
            "Epoch 2641/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8785 - val_loss: 0.1023 - val_acc: 0.8886\n",
            "Epoch 2642/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8854 - val_loss: 0.1024 - val_acc: 0.8888\n",
            "Epoch 2643/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8867 - val_loss: 0.1023 - val_acc: 0.8888\n",
            "Epoch 2644/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8878 - val_loss: 0.1021 - val_acc: 0.8885\n",
            "Epoch 2645/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8877 - val_loss: 0.1017 - val_acc: 0.8882\n",
            "Epoch 2646/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8832 - val_loss: 0.1013 - val_acc: 0.8879\n",
            "Epoch 2647/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8887 - val_loss: 0.1012 - val_acc: 0.8876\n",
            "Epoch 2648/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8837 - val_loss: 0.1014 - val_acc: 0.8873\n",
            "Epoch 2649/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8869 - val_loss: 0.1014 - val_acc: 0.8873\n",
            "Epoch 2650/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8907 - val_loss: 0.1012 - val_acc: 0.8876\n",
            "Epoch 2651/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8796 - val_loss: 0.1009 - val_acc: 0.8880\n",
            "Epoch 2652/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8948 - val_loss: 0.1007 - val_acc: 0.8882\n",
            "Epoch 2653/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8877 - val_loss: 0.1005 - val_acc: 0.8881\n",
            "Epoch 2654/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8877 - val_loss: 0.1004 - val_acc: 0.8878\n",
            "Epoch 2655/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8836 - val_loss: 0.1008 - val_acc: 0.8873\n",
            "Epoch 2656/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8938 - val_loss: 0.1011 - val_acc: 0.8868\n",
            "Epoch 2657/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8785 - val_loss: 0.1008 - val_acc: 0.8868\n",
            "Epoch 2658/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8835 - val_loss: 0.1002 - val_acc: 0.8872\n",
            "Epoch 2659/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8839 - val_loss: 0.0998 - val_acc: 0.8876\n",
            "Epoch 2660/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8834 - val_loss: 0.0999 - val_acc: 0.8878\n",
            "Epoch 2661/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8745 - val_loss: 0.1000 - val_acc: 0.8878\n",
            "Epoch 2662/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8744 - val_loss: 0.0998 - val_acc: 0.8875\n",
            "Epoch 2663/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8798 - val_loss: 0.0994 - val_acc: 0.8872\n",
            "Epoch 2664/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8749 - val_loss: 0.0994 - val_acc: 0.8869\n",
            "Epoch 2665/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8746 - val_loss: 0.0994 - val_acc: 0.8867\n",
            "Epoch 2666/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8895 - val_loss: 0.0993 - val_acc: 0.8869\n",
            "Epoch 2667/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8891 - val_loss: 0.0993 - val_acc: 0.8871\n",
            "Epoch 2668/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8745 - val_loss: 0.0991 - val_acc: 0.8873\n",
            "Epoch 2669/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8925 - val_loss: 0.0990 - val_acc: 0.8874\n",
            "Epoch 2670/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8806 - val_loss: 0.0991 - val_acc: 0.8872\n",
            "Epoch 2671/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8872 - val_loss: 0.0991 - val_acc: 0.8868\n",
            "Epoch 2672/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8843 - val_loss: 0.0989 - val_acc: 0.8867\n",
            "Epoch 2673/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8864 - val_loss: 0.0987 - val_acc: 0.8866\n",
            "Epoch 2674/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8879 - val_loss: 0.0987 - val_acc: 0.8867\n",
            "Epoch 2675/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8879 - val_loss: 0.0986 - val_acc: 0.8869\n",
            "Epoch 2676/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8737 - val_loss: 0.0986 - val_acc: 0.8871\n",
            "Epoch 2677/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3449 - acc: 0.8503 - val_loss: 0.1009 - val_acc: 0.8857\n",
            "Epoch 2678/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8795 - val_loss: 0.1038 - val_acc: 0.8850\n",
            "Epoch 2679/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8803 - val_loss: 0.1040 - val_acc: 0.8859\n",
            "Epoch 2680/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8767 - val_loss: 0.1028 - val_acc: 0.8876\n",
            "Epoch 2681/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8788 - val_loss: 0.1023 - val_acc: 0.8888\n",
            "Epoch 2682/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8839 - val_loss: 0.1027 - val_acc: 0.8893\n",
            "Epoch 2683/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8815 - val_loss: 0.1031 - val_acc: 0.8894\n",
            "Epoch 2684/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8838 - val_loss: 0.1029 - val_acc: 0.8893\n",
            "Epoch 2685/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8876 - val_loss: 0.1026 - val_acc: 0.8889\n",
            "Epoch 2686/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8895 - val_loss: 0.1025 - val_acc: 0.8884\n",
            "Epoch 2687/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8773 - val_loss: 0.1027 - val_acc: 0.8878\n",
            "Epoch 2688/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8769 - val_loss: 0.1030 - val_acc: 0.8874\n",
            "Epoch 2689/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8758 - val_loss: 0.1029 - val_acc: 0.8874\n",
            "Epoch 2690/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8847 - val_loss: 0.1024 - val_acc: 0.8876\n",
            "Epoch 2691/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1340 - acc: 0.8794 - val_loss: 0.1021 - val_acc: 0.8879\n",
            "Epoch 2692/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8886 - val_loss: 0.1017 - val_acc: 0.8884\n",
            "Epoch 2693/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8919 - val_loss: 0.1016 - val_acc: 0.8886\n",
            "Epoch 2694/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8903 - val_loss: 0.1014 - val_acc: 0.8887\n",
            "Epoch 2695/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8946 - val_loss: 0.1010 - val_acc: 0.8887\n",
            "Epoch 2696/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8872 - val_loss: 0.1005 - val_acc: 0.8884\n",
            "Epoch 2697/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8847 - val_loss: 0.1001 - val_acc: 0.8879\n",
            "Epoch 2698/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8863 - val_loss: 0.1001 - val_acc: 0.8875\n",
            "Epoch 2699/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8751 - val_loss: 0.1001 - val_acc: 0.8872\n",
            "Epoch 2700/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8843 - val_loss: 0.0998 - val_acc: 0.8872\n",
            "Epoch 2701/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8862 - val_loss: 0.0995 - val_acc: 0.8874\n",
            "Epoch 2702/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8853 - val_loss: 0.0993 - val_acc: 0.8877\n",
            "Epoch 2703/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8880 - val_loss: 0.0992 - val_acc: 0.8878\n",
            "Epoch 2704/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8884 - val_loss: 0.0990 - val_acc: 0.8877\n",
            "Epoch 2705/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8884 - val_loss: 0.0988 - val_acc: 0.8875\n",
            "Epoch 2706/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8885 - val_loss: 0.0988 - val_acc: 0.8871\n",
            "Epoch 2707/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8855 - val_loss: 0.0988 - val_acc: 0.8867\n",
            "Epoch 2708/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8803 - val_loss: 0.0988 - val_acc: 0.8863\n",
            "Epoch 2709/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8801 - val_loss: 0.0988 - val_acc: 0.8861\n",
            "Epoch 2710/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8881 - val_loss: 0.0987 - val_acc: 0.8865\n",
            "Epoch 2711/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8886 - val_loss: 0.0986 - val_acc: 0.8870\n",
            "Epoch 2712/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8829 - val_loss: 0.0986 - val_acc: 0.8875\n",
            "Epoch 2713/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8836 - val_loss: 0.0986 - val_acc: 0.8876\n",
            "Epoch 2714/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8868 - val_loss: 0.0987 - val_acc: 0.8874\n",
            "Epoch 2715/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8844 - val_loss: 0.0985 - val_acc: 0.8869\n",
            "Epoch 2716/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8907 - val_loss: 0.0984 - val_acc: 0.8863\n",
            "Epoch 2717/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8867 - val_loss: 0.0986 - val_acc: 0.8859\n",
            "Epoch 2718/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1765 - acc: 0.8655 - val_loss: 0.0997 - val_acc: 0.8853\n",
            "Epoch 2719/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8783 - val_loss: 0.0998 - val_acc: 0.8857\n",
            "Epoch 2720/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8857 - val_loss: 0.0994 - val_acc: 0.8866\n",
            "Epoch 2721/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8838 - val_loss: 0.0991 - val_acc: 0.8877\n",
            "Epoch 2722/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8889 - val_loss: 0.0994 - val_acc: 0.8884\n",
            "Epoch 2723/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8849 - val_loss: 0.0996 - val_acc: 0.8887\n",
            "Epoch 2724/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8852 - val_loss: 0.0994 - val_acc: 0.8885\n",
            "Epoch 2725/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8852 - val_loss: 0.0991 - val_acc: 0.8879\n",
            "Epoch 2726/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3260 - acc: 0.8545 - val_loss: 0.1021 - val_acc: 0.8860\n",
            "Epoch 2727/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8743 - val_loss: 0.1081 - val_acc: 0.8841\n",
            "Epoch 2728/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1504 - acc: 0.8782 - val_loss: 0.1137 - val_acc: 0.8830\n",
            "Epoch 2729/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8714 - val_loss: 0.1129 - val_acc: 0.8849\n",
            "Epoch 2730/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8839 - val_loss: 0.1087 - val_acc: 0.8875\n",
            "Epoch 2731/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1924 - acc: 0.8606 - val_loss: 0.1072 - val_acc: 0.8890\n",
            "Epoch 2732/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8763 - val_loss: 0.1072 - val_acc: 0.8898\n",
            "Epoch 2733/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8916 - val_loss: 0.1087 - val_acc: 0.8900\n",
            "Epoch 2734/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8910 - val_loss: 0.1102 - val_acc: 0.8900\n",
            "Epoch 2735/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8987 - val_loss: 0.1106 - val_acc: 0.8900\n",
            "Epoch 2736/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8903 - val_loss: 0.1095 - val_acc: 0.8899\n",
            "Epoch 2737/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1908 - acc: 0.8820 - val_loss: 0.1088 - val_acc: 0.8897\n",
            "Epoch 2738/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8895 - val_loss: 0.1097 - val_acc: 0.8892\n",
            "Epoch 2739/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1514 - acc: 0.8768 - val_loss: 0.1118 - val_acc: 0.8887\n",
            "Epoch 2740/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8839 - val_loss: 0.1132 - val_acc: 0.8884\n",
            "Epoch 2741/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8834 - val_loss: 0.1128 - val_acc: 0.8885\n",
            "Epoch 2742/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8883 - val_loss: 0.1108 - val_acc: 0.8890\n",
            "Epoch 2743/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8834 - val_loss: 0.1085 - val_acc: 0.8895\n",
            "Epoch 2744/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1778 - acc: 0.8807 - val_loss: 0.1079 - val_acc: 0.8898\n",
            "Epoch 2745/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8909 - val_loss: 0.1078 - val_acc: 0.8899\n",
            "Epoch 2746/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8849 - val_loss: 0.1079 - val_acc: 0.8900\n",
            "Epoch 2747/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8933 - val_loss: 0.1078 - val_acc: 0.8900\n",
            "Epoch 2748/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2346 - acc: 0.8754 - val_loss: 0.1076 - val_acc: 0.8899\n",
            "Epoch 2749/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1697 - acc: 0.8826 - val_loss: 0.1084 - val_acc: 0.8898\n",
            "Epoch 2750/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1454 - acc: 0.8878 - val_loss: 0.1105 - val_acc: 0.8896\n",
            "Epoch 2751/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8895 - val_loss: 0.1120 - val_acc: 0.8894\n",
            "Epoch 2752/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8858 - val_loss: 0.1121 - val_acc: 0.8893\n",
            "Epoch 2753/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8859 - val_loss: 0.1110 - val_acc: 0.8894\n",
            "Epoch 2754/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8794 - val_loss: 0.1095 - val_acc: 0.8896\n",
            "Epoch 2755/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8902 - val_loss: 0.1083 - val_acc: 0.8897\n",
            "Epoch 2756/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8903 - val_loss: 0.1079 - val_acc: 0.8898\n",
            "Epoch 2757/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8831 - val_loss: 0.1080 - val_acc: 0.8898\n",
            "Epoch 2758/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8909 - val_loss: 0.1079 - val_acc: 0.8898\n",
            "Epoch 2759/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8912 - val_loss: 0.1070 - val_acc: 0.8898\n",
            "Epoch 2760/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8913 - val_loss: 0.1057 - val_acc: 0.8896\n",
            "Epoch 2761/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8936 - val_loss: 0.1046 - val_acc: 0.8893\n",
            "Epoch 2762/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8932 - val_loss: 0.1039 - val_acc: 0.8889\n",
            "Epoch 2763/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8965 - val_loss: 0.1035 - val_acc: 0.8885\n",
            "Epoch 2764/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8913 - val_loss: 0.1031 - val_acc: 0.8882\n",
            "Epoch 2765/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8827 - val_loss: 0.1025 - val_acc: 0.8881\n",
            "Epoch 2766/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8940 - val_loss: 0.1018 - val_acc: 0.8881\n",
            "Epoch 2767/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8839 - val_loss: 0.1010 - val_acc: 0.8883\n",
            "Epoch 2768/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8871 - val_loss: 0.1006 - val_acc: 0.8885\n",
            "Epoch 2769/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8874 - val_loss: 0.1003 - val_acc: 0.8886\n",
            "Epoch 2770/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8901 - val_loss: 0.1001 - val_acc: 0.8885\n",
            "Epoch 2771/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8878 - val_loss: 0.0997 - val_acc: 0.8882\n",
            "Epoch 2772/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1891 - acc: 0.8658 - val_loss: 0.0995 - val_acc: 0.8878\n",
            "Epoch 2773/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8844 - val_loss: 0.0997 - val_acc: 0.8872\n",
            "Epoch 2774/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8815 - val_loss: 0.1000 - val_acc: 0.8868\n",
            "Epoch 2775/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8887 - val_loss: 0.0999 - val_acc: 0.8867\n",
            "Epoch 2776/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8830 - val_loss: 0.0995 - val_acc: 0.8870\n",
            "Epoch 2777/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8834 - val_loss: 0.0991 - val_acc: 0.8875\n",
            "Epoch 2778/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1546 - acc: 0.8856 - val_loss: 0.0992 - val_acc: 0.8877\n",
            "Epoch 2779/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8958 - val_loss: 0.0993 - val_acc: 0.8878\n",
            "Epoch 2780/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8837 - val_loss: 0.0991 - val_acc: 0.8878\n",
            "Epoch 2781/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8851 - val_loss: 0.0990 - val_acc: 0.8878\n",
            "Epoch 2782/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8849 - val_loss: 0.0989 - val_acc: 0.8878\n",
            "Epoch 2783/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8855 - val_loss: 0.0989 - val_acc: 0.8878\n",
            "Epoch 2784/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8914 - val_loss: 0.0989 - val_acc: 0.8877\n",
            "Epoch 2785/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3275 - acc: 0.8536 - val_loss: 0.1021 - val_acc: 0.8862\n",
            "Epoch 2786/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8807 - val_loss: 0.1059 - val_acc: 0.8851\n",
            "Epoch 2787/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8841 - val_loss: 0.1070 - val_acc: 0.8854\n",
            "Epoch 2788/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8846 - val_loss: 0.1054 - val_acc: 0.8869\n",
            "Epoch 2789/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8851 - val_loss: 0.1033 - val_acc: 0.8884\n",
            "Epoch 2790/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8929 - val_loss: 0.1028 - val_acc: 0.8892\n",
            "Epoch 2791/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8879 - val_loss: 0.1037 - val_acc: 0.8894\n",
            "Epoch 2792/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8901 - val_loss: 0.1046 - val_acc: 0.8894\n",
            "Epoch 2793/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8901 - val_loss: 0.1044 - val_acc: 0.8893\n",
            "Epoch 2794/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8849 - val_loss: 0.1034 - val_acc: 0.8889\n",
            "Epoch 2795/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8859 - val_loss: 0.1026 - val_acc: 0.8883\n",
            "Epoch 2796/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8899 - val_loss: 0.1026 - val_acc: 0.8877\n",
            "Epoch 2797/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8873 - val_loss: 0.1031 - val_acc: 0.8870\n",
            "Epoch 2798/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8866 - val_loss: 0.1032 - val_acc: 0.8868\n",
            "Epoch 2799/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8891 - val_loss: 0.1025 - val_acc: 0.8871\n",
            "Epoch 2800/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8757 - val_loss: 0.1014 - val_acc: 0.8878\n",
            "Epoch 2801/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8765 - val_loss: 0.1008 - val_acc: 0.8884\n",
            "Epoch 2802/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8825 - val_loss: 0.1006 - val_acc: 0.8887\n",
            "Epoch 2803/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8764 - val_loss: 0.1005 - val_acc: 0.8888\n",
            "Epoch 2804/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8767 - val_loss: 0.1003 - val_acc: 0.8886\n",
            "Epoch 2805/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8959 - val_loss: 0.1000 - val_acc: 0.8883\n",
            "Epoch 2806/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8877 - val_loss: 0.0996 - val_acc: 0.8878\n",
            "Epoch 2807/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1581 - acc: 0.8789 - val_loss: 0.1001 - val_acc: 0.8868\n",
            "Epoch 2808/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8847 - val_loss: 0.1008 - val_acc: 0.8861\n",
            "Epoch 2809/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8843 - val_loss: 0.1006 - val_acc: 0.8863\n",
            "Epoch 2810/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8890 - val_loss: 0.0999 - val_acc: 0.8869\n",
            "Epoch 2811/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8859 - val_loss: 0.0995 - val_acc: 0.8876\n",
            "Epoch 2812/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8901 - val_loss: 0.0995 - val_acc: 0.8881\n",
            "Epoch 2813/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8904 - val_loss: 0.0996 - val_acc: 0.8882\n",
            "Epoch 2814/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8854 - val_loss: 0.0991 - val_acc: 0.8878\n",
            "Epoch 2815/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8912 - val_loss: 0.0988 - val_acc: 0.8871\n",
            "Epoch 2816/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8772 - val_loss: 0.0988 - val_acc: 0.8864\n",
            "Epoch 2817/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8765 - val_loss: 0.0991 - val_acc: 0.8858\n",
            "Epoch 2818/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8822 - val_loss: 0.0996 - val_acc: 0.8856\n",
            "Epoch 2819/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8875 - val_loss: 0.0996 - val_acc: 0.8861\n",
            "Epoch 2820/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8869 - val_loss: 0.0993 - val_acc: 0.8871\n",
            "Epoch 2821/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8837 - val_loss: 0.0992 - val_acc: 0.8879\n",
            "Epoch 2822/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8897 - val_loss: 0.0992 - val_acc: 0.8882\n",
            "Epoch 2823/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8878 - val_loss: 0.0991 - val_acc: 0.8880\n",
            "Epoch 2824/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8835 - val_loss: 0.0988 - val_acc: 0.8875\n",
            "Epoch 2825/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8889 - val_loss: 0.0985 - val_acc: 0.8869\n",
            "Epoch 2826/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8861 - val_loss: 0.0984 - val_acc: 0.8865\n",
            "Epoch 2827/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8847 - val_loss: 0.0985 - val_acc: 0.8864\n",
            "Epoch 2828/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8882 - val_loss: 0.0987 - val_acc: 0.8865\n",
            "Epoch 2829/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8906 - val_loss: 0.0986 - val_acc: 0.8868\n",
            "Epoch 2830/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1605 - acc: 0.8824 - val_loss: 0.0988 - val_acc: 0.8870\n",
            "Epoch 2831/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8878 - val_loss: 0.0988 - val_acc: 0.8873\n",
            "Epoch 2832/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8942 - val_loss: 0.0989 - val_acc: 0.8876\n",
            "Epoch 2833/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8948 - val_loss: 0.0989 - val_acc: 0.8879\n",
            "Epoch 2834/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8779 - val_loss: 0.0984 - val_acc: 0.8880\n",
            "Epoch 2835/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8778 - val_loss: 0.0983 - val_acc: 0.8878\n",
            "Epoch 2836/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8834 - val_loss: 0.0986 - val_acc: 0.8875\n",
            "Epoch 2837/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8890 - val_loss: 0.0988 - val_acc: 0.8873\n",
            "Epoch 2838/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8829 - val_loss: 0.0988 - val_acc: 0.8872\n",
            "Epoch 2839/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8875 - val_loss: 0.0986 - val_acc: 0.8874\n",
            "Epoch 2840/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8766 - val_loss: 0.0983 - val_acc: 0.8877\n",
            "Epoch 2841/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0911 - acc: 0.8958 - val_loss: 0.0982 - val_acc: 0.8880\n",
            "Epoch 2842/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8819 - val_loss: 0.0982 - val_acc: 0.8881\n",
            "Epoch 2843/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8820 - val_loss: 0.0982 - val_acc: 0.8880\n",
            "Epoch 2844/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8901 - val_loss: 0.0981 - val_acc: 0.8879\n",
            "Epoch 2845/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8868 - val_loss: 0.0980 - val_acc: 0.8877\n",
            "Epoch 2846/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8839 - val_loss: 0.0982 - val_acc: 0.8875\n",
            "Epoch 2847/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2609 - acc: 0.8659 - val_loss: 0.0997 - val_acc: 0.8863\n",
            "Epoch 2848/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8925 - val_loss: 0.1011 - val_acc: 0.8858\n",
            "Epoch 2849/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8685 - val_loss: 0.1011 - val_acc: 0.8863\n",
            "Epoch 2850/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8838 - val_loss: 0.1002 - val_acc: 0.8875\n",
            "Epoch 2851/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8896 - val_loss: 0.0997 - val_acc: 0.8886\n",
            "Epoch 2852/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8903 - val_loss: 0.1004 - val_acc: 0.8892\n",
            "Epoch 2853/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8861 - val_loss: 0.1012 - val_acc: 0.8894\n",
            "Epoch 2854/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8925 - val_loss: 0.1011 - val_acc: 0.8894\n",
            "Epoch 2855/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8925 - val_loss: 0.1004 - val_acc: 0.8892\n",
            "Epoch 2856/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8883 - val_loss: 0.0999 - val_acc: 0.8887\n",
            "Epoch 2857/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8878 - val_loss: 0.1000 - val_acc: 0.8881\n",
            "Epoch 2858/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8776 - val_loss: 0.1003 - val_acc: 0.8876\n",
            "Epoch 2859/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8770 - val_loss: 0.1003 - val_acc: 0.8874\n",
            "Epoch 2860/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8854 - val_loss: 0.0998 - val_acc: 0.8876\n",
            "Epoch 2861/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8764 - val_loss: 0.0992 - val_acc: 0.8881\n",
            "Epoch 2862/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8850 - val_loss: 0.0989 - val_acc: 0.8885\n",
            "Epoch 2863/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8844 - val_loss: 0.0989 - val_acc: 0.8886\n",
            "Epoch 2864/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8822 - val_loss: 0.0985 - val_acc: 0.8885\n",
            "Epoch 2865/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1558 - acc: 0.8780 - val_loss: 0.0985 - val_acc: 0.8880\n",
            "Epoch 2866/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1603 - acc: 0.8803 - val_loss: 0.0994 - val_acc: 0.8872\n",
            "Epoch 2867/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8881 - val_loss: 0.1003 - val_acc: 0.8866\n",
            "Epoch 2868/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2040 - acc: 0.8687 - val_loss: 0.1025 - val_acc: 0.8861\n",
            "Epoch 2869/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8841 - val_loss: 0.1027 - val_acc: 0.8867\n",
            "Epoch 2870/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8844 - val_loss: 0.1018 - val_acc: 0.8879\n",
            "Epoch 2871/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8856 - val_loss: 0.1013 - val_acc: 0.8888\n",
            "Epoch 2872/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8923 - val_loss: 0.1015 - val_acc: 0.8894\n",
            "Epoch 2873/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8926 - val_loss: 0.1021 - val_acc: 0.8895\n",
            "Epoch 2874/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2136 - acc: 0.8708 - val_loss: 0.1019 - val_acc: 0.8894\n",
            "Epoch 2875/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8860 - val_loss: 0.1019 - val_acc: 0.8892\n",
            "Epoch 2876/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8907 - val_loss: 0.1023 - val_acc: 0.8887\n",
            "Epoch 2877/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8797 - val_loss: 0.1030 - val_acc: 0.8882\n",
            "Epoch 2878/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8805 - val_loss: 0.1033 - val_acc: 0.8879\n",
            "Epoch 2879/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8933 - val_loss: 0.1030 - val_acc: 0.8879\n",
            "Epoch 2880/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8897 - val_loss: 0.1023 - val_acc: 0.8882\n",
            "Epoch 2881/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8906 - val_loss: 0.1017 - val_acc: 0.8886\n",
            "Epoch 2882/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8910 - val_loss: 0.1015 - val_acc: 0.8889\n",
            "Epoch 2883/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8873 - val_loss: 0.1015 - val_acc: 0.8892\n",
            "Epoch 2884/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8808 - val_loss: 0.1011 - val_acc: 0.8892\n",
            "Epoch 2885/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1502 - acc: 0.8726 - val_loss: 0.1005 - val_acc: 0.8889\n",
            "Epoch 2886/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8907 - val_loss: 0.1004 - val_acc: 0.8885\n",
            "Epoch 2887/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8788 - val_loss: 0.1005 - val_acc: 0.8880\n",
            "Epoch 2888/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0910 - acc: 0.8983 - val_loss: 0.1003 - val_acc: 0.8877\n",
            "Epoch 2889/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0907 - acc: 0.8981 - val_loss: 0.0999 - val_acc: 0.8877\n",
            "Epoch 2890/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8917 - val_loss: 0.0994 - val_acc: 0.8879\n",
            "Epoch 2891/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8857 - val_loss: 0.0991 - val_acc: 0.8882\n",
            "Epoch 2892/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8832 - val_loss: 0.0989 - val_acc: 0.8884\n",
            "Epoch 2893/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8825 - val_loss: 0.0985 - val_acc: 0.8883\n",
            "Epoch 2894/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8843 - val_loss: 0.0981 - val_acc: 0.8881\n",
            "Epoch 2895/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8862 - val_loss: 0.0979 - val_acc: 0.8877\n",
            "Epoch 2896/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1528 - acc: 0.8723 - val_loss: 0.0982 - val_acc: 0.8871\n",
            "Epoch 2897/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8810 - val_loss: 0.0986 - val_acc: 0.8865\n",
            "Epoch 2898/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1976 - acc: 0.8703 - val_loss: 0.0999 - val_acc: 0.8859\n",
            "Epoch 2899/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8825 - val_loss: 0.1000 - val_acc: 0.8864\n",
            "Epoch 2900/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1663 - acc: 0.8706 - val_loss: 0.1002 - val_acc: 0.8870\n",
            "Epoch 2901/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8844 - val_loss: 0.0999 - val_acc: 0.8879\n",
            "Epoch 2902/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8908 - val_loss: 0.0998 - val_acc: 0.8887\n",
            "Epoch 2903/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8880 - val_loss: 0.0999 - val_acc: 0.8891\n",
            "Epoch 2904/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8781 - val_loss: 0.1001 - val_acc: 0.8892\n",
            "Epoch 2905/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8783 - val_loss: 0.1002 - val_acc: 0.8891\n",
            "Epoch 2906/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8961 - val_loss: 0.1001 - val_acc: 0.8888\n",
            "Epoch 2907/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8960 - val_loss: 0.1001 - val_acc: 0.8885\n",
            "Epoch 2908/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8840 - val_loss: 0.1000 - val_acc: 0.8883\n",
            "Epoch 2909/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8920 - val_loss: 0.0998 - val_acc: 0.8881\n",
            "Epoch 2910/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0940 - acc: 0.8919 - val_loss: 0.0996 - val_acc: 0.8881\n",
            "Epoch 2911/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8896 - val_loss: 0.0992 - val_acc: 0.8882\n",
            "Epoch 2912/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8863 - val_loss: 0.0988 - val_acc: 0.8884\n",
            "Epoch 2913/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8866 - val_loss: 0.0987 - val_acc: 0.8884\n",
            "Epoch 2914/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8903 - val_loss: 0.0986 - val_acc: 0.8884\n",
            "Epoch 2915/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8864 - val_loss: 0.0984 - val_acc: 0.8884\n",
            "Epoch 2916/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8864 - val_loss: 0.0983 - val_acc: 0.8883\n",
            "Epoch 2917/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8909 - val_loss: 0.0980 - val_acc: 0.8882\n",
            "Epoch 2918/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8910 - val_loss: 0.0978 - val_acc: 0.8879\n",
            "Epoch 2919/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8791 - val_loss: 0.0977 - val_acc: 0.8876\n",
            "Epoch 2920/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8789 - val_loss: 0.0976 - val_acc: 0.8874\n",
            "Epoch 2921/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8877 - val_loss: 0.0974 - val_acc: 0.8874\n",
            "Epoch 2922/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8878 - val_loss: 0.0973 - val_acc: 0.8877\n",
            "Epoch 2923/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8882 - val_loss: 0.0972 - val_acc: 0.8878\n",
            "Epoch 2924/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3152 - acc: 0.8493 - val_loss: 0.0985 - val_acc: 0.8867\n",
            "Epoch 2925/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8922 - val_loss: 0.1006 - val_acc: 0.8859\n",
            "Epoch 2926/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8916 - val_loss: 0.1011 - val_acc: 0.8862\n",
            "Epoch 2927/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8888 - val_loss: 0.1002 - val_acc: 0.8872\n",
            "Epoch 2928/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2540 - acc: 0.8566 - val_loss: 0.1021 - val_acc: 0.8873\n",
            "Epoch 2929/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8875 - val_loss: 0.1029 - val_acc: 0.8879\n",
            "Epoch 2930/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8791 - val_loss: 0.1029 - val_acc: 0.8886\n",
            "Epoch 2931/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8841 - val_loss: 0.1026 - val_acc: 0.8892\n",
            "Epoch 2932/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8846 - val_loss: 0.1027 - val_acc: 0.8895\n",
            "Epoch 2933/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1960 - acc: 0.8750 - val_loss: 0.1035 - val_acc: 0.8896\n",
            "Epoch 2934/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8907 - val_loss: 0.1042 - val_acc: 0.8896\n",
            "Epoch 2935/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8900 - val_loss: 0.1045 - val_acc: 0.8896\n",
            "Epoch 2936/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8906 - val_loss: 0.1047 - val_acc: 0.8895\n",
            "Epoch 2937/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8899 - val_loss: 0.1048 - val_acc: 0.8895\n",
            "Epoch 2938/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8896 - val_loss: 0.1048 - val_acc: 0.8894\n",
            "Epoch 2939/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8888 - val_loss: 0.1046 - val_acc: 0.8893\n",
            "Epoch 2940/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8881 - val_loss: 0.1043 - val_acc: 0.8893\n",
            "Epoch 2941/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8881 - val_loss: 0.1037 - val_acc: 0.8893\n",
            "Epoch 2942/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8917 - val_loss: 0.1031 - val_acc: 0.8894\n",
            "Epoch 2943/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1637 - acc: 0.8840 - val_loss: 0.1031 - val_acc: 0.8893\n",
            "Epoch 2944/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8886 - val_loss: 0.1035 - val_acc: 0.8892\n",
            "Epoch 2945/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8948 - val_loss: 0.1035 - val_acc: 0.8891\n",
            "Epoch 2946/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8865 - val_loss: 0.1033 - val_acc: 0.8892\n",
            "Epoch 2947/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8860 - val_loss: 0.1025 - val_acc: 0.8893\n",
            "Epoch 2948/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1553 - acc: 0.8801 - val_loss: 0.1023 - val_acc: 0.8894\n",
            "Epoch 2949/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8992 - val_loss: 0.1021 - val_acc: 0.8895\n",
            "Epoch 2950/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8991 - val_loss: 0.1020 - val_acc: 0.8895\n",
            "Epoch 2951/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8994 - val_loss: 0.1020 - val_acc: 0.8895\n",
            "Epoch 2952/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8993 - val_loss: 0.1018 - val_acc: 0.8894\n",
            "Epoch 2953/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8872 - val_loss: 0.1013 - val_acc: 0.8892\n",
            "Epoch 2954/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8896 - val_loss: 0.1006 - val_acc: 0.8890\n",
            "Epoch 2955/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8956 - val_loss: 0.1002 - val_acc: 0.8888\n",
            "Epoch 2956/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8811 - val_loss: 0.0999 - val_acc: 0.8885\n",
            "Epoch 2957/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8809 - val_loss: 0.0996 - val_acc: 0.8883\n",
            "Epoch 2958/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8818 - val_loss: 0.0994 - val_acc: 0.8883\n",
            "Epoch 2959/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2543 - acc: 0.8609 - val_loss: 0.1007 - val_acc: 0.8878\n",
            "Epoch 2960/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8885 - val_loss: 0.1017 - val_acc: 0.8876\n",
            "Epoch 2961/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8788 - val_loss: 0.1016 - val_acc: 0.8878\n",
            "Epoch 2962/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8946 - val_loss: 0.1008 - val_acc: 0.8884\n",
            "Epoch 2963/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8821 - val_loss: 0.1002 - val_acc: 0.8890\n",
            "Epoch 2964/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8788 - val_loss: 0.1003 - val_acc: 0.8893\n",
            "Epoch 2965/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8921 - val_loss: 0.1004 - val_acc: 0.8893\n",
            "Epoch 2966/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8845 - val_loss: 0.1002 - val_acc: 0.8892\n",
            "Epoch 2967/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8899 - val_loss: 0.0997 - val_acc: 0.8889\n",
            "Epoch 2968/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8919 - val_loss: 0.0994 - val_acc: 0.8884\n",
            "Epoch 2969/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8915 - val_loss: 0.0995 - val_acc: 0.8878\n",
            "Epoch 2970/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8942 - val_loss: 0.0994 - val_acc: 0.8876\n",
            "Epoch 2971/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8942 - val_loss: 0.0990 - val_acc: 0.8877\n",
            "Epoch 2972/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8909 - val_loss: 0.0985 - val_acc: 0.8882\n",
            "Epoch 2973/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1722 - acc: 0.8721 - val_loss: 0.0985 - val_acc: 0.8882\n",
            "Epoch 2974/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8812 - val_loss: 0.0985 - val_acc: 0.8883\n",
            "Epoch 2975/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8836 - val_loss: 0.0986 - val_acc: 0.8883\n",
            "Epoch 2976/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8832 - val_loss: 0.0985 - val_acc: 0.8883\n",
            "Epoch 2977/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8885 - val_loss: 0.0983 - val_acc: 0.8883\n",
            "Epoch 2978/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8853 - val_loss: 0.0981 - val_acc: 0.8883\n",
            "Epoch 2979/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2260 - acc: 0.8652 - val_loss: 0.0987 - val_acc: 0.8875\n",
            "Epoch 2980/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2642 - acc: 0.8470 - val_loss: 0.1039 - val_acc: 0.8855\n",
            "Epoch 2981/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8793 - val_loss: 0.1077 - val_acc: 0.8847\n",
            "Epoch 2982/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8849 - val_loss: 0.1070 - val_acc: 0.8861\n",
            "Epoch 2983/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1736 - acc: 0.8675 - val_loss: 0.1055 - val_acc: 0.8878\n",
            "Epoch 2984/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8933 - val_loss: 0.1040 - val_acc: 0.8892\n",
            "Epoch 2985/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8914 - val_loss: 0.1043 - val_acc: 0.8898\n",
            "Epoch 2986/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8841 - val_loss: 0.1056 - val_acc: 0.8899\n",
            "Epoch 2987/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8967 - val_loss: 0.1066 - val_acc: 0.8899\n",
            "Epoch 2988/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8967 - val_loss: 0.1064 - val_acc: 0.8897\n",
            "Epoch 2989/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8912 - val_loss: 0.1055 - val_acc: 0.8895\n",
            "Epoch 2990/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2435 - acc: 0.8738 - val_loss: 0.1060 - val_acc: 0.8890\n",
            "Epoch 2991/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8889 - val_loss: 0.1078 - val_acc: 0.8885\n",
            "Epoch 2992/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8903 - val_loss: 0.1093 - val_acc: 0.8882\n",
            "Epoch 2993/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8869 - val_loss: 0.1096 - val_acc: 0.8883\n",
            "Epoch 2994/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8890 - val_loss: 0.1087 - val_acc: 0.8887\n",
            "Epoch 2995/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8876 - val_loss: 0.1074 - val_acc: 0.8892\n",
            "Epoch 2996/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8901 - val_loss: 0.1062 - val_acc: 0.8896\n",
            "Epoch 2997/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8906 - val_loss: 0.1057 - val_acc: 0.8899\n",
            "Epoch 2998/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8932 - val_loss: 0.1057 - val_acc: 0.8900\n",
            "Epoch 2999/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8862 - val_loss: 0.1055 - val_acc: 0.8900\n",
            "Epoch 3000/3000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8863 - val_loss: 0.1047 - val_acc: 0.8898\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "latent (Dense)               (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "output (Conv2D)              (None, 64, 64, 1)         145       \n",
            "=================================================================\n",
            "Total params: 1,053,473\n",
            "Trainable params: 1,053,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAMHCAYAAAD7ABn5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCCF8RAorIYQQQggf+X9E06Bvos9tJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABUkAAANHCAYAAAALxtxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 1728x1728 with 19 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y07hnxXdj0qI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "seen_encoder.save('seen_encoder.h5')\n",
        "seen_autoencoder.save('seen_autoencoder.h5')\n",
        "files.download('seen_encoder.h5')\n",
        "files.download('seen_autoencoder.h5')\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kzCFOnutGzhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172903
        },
        "outputId": "fc8ab402-46a4-4b94-d212-e17b434e7b9b"
      },
      "cell_type": "code",
      "source": [
        "unseen_encoder,unseen_autoencoder = train_encoder(unseen_dataset,epochs=5000)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6900 - acc: 0.8094 - val_loss: 0.6842 - val_acc: 0.8856\n",
            "Epoch 2/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6842 - acc: 0.8741 - val_loss: 0.6726 - val_acc: 0.8950\n",
            "Epoch 3/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6723 - acc: 0.8854 - val_loss: 0.6538 - val_acc: 0.8975\n",
            "Epoch 4/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6527 - acc: 0.8832 - val_loss: 0.6257 - val_acc: 0.8984\n",
            "Epoch 5/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6239 - acc: 0.8839 - val_loss: 0.5860 - val_acc: 0.8987\n",
            "Epoch 6/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5830 - acc: 0.8842 - val_loss: 0.5331 - val_acc: 0.8988\n",
            "Epoch 7/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5311 - acc: 0.8859 - val_loss: 0.4685 - val_acc: 0.8988\n",
            "Epoch 8/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4686 - acc: 0.8911 - val_loss: 0.3979 - val_acc: 0.8988\n",
            "Epoch 9/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3984 - acc: 0.8918 - val_loss: 0.3331 - val_acc: 0.8988\n",
            "Epoch 10/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3372 - acc: 0.8918 - val_loss: 0.2891 - val_acc: 0.8988\n",
            "Epoch 11/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3051 - acc: 0.8873 - val_loss: 0.2734 - val_acc: 0.8988\n",
            "Epoch 12/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3132 - acc: 0.8849 - val_loss: 0.2748 - val_acc: 0.8988\n",
            "Epoch 13/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3015 - acc: 0.8878 - val_loss: 0.2756 - val_acc: 0.8988\n",
            "Epoch 14/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3099 - acc: 0.8867 - val_loss: 0.2674 - val_acc: 0.8988\n",
            "Epoch 15/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2831 - acc: 0.8929 - val_loss: 0.2526 - val_acc: 0.8988\n",
            "Epoch 16/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2674 - acc: 0.8929 - val_loss: 0.2355 - val_acc: 0.8988\n",
            "Epoch 17/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2591 - acc: 0.8920 - val_loss: 0.2200 - val_acc: 0.8988\n",
            "Epoch 18/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2423 - acc: 0.8885 - val_loss: 0.2092 - val_acc: 0.8988\n",
            "Epoch 19/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2206 - acc: 0.8932 - val_loss: 0.2035 - val_acc: 0.8988\n",
            "Epoch 20/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2146 - acc: 0.8889 - val_loss: 0.2013 - val_acc: 0.8988\n",
            "Epoch 21/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2324 - acc: 0.8890 - val_loss: 0.2013 - val_acc: 0.8988\n",
            "Epoch 22/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2146 - acc: 0.8889 - val_loss: 0.2021 - val_acc: 0.8988\n",
            "Epoch 23/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2143 - acc: 0.8889 - val_loss: 0.2026 - val_acc: 0.8988\n",
            "Epoch 24/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2083 - acc: 0.8926 - val_loss: 0.2019 - val_acc: 0.8988\n",
            "Epoch 25/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2168 - acc: 0.8866 - val_loss: 0.2002 - val_acc: 0.8988\n",
            "Epoch 26/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2294 - acc: 0.8815 - val_loss: 0.1979 - val_acc: 0.8988\n",
            "Epoch 27/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2272 - acc: 0.8815 - val_loss: 0.1952 - val_acc: 0.8988\n",
            "Epoch 28/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1950 - acc: 0.8985 - val_loss: 0.1914 - val_acc: 0.8988\n",
            "Epoch 29/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1910 - acc: 0.8985 - val_loss: 0.1873 - val_acc: 0.8988\n",
            "Epoch 30/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2080 - acc: 0.8880 - val_loss: 0.1838 - val_acc: 0.8988\n",
            "Epoch 31/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2111 - acc: 0.8843 - val_loss: 0.1813 - val_acc: 0.8988\n",
            "Epoch 32/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2121 - acc: 0.8843 - val_loss: 0.1794 - val_acc: 0.8988\n",
            "Epoch 33/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1902 - acc: 0.8917 - val_loss: 0.1780 - val_acc: 0.8988\n",
            "Epoch 34/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1912 - acc: 0.8907 - val_loss: 0.1768 - val_acc: 0.8988\n",
            "Epoch 35/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1902 - acc: 0.8907 - val_loss: 0.1757 - val_acc: 0.8988\n",
            "Epoch 36/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1980 - acc: 0.8885 - val_loss: 0.1747 - val_acc: 0.8988\n",
            "Epoch 37/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1971 - acc: 0.8885 - val_loss: 0.1738 - val_acc: 0.8988\n",
            "Epoch 38/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1796 - acc: 0.8931 - val_loss: 0.1731 - val_acc: 0.8988\n",
            "Epoch 39/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1864 - acc: 0.8903 - val_loss: 0.1723 - val_acc: 0.8988\n",
            "Epoch 40/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1851 - acc: 0.8903 - val_loss: 0.1715 - val_acc: 0.8988\n",
            "Epoch 41/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1945 - acc: 0.8865 - val_loss: 0.1709 - val_acc: 0.8988\n",
            "Epoch 42/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2286 - acc: 0.8721 - val_loss: 0.1710 - val_acc: 0.8988\n",
            "Epoch 43/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1965 - acc: 0.8847 - val_loss: 0.1713 - val_acc: 0.8988\n",
            "Epoch 44/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1942 - acc: 0.8912 - val_loss: 0.1718 - val_acc: 0.8988\n",
            "Epoch 45/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1845 - acc: 0.8950 - val_loss: 0.1718 - val_acc: 0.8988\n",
            "Epoch 46/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1926 - acc: 0.8856 - val_loss: 0.1716 - val_acc: 0.8988\n",
            "Epoch 47/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1972 - acc: 0.8828 - val_loss: 0.1713 - val_acc: 0.8988\n",
            "Epoch 48/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1746 - acc: 0.8929 - val_loss: 0.1703 - val_acc: 0.8988\n",
            "Epoch 49/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1737 - acc: 0.8929 - val_loss: 0.1688 - val_acc: 0.8988\n",
            "Epoch 50/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1810 - acc: 0.8901 - val_loss: 0.1672 - val_acc: 0.8988\n",
            "Epoch 51/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1749 - acc: 0.8926 - val_loss: 0.1656 - val_acc: 0.8988\n",
            "Epoch 52/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1775 - acc: 0.8891 - val_loss: 0.1643 - val_acc: 0.8988\n",
            "Epoch 53/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1903 - acc: 0.8820 - val_loss: 0.1633 - val_acc: 0.8988\n",
            "Epoch 54/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1851 - acc: 0.8893 - val_loss: 0.1626 - val_acc: 0.8988\n",
            "Epoch 55/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1608 - acc: 0.8976 - val_loss: 0.1619 - val_acc: 0.8988\n",
            "Epoch 56/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1987 - acc: 0.8876 - val_loss: 0.1613 - val_acc: 0.8988\n",
            "Epoch 57/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1978 - acc: 0.8876 - val_loss: 0.1609 - val_acc: 0.8988\n",
            "Epoch 58/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1548 - acc: 0.9023 - val_loss: 0.1604 - val_acc: 0.8988\n",
            "Epoch 59/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1845 - acc: 0.8910 - val_loss: 0.1600 - val_acc: 0.8988\n",
            "Epoch 60/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1837 - acc: 0.8797 - val_loss: 0.1599 - val_acc: 0.8988\n",
            "Epoch 61/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1760 - acc: 0.8883 - val_loss: 0.1598 - val_acc: 0.8988\n",
            "Epoch 62/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1751 - acc: 0.8883 - val_loss: 0.1598 - val_acc: 0.8988\n",
            "Epoch 63/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1733 - acc: 0.8869 - val_loss: 0.1598 - val_acc: 0.8988\n",
            "Epoch 64/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1813 - acc: 0.8855 - val_loss: 0.1597 - val_acc: 0.8988\n",
            "Epoch 65/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1807 - acc: 0.8855 - val_loss: 0.1594 - val_acc: 0.8988\n",
            "Epoch 66/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1686 - acc: 0.8892 - val_loss: 0.1589 - val_acc: 0.8988\n",
            "Epoch 67/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1713 - acc: 0.8894 - val_loss: 0.1582 - val_acc: 0.8988\n",
            "Epoch 68/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1603 - acc: 0.8966 - val_loss: 0.1572 - val_acc: 0.8988\n",
            "Epoch 69/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1569 - acc: 0.8966 - val_loss: 0.1562 - val_acc: 0.8988\n",
            "Epoch 70/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1811 - acc: 0.8867 - val_loss: 0.1556 - val_acc: 0.8988\n",
            "Epoch 71/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1710 - acc: 0.8867 - val_loss: 0.1551 - val_acc: 0.8988\n",
            "Epoch 72/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1678 - acc: 0.8868 - val_loss: 0.1547 - val_acc: 0.8988\n",
            "Epoch 73/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1741 - acc: 0.8828 - val_loss: 0.1544 - val_acc: 0.8988\n",
            "Epoch 74/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1751 - acc: 0.8831 - val_loss: 0.1542 - val_acc: 0.8988\n",
            "Epoch 75/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1743 - acc: 0.8831 - val_loss: 0.1542 - val_acc: 0.8988\n",
            "Epoch 76/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1635 - acc: 0.8929 - val_loss: 0.1542 - val_acc: 0.8988\n",
            "Epoch 77/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1786 - acc: 0.8864 - val_loss: 0.1541 - val_acc: 0.8988\n",
            "Epoch 78/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1862 - acc: 0.8789 - val_loss: 0.1542 - val_acc: 0.8988\n",
            "Epoch 79/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1550 - acc: 0.8967 - val_loss: 0.1538 - val_acc: 0.8988\n",
            "Epoch 80/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1707 - acc: 0.8891 - val_loss: 0.1534 - val_acc: 0.8988\n",
            "Epoch 81/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1968 - acc: 0.8845 - val_loss: 0.1533 - val_acc: 0.8988\n",
            "Epoch 82/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1705 - acc: 0.8816 - val_loss: 0.1532 - val_acc: 0.8988\n",
            "Epoch 83/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1697 - acc: 0.8816 - val_loss: 0.1530 - val_acc: 0.8988\n",
            "Epoch 84/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1636 - acc: 0.8920 - val_loss: 0.1525 - val_acc: 0.8988\n",
            "Epoch 85/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1631 - acc: 0.8920 - val_loss: 0.1519 - val_acc: 0.8988\n",
            "Epoch 86/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1652 - acc: 0.8923 - val_loss: 0.1513 - val_acc: 0.8988\n",
            "Epoch 87/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1851 - acc: 0.8856 - val_loss: 0.1511 - val_acc: 0.8988\n",
            "Epoch 88/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1691 - acc: 0.8853 - val_loss: 0.1509 - val_acc: 0.8988\n",
            "Epoch 89/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 0.8932 - val_loss: 0.1509 - val_acc: 0.8988\n",
            "Epoch 90/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1621 - acc: 0.8932 - val_loss: 0.1508 - val_acc: 0.8988\n",
            "Epoch 91/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1799 - acc: 0.8852 - val_loss: 0.1509 - val_acc: 0.8988\n",
            "Epoch 92/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1683 - acc: 0.8865 - val_loss: 0.1510 - val_acc: 0.8988\n",
            "Epoch 93/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1794 - acc: 0.8787 - val_loss: 0.1512 - val_acc: 0.8988\n",
            "Epoch 94/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1600 - acc: 0.8948 - val_loss: 0.1510 - val_acc: 0.8988\n",
            "Epoch 95/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1726 - acc: 0.8885 - val_loss: 0.1506 - val_acc: 0.8988\n",
            "Epoch 96/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1719 - acc: 0.8905 - val_loss: 0.1500 - val_acc: 0.8988\n",
            "Epoch 97/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1626 - acc: 0.8915 - val_loss: 0.1495 - val_acc: 0.8988\n",
            "Epoch 98/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1648 - acc: 0.8878 - val_loss: 0.1489 - val_acc: 0.8988\n",
            "Epoch 99/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1784 - acc: 0.8792 - val_loss: 0.1486 - val_acc: 0.8988\n",
            "Epoch 100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1756 - acc: 0.8842 - val_loss: 0.1485 - val_acc: 0.8988\n",
            "Epoch 101/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1763 - acc: 0.8833 - val_loss: 0.1484 - val_acc: 0.8988\n",
            "Epoch 102/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1579 - acc: 0.8890 - val_loss: 0.1482 - val_acc: 0.8988\n",
            "Epoch 103/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1650 - acc: 0.8878 - val_loss: 0.1480 - val_acc: 0.8988\n",
            "Epoch 104/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1567 - acc: 0.8970 - val_loss: 0.1477 - val_acc: 0.8988\n",
            "Epoch 105/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1522 - acc: 0.8930 - val_loss: 0.1474 - val_acc: 0.8988\n",
            "Epoch 106/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1518 - acc: 0.8930 - val_loss: 0.1471 - val_acc: 0.8988\n",
            "Epoch 107/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1488 - acc: 0.8945 - val_loss: 0.1470 - val_acc: 0.8988\n",
            "Epoch 108/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1486 - acc: 0.8945 - val_loss: 0.1469 - val_acc: 0.8988\n",
            "Epoch 109/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1670 - acc: 0.8899 - val_loss: 0.1467 - val_acc: 0.8988\n",
            "Epoch 110/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1667 - acc: 0.8899 - val_loss: 0.1466 - val_acc: 0.8988\n",
            "Epoch 111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1807 - acc: 0.8786 - val_loss: 0.1466 - val_acc: 0.8988\n",
            "Epoch 112/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1602 - acc: 0.8891 - val_loss: 0.1468 - val_acc: 0.8988\n",
            "Epoch 113/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1630 - acc: 0.8879 - val_loss: 0.1471 - val_acc: 0.8988\n",
            "Epoch 114/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1629 - acc: 0.8854 - val_loss: 0.1472 - val_acc: 0.8988\n",
            "Epoch 115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2381 - acc: 0.8773 - val_loss: 0.1489 - val_acc: 0.8988\n",
            "Epoch 116/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1960 - acc: 0.8773 - val_loss: 0.1508 - val_acc: 0.8988\n",
            "Epoch 117/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8996 - val_loss: 0.1511 - val_acc: 0.8988\n",
            "Epoch 118/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1654 - acc: 0.8900 - val_loss: 0.1499 - val_acc: 0.8988\n",
            "Epoch 119/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1642 - acc: 0.8900 - val_loss: 0.1479 - val_acc: 0.8988\n",
            "Epoch 120/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1891 - acc: 0.8856 - val_loss: 0.1468 - val_acc: 0.8988\n",
            "Epoch 121/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1547 - acc: 0.8910 - val_loss: 0.1459 - val_acc: 0.8988\n",
            "Epoch 122/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1687 - acc: 0.8830 - val_loss: 0.1455 - val_acc: 0.8988\n",
            "Epoch 123/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1689 - acc: 0.8830 - val_loss: 0.1453 - val_acc: 0.8988\n",
            "Epoch 124/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2157 - acc: 0.8807 - val_loss: 0.1452 - val_acc: 0.8988\n",
            "Epoch 125/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1876 - acc: 0.8839 - val_loss: 0.1456 - val_acc: 0.8988\n",
            "Epoch 126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1752 - acc: 0.8839 - val_loss: 0.1465 - val_acc: 0.8988\n",
            "Epoch 127/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - acc: 0.8874 - val_loss: 0.1474 - val_acc: 0.8988\n",
            "Epoch 128/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1534 - acc: 0.8930 - val_loss: 0.1473 - val_acc: 0.8988\n",
            "Epoch 129/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1611 - acc: 0.8903 - val_loss: 0.1465 - val_acc: 0.8988\n",
            "Epoch 130/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1568 - acc: 0.8976 - val_loss: 0.1454 - val_acc: 0.8988\n",
            "Epoch 131/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8976 - val_loss: 0.1445 - val_acc: 0.8988\n",
            "Epoch 132/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1650 - acc: 0.8862 - val_loss: 0.1441 - val_acc: 0.8988\n",
            "Epoch 133/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2098 - acc: 0.8773 - val_loss: 0.1440 - val_acc: 0.8988\n",
            "Epoch 134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1768 - acc: 0.8773 - val_loss: 0.1439 - val_acc: 0.8988\n",
            "Epoch 135/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1704 - acc: 0.8801 - val_loss: 0.1442 - val_acc: 0.8988\n",
            "Epoch 136/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1526 - acc: 0.8876 - val_loss: 0.1445 - val_acc: 0.8988\n",
            "Epoch 137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1787 - acc: 0.8752 - val_loss: 0.1448 - val_acc: 0.8988\n",
            "Epoch 138/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1784 - acc: 0.8752 - val_loss: 0.1449 - val_acc: 0.8988\n",
            "Epoch 139/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1549 - acc: 0.8938 - val_loss: 0.1445 - val_acc: 0.8988\n",
            "Epoch 140/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1600 - acc: 0.8865 - val_loss: 0.1436 - val_acc: 0.8988\n",
            "Epoch 141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1647 - acc: 0.8841 - val_loss: 0.1430 - val_acc: 0.8988\n",
            "Epoch 142/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1805 - acc: 0.8872 - val_loss: 0.1427 - val_acc: 0.8988\n",
            "Epoch 143/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1555 - acc: 0.8877 - val_loss: 0.1425 - val_acc: 0.8988\n",
            "Epoch 144/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1546 - acc: 0.8903 - val_loss: 0.1422 - val_acc: 0.8988\n",
            "Epoch 145/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1656 - acc: 0.8816 - val_loss: 0.1419 - val_acc: 0.8988\n",
            "Epoch 146/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1573 - acc: 0.8870 - val_loss: 0.1416 - val_acc: 0.8988\n",
            "Epoch 147/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1602 - acc: 0.8866 - val_loss: 0.1414 - val_acc: 0.8988\n",
            "Epoch 148/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1597 - acc: 0.8866 - val_loss: 0.1414 - val_acc: 0.8988\n",
            "Epoch 149/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1653 - acc: 0.8876 - val_loss: 0.1412 - val_acc: 0.8988\n",
            "Epoch 150/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1553 - acc: 0.8874 - val_loss: 0.1410 - val_acc: 0.8988\n",
            "Epoch 151/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1511 - acc: 0.8922 - val_loss: 0.1406 - val_acc: 0.8988\n",
            "Epoch 152/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1545 - acc: 0.8877 - val_loss: 0.1403 - val_acc: 0.8988\n",
            "Epoch 153/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8913 - val_loss: 0.1400 - val_acc: 0.8988\n",
            "Epoch 154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1733 - acc: 0.8917 - val_loss: 0.1399 - val_acc: 0.8988\n",
            "Epoch 155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1465 - acc: 0.8923 - val_loss: 0.1399 - val_acc: 0.8988\n",
            "Epoch 156/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1789 - acc: 0.8703 - val_loss: 0.1400 - val_acc: 0.8988\n",
            "Epoch 157/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1581 - acc: 0.8845 - val_loss: 0.1401 - val_acc: 0.8988\n",
            "Epoch 158/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1460 - acc: 0.8972 - val_loss: 0.1399 - val_acc: 0.8988\n",
            "Epoch 159/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1537 - acc: 0.8902 - val_loss: 0.1396 - val_acc: 0.8988\n",
            "Epoch 160/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1584 - acc: 0.8873 - val_loss: 0.1393 - val_acc: 0.8988\n",
            "Epoch 161/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1579 - acc: 0.8873 - val_loss: 0.1390 - val_acc: 0.8988\n",
            "Epoch 162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1460 - acc: 0.8949 - val_loss: 0.1388 - val_acc: 0.8988\n",
            "Epoch 163/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8897 - val_loss: 0.1386 - val_acc: 0.8988\n",
            "Epoch 164/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1640 - acc: 0.8829 - val_loss: 0.1384 - val_acc: 0.8988\n",
            "Epoch 165/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1634 - acc: 0.8829 - val_loss: 0.1385 - val_acc: 0.8988\n",
            "Epoch 166/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565 - acc: 0.8840 - val_loss: 0.1385 - val_acc: 0.8988\n",
            "Epoch 167/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1538 - acc: 0.8905 - val_loss: 0.1384 - val_acc: 0.8988\n",
            "Epoch 168/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1482 - acc: 0.8923 - val_loss: 0.1379 - val_acc: 0.8988\n",
            "Epoch 169/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1544 - acc: 0.8876 - val_loss: 0.1376 - val_acc: 0.8988\n",
            "Epoch 170/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1438 - acc: 0.8939 - val_loss: 0.1373 - val_acc: 0.8988\n",
            "Epoch 171/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8860 - val_loss: 0.1372 - val_acc: 0.8988\n",
            "Epoch 172/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1749 - acc: 0.8825 - val_loss: 0.1371 - val_acc: 0.8988\n",
            "Epoch 173/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1570 - acc: 0.8859 - val_loss: 0.1370 - val_acc: 0.8988\n",
            "Epoch 174/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1565 - acc: 0.8859 - val_loss: 0.1369 - val_acc: 0.8988\n",
            "Epoch 175/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1571 - acc: 0.8852 - val_loss: 0.1368 - val_acc: 0.8988\n",
            "Epoch 176/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1589 - acc: 0.8843 - val_loss: 0.1365 - val_acc: 0.8988\n",
            "Epoch 177/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - acc: 0.8843 - val_loss: 0.1362 - val_acc: 0.8988\n",
            "Epoch 178/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1502 - acc: 0.8867 - val_loss: 0.1358 - val_acc: 0.8988\n",
            "Epoch 179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1569 - acc: 0.8838 - val_loss: 0.1357 - val_acc: 0.8988\n",
            "Epoch 180/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8920 - val_loss: 0.1356 - val_acc: 0.8988\n",
            "Epoch 181/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1505 - acc: 0.8857 - val_loss: 0.1354 - val_acc: 0.8988\n",
            "Epoch 182/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1497 - acc: 0.8890 - val_loss: 0.1353 - val_acc: 0.8988\n",
            "Epoch 183/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1539 - acc: 0.8879 - val_loss: 0.1354 - val_acc: 0.8988\n",
            "Epoch 184/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1564 - acc: 0.8817 - val_loss: 0.1354 - val_acc: 0.8988\n",
            "Epoch 185/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1992 - acc: 0.8865 - val_loss: 0.1372 - val_acc: 0.8988\n",
            "Epoch 186/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - acc: 0.8865 - val_loss: 0.1380 - val_acc: 0.8988\n",
            "Epoch 187/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1407 - acc: 0.8942 - val_loss: 0.1369 - val_acc: 0.8988\n",
            "Epoch 188/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1504 - acc: 0.8873 - val_loss: 0.1354 - val_acc: 0.8988\n",
            "Epoch 189/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8921 - val_loss: 0.1346 - val_acc: 0.8988\n",
            "Epoch 190/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1462 - acc: 0.8887 - val_loss: 0.1350 - val_acc: 0.8988\n",
            "Epoch 191/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1334 - acc: 0.9004 - val_loss: 0.1353 - val_acc: 0.8988\n",
            "Epoch 192/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1481 - acc: 0.8909 - val_loss: 0.1343 - val_acc: 0.8988\n",
            "Epoch 193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1464 - acc: 0.8909 - val_loss: 0.1339 - val_acc: 0.8988\n",
            "Epoch 194/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1578 - acc: 0.8853 - val_loss: 0.1345 - val_acc: 0.8988\n",
            "Epoch 195/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1607 - acc: 0.8850 - val_loss: 0.1353 - val_acc: 0.8988\n",
            "Epoch 196/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1533 - acc: 0.8875 - val_loss: 0.1353 - val_acc: 0.8988\n",
            "Epoch 197/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8933 - val_loss: 0.1347 - val_acc: 0.8988\n",
            "Epoch 198/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1620 - acc: 0.8835 - val_loss: 0.1341 - val_acc: 0.8988\n",
            "Epoch 199/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1612 - acc: 0.8835 - val_loss: 0.1336 - val_acc: 0.8988\n",
            "Epoch 200/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1601 - acc: 0.8839 - val_loss: 0.1334 - val_acc: 0.8988\n",
            "Epoch 201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1508 - acc: 0.8868 - val_loss: 0.1330 - val_acc: 0.8988\n",
            "Epoch 202/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1495 - acc: 0.8855 - val_loss: 0.1326 - val_acc: 0.8988\n",
            "Epoch 203/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1733 - acc: 0.8760 - val_loss: 0.1325 - val_acc: 0.8988\n",
            "Epoch 204/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1652 - acc: 0.8942 - val_loss: 0.1329 - val_acc: 0.8988\n",
            "Epoch 205/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8942 - val_loss: 0.1332 - val_acc: 0.8988\n",
            "Epoch 206/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1416 - acc: 0.8907 - val_loss: 0.1330 - val_acc: 0.8988\n",
            "Epoch 207/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1421 - acc: 0.8896 - val_loss: 0.1325 - val_acc: 0.8988\n",
            "Epoch 208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1415 - acc: 0.8896 - val_loss: 0.1321 - val_acc: 0.8988\n",
            "Epoch 209/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1454 - acc: 0.8905 - val_loss: 0.1319 - val_acc: 0.8988\n",
            "Epoch 210/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1470 - acc: 0.8903 - val_loss: 0.1318 - val_acc: 0.8988\n",
            "Epoch 211/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1420 - acc: 0.8892 - val_loss: 0.1315 - val_acc: 0.8988\n",
            "Epoch 212/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1668 - acc: 0.8773 - val_loss: 0.1316 - val_acc: 0.8988\n",
            "Epoch 213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1651 - acc: 0.8773 - val_loss: 0.1321 - val_acc: 0.8988\n",
            "Epoch 214/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1392 - acc: 0.8950 - val_loss: 0.1323 - val_acc: 0.8988\n",
            "Epoch 215/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1525 - acc: 0.8856 - val_loss: 0.1319 - val_acc: 0.8988\n",
            "Epoch 216/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1499 - acc: 0.8855 - val_loss: 0.1314 - val_acc: 0.8988\n",
            "Epoch 217/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1568 - acc: 0.8841 - val_loss: 0.1311 - val_acc: 0.8988\n",
            "Epoch 218/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1498 - acc: 0.8852 - val_loss: 0.1309 - val_acc: 0.8988\n",
            "Epoch 219/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2242 - acc: 0.8880 - val_loss: 0.1315 - val_acc: 0.8988\n",
            "Epoch 220/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1476 - acc: 0.8880 - val_loss: 0.1325 - val_acc: 0.8988\n",
            "Epoch 221/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1532 - acc: 0.8838 - val_loss: 0.1330 - val_acc: 0.8988\n",
            "Epoch 222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8872 - val_loss: 0.1323 - val_acc: 0.8988\n",
            "Epoch 223/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8974 - val_loss: 0.1313 - val_acc: 0.8988\n",
            "Epoch 224/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1448 - acc: 0.8893 - val_loss: 0.1312 - val_acc: 0.8988\n",
            "Epoch 225/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1413 - acc: 0.8921 - val_loss: 0.1312 - val_acc: 0.8988\n",
            "Epoch 226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1573 - acc: 0.8813 - val_loss: 0.1305 - val_acc: 0.8988\n",
            "Epoch 227/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1488 - acc: 0.8843 - val_loss: 0.1303 - val_acc: 0.8988\n",
            "Epoch 228/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1419 - acc: 0.8917 - val_loss: 0.1307 - val_acc: 0.8987\n",
            "Epoch 229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1385 - acc: 0.8942 - val_loss: 0.1310 - val_acc: 0.8987\n",
            "Epoch 230/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1464 - acc: 0.8895 - val_loss: 0.1308 - val_acc: 0.8987\n",
            "Epoch 231/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1459 - acc: 0.8895 - val_loss: 0.1304 - val_acc: 0.8987\n",
            "Epoch 232/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1470 - acc: 0.8889 - val_loss: 0.1300 - val_acc: 0.8987\n",
            "Epoch 233/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1481 - acc: 0.8824 - val_loss: 0.1298 - val_acc: 0.8987\n",
            "Epoch 234/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8824 - val_loss: 0.1298 - val_acc: 0.8988\n",
            "Epoch 235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1479 - acc: 0.8933 - val_loss: 0.1297 - val_acc: 0.8987\n",
            "Epoch 236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1416 - acc: 0.8912 - val_loss: 0.1294 - val_acc: 0.8987\n",
            "Epoch 237/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1426 - acc: 0.8880 - val_loss: 0.1294 - val_acc: 0.8987\n",
            "Epoch 238/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8854 - val_loss: 0.1296 - val_acc: 0.8987\n",
            "Epoch 239/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1525 - acc: 0.8832 - val_loss: 0.1294 - val_acc: 0.8987\n",
            "Epoch 240/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8920 - val_loss: 0.1289 - val_acc: 0.8987\n",
            "Epoch 241/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1380 - acc: 0.8905 - val_loss: 0.1284 - val_acc: 0.8987\n",
            "Epoch 242/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1472 - acc: 0.8856 - val_loss: 0.1282 - val_acc: 0.8987\n",
            "Epoch 243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8935 - val_loss: 0.1281 - val_acc: 0.8987\n",
            "Epoch 244/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1354 - acc: 0.8935 - val_loss: 0.1281 - val_acc: 0.8987\n",
            "Epoch 245/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1529 - acc: 0.8830 - val_loss: 0.1280 - val_acc: 0.8987\n",
            "Epoch 246/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1439 - acc: 0.8828 - val_loss: 0.1282 - val_acc: 0.8986\n",
            "Epoch 247/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2165 - acc: 0.8832 - val_loss: 0.1312 - val_acc: 0.8984\n",
            "Epoch 248/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1535 - acc: 0.8833 - val_loss: 0.1333 - val_acc: 0.8984\n",
            "Epoch 249/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8925 - val_loss: 0.1320 - val_acc: 0.8985\n",
            "Epoch 250/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8865 - val_loss: 0.1291 - val_acc: 0.8986\n",
            "Epoch 251/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8866 - val_loss: 0.1282 - val_acc: 0.8987\n",
            "Epoch 252/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1894 - acc: 0.8978 - val_loss: 0.1285 - val_acc: 0.8987\n",
            "Epoch 253/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8978 - val_loss: 0.1286 - val_acc: 0.8987\n",
            "Epoch 254/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1405 - acc: 0.8923 - val_loss: 0.1285 - val_acc: 0.8987\n",
            "Epoch 255/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1400 - acc: 0.8923 - val_loss: 0.1286 - val_acc: 0.8987\n",
            "Epoch 256/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1813 - acc: 0.8935 - val_loss: 0.1304 - val_acc: 0.8987\n",
            "Epoch 257/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - acc: 0.8935 - val_loss: 0.1318 - val_acc: 0.8987\n",
            "Epoch 258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1489 - acc: 0.8916 - val_loss: 0.1316 - val_acc: 0.8987\n",
            "Epoch 259/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1408 - acc: 0.8912 - val_loss: 0.1302 - val_acc: 0.8987\n",
            "Epoch 260/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1454 - acc: 0.8880 - val_loss: 0.1292 - val_acc: 0.8987\n",
            "Epoch 261/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2152 - acc: 0.8858 - val_loss: 0.1297 - val_acc: 0.8988\n",
            "Epoch 262/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8858 - val_loss: 0.1299 - val_acc: 0.8988\n",
            "Epoch 263/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1466 - acc: 0.8892 - val_loss: 0.1301 - val_acc: 0.8988\n",
            "Epoch 264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1506 - acc: 0.8851 - val_loss: 0.1299 - val_acc: 0.8988\n",
            "Epoch 265/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1504 - acc: 0.8851 - val_loss: 0.1296 - val_acc: 0.8988\n",
            "Epoch 266/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8877 - val_loss: 0.1293 - val_acc: 0.8988\n",
            "Epoch 267/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8924 - val_loss: 0.1290 - val_acc: 0.8988\n",
            "Epoch 268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8922 - val_loss: 0.1289 - val_acc: 0.8988\n",
            "Epoch 269/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8917 - val_loss: 0.1286 - val_acc: 0.8988\n",
            "Epoch 270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1563 - acc: 0.8804 - val_loss: 0.1284 - val_acc: 0.8988\n",
            "Epoch 271/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1378 - acc: 0.8900 - val_loss: 0.1283 - val_acc: 0.8987\n",
            "Epoch 272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8958 - val_loss: 0.1283 - val_acc: 0.8987\n",
            "Epoch 273/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1467 - acc: 0.8835 - val_loss: 0.1282 - val_acc: 0.8987\n",
            "Epoch 274/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8981 - val_loss: 0.1279 - val_acc: 0.8987\n",
            "Epoch 275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1353 - acc: 0.8925 - val_loss: 0.1276 - val_acc: 0.8987\n",
            "Epoch 276/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1349 - acc: 0.8925 - val_loss: 0.1273 - val_acc: 0.8987\n",
            "Epoch 277/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8896 - val_loss: 0.1271 - val_acc: 0.8987\n",
            "Epoch 278/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8971 - val_loss: 0.1269 - val_acc: 0.8987\n",
            "Epoch 279/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1466 - acc: 0.8847 - val_loss: 0.1267 - val_acc: 0.8987\n",
            "Epoch 280/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1458 - acc: 0.8855 - val_loss: 0.1265 - val_acc: 0.8987\n",
            "Epoch 281/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8855 - val_loss: 0.1264 - val_acc: 0.8987\n",
            "Epoch 282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8941 - val_loss: 0.1263 - val_acc: 0.8987\n",
            "Epoch 283/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8950 - val_loss: 0.1262 - val_acc: 0.8987\n",
            "Epoch 284/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1449 - acc: 0.8848 - val_loss: 0.1261 - val_acc: 0.8986\n",
            "Epoch 285/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8853 - val_loss: 0.1260 - val_acc: 0.8986\n",
            "Epoch 286/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1383 - acc: 0.8900 - val_loss: 0.1259 - val_acc: 0.8986\n",
            "Epoch 287/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1402 - acc: 0.8848 - val_loss: 0.1257 - val_acc: 0.8985\n",
            "Epoch 288/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1389 - acc: 0.8882 - val_loss: 0.1255 - val_acc: 0.8985\n",
            "Epoch 289/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2043 - acc: 0.8904 - val_loss: 0.1273 - val_acc: 0.8983\n",
            "Epoch 290/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1366 - acc: 0.8902 - val_loss: 0.1293 - val_acc: 0.8982\n",
            "Epoch 291/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2245 - acc: 0.8769 - val_loss: 0.1353 - val_acc: 0.8979\n",
            "Epoch 292/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1644 - acc: 0.8775 - val_loss: 0.1363 - val_acc: 0.8981\n",
            "Epoch 293/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1389 - acc: 0.8968 - val_loss: 0.1328 - val_acc: 0.8985\n",
            "Epoch 294/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8860 - val_loss: 0.1295 - val_acc: 0.8987\n",
            "Epoch 295/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1644 - acc: 0.8769 - val_loss: 0.1289 - val_acc: 0.8987\n",
            "Epoch 296/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1501 - acc: 0.8826 - val_loss: 0.1286 - val_acc: 0.8988\n",
            "Epoch 297/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2015 - acc: 0.8919 - val_loss: 0.1278 - val_acc: 0.8987\n",
            "Epoch 298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8970 - val_loss: 0.1287 - val_acc: 0.8987\n",
            "Epoch 299/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8969 - val_loss: 0.1296 - val_acc: 0.8987\n",
            "Epoch 300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8861 - val_loss: 0.1297 - val_acc: 0.8987\n",
            "Epoch 301/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1436 - acc: 0.8861 - val_loss: 0.1292 - val_acc: 0.8987\n",
            "Epoch 302/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1445 - acc: 0.8868 - val_loss: 0.1284 - val_acc: 0.8987\n",
            "Epoch 303/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1353 - acc: 0.8937 - val_loss: 0.1278 - val_acc: 0.8987\n",
            "Epoch 304/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1510 - acc: 0.8817 - val_loss: 0.1276 - val_acc: 0.8987\n",
            "Epoch 305/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1550 - acc: 0.8798 - val_loss: 0.1272 - val_acc: 0.8988\n",
            "Epoch 306/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8866 - val_loss: 0.1268 - val_acc: 0.8988\n",
            "Epoch 307/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1488 - acc: 0.8844 - val_loss: 0.1265 - val_acc: 0.8988\n",
            "Epoch 308/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1484 - acc: 0.8844 - val_loss: 0.1265 - val_acc: 0.8988\n",
            "Epoch 309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8991 - val_loss: 0.1265 - val_acc: 0.8987\n",
            "Epoch 310/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1392 - acc: 0.8942 - val_loss: 0.1264 - val_acc: 0.8987\n",
            "Epoch 311/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8957 - val_loss: 0.1262 - val_acc: 0.8987\n",
            "Epoch 312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1541 - acc: 0.8764 - val_loss: 0.1259 - val_acc: 0.8987\n",
            "Epoch 313/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1503 - acc: 0.8804 - val_loss: 0.1259 - val_acc: 0.8987\n",
            "Epoch 314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1529 - acc: 0.8773 - val_loss: 0.1259 - val_acc: 0.8987\n",
            "Epoch 315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1380 - acc: 0.8882 - val_loss: 0.1258 - val_acc: 0.8987\n",
            "Epoch 316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1379 - acc: 0.8882 - val_loss: 0.1255 - val_acc: 0.8987\n",
            "Epoch 317/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2253 - acc: 0.8854 - val_loss: 0.1271 - val_acc: 0.8986\n",
            "Epoch 318/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1425 - acc: 0.8853 - val_loss: 0.1289 - val_acc: 0.8985\n",
            "Epoch 319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1455 - acc: 0.8851 - val_loss: 0.1289 - val_acc: 0.8985\n",
            "Epoch 320/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8851 - val_loss: 0.1275 - val_acc: 0.8986\n",
            "Epoch 321/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8903 - val_loss: 0.1262 - val_acc: 0.8987\n",
            "Epoch 322/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8904 - val_loss: 0.1261 - val_acc: 0.8987\n",
            "Epoch 323/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8885 - val_loss: 0.1264 - val_acc: 0.8987\n",
            "Epoch 324/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1819 - acc: 0.8744 - val_loss: 0.1253 - val_acc: 0.8987\n",
            "Epoch 325/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1542 - acc: 0.8769 - val_loss: 0.1252 - val_acc: 0.8986\n",
            "Epoch 326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1438 - acc: 0.8839 - val_loss: 0.1262 - val_acc: 0.8986\n",
            "Epoch 327/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8831 - val_loss: 0.1267 - val_acc: 0.8985\n",
            "Epoch 328/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1868 - acc: 0.8778 - val_loss: 0.1281 - val_acc: 0.8985\n",
            "Epoch 329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8946 - val_loss: 0.1276 - val_acc: 0.8985\n",
            "Epoch 330/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8946 - val_loss: 0.1258 - val_acc: 0.8986\n",
            "Epoch 331/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8864 - val_loss: 0.1251 - val_acc: 0.8987\n",
            "Epoch 332/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1323 - acc: 0.8953 - val_loss: 0.1255 - val_acc: 0.8987\n",
            "Epoch 333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1327 - acc: 0.8953 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8921 - val_loss: 0.1252 - val_acc: 0.8987\n",
            "Epoch 335/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2412 - acc: 0.8814 - val_loss: 0.1259 - val_acc: 0.8985\n",
            "Epoch 336/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8812 - val_loss: 0.1301 - val_acc: 0.8983\n",
            "Epoch 337/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1590 - acc: 0.8913 - val_loss: 0.1351 - val_acc: 0.8981\n",
            "Epoch 338/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8868 - val_loss: 0.1356 - val_acc: 0.8981\n",
            "Epoch 339/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2107 - acc: 0.8838 - val_loss: 0.1367 - val_acc: 0.8982\n",
            "Epoch 340/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1571 - acc: 0.8808 - val_loss: 0.1344 - val_acc: 0.8984\n",
            "Epoch 341/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1512 - acc: 0.8927 - val_loss: 0.1311 - val_acc: 0.8985\n",
            "Epoch 342/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8974 - val_loss: 0.1283 - val_acc: 0.8987\n",
            "Epoch 343/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - acc: 0.8846 - val_loss: 0.1277 - val_acc: 0.8987\n",
            "Epoch 344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1448 - acc: 0.8847 - val_loss: 0.1279 - val_acc: 0.8987\n",
            "Epoch 345/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8930 - val_loss: 0.1284 - val_acc: 0.8988\n",
            "Epoch 346/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - acc: 0.8802 - val_loss: 0.1280 - val_acc: 0.8988\n",
            "Epoch 347/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1570 - acc: 0.8776 - val_loss: 0.1270 - val_acc: 0.8988\n",
            "Epoch 348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1407 - acc: 0.8878 - val_loss: 0.1266 - val_acc: 0.8988\n",
            "Epoch 349/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1391 - acc: 0.8895 - val_loss: 0.1270 - val_acc: 0.8988\n",
            "Epoch 350/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8918 - val_loss: 0.1274 - val_acc: 0.8987\n",
            "Epoch 351/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1407 - acc: 0.8907 - val_loss: 0.1276 - val_acc: 0.8987\n",
            "Epoch 352/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8994 - val_loss: 0.1272 - val_acc: 0.8987\n",
            "Epoch 353/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8892 - val_loss: 0.1265 - val_acc: 0.8987\n",
            "Epoch 354/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1587 - acc: 0.8939 - val_loss: 0.1263 - val_acc: 0.8987\n",
            "Epoch 355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8922 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 356/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1752 - acc: 0.8841 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8857 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 358/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2123 - acc: 0.8901 - val_loss: 0.1274 - val_acc: 0.8987\n",
            "Epoch 359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1384 - acc: 0.8892 - val_loss: 0.1285 - val_acc: 0.8987\n",
            "Epoch 360/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1578 - acc: 0.8869 - val_loss: 0.1290 - val_acc: 0.8987\n",
            "Epoch 361/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1430 - acc: 0.8883 - val_loss: 0.1282 - val_acc: 0.8987\n",
            "Epoch 362/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1427 - acc: 0.8863 - val_loss: 0.1269 - val_acc: 0.8987\n",
            "Epoch 363/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1451 - acc: 0.8821 - val_loss: 0.1261 - val_acc: 0.8987\n",
            "Epoch 364/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1443 - acc: 0.8849 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 365/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1443 - acc: 0.8849 - val_loss: 0.1262 - val_acc: 0.8987\n",
            "Epoch 366/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1420 - acc: 0.8854 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 367/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1333 - acc: 0.8925 - val_loss: 0.1255 - val_acc: 0.8987\n",
            "Epoch 368/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8905 - val_loss: 0.1251 - val_acc: 0.8987\n",
            "Epoch 369/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1463 - acc: 0.8812 - val_loss: 0.1251 - val_acc: 0.8986\n",
            "Epoch 370/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1459 - acc: 0.8811 - val_loss: 0.1254 - val_acc: 0.8986\n",
            "Epoch 371/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1392 - acc: 0.8905 - val_loss: 0.1253 - val_acc: 0.8986\n",
            "Epoch 372/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1431 - acc: 0.8853 - val_loss: 0.1248 - val_acc: 0.8986\n",
            "Epoch 373/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8882 - val_loss: 0.1242 - val_acc: 0.8986\n",
            "Epoch 374/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8855 - val_loss: 0.1237 - val_acc: 0.8986\n",
            "Epoch 375/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8904 - val_loss: 0.1236 - val_acc: 0.8986\n",
            "Epoch 376/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8953 - val_loss: 0.1237 - val_acc: 0.8986\n",
            "Epoch 377/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8953 - val_loss: 0.1236 - val_acc: 0.8986\n",
            "Epoch 378/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8908 - val_loss: 0.1233 - val_acc: 0.8985\n",
            "Epoch 379/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1466 - acc: 0.8821 - val_loss: 0.1230 - val_acc: 0.8984\n",
            "Epoch 380/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8950 - val_loss: 0.1229 - val_acc: 0.8983\n",
            "Epoch 381/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8949 - val_loss: 0.1230 - val_acc: 0.8982\n",
            "Epoch 382/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8987 - val_loss: 0.1228 - val_acc: 0.8981\n",
            "Epoch 383/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1408 - acc: 0.8890 - val_loss: 0.1227 - val_acc: 0.8981\n",
            "Epoch 384/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1403 - acc: 0.8890 - val_loss: 0.1225 - val_acc: 0.8980\n",
            "Epoch 385/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8940 - val_loss: 0.1222 - val_acc: 0.8980\n",
            "Epoch 386/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1446 - acc: 0.8827 - val_loss: 0.1219 - val_acc: 0.8980\n",
            "Epoch 387/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1442 - acc: 0.8826 - val_loss: 0.1218 - val_acc: 0.8979\n",
            "Epoch 388/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1828 - acc: 0.8833 - val_loss: 0.1224 - val_acc: 0.8976\n",
            "Epoch 389/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1936 - acc: 0.8838 - val_loss: 0.1252 - val_acc: 0.8970\n",
            "Epoch 390/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1393 - acc: 0.8850 - val_loss: 0.1272 - val_acc: 0.8968\n",
            "Epoch 391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1498 - acc: 0.8766 - val_loss: 0.1263 - val_acc: 0.8972\n",
            "Epoch 392/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1500 - acc: 0.8839 - val_loss: 0.1240 - val_acc: 0.8977\n",
            "Epoch 393/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8906 - val_loss: 0.1227 - val_acc: 0.8982\n",
            "Epoch 394/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1358 - acc: 0.8892 - val_loss: 0.1236 - val_acc: 0.8984\n",
            "Epoch 395/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1347 - acc: 0.8894 - val_loss: 0.1244 - val_acc: 0.8985\n",
            "Epoch 396/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1438 - acc: 0.8850 - val_loss: 0.1235 - val_acc: 0.8985\n",
            "Epoch 397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8891 - val_loss: 0.1223 - val_acc: 0.8984\n",
            "Epoch 398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8891 - val_loss: 0.1223 - val_acc: 0.8982\n",
            "Epoch 399/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8876 - val_loss: 0.1231 - val_acc: 0.8980\n",
            "Epoch 400/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8969 - val_loss: 0.1234 - val_acc: 0.8979\n",
            "Epoch 401/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1375 - acc: 0.8873 - val_loss: 0.1229 - val_acc: 0.8980\n",
            "Epoch 402/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8899 - val_loss: 0.1222 - val_acc: 0.8982\n",
            "Epoch 403/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1814 - acc: 0.8775 - val_loss: 0.1220 - val_acc: 0.8982\n",
            "Epoch 404/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8902 - val_loss: 0.1219 - val_acc: 0.8983\n",
            "Epoch 405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8913 - val_loss: 0.1218 - val_acc: 0.8983\n",
            "Epoch 406/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8825 - val_loss: 0.1218 - val_acc: 0.8982\n",
            "Epoch 407/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8886 - val_loss: 0.1217 - val_acc: 0.8982\n",
            "Epoch 408/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8849 - val_loss: 0.1216 - val_acc: 0.8981\n",
            "Epoch 409/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1414 - acc: 0.8842 - val_loss: 0.1215 - val_acc: 0.8980\n",
            "Epoch 410/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1401 - acc: 0.8853 - val_loss: 0.1214 - val_acc: 0.8978\n",
            "Epoch 411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1396 - acc: 0.8852 - val_loss: 0.1213 - val_acc: 0.8978\n",
            "Epoch 412/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8932 - val_loss: 0.1211 - val_acc: 0.8977\n",
            "Epoch 413/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1722 - acc: 0.8876 - val_loss: 0.1214 - val_acc: 0.8975\n",
            "Epoch 414/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1615 - acc: 0.8853 - val_loss: 0.1225 - val_acc: 0.8972\n",
            "Epoch 415/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8820 - val_loss: 0.1229 - val_acc: 0.8972\n",
            "Epoch 416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1375 - acc: 0.8826 - val_loss: 0.1223 - val_acc: 0.8974\n",
            "Epoch 417/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8830 - val_loss: 0.1215 - val_acc: 0.8978\n",
            "Epoch 418/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1593 - acc: 0.8840 - val_loss: 0.1216 - val_acc: 0.8979\n",
            "Epoch 419/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8845 - val_loss: 0.1217 - val_acc: 0.8979\n",
            "Epoch 420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8923 - val_loss: 0.1217 - val_acc: 0.8980\n",
            "Epoch 421/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1323 - acc: 0.8916 - val_loss: 0.1216 - val_acc: 0.8980\n",
            "Epoch 422/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8944 - val_loss: 0.1213 - val_acc: 0.8979\n",
            "Epoch 423/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8943 - val_loss: 0.1211 - val_acc: 0.8978\n",
            "Epoch 424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8925 - val_loss: 0.1211 - val_acc: 0.8977\n",
            "Epoch 425/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - acc: 0.8876 - val_loss: 0.1211 - val_acc: 0.8976\n",
            "Epoch 426/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1409 - acc: 0.8873 - val_loss: 0.1211 - val_acc: 0.8977\n",
            "Epoch 427/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1355 - acc: 0.8879 - val_loss: 0.1209 - val_acc: 0.8978\n",
            "Epoch 428/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8919 - val_loss: 0.1207 - val_acc: 0.8979\n",
            "Epoch 429/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8857 - val_loss: 0.1205 - val_acc: 0.8978\n",
            "Epoch 430/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8805 - val_loss: 0.1202 - val_acc: 0.8976\n",
            "Epoch 431/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1560 - acc: 0.8793 - val_loss: 0.1205 - val_acc: 0.8969\n",
            "Epoch 432/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1426 - acc: 0.8800 - val_loss: 0.1212 - val_acc: 0.8962\n",
            "Epoch 433/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8957 - val_loss: 0.1212 - val_acc: 0.8960\n",
            "Epoch 434/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8861 - val_loss: 0.1206 - val_acc: 0.8963\n",
            "Epoch 435/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8868 - val_loss: 0.1201 - val_acc: 0.8967\n",
            "Epoch 436/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8951 - val_loss: 0.1199 - val_acc: 0.8969\n",
            "Epoch 437/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1797 - acc: 0.8904 - val_loss: 0.1204 - val_acc: 0.8962\n",
            "Epoch 438/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8902 - val_loss: 0.1217 - val_acc: 0.8958\n",
            "Epoch 439/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1292 - acc: 0.8877 - val_loss: 0.1218 - val_acc: 0.8959\n",
            "Epoch 440/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - acc: 0.8851 - val_loss: 0.1210 - val_acc: 0.8966\n",
            "Epoch 441/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8910 - val_loss: 0.1204 - val_acc: 0.8972\n",
            "Epoch 442/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8912 - val_loss: 0.1204 - val_acc: 0.8975\n",
            "Epoch 443/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8916 - val_loss: 0.1202 - val_acc: 0.8977\n",
            "Epoch 444/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8891 - val_loss: 0.1197 - val_acc: 0.8975\n",
            "Epoch 445/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1340 - acc: 0.8856 - val_loss: 0.1196 - val_acc: 0.8972\n",
            "Epoch 446/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2048 - acc: 0.8842 - val_loss: 0.1217 - val_acc: 0.8963\n",
            "Epoch 447/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8886 - val_loss: 0.1233 - val_acc: 0.8959\n",
            "Epoch 448/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8921 - val_loss: 0.1228 - val_acc: 0.8962\n",
            "Epoch 449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8925 - val_loss: 0.1214 - val_acc: 0.8969\n",
            "Epoch 450/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1524 - acc: 0.8719 - val_loss: 0.1205 - val_acc: 0.8976\n",
            "Epoch 451/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8847 - val_loss: 0.1209 - val_acc: 0.8980\n",
            "Epoch 452/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8922 - val_loss: 0.1211 - val_acc: 0.8981\n",
            "Epoch 453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8923 - val_loss: 0.1204 - val_acc: 0.8981\n",
            "Epoch 454/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8892 - val_loss: 0.1199 - val_acc: 0.8980\n",
            "Epoch 455/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8920 - val_loss: 0.1199 - val_acc: 0.8978\n",
            "Epoch 456/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1522 - acc: 0.8852 - val_loss: 0.1209 - val_acc: 0.8974\n",
            "Epoch 457/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2265 - acc: 0.8848 - val_loss: 0.1256 - val_acc: 0.8968\n",
            "Epoch 458/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1377 - acc: 0.8881 - val_loss: 0.1278 - val_acc: 0.8969\n",
            "Epoch 459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2163 - acc: 0.8875 - val_loss: 0.1338 - val_acc: 0.8970\n",
            "Epoch 460/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1934 - acc: 0.8831 - val_loss: 0.1372 - val_acc: 0.8975\n",
            "Epoch 461/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1613 - acc: 0.8858 - val_loss: 0.1331 - val_acc: 0.8983\n",
            "Epoch 462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.9019 - val_loss: 0.1276 - val_acc: 0.8986\n",
            "Epoch 463/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.9022 - val_loss: 0.1261 - val_acc: 0.8987\n",
            "Epoch 464/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1376 - acc: 0.8910 - val_loss: 0.1280 - val_acc: 0.8987\n",
            "Epoch 465/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1738 - acc: 0.8845 - val_loss: 0.1272 - val_acc: 0.8987\n",
            "Epoch 466/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2095 - acc: 0.8895 - val_loss: 0.1247 - val_acc: 0.8987\n",
            "Epoch 467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1465 - acc: 0.8877 - val_loss: 0.1259 - val_acc: 0.8987\n",
            "Epoch 468/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1365 - acc: 0.8910 - val_loss: 0.1282 - val_acc: 0.8986\n",
            "Epoch 469/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1471 - acc: 0.8849 - val_loss: 0.1297 - val_acc: 0.8986\n",
            "Epoch 470/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8891 - val_loss: 0.1299 - val_acc: 0.8986\n",
            "Epoch 471/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1407 - acc: 0.8893 - val_loss: 0.1290 - val_acc: 0.8986\n",
            "Epoch 472/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8964 - val_loss: 0.1275 - val_acc: 0.8987\n",
            "Epoch 473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8941 - val_loss: 0.1264 - val_acc: 0.8987\n",
            "Epoch 474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1406 - acc: 0.8865 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 475/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1421 - acc: 0.8886 - val_loss: 0.1260 - val_acc: 0.8987\n",
            "Epoch 476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1379 - acc: 0.8867 - val_loss: 0.1259 - val_acc: 0.8987\n",
            "Epoch 477/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1456 - acc: 0.8827 - val_loss: 0.1252 - val_acc: 0.8987\n",
            "Epoch 478/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8831 - val_loss: 0.1244 - val_acc: 0.8987\n",
            "Epoch 479/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8927 - val_loss: 0.1240 - val_acc: 0.8987\n",
            "Epoch 480/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1439 - acc: 0.8864 - val_loss: 0.1240 - val_acc: 0.8987\n",
            "Epoch 481/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8789 - val_loss: 0.1240 - val_acc: 0.8987\n",
            "Epoch 482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8966 - val_loss: 0.1239 - val_acc: 0.8987\n",
            "Epoch 483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8965 - val_loss: 0.1234 - val_acc: 0.8987\n",
            "Epoch 484/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8890 - val_loss: 0.1228 - val_acc: 0.8987\n",
            "Epoch 485/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1826 - acc: 0.8916 - val_loss: 0.1228 - val_acc: 0.8986\n",
            "Epoch 486/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1395 - acc: 0.8845 - val_loss: 0.1226 - val_acc: 0.8986\n",
            "Epoch 487/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1520 - acc: 0.8825 - val_loss: 0.1226 - val_acc: 0.8986\n",
            "Epoch 488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8896 - val_loss: 0.1222 - val_acc: 0.8986\n",
            "Epoch 489/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1341 - acc: 0.8929 - val_loss: 0.1218 - val_acc: 0.8986\n",
            "Epoch 490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1621 - acc: 0.8841 - val_loss: 0.1216 - val_acc: 0.8985\n",
            "Epoch 491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8851 - val_loss: 0.1213 - val_acc: 0.8985\n",
            "Epoch 492/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8851 - val_loss: 0.1211 - val_acc: 0.8984\n",
            "Epoch 493/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8930 - val_loss: 0.1208 - val_acc: 0.8984\n",
            "Epoch 494/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2646 - acc: 0.8735 - val_loss: 0.1228 - val_acc: 0.8981\n",
            "Epoch 495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - acc: 0.8741 - val_loss: 0.1267 - val_acc: 0.8978\n",
            "Epoch 496/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1489 - acc: 0.8782 - val_loss: 0.1288 - val_acc: 0.8976\n",
            "Epoch 497/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1508 - acc: 0.8780 - val_loss: 0.1277 - val_acc: 0.8977\n",
            "Epoch 498/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1340 - acc: 0.8939 - val_loss: 0.1244 - val_acc: 0.8980\n",
            "Epoch 499/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8911 - val_loss: 0.1219 - val_acc: 0.8983\n",
            "Epoch 500/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8882 - val_loss: 0.1218 - val_acc: 0.8985\n",
            "Epoch 501/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8912 - val_loss: 0.1230 - val_acc: 0.8985\n",
            "Epoch 502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8872 - val_loss: 0.1227 - val_acc: 0.8985\n",
            "Epoch 503/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1418 - acc: 0.8871 - val_loss: 0.1211 - val_acc: 0.8983\n",
            "Epoch 504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1466 - acc: 0.8790 - val_loss: 0.1205 - val_acc: 0.8980\n",
            "Epoch 505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1405 - acc: 0.8829 - val_loss: 0.1216 - val_acc: 0.8975\n",
            "Epoch 506/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1535 - acc: 0.8802 - val_loss: 0.1232 - val_acc: 0.8970\n",
            "Epoch 507/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8862 - val_loss: 0.1237 - val_acc: 0.8966\n",
            "Epoch 508/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8955 - val_loss: 0.1227 - val_acc: 0.8967\n",
            "Epoch 509/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8908 - val_loss: 0.1209 - val_acc: 0.8971\n",
            "Epoch 510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8914 - val_loss: 0.1197 - val_acc: 0.8976\n",
            "Epoch 511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1366 - acc: 0.8872 - val_loss: 0.1198 - val_acc: 0.8979\n",
            "Epoch 512/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8949 - val_loss: 0.1203 - val_acc: 0.8981\n",
            "Epoch 513/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8893 - val_loss: 0.1202 - val_acc: 0.8981\n",
            "Epoch 514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8893 - val_loss: 0.1193 - val_acc: 0.8979\n",
            "Epoch 515/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8880 - val_loss: 0.1187 - val_acc: 0.8975\n",
            "Epoch 516/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1333 - acc: 0.8861 - val_loss: 0.1190 - val_acc: 0.8968\n",
            "Epoch 517/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8838 - val_loss: 0.1194 - val_acc: 0.8963\n",
            "Epoch 518/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8853 - val_loss: 0.1194 - val_acc: 0.8960\n",
            "Epoch 519/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1313 - acc: 0.8850 - val_loss: 0.1190 - val_acc: 0.8960\n",
            "Epoch 520/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1491 - acc: 0.8747 - val_loss: 0.1184 - val_acc: 0.8962\n",
            "Epoch 521/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8859 - val_loss: 0.1181 - val_acc: 0.8964\n",
            "Epoch 522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2010 - acc: 0.8845 - val_loss: 0.1183 - val_acc: 0.8961\n",
            "Epoch 523/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8916 - val_loss: 0.1186 - val_acc: 0.8958\n",
            "Epoch 524/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1341 - acc: 0.8825 - val_loss: 0.1186 - val_acc: 0.8959\n",
            "Epoch 525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8881 - val_loss: 0.1183 - val_acc: 0.8961\n",
            "Epoch 526/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8884 - val_loss: 0.1180 - val_acc: 0.8964\n",
            "Epoch 527/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8803 - val_loss: 0.1178 - val_acc: 0.8966\n",
            "Epoch 528/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8897 - val_loss: 0.1178 - val_acc: 0.8968\n",
            "Epoch 529/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1378 - acc: 0.8815 - val_loss: 0.1178 - val_acc: 0.8968\n",
            "Epoch 530/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8853 - val_loss: 0.1177 - val_acc: 0.8967\n",
            "Epoch 531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8906 - val_loss: 0.1174 - val_acc: 0.8966\n",
            "Epoch 532/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8906 - val_loss: 0.1173 - val_acc: 0.8966\n",
            "Epoch 533/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8872 - val_loss: 0.1173 - val_acc: 0.8965\n",
            "Epoch 534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8871 - val_loss: 0.1174 - val_acc: 0.8964\n",
            "Epoch 535/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8940 - val_loss: 0.1175 - val_acc: 0.8963\n",
            "Epoch 536/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8833 - val_loss: 0.1173 - val_acc: 0.8962\n",
            "Epoch 537/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8813 - val_loss: 0.1171 - val_acc: 0.8961\n",
            "Epoch 538/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1573 - acc: 0.8738 - val_loss: 0.1172 - val_acc: 0.8959\n",
            "Epoch 539/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8772 - val_loss: 0.1173 - val_acc: 0.8959\n",
            "Epoch 540/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8843 - val_loss: 0.1172 - val_acc: 0.8958\n",
            "Epoch 541/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8842 - val_loss: 0.1169 - val_acc: 0.8958\n",
            "Epoch 542/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8876 - val_loss: 0.1166 - val_acc: 0.8958\n",
            "Epoch 543/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8912 - val_loss: 0.1166 - val_acc: 0.8959\n",
            "Epoch 544/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1297 - acc: 0.8840 - val_loss: 0.1166 - val_acc: 0.8959\n",
            "Epoch 545/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8819 - val_loss: 0.1165 - val_acc: 0.8955\n",
            "Epoch 546/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1517 - acc: 0.8800 - val_loss: 0.1168 - val_acc: 0.8943\n",
            "Epoch 547/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8831 - val_loss: 0.1172 - val_acc: 0.8937\n",
            "Epoch 548/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1372 - acc: 0.8764 - val_loss: 0.1170 - val_acc: 0.8938\n",
            "Epoch 549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8767 - val_loss: 0.1163 - val_acc: 0.8945\n",
            "Epoch 550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8822 - val_loss: 0.1162 - val_acc: 0.8953\n",
            "Epoch 551/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8837 - val_loss: 0.1162 - val_acc: 0.8955\n",
            "Epoch 552/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8812 - val_loss: 0.1161 - val_acc: 0.8953\n",
            "Epoch 553/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8842 - val_loss: 0.1160 - val_acc: 0.8949\n",
            "Epoch 554/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8828 - val_loss: 0.1161 - val_acc: 0.8947\n",
            "Epoch 555/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8877 - val_loss: 0.1160 - val_acc: 0.8946\n",
            "Epoch 556/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8878 - val_loss: 0.1159 - val_acc: 0.8946\n",
            "Epoch 557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8873 - val_loss: 0.1157 - val_acc: 0.8948\n",
            "Epoch 558/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8876 - val_loss: 0.1156 - val_acc: 0.8951\n",
            "Epoch 559/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8880 - val_loss: 0.1155 - val_acc: 0.8951\n",
            "Epoch 560/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1456 - acc: 0.8788 - val_loss: 0.1154 - val_acc: 0.8950\n",
            "Epoch 561/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2222 - acc: 0.8702 - val_loss: 0.1169 - val_acc: 0.8948\n",
            "Epoch 562/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1358 - acc: 0.8810 - val_loss: 0.1186 - val_acc: 0.8953\n",
            "Epoch 563/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1292 - acc: 0.8875 - val_loss: 0.1187 - val_acc: 0.8962\n",
            "Epoch 564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8847 - val_loss: 0.1177 - val_acc: 0.8971\n",
            "Epoch 565/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1356 - acc: 0.8849 - val_loss: 0.1168 - val_acc: 0.8976\n",
            "Epoch 566/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8874 - val_loss: 0.1167 - val_acc: 0.8977\n",
            "Epoch 567/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8884 - val_loss: 0.1168 - val_acc: 0.8976\n",
            "Epoch 568/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8883 - val_loss: 0.1169 - val_acc: 0.8973\n",
            "Epoch 569/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8822 - val_loss: 0.1169 - val_acc: 0.8969\n",
            "Epoch 570/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1313 - acc: 0.8817 - val_loss: 0.1170 - val_acc: 0.8965\n",
            "Epoch 571/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8882 - val_loss: 0.1171 - val_acc: 0.8962\n",
            "Epoch 572/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1476 - acc: 0.8729 - val_loss: 0.1169 - val_acc: 0.8961\n",
            "Epoch 573/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8842 - val_loss: 0.1164 - val_acc: 0.8964\n",
            "Epoch 574/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8920 - val_loss: 0.1160 - val_acc: 0.8967\n",
            "Epoch 575/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8836 - val_loss: 0.1159 - val_acc: 0.8969\n",
            "Epoch 576/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8837 - val_loss: 0.1160 - val_acc: 0.8969\n",
            "Epoch 577/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8821 - val_loss: 0.1159 - val_acc: 0.8966\n",
            "Epoch 578/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1395 - acc: 0.8840 - val_loss: 0.1157 - val_acc: 0.8958\n",
            "Epoch 579/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1379 - acc: 0.8775 - val_loss: 0.1158 - val_acc: 0.8952\n",
            "Epoch 580/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8817 - val_loss: 0.1158 - val_acc: 0.8950\n",
            "Epoch 581/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8798 - val_loss: 0.1156 - val_acc: 0.8953\n",
            "Epoch 582/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8802 - val_loss: 0.1154 - val_acc: 0.8957\n",
            "Epoch 583/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1328 - acc: 0.8805 - val_loss: 0.1152 - val_acc: 0.8958\n",
            "Epoch 584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1351 - acc: 0.8883 - val_loss: 0.1151 - val_acc: 0.8956\n",
            "Epoch 585/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8891 - val_loss: 0.1151 - val_acc: 0.8952\n",
            "Epoch 586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2643 - acc: 0.8767 - val_loss: 0.1187 - val_acc: 0.8929\n",
            "Epoch 587/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2578 - acc: 0.8616 - val_loss: 0.1337 - val_acc: 0.8882\n",
            "Epoch 588/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1495 - acc: 0.8708 - val_loss: 0.1408 - val_acc: 0.8883\n",
            "Epoch 589/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1608 - acc: 0.8706 - val_loss: 0.1362 - val_acc: 0.8929\n",
            "Epoch 590/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1697 - acc: 0.8836 - val_loss: 0.1293 - val_acc: 0.8964\n",
            "Epoch 591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8927 - val_loss: 0.1228 - val_acc: 0.8981\n",
            "Epoch 592/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1356 - acc: 0.8876 - val_loss: 0.1222 - val_acc: 0.8986\n",
            "Epoch 593/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2144 - acc: 0.8878 - val_loss: 0.1243 - val_acc: 0.8987\n",
            "Epoch 594/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8886 - val_loss: 0.1248 - val_acc: 0.8987\n",
            "Epoch 595/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8901 - val_loss: 0.1242 - val_acc: 0.8986\n",
            "Epoch 596/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2150 - acc: 0.8905 - val_loss: 0.1257 - val_acc: 0.8986\n",
            "Epoch 597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1597 - acc: 0.8943 - val_loss: 0.1298 - val_acc: 0.8985\n",
            "Epoch 598/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1677 - acc: 0.8848 - val_loss: 0.1346 - val_acc: 0.8985\n",
            "Epoch 599/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1511 - acc: 0.8851 - val_loss: 0.1368 - val_acc: 0.8985\n",
            "Epoch 600/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1575 - acc: 0.8927 - val_loss: 0.1359 - val_acc: 0.8986\n",
            "Epoch 601/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1591 - acc: 0.8773 - val_loss: 0.1328 - val_acc: 0.8986\n",
            "Epoch 602/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1563 - acc: 0.8774 - val_loss: 0.1291 - val_acc: 0.8987\n",
            "Epoch 603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - acc: 0.8835 - val_loss: 0.1263 - val_acc: 0.8987\n",
            "Epoch 604/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1416 - acc: 0.8877 - val_loss: 0.1255 - val_acc: 0.8987\n",
            "Epoch 605/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1489 - acc: 0.8839 - val_loss: 0.1259 - val_acc: 0.8988\n",
            "Epoch 606/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1436 - acc: 0.8854 - val_loss: 0.1261 - val_acc: 0.8988\n",
            "Epoch 607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8854 - val_loss: 0.1252 - val_acc: 0.8988\n",
            "Epoch 608/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1592 - acc: 0.8760 - val_loss: 0.1239 - val_acc: 0.8988\n",
            "Epoch 609/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8942 - val_loss: 0.1233 - val_acc: 0.8988\n",
            "Epoch 610/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8954 - val_loss: 0.1232 - val_acc: 0.8987\n",
            "Epoch 611/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8954 - val_loss: 0.1233 - val_acc: 0.8987\n",
            "Epoch 612/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8895 - val_loss: 0.1233 - val_acc: 0.8987\n",
            "Epoch 613/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1347 - acc: 0.8905 - val_loss: 0.1229 - val_acc: 0.8987\n",
            "Epoch 614/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1360 - acc: 0.8902 - val_loss: 0.1223 - val_acc: 0.8987\n",
            "Epoch 615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8891 - val_loss: 0.1215 - val_acc: 0.8987\n",
            "Epoch 616/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1471 - acc: 0.8784 - val_loss: 0.1208 - val_acc: 0.8987\n",
            "Epoch 617/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8950 - val_loss: 0.1203 - val_acc: 0.8987\n",
            "Epoch 618/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1390 - acc: 0.8857 - val_loss: 0.1200 - val_acc: 0.8987\n",
            "Epoch 619/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8859 - val_loss: 0.1196 - val_acc: 0.8987\n",
            "Epoch 620/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8854 - val_loss: 0.1192 - val_acc: 0.8986\n",
            "Epoch 621/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1361 - acc: 0.8854 - val_loss: 0.1188 - val_acc: 0.8985\n",
            "Epoch 622/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8852 - val_loss: 0.1184 - val_acc: 0.8984\n",
            "Epoch 623/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8844 - val_loss: 0.1181 - val_acc: 0.8982\n",
            "Epoch 624/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1327 - acc: 0.8872 - val_loss: 0.1179 - val_acc: 0.8981\n",
            "Epoch 625/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2216 - acc: 0.8867 - val_loss: 0.1188 - val_acc: 0.8979\n",
            "Epoch 626/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8968 - val_loss: 0.1198 - val_acc: 0.8977\n",
            "Epoch 627/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8966 - val_loss: 0.1199 - val_acc: 0.8977\n",
            "Epoch 628/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8845 - val_loss: 0.1191 - val_acc: 0.8978\n",
            "Epoch 629/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8912 - val_loss: 0.1179 - val_acc: 0.8979\n",
            "Epoch 630/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1391 - acc: 0.8806 - val_loss: 0.1170 - val_acc: 0.8980\n",
            "Epoch 631/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8909 - val_loss: 0.1170 - val_acc: 0.8981\n",
            "Epoch 632/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8909 - val_loss: 0.1172 - val_acc: 0.8981\n",
            "Epoch 633/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2112 - acc: 0.8834 - val_loss: 0.1166 - val_acc: 0.8978\n",
            "Epoch 634/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8796 - val_loss: 0.1173 - val_acc: 0.8974\n",
            "Epoch 635/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - acc: 0.8876 - val_loss: 0.1185 - val_acc: 0.8969\n",
            "Epoch 636/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8892 - val_loss: 0.1190 - val_acc: 0.8966\n",
            "Epoch 637/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8889 - val_loss: 0.1182 - val_acc: 0.8967\n",
            "Epoch 638/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1841 - acc: 0.8822 - val_loss: 0.1180 - val_acc: 0.8969\n",
            "Epoch 639/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8895 - val_loss: 0.1172 - val_acc: 0.8973\n",
            "Epoch 640/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8898 - val_loss: 0.1166 - val_acc: 0.8976\n",
            "Epoch 641/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8867 - val_loss: 0.1165 - val_acc: 0.8978\n",
            "Epoch 642/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8868 - val_loss: 0.1169 - val_acc: 0.8979\n",
            "Epoch 643/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8824 - val_loss: 0.1167 - val_acc: 0.8979\n",
            "Epoch 644/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8910 - val_loss: 0.1162 - val_acc: 0.8976\n",
            "Epoch 645/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1225 - acc: 0.8909 - val_loss: 0.1159 - val_acc: 0.8971\n",
            "Epoch 646/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8834 - val_loss: 0.1160 - val_acc: 0.8965\n",
            "Epoch 647/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8917 - val_loss: 0.1163 - val_acc: 0.8960\n",
            "Epoch 648/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8911 - val_loss: 0.1164 - val_acc: 0.8957\n",
            "Epoch 649/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1294 - acc: 0.8793 - val_loss: 0.1161 - val_acc: 0.8956\n",
            "Epoch 650/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2276 - acc: 0.8791 - val_loss: 0.1174 - val_acc: 0.8952\n",
            "Epoch 651/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1354 - acc: 0.8792 - val_loss: 0.1181 - val_acc: 0.8953\n",
            "Epoch 652/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1358 - acc: 0.8791 - val_loss: 0.1176 - val_acc: 0.8959\n",
            "Epoch 653/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8900 - val_loss: 0.1165 - val_acc: 0.8968\n",
            "Epoch 654/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8848 - val_loss: 0.1161 - val_acc: 0.8974\n",
            "Epoch 655/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8871 - val_loss: 0.1166 - val_acc: 0.8978\n",
            "Epoch 656/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8876 - val_loss: 0.1168 - val_acc: 0.8980\n",
            "Epoch 657/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8838 - val_loss: 0.1162 - val_acc: 0.8978\n",
            "Epoch 658/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8916 - val_loss: 0.1154 - val_acc: 0.8974\n",
            "Epoch 659/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8914 - val_loss: 0.1152 - val_acc: 0.8969\n",
            "Epoch 660/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8920 - val_loss: 0.1155 - val_acc: 0.8963\n",
            "Epoch 661/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8919 - val_loss: 0.1157 - val_acc: 0.8958\n",
            "Epoch 662/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8911 - val_loss: 0.1155 - val_acc: 0.8957\n",
            "Epoch 663/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8849 - val_loss: 0.1151 - val_acc: 0.8958\n",
            "Epoch 664/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8855 - val_loss: 0.1145 - val_acc: 0.8962\n",
            "Epoch 665/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8861 - val_loss: 0.1144 - val_acc: 0.8965\n",
            "Epoch 666/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8866 - val_loss: 0.1144 - val_acc: 0.8967\n",
            "Epoch 667/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8868 - val_loss: 0.1143 - val_acc: 0.8967\n",
            "Epoch 668/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8858 - val_loss: 0.1141 - val_acc: 0.8963\n",
            "Epoch 669/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1442 - acc: 0.8827 - val_loss: 0.1141 - val_acc: 0.8957\n",
            "Epoch 670/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8843 - val_loss: 0.1143 - val_acc: 0.8952\n",
            "Epoch 671/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1432 - acc: 0.8693 - val_loss: 0.1145 - val_acc: 0.8947\n",
            "Epoch 672/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8878 - val_loss: 0.1143 - val_acc: 0.8948\n",
            "Epoch 673/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1366 - acc: 0.8764 - val_loss: 0.1139 - val_acc: 0.8951\n",
            "Epoch 674/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2305 - acc: 0.8750 - val_loss: 0.1147 - val_acc: 0.8944\n",
            "Epoch 675/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8860 - val_loss: 0.1156 - val_acc: 0.8942\n",
            "Epoch 676/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1535 - acc: 0.8867 - val_loss: 0.1163 - val_acc: 0.8944\n",
            "Epoch 677/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8915 - val_loss: 0.1157 - val_acc: 0.8954\n",
            "Epoch 678/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8790 - val_loss: 0.1150 - val_acc: 0.8964\n",
            "Epoch 679/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8956 - val_loss: 0.1148 - val_acc: 0.8971\n",
            "Epoch 680/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1244 - acc: 0.8884 - val_loss: 0.1150 - val_acc: 0.8975\n",
            "Epoch 681/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8887 - val_loss: 0.1148 - val_acc: 0.8974\n",
            "Epoch 682/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8921 - val_loss: 0.1144 - val_acc: 0.8972\n",
            "Epoch 683/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8829 - val_loss: 0.1143 - val_acc: 0.8968\n",
            "Epoch 684/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8833 - val_loss: 0.1146 - val_acc: 0.8963\n",
            "Epoch 685/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8828 - val_loss: 0.1148 - val_acc: 0.8960\n",
            "Epoch 686/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8926 - val_loss: 0.1148 - val_acc: 0.8961\n",
            "Epoch 687/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8824 - val_loss: 0.1144 - val_acc: 0.8963\n",
            "Epoch 688/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8826 - val_loss: 0.1140 - val_acc: 0.8967\n",
            "Epoch 689/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8833 - val_loss: 0.1138 - val_acc: 0.8970\n",
            "Epoch 690/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8884 - val_loss: 0.1137 - val_acc: 0.8971\n",
            "Epoch 691/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8854 - val_loss: 0.1136 - val_acc: 0.8971\n",
            "Epoch 692/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8865 - val_loss: 0.1134 - val_acc: 0.8969\n",
            "Epoch 693/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8889 - val_loss: 0.1133 - val_acc: 0.8966\n",
            "Epoch 694/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1664 - acc: 0.8904 - val_loss: 0.1137 - val_acc: 0.8959\n",
            "Epoch 695/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8946 - val_loss: 0.1144 - val_acc: 0.8954\n",
            "Epoch 696/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1398 - acc: 0.8745 - val_loss: 0.1144 - val_acc: 0.8955\n",
            "Epoch 697/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8946 - val_loss: 0.1138 - val_acc: 0.8958\n",
            "Epoch 698/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8712 - val_loss: 0.1134 - val_acc: 0.8962\n",
            "Epoch 699/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8836 - val_loss: 0.1133 - val_acc: 0.8965\n",
            "Epoch 700/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8805 - val_loss: 0.1133 - val_acc: 0.8964\n",
            "Epoch 701/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8893 - val_loss: 0.1130 - val_acc: 0.8960\n",
            "Epoch 702/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8890 - val_loss: 0.1130 - val_acc: 0.8954\n",
            "Epoch 703/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8972 - val_loss: 0.1131 - val_acc: 0.8950\n",
            "Epoch 704/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8967 - val_loss: 0.1131 - val_acc: 0.8949\n",
            "Epoch 705/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1707 - acc: 0.8771 - val_loss: 0.1136 - val_acc: 0.8945\n",
            "Epoch 706/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8895 - val_loss: 0.1137 - val_acc: 0.8946\n",
            "Epoch 707/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8779 - val_loss: 0.1133 - val_acc: 0.8951\n",
            "Epoch 708/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8785 - val_loss: 0.1129 - val_acc: 0.8958\n",
            "Epoch 709/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8818 - val_loss: 0.1129 - val_acc: 0.8963\n",
            "Epoch 710/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8840 - val_loss: 0.1130 - val_acc: 0.8964\n",
            "Epoch 711/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8819 - val_loss: 0.1128 - val_acc: 0.8962\n",
            "Epoch 712/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298 - acc: 0.8818 - val_loss: 0.1126 - val_acc: 0.8958\n",
            "Epoch 713/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8964 - val_loss: 0.1125 - val_acc: 0.8952\n",
            "Epoch 714/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8914 - val_loss: 0.1125 - val_acc: 0.8949\n",
            "Epoch 715/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8882 - val_loss: 0.1127 - val_acc: 0.8947\n",
            "Epoch 716/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1320 - acc: 0.8753 - val_loss: 0.1127 - val_acc: 0.8948\n",
            "Epoch 717/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8755 - val_loss: 0.1125 - val_acc: 0.8951\n",
            "Epoch 718/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8986 - val_loss: 0.1123 - val_acc: 0.8957\n",
            "Epoch 719/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8740 - val_loss: 0.1121 - val_acc: 0.8957\n",
            "Epoch 720/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8854 - val_loss: 0.1121 - val_acc: 0.8954\n",
            "Epoch 721/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8813 - val_loss: 0.1121 - val_acc: 0.8949\n",
            "Epoch 722/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8809 - val_loss: 0.1121 - val_acc: 0.8944\n",
            "Epoch 723/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8820 - val_loss: 0.1119 - val_acc: 0.8943\n",
            "Epoch 724/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8900 - val_loss: 0.1118 - val_acc: 0.8945\n",
            "Epoch 725/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8878 - val_loss: 0.1118 - val_acc: 0.8945\n",
            "Epoch 726/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8849 - val_loss: 0.1118 - val_acc: 0.8945\n",
            "Epoch 727/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8834 - val_loss: 0.1117 - val_acc: 0.8945\n",
            "Epoch 728/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8748 - val_loss: 0.1117 - val_acc: 0.8943\n",
            "Epoch 729/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1320 - acc: 0.8724 - val_loss: 0.1116 - val_acc: 0.8939\n",
            "Epoch 730/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8775 - val_loss: 0.1116 - val_acc: 0.8938\n",
            "Epoch 731/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8836 - val_loss: 0.1114 - val_acc: 0.8940\n",
            "Epoch 732/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1328 - acc: 0.8688 - val_loss: 0.1113 - val_acc: 0.8942\n",
            "Epoch 733/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1635 - acc: 0.8787 - val_loss: 0.1114 - val_acc: 0.8947\n",
            "Epoch 734/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1963 - acc: 0.8791 - val_loss: 0.1130 - val_acc: 0.8939\n",
            "Epoch 735/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8831 - val_loss: 0.1144 - val_acc: 0.8940\n",
            "Epoch 736/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8815 - val_loss: 0.1141 - val_acc: 0.8950\n",
            "Epoch 737/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8913 - val_loss: 0.1132 - val_acc: 0.8963\n",
            "Epoch 738/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8896 - val_loss: 0.1131 - val_acc: 0.8970\n",
            "Epoch 739/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8846 - val_loss: 0.1128 - val_acc: 0.8971\n",
            "Epoch 740/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8798 - val_loss: 0.1122 - val_acc: 0.8967\n",
            "Epoch 741/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8903 - val_loss: 0.1123 - val_acc: 0.8960\n",
            "Epoch 742/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8896 - val_loss: 0.1127 - val_acc: 0.8956\n",
            "Epoch 743/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8840 - val_loss: 0.1127 - val_acc: 0.8955\n",
            "Epoch 744/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8776 - val_loss: 0.1125 - val_acc: 0.8956\n",
            "Epoch 745/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8902 - val_loss: 0.1122 - val_acc: 0.8959\n",
            "Epoch 746/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8905 - val_loss: 0.1120 - val_acc: 0.8961\n",
            "Epoch 747/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8820 - val_loss: 0.1118 - val_acc: 0.8960\n",
            "Epoch 748/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8820 - val_loss: 0.1116 - val_acc: 0.8957\n",
            "Epoch 749/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8903 - val_loss: 0.1115 - val_acc: 0.8954\n",
            "Epoch 750/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2484 - acc: 0.8629 - val_loss: 0.1148 - val_acc: 0.8935\n",
            "Epoch 751/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1352 - acc: 0.8712 - val_loss: 0.1181 - val_acc: 0.8925\n",
            "Epoch 752/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1473 - acc: 0.8774 - val_loss: 0.1181 - val_acc: 0.8933\n",
            "Epoch 753/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1524 - acc: 0.8818 - val_loss: 0.1166 - val_acc: 0.8950\n",
            "Epoch 754/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8875 - val_loss: 0.1144 - val_acc: 0.8968\n",
            "Epoch 755/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1248 - acc: 0.8886 - val_loss: 0.1148 - val_acc: 0.8977\n",
            "Epoch 756/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8988 - val_loss: 0.1164 - val_acc: 0.8981\n",
            "Epoch 757/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8991 - val_loss: 0.1158 - val_acc: 0.8980\n",
            "Epoch 758/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1473 - acc: 0.8876 - val_loss: 0.1136 - val_acc: 0.8974\n",
            "Epoch 759/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8926 - val_loss: 0.1138 - val_acc: 0.8964\n",
            "Epoch 760/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8904 - val_loss: 0.1151 - val_acc: 0.8955\n",
            "Epoch 761/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8795 - val_loss: 0.1157 - val_acc: 0.8951\n",
            "Epoch 762/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8864 - val_loss: 0.1152 - val_acc: 0.8953\n",
            "Epoch 763/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8866 - val_loss: 0.1140 - val_acc: 0.8959\n",
            "Epoch 764/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8858 - val_loss: 0.1132 - val_acc: 0.8967\n",
            "Epoch 765/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8861 - val_loss: 0.1132 - val_acc: 0.8973\n",
            "Epoch 766/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8848 - val_loss: 0.1133 - val_acc: 0.8975\n",
            "Epoch 767/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1292 - acc: 0.8807 - val_loss: 0.1129 - val_acc: 0.8973\n",
            "Epoch 768/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2745 - acc: 0.8769 - val_loss: 0.1143 - val_acc: 0.8962\n",
            "Epoch 769/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1294 - acc: 0.8820 - val_loss: 0.1190 - val_acc: 0.8953\n",
            "Epoch 770/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1248 - acc: 0.8894 - val_loss: 0.1214 - val_acc: 0.8951\n",
            "Epoch 771/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8866 - val_loss: 0.1198 - val_acc: 0.8960\n",
            "Epoch 772/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2144 - acc: 0.8701 - val_loss: 0.1209 - val_acc: 0.8964\n",
            "Epoch 773/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1396 - acc: 0.8783 - val_loss: 0.1195 - val_acc: 0.8972\n",
            "Epoch 774/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1379 - acc: 0.8796 - val_loss: 0.1180 - val_acc: 0.8978\n",
            "Epoch 775/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8894 - val_loss: 0.1176 - val_acc: 0.8981\n",
            "Epoch 776/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8900 - val_loss: 0.1175 - val_acc: 0.8983\n",
            "Epoch 777/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8852 - val_loss: 0.1163 - val_acc: 0.8982\n",
            "Epoch 778/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2070 - acc: 0.8858 - val_loss: 0.1154 - val_acc: 0.8977\n",
            "Epoch 779/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8840 - val_loss: 0.1165 - val_acc: 0.8972\n",
            "Epoch 780/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8942 - val_loss: 0.1178 - val_acc: 0.8968\n",
            "Epoch 781/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8807 - val_loss: 0.1183 - val_acc: 0.8967\n",
            "Epoch 782/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8805 - val_loss: 0.1177 - val_acc: 0.8968\n",
            "Epoch 783/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8803 - val_loss: 0.1165 - val_acc: 0.8972\n",
            "Epoch 784/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1357 - acc: 0.8805 - val_loss: 0.1155 - val_acc: 0.8975\n",
            "Epoch 785/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2112 - acc: 0.8849 - val_loss: 0.1158 - val_acc: 0.8975\n",
            "Epoch 786/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1914 - acc: 0.8938 - val_loss: 0.1170 - val_acc: 0.8976\n",
            "Epoch 787/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8981 - val_loss: 0.1178 - val_acc: 0.8977\n",
            "Epoch 788/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8888 - val_loss: 0.1181 - val_acc: 0.8978\n",
            "Epoch 789/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8939 - val_loss: 0.1179 - val_acc: 0.8980\n",
            "Epoch 790/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8900 - val_loss: 0.1174 - val_acc: 0.8981\n",
            "Epoch 791/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1376 - acc: 0.8823 - val_loss: 0.1169 - val_acc: 0.8982\n",
            "Epoch 792/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2204 - acc: 0.8802 - val_loss: 0.1177 - val_acc: 0.8982\n",
            "Epoch 793/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1327 - acc: 0.8840 - val_loss: 0.1183 - val_acc: 0.8982\n",
            "Epoch 794/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8859 - val_loss: 0.1184 - val_acc: 0.8981\n",
            "Epoch 795/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1386 - acc: 0.8783 - val_loss: 0.1179 - val_acc: 0.8981\n",
            "Epoch 796/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8910 - val_loss: 0.1172 - val_acc: 0.8981\n",
            "Epoch 797/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8871 - val_loss: 0.1165 - val_acc: 0.8981\n",
            "Epoch 798/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8884 - val_loss: 0.1159 - val_acc: 0.8981\n",
            "Epoch 799/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8848 - val_loss: 0.1154 - val_acc: 0.8979\n",
            "Epoch 800/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8847 - val_loss: 0.1150 - val_acc: 0.8977\n",
            "Epoch 801/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8881 - val_loss: 0.1146 - val_acc: 0.8975\n",
            "Epoch 802/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1950 - acc: 0.8841 - val_loss: 0.1149 - val_acc: 0.8970\n",
            "Epoch 803/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1726 - acc: 0.8907 - val_loss: 0.1165 - val_acc: 0.8965\n",
            "Epoch 804/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8950 - val_loss: 0.1176 - val_acc: 0.8963\n",
            "Epoch 805/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8854 - val_loss: 0.1173 - val_acc: 0.8964\n",
            "Epoch 806/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1429 - acc: 0.8733 - val_loss: 0.1162 - val_acc: 0.8968\n",
            "Epoch 807/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1413 - acc: 0.8734 - val_loss: 0.1148 - val_acc: 0.8973\n",
            "Epoch 808/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8899 - val_loss: 0.1140 - val_acc: 0.8978\n",
            "Epoch 809/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8928 - val_loss: 0.1141 - val_acc: 0.8981\n",
            "Epoch 810/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8885 - val_loss: 0.1142 - val_acc: 0.8981\n",
            "Epoch 811/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2282 - acc: 0.8816 - val_loss: 0.1137 - val_acc: 0.8977\n",
            "Epoch 812/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8833 - val_loss: 0.1151 - val_acc: 0.8970\n",
            "Epoch 813/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8826 - val_loss: 0.1166 - val_acc: 0.8965\n",
            "Epoch 814/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8839 - val_loss: 0.1168 - val_acc: 0.8964\n",
            "Epoch 815/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8839 - val_loss: 0.1156 - val_acc: 0.8967\n",
            "Epoch 816/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8925 - val_loss: 0.1142 - val_acc: 0.8973\n",
            "Epoch 817/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8896 - val_loss: 0.1138 - val_acc: 0.8977\n",
            "Epoch 818/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8908 - val_loss: 0.1143 - val_acc: 0.8979\n",
            "Epoch 819/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2225 - acc: 0.8798 - val_loss: 0.1134 - val_acc: 0.8976\n",
            "Epoch 820/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8832 - val_loss: 0.1137 - val_acc: 0.8970\n",
            "Epoch 821/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8862 - val_loss: 0.1148 - val_acc: 0.8963\n",
            "Epoch 822/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8854 - val_loss: 0.1154 - val_acc: 0.8960\n",
            "Epoch 823/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1466 - acc: 0.8866 - val_loss: 0.1153 - val_acc: 0.8961\n",
            "Epoch 824/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8904 - val_loss: 0.1143 - val_acc: 0.8967\n",
            "Epoch 825/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8867 - val_loss: 0.1134 - val_acc: 0.8973\n",
            "Epoch 826/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8936 - val_loss: 0.1134 - val_acc: 0.8977\n",
            "Epoch 827/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8939 - val_loss: 0.1136 - val_acc: 0.8978\n",
            "Epoch 828/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8876 - val_loss: 0.1132 - val_acc: 0.8975\n",
            "Epoch 829/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8876 - val_loss: 0.1125 - val_acc: 0.8969\n",
            "Epoch 830/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2481 - acc: 0.8800 - val_loss: 0.1140 - val_acc: 0.8954\n",
            "Epoch 831/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1220 - acc: 0.8895 - val_loss: 0.1169 - val_acc: 0.8944\n",
            "Epoch 832/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8816 - val_loss: 0.1179 - val_acc: 0.8943\n",
            "Epoch 833/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8817 - val_loss: 0.1164 - val_acc: 0.8953\n",
            "Epoch 834/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8780 - val_loss: 0.1142 - val_acc: 0.8965\n",
            "Epoch 835/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8788 - val_loss: 0.1134 - val_acc: 0.8974\n",
            "Epoch 836/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8970 - val_loss: 0.1141 - val_acc: 0.8979\n",
            "Epoch 837/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8978 - val_loss: 0.1147 - val_acc: 0.8980\n",
            "Epoch 838/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8874 - val_loss: 0.1137 - val_acc: 0.8977\n",
            "Epoch 839/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8869 - val_loss: 0.1125 - val_acc: 0.8969\n",
            "Epoch 840/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8952 - val_loss: 0.1126 - val_acc: 0.8957\n",
            "Epoch 841/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8896 - val_loss: 0.1134 - val_acc: 0.8946\n",
            "Epoch 842/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8884 - val_loss: 0.1138 - val_acc: 0.8939\n",
            "Epoch 843/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8858 - val_loss: 0.1133 - val_acc: 0.8940\n",
            "Epoch 844/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8833 - val_loss: 0.1122 - val_acc: 0.8947\n",
            "Epoch 845/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8837 - val_loss: 0.1114 - val_acc: 0.8957\n",
            "Epoch 846/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8888 - val_loss: 0.1115 - val_acc: 0.8964\n",
            "Epoch 847/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2294 - acc: 0.8811 - val_loss: 0.1116 - val_acc: 0.8962\n",
            "Epoch 848/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8879 - val_loss: 0.1122 - val_acc: 0.8958\n",
            "Epoch 849/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8837 - val_loss: 0.1129 - val_acc: 0.8953\n",
            "Epoch 850/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1397 - acc: 0.8686 - val_loss: 0.1131 - val_acc: 0.8952\n",
            "Epoch 851/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8872 - val_loss: 0.1126 - val_acc: 0.8954\n",
            "Epoch 852/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8917 - val_loss: 0.1120 - val_acc: 0.8959\n",
            "Epoch 853/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2573 - acc: 0.8649 - val_loss: 0.1144 - val_acc: 0.8952\n",
            "Epoch 854/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8830 - val_loss: 0.1162 - val_acc: 0.8950\n",
            "Epoch 855/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8827 - val_loss: 0.1162 - val_acc: 0.8956\n",
            "Epoch 856/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8807 - val_loss: 0.1153 - val_acc: 0.8965\n",
            "Epoch 857/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1844 - acc: 0.8825 - val_loss: 0.1156 - val_acc: 0.8970\n",
            "Epoch 858/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.8881 - val_loss: 0.1154 - val_acc: 0.8975\n",
            "Epoch 859/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8918 - val_loss: 0.1152 - val_acc: 0.8978\n",
            "Epoch 860/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1247 - acc: 0.8881 - val_loss: 0.1150 - val_acc: 0.8979\n",
            "Epoch 861/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8812 - val_loss: 0.1145 - val_acc: 0.8978\n",
            "Epoch 862/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8887 - val_loss: 0.1142 - val_acc: 0.8976\n",
            "Epoch 863/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8961 - val_loss: 0.1140 - val_acc: 0.8972\n",
            "Epoch 864/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8920 - val_loss: 0.1140 - val_acc: 0.8969\n",
            "Epoch 865/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8864 - val_loss: 0.1140 - val_acc: 0.8964\n",
            "Epoch 866/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1551 - acc: 0.8827 - val_loss: 0.1141 - val_acc: 0.8960\n",
            "Epoch 867/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.9000 - val_loss: 0.1139 - val_acc: 0.8959\n",
            "Epoch 868/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1313 - acc: 0.8765 - val_loss: 0.1134 - val_acc: 0.8960\n",
            "Epoch 869/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1306 - acc: 0.8766 - val_loss: 0.1129 - val_acc: 0.8963\n",
            "Epoch 870/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2302 - acc: 0.8756 - val_loss: 0.1135 - val_acc: 0.8961\n",
            "Epoch 871/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8843 - val_loss: 0.1143 - val_acc: 0.8960\n",
            "Epoch 872/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8890 - val_loss: 0.1145 - val_acc: 0.8962\n",
            "Epoch 873/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8834 - val_loss: 0.1140 - val_acc: 0.8967\n",
            "Epoch 874/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8878 - val_loss: 0.1136 - val_acc: 0.8972\n",
            "Epoch 875/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8881 - val_loss: 0.1133 - val_acc: 0.8975\n",
            "Epoch 876/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8959 - val_loss: 0.1130 - val_acc: 0.8975\n",
            "Epoch 877/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8958 - val_loss: 0.1127 - val_acc: 0.8973\n",
            "Epoch 878/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8849 - val_loss: 0.1124 - val_acc: 0.8968\n",
            "Epoch 879/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1345 - acc: 0.8823 - val_loss: 0.1122 - val_acc: 0.8961\n",
            "Epoch 880/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8842 - val_loss: 0.1122 - val_acc: 0.8955\n",
            "Epoch 881/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8796 - val_loss: 0.1121 - val_acc: 0.8951\n",
            "Epoch 882/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8792 - val_loss: 0.1116 - val_acc: 0.8951\n",
            "Epoch 883/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8817 - val_loss: 0.1111 - val_acc: 0.8955\n",
            "Epoch 884/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2699 - acc: 0.8734 - val_loss: 0.1130 - val_acc: 0.8947\n",
            "Epoch 885/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8822 - val_loss: 0.1151 - val_acc: 0.8943\n",
            "Epoch 886/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1371 - acc: 0.8738 - val_loss: 0.1153 - val_acc: 0.8950\n",
            "Epoch 887/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8927 - val_loss: 0.1139 - val_acc: 0.8961\n",
            "Epoch 888/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8862 - val_loss: 0.1129 - val_acc: 0.8971\n",
            "Epoch 889/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8826 - val_loss: 0.1129 - val_acc: 0.8975\n",
            "Epoch 890/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8830 - val_loss: 0.1129 - val_acc: 0.8975\n",
            "Epoch 891/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1682 - acc: 0.8769 - val_loss: 0.1123 - val_acc: 0.8970\n",
            "Epoch 892/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8908 - val_loss: 0.1122 - val_acc: 0.8964\n",
            "Epoch 893/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8900 - val_loss: 0.1126 - val_acc: 0.8957\n",
            "Epoch 894/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8797 - val_loss: 0.1130 - val_acc: 0.8952\n",
            "Epoch 895/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8824 - val_loss: 0.1128 - val_acc: 0.8951\n",
            "Epoch 896/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8762 - val_loss: 0.1123 - val_acc: 0.8955\n",
            "Epoch 897/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8903 - val_loss: 0.1118 - val_acc: 0.8960\n",
            "Epoch 898/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1387 - acc: 0.8714 - val_loss: 0.1114 - val_acc: 0.8963\n",
            "Epoch 899/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8716 - val_loss: 0.1110 - val_acc: 0.8961\n",
            "Epoch 900/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8762 - val_loss: 0.1108 - val_acc: 0.8956\n",
            "Epoch 901/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8759 - val_loss: 0.1108 - val_acc: 0.8951\n",
            "Epoch 902/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8879 - val_loss: 0.1108 - val_acc: 0.8947\n",
            "Epoch 903/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8843 - val_loss: 0.1106 - val_acc: 0.8946\n",
            "Epoch 904/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1804 - acc: 0.8751 - val_loss: 0.1111 - val_acc: 0.8941\n",
            "Epoch 905/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8827 - val_loss: 0.1111 - val_acc: 0.8941\n",
            "Epoch 906/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8820 - val_loss: 0.1105 - val_acc: 0.8948\n",
            "Epoch 907/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8830 - val_loss: 0.1101 - val_acc: 0.8956\n",
            "Epoch 908/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1409 - acc: 0.8775 - val_loss: 0.1104 - val_acc: 0.8962\n",
            "Epoch 909/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8809 - val_loss: 0.1105 - val_acc: 0.8961\n",
            "Epoch 910/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8810 - val_loss: 0.1102 - val_acc: 0.8954\n",
            "Epoch 911/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8837 - val_loss: 0.1103 - val_acc: 0.8945\n",
            "Epoch 912/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8830 - val_loss: 0.1106 - val_acc: 0.8938\n",
            "Epoch 913/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8880 - val_loss: 0.1107 - val_acc: 0.8937\n",
            "Epoch 914/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8880 - val_loss: 0.1104 - val_acc: 0.8941\n",
            "Epoch 915/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8897 - val_loss: 0.1099 - val_acc: 0.8948\n",
            "Epoch 916/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8907 - val_loss: 0.1096 - val_acc: 0.8954\n",
            "Epoch 917/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8927 - val_loss: 0.1096 - val_acc: 0.8958\n",
            "Epoch 918/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3042 - acc: 0.8612 - val_loss: 0.1116 - val_acc: 0.8938\n",
            "Epoch 919/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1972 - acc: 0.8694 - val_loss: 0.1178 - val_acc: 0.8922\n",
            "Epoch 920/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8817 - val_loss: 0.1207 - val_acc: 0.8926\n",
            "Epoch 921/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2130 - acc: 0.8614 - val_loss: 0.1232 - val_acc: 0.8937\n",
            "Epoch 922/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1363 - acc: 0.8793 - val_loss: 0.1209 - val_acc: 0.8958\n",
            "Epoch 923/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1476 - acc: 0.8734 - val_loss: 0.1177 - val_acc: 0.8973\n",
            "Epoch 924/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8979 - val_loss: 0.1171 - val_acc: 0.8981\n",
            "Epoch 925/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8989 - val_loss: 0.1188 - val_acc: 0.8984\n",
            "Epoch 926/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8885 - val_loss: 0.1192 - val_acc: 0.8985\n",
            "Epoch 927/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8934 - val_loss: 0.1179 - val_acc: 0.8984\n",
            "Epoch 928/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8849 - val_loss: 0.1163 - val_acc: 0.8982\n",
            "Epoch 929/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8846 - val_loss: 0.1162 - val_acc: 0.8978\n",
            "Epoch 930/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1323 - acc: 0.8817 - val_loss: 0.1171 - val_acc: 0.8974\n",
            "Epoch 931/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8898 - val_loss: 0.1181 - val_acc: 0.8972\n",
            "Epoch 932/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1373 - acc: 0.8802 - val_loss: 0.1181 - val_acc: 0.8970\n",
            "Epoch 933/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8819 - val_loss: 0.1171 - val_acc: 0.8972\n",
            "Epoch 934/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8854 - val_loss: 0.1156 - val_acc: 0.8975\n",
            "Epoch 935/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8911 - val_loss: 0.1145 - val_acc: 0.8979\n",
            "Epoch 936/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1410 - acc: 0.8883 - val_loss: 0.1141 - val_acc: 0.8981\n",
            "Epoch 937/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8890 - val_loss: 0.1142 - val_acc: 0.8982\n",
            "Epoch 938/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8893 - val_loss: 0.1140 - val_acc: 0.8982\n",
            "Epoch 939/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8969 - val_loss: 0.1135 - val_acc: 0.8982\n",
            "Epoch 940/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8854 - val_loss: 0.1127 - val_acc: 0.8980\n",
            "Epoch 941/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1269 - acc: 0.8836 - val_loss: 0.1122 - val_acc: 0.8976\n",
            "Epoch 942/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1614 - acc: 0.8755 - val_loss: 0.1128 - val_acc: 0.8969\n",
            "Epoch 943/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1396 - acc: 0.8788 - val_loss: 0.1139 - val_acc: 0.8962\n",
            "Epoch 944/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1293 - acc: 0.8837 - val_loss: 0.1142 - val_acc: 0.8958\n",
            "Epoch 945/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8844 - val_loss: 0.1134 - val_acc: 0.8958\n",
            "Epoch 946/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8871 - val_loss: 0.1119 - val_acc: 0.8962\n",
            "Epoch 947/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8912 - val_loss: 0.1110 - val_acc: 0.8967\n",
            "Epoch 948/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8854 - val_loss: 0.1112 - val_acc: 0.8970\n",
            "Epoch 949/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8857 - val_loss: 0.1115 - val_acc: 0.8971\n",
            "Epoch 950/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8827 - val_loss: 0.1109 - val_acc: 0.8967\n",
            "Epoch 951/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8864 - val_loss: 0.1101 - val_acc: 0.8960\n",
            "Epoch 952/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8793 - val_loss: 0.1100 - val_acc: 0.8951\n",
            "Epoch 953/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8781 - val_loss: 0.1104 - val_acc: 0.8942\n",
            "Epoch 954/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8828 - val_loss: 0.1106 - val_acc: 0.8936\n",
            "Epoch 955/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8751 - val_loss: 0.1104 - val_acc: 0.8934\n",
            "Epoch 956/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8814 - val_loss: 0.1098 - val_acc: 0.8938\n",
            "Epoch 957/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1225 - acc: 0.8798 - val_loss: 0.1093 - val_acc: 0.8943\n",
            "Epoch 958/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8821 - val_loss: 0.1094 - val_acc: 0.8949\n",
            "Epoch 959/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1325 - acc: 0.8847 - val_loss: 0.1096 - val_acc: 0.8953\n",
            "Epoch 960/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1380 - acc: 0.8820 - val_loss: 0.1091 - val_acc: 0.8947\n",
            "Epoch 961/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8841 - val_loss: 0.1090 - val_acc: 0.8937\n",
            "Epoch 962/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8865 - val_loss: 0.1095 - val_acc: 0.8926\n",
            "Epoch 963/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8855 - val_loss: 0.1099 - val_acc: 0.8921\n",
            "Epoch 964/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - acc: 0.8613 - val_loss: 0.1093 - val_acc: 0.8927\n",
            "Epoch 965/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2154 - acc: 0.8594 - val_loss: 0.1094 - val_acc: 0.8936\n",
            "Epoch 966/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8853 - val_loss: 0.1097 - val_acc: 0.8947\n",
            "Epoch 967/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8862 - val_loss: 0.1099 - val_acc: 0.8955\n",
            "Epoch 968/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1779 - acc: 0.8785 - val_loss: 0.1104 - val_acc: 0.8956\n",
            "Epoch 969/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8836 - val_loss: 0.1106 - val_acc: 0.8957\n",
            "Epoch 970/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8923 - val_loss: 0.1105 - val_acc: 0.8959\n",
            "Epoch 971/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8854 - val_loss: 0.1102 - val_acc: 0.8962\n",
            "Epoch 972/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8802 - val_loss: 0.1101 - val_acc: 0.8963\n",
            "Epoch 973/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8816 - val_loss: 0.1101 - val_acc: 0.8964\n",
            "Epoch 974/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1370 - acc: 0.8789 - val_loss: 0.1102 - val_acc: 0.8963\n",
            "Epoch 975/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8883 - val_loss: 0.1102 - val_acc: 0.8961\n",
            "Epoch 976/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1355 - acc: 0.8727 - val_loss: 0.1102 - val_acc: 0.8959\n",
            "Epoch 977/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8890 - val_loss: 0.1100 - val_acc: 0.8960\n",
            "Epoch 978/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8914 - val_loss: 0.1098 - val_acc: 0.8961\n",
            "Epoch 979/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8830 - val_loss: 0.1097 - val_acc: 0.8963\n",
            "Epoch 980/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8808 - val_loss: 0.1096 - val_acc: 0.8963\n",
            "Epoch 981/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8830 - val_loss: 0.1094 - val_acc: 0.8963\n",
            "Epoch 982/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8775 - val_loss: 0.1091 - val_acc: 0.8960\n",
            "Epoch 983/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8773 - val_loss: 0.1089 - val_acc: 0.8957\n",
            "Epoch 984/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8818 - val_loss: 0.1089 - val_acc: 0.8954\n",
            "Epoch 985/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1834 - acc: 0.8733 - val_loss: 0.1096 - val_acc: 0.8945\n",
            "Epoch 986/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8786 - val_loss: 0.1101 - val_acc: 0.8941\n",
            "Epoch 987/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8787 - val_loss: 0.1098 - val_acc: 0.8945\n",
            "Epoch 988/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.8812 - val_loss: 0.1093 - val_acc: 0.8951\n",
            "Epoch 989/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8825 - val_loss: 0.1092 - val_acc: 0.8957\n",
            "Epoch 990/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2392 - acc: 0.8728 - val_loss: 0.1100 - val_acc: 0.8952\n",
            "Epoch 991/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8851 - val_loss: 0.1110 - val_acc: 0.8950\n",
            "Epoch 992/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8778 - val_loss: 0.1113 - val_acc: 0.8950\n",
            "Epoch 993/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8821 - val_loss: 0.1108 - val_acc: 0.8954\n",
            "Epoch 994/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8917 - val_loss: 0.1102 - val_acc: 0.8960\n",
            "Epoch 995/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8924 - val_loss: 0.1100 - val_acc: 0.8964\n",
            "Epoch 996/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8899 - val_loss: 0.1102 - val_acc: 0.8968\n",
            "Epoch 997/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8864 - val_loss: 0.1102 - val_acc: 0.8968\n",
            "Epoch 998/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2437 - acc: 0.8766 - val_loss: 0.1102 - val_acc: 0.8959\n",
            "Epoch 999/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8876 - val_loss: 0.1117 - val_acc: 0.8952\n",
            "Epoch 1000/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8872 - val_loss: 0.1131 - val_acc: 0.8948\n",
            "Epoch 1001/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8918 - val_loss: 0.1128 - val_acc: 0.8953\n",
            "Epoch 1002/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8822 - val_loss: 0.1118 - val_acc: 0.8962\n",
            "Epoch 1003/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8832 - val_loss: 0.1111 - val_acc: 0.8970\n",
            "Epoch 1004/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8916 - val_loss: 0.1113 - val_acc: 0.8976\n",
            "Epoch 1005/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8921 - val_loss: 0.1116 - val_acc: 0.8977\n",
            "Epoch 1006/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1327 - acc: 0.8756 - val_loss: 0.1110 - val_acc: 0.8974\n",
            "Epoch 1007/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8836 - val_loss: 0.1103 - val_acc: 0.8966\n",
            "Epoch 1008/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8818 - val_loss: 0.1102 - val_acc: 0.8957\n",
            "Epoch 1009/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8835 - val_loss: 0.1105 - val_acc: 0.8948\n",
            "Epoch 1010/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8805 - val_loss: 0.1108 - val_acc: 0.8941\n",
            "Epoch 1011/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8802 - val_loss: 0.1104 - val_acc: 0.8941\n",
            "Epoch 1012/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1382 - acc: 0.8695 - val_loss: 0.1095 - val_acc: 0.8949\n",
            "Epoch 1013/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8896 - val_loss: 0.1089 - val_acc: 0.8960\n",
            "Epoch 1014/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8934 - val_loss: 0.1093 - val_acc: 0.8965\n",
            "Epoch 1015/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8938 - val_loss: 0.1091 - val_acc: 0.8965\n",
            "Epoch 1016/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8868 - val_loss: 0.1085 - val_acc: 0.8959\n",
            "Epoch 1017/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8869 - val_loss: 0.1083 - val_acc: 0.8948\n",
            "Epoch 1018/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8855 - val_loss: 0.1087 - val_acc: 0.8937\n",
            "Epoch 1019/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8846 - val_loss: 0.1089 - val_acc: 0.8931\n",
            "Epoch 1020/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8719 - val_loss: 0.1084 - val_acc: 0.8936\n",
            "Epoch 1021/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8699 - val_loss: 0.1079 - val_acc: 0.8945\n",
            "Epoch 1022/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8911 - val_loss: 0.1081 - val_acc: 0.8953\n",
            "Epoch 1023/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8822 - val_loss: 0.1081 - val_acc: 0.8954\n",
            "Epoch 1024/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8825 - val_loss: 0.1077 - val_acc: 0.8946\n",
            "Epoch 1025/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1518 - acc: 0.8757 - val_loss: 0.1082 - val_acc: 0.8930\n",
            "Epoch 1026/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8774 - val_loss: 0.1089 - val_acc: 0.8922\n",
            "Epoch 1027/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8800 - val_loss: 0.1083 - val_acc: 0.8928\n",
            "Epoch 1028/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8774 - val_loss: 0.1076 - val_acc: 0.8938\n",
            "Epoch 1029/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8816 - val_loss: 0.1074 - val_acc: 0.8949\n",
            "Epoch 1030/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8829 - val_loss: 0.1078 - val_acc: 0.8955\n",
            "Epoch 1031/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8940 - val_loss: 0.1078 - val_acc: 0.8955\n",
            "Epoch 1032/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8893 - val_loss: 0.1074 - val_acc: 0.8948\n",
            "Epoch 1033/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8766 - val_loss: 0.1075 - val_acc: 0.8936\n",
            "Epoch 1034/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8790 - val_loss: 0.1079 - val_acc: 0.8926\n",
            "Epoch 1035/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8864 - val_loss: 0.1081 - val_acc: 0.8921\n",
            "Epoch 1036/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8864 - val_loss: 0.1076 - val_acc: 0.8928\n",
            "Epoch 1037/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8826 - val_loss: 0.1072 - val_acc: 0.8938\n",
            "Epoch 1038/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8835 - val_loss: 0.1072 - val_acc: 0.8946\n",
            "Epoch 1039/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8866 - val_loss: 0.1073 - val_acc: 0.8953\n",
            "Epoch 1040/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8872 - val_loss: 0.1074 - val_acc: 0.8955\n",
            "Epoch 1041/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8878 - val_loss: 0.1072 - val_acc: 0.8952\n",
            "Epoch 1042/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8895 - val_loss: 0.1072 - val_acc: 0.8947\n",
            "Epoch 1043/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8877 - val_loss: 0.1074 - val_acc: 0.8941\n",
            "Epoch 1044/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8833 - val_loss: 0.1074 - val_acc: 0.8939\n",
            "Epoch 1045/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8831 - val_loss: 0.1072 - val_acc: 0.8941\n",
            "Epoch 1046/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8830 - val_loss: 0.1070 - val_acc: 0.8947\n",
            "Epoch 1047/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1732 - acc: 0.8741 - val_loss: 0.1073 - val_acc: 0.8945\n",
            "Epoch 1048/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8874 - val_loss: 0.1075 - val_acc: 0.8944\n",
            "Epoch 1049/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8874 - val_loss: 0.1076 - val_acc: 0.8946\n",
            "Epoch 1050/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8818 - val_loss: 0.1075 - val_acc: 0.8948\n",
            "Epoch 1051/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8818 - val_loss: 0.1075 - val_acc: 0.8951\n",
            "Epoch 1052/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8785 - val_loss: 0.1075 - val_acc: 0.8953\n",
            "Epoch 1053/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8794 - val_loss: 0.1073 - val_acc: 0.8953\n",
            "Epoch 1054/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8794 - val_loss: 0.1071 - val_acc: 0.8951\n",
            "Epoch 1055/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8866 - val_loss: 0.1070 - val_acc: 0.8949\n",
            "Epoch 1056/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8778 - val_loss: 0.1070 - val_acc: 0.8946\n",
            "Epoch 1057/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8777 - val_loss: 0.1070 - val_acc: 0.8943\n",
            "Epoch 1058/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8885 - val_loss: 0.1070 - val_acc: 0.8943\n",
            "Epoch 1059/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8829 - val_loss: 0.1069 - val_acc: 0.8942\n",
            "Epoch 1060/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2156 - acc: 0.8791 - val_loss: 0.1077 - val_acc: 0.8937\n",
            "Epoch 1061/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8925 - val_loss: 0.1081 - val_acc: 0.8942\n",
            "Epoch 1062/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8877 - val_loss: 0.1078 - val_acc: 0.8952\n",
            "Epoch 1063/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8887 - val_loss: 0.1077 - val_acc: 0.8961\n",
            "Epoch 1064/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8910 - val_loss: 0.1080 - val_acc: 0.8967\n",
            "Epoch 1065/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8924 - val_loss: 0.1080 - val_acc: 0.8967\n",
            "Epoch 1066/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8925 - val_loss: 0.1078 - val_acc: 0.8964\n",
            "Epoch 1067/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2350 - acc: 0.8767 - val_loss: 0.1099 - val_acc: 0.8947\n",
            "Epoch 1068/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8831 - val_loss: 0.1130 - val_acc: 0.8938\n",
            "Epoch 1069/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2387 - acc: 0.8596 - val_loss: 0.1193 - val_acc: 0.8928\n",
            "Epoch 1070/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8784 - val_loss: 0.1207 - val_acc: 0.8941\n",
            "Epoch 1071/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1315 - acc: 0.8859 - val_loss: 0.1173 - val_acc: 0.8964\n",
            "Epoch 1072/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8825 - val_loss: 0.1140 - val_acc: 0.8979\n",
            "Epoch 1073/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8864 - val_loss: 0.1147 - val_acc: 0.8985\n",
            "Epoch 1074/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1428 - acc: 0.8725 - val_loss: 0.1163 - val_acc: 0.8986\n",
            "Epoch 1075/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8921 - val_loss: 0.1154 - val_acc: 0.8986\n",
            "Epoch 1076/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8921 - val_loss: 0.1132 - val_acc: 0.8984\n",
            "Epoch 1077/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1358 - acc: 0.8802 - val_loss: 0.1122 - val_acc: 0.8979\n",
            "Epoch 1078/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1334 - acc: 0.8798 - val_loss: 0.1130 - val_acc: 0.8971\n",
            "Epoch 1079/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8939 - val_loss: 0.1140 - val_acc: 0.8965\n",
            "Epoch 1080/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1808 - acc: 0.8876 - val_loss: 0.1159 - val_acc: 0.8958\n",
            "Epoch 1081/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8929 - val_loss: 0.1162 - val_acc: 0.8957\n",
            "Epoch 1082/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8941 - val_loss: 0.1149 - val_acc: 0.8961\n",
            "Epoch 1083/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8900 - val_loss: 0.1129 - val_acc: 0.8969\n",
            "Epoch 1084/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8908 - val_loss: 0.1117 - val_acc: 0.8975\n",
            "Epoch 1085/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1570 - acc: 0.8904 - val_loss: 0.1116 - val_acc: 0.8979\n",
            "Epoch 1086/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8921 - val_loss: 0.1116 - val_acc: 0.8981\n",
            "Epoch 1087/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8964 - val_loss: 0.1114 - val_acc: 0.8981\n",
            "Epoch 1088/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8837 - val_loss: 0.1109 - val_acc: 0.8980\n",
            "Epoch 1089/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2130 - acc: 0.8844 - val_loss: 0.1110 - val_acc: 0.8977\n",
            "Epoch 1090/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8948 - val_loss: 0.1123 - val_acc: 0.8973\n",
            "Epoch 1091/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1264 - acc: 0.8829 - val_loss: 0.1133 - val_acc: 0.8971\n",
            "Epoch 1092/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8827 - val_loss: 0.1130 - val_acc: 0.8971\n",
            "Epoch 1093/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8883 - val_loss: 0.1120 - val_acc: 0.8973\n",
            "Epoch 1094/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8836 - val_loss: 0.1110 - val_acc: 0.8976\n",
            "Epoch 1095/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8838 - val_loss: 0.1104 - val_acc: 0.8977\n",
            "Epoch 1096/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8929 - val_loss: 0.1101 - val_acc: 0.8977\n",
            "Epoch 1097/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8900 - val_loss: 0.1098 - val_acc: 0.8976\n",
            "Epoch 1098/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8898 - val_loss: 0.1094 - val_acc: 0.8973\n",
            "Epoch 1099/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1329 - acc: 0.8760 - val_loss: 0.1089 - val_acc: 0.8969\n",
            "Epoch 1100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2215 - acc: 0.8817 - val_loss: 0.1093 - val_acc: 0.8962\n",
            "Epoch 1101/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8716 - val_loss: 0.1105 - val_acc: 0.8956\n",
            "Epoch 1102/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8824 - val_loss: 0.1111 - val_acc: 0.8955\n",
            "Epoch 1103/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8821 - val_loss: 0.1105 - val_acc: 0.8957\n",
            "Epoch 1104/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8794 - val_loss: 0.1094 - val_acc: 0.8963\n",
            "Epoch 1105/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8903 - val_loss: 0.1087 - val_acc: 0.8968\n",
            "Epoch 1106/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8908 - val_loss: 0.1088 - val_acc: 0.8971\n",
            "Epoch 1107/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8985 - val_loss: 0.1090 - val_acc: 0.8971\n",
            "Epoch 1108/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8985 - val_loss: 0.1088 - val_acc: 0.8968\n",
            "Epoch 1109/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8844 - val_loss: 0.1082 - val_acc: 0.8963\n",
            "Epoch 1110/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8908 - val_loss: 0.1079 - val_acc: 0.8956\n",
            "Epoch 1111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8796 - val_loss: 0.1080 - val_acc: 0.8948\n",
            "Epoch 1112/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8749 - val_loss: 0.1082 - val_acc: 0.8942\n",
            "Epoch 1113/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8802 - val_loss: 0.1081 - val_acc: 0.8941\n",
            "Epoch 1114/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8823 - val_loss: 0.1075 - val_acc: 0.8945\n",
            "Epoch 1115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2972 - acc: 0.8597 - val_loss: 0.1100 - val_acc: 0.8938\n",
            "Epoch 1116/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1715 - acc: 0.8758 - val_loss: 0.1132 - val_acc: 0.8936\n",
            "Epoch 1117/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8945 - val_loss: 0.1136 - val_acc: 0.8947\n",
            "Epoch 1118/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8837 - val_loss: 0.1122 - val_acc: 0.8962\n",
            "Epoch 1119/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8737 - val_loss: 0.1111 - val_acc: 0.8974\n",
            "Epoch 1120/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2108 - acc: 0.8696 - val_loss: 0.1117 - val_acc: 0.8977\n",
            "Epoch 1121/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1291 - acc: 0.8792 - val_loss: 0.1118 - val_acc: 0.8978\n",
            "Epoch 1122/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.9005 - val_loss: 0.1118 - val_acc: 0.8977\n",
            "Epoch 1123/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8768 - val_loss: 0.1116 - val_acc: 0.8975\n",
            "Epoch 1124/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8866 - val_loss: 0.1115 - val_acc: 0.8972\n",
            "Epoch 1125/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8863 - val_loss: 0.1114 - val_acc: 0.8970\n",
            "Epoch 1126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8834 - val_loss: 0.1113 - val_acc: 0.8969\n",
            "Epoch 1127/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8826 - val_loss: 0.1110 - val_acc: 0.8970\n",
            "Epoch 1128/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8826 - val_loss: 0.1108 - val_acc: 0.8970\n",
            "Epoch 1129/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8885 - val_loss: 0.1105 - val_acc: 0.8972\n",
            "Epoch 1130/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8867 - val_loss: 0.1102 - val_acc: 0.8973\n",
            "Epoch 1131/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8780 - val_loss: 0.1099 - val_acc: 0.8974\n",
            "Epoch 1132/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8756 - val_loss: 0.1095 - val_acc: 0.8972\n",
            "Epoch 1133/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8754 - val_loss: 0.1090 - val_acc: 0.8969\n",
            "Epoch 1134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8811 - val_loss: 0.1086 - val_acc: 0.8966\n",
            "Epoch 1135/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8806 - val_loss: 0.1083 - val_acc: 0.8964\n",
            "Epoch 1136/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8718 - val_loss: 0.1081 - val_acc: 0.8962\n",
            "Epoch 1137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8717 - val_loss: 0.1078 - val_acc: 0.8961\n",
            "Epoch 1138/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8924 - val_loss: 0.1075 - val_acc: 0.8960\n",
            "Epoch 1139/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8859 - val_loss: 0.1073 - val_acc: 0.8959\n",
            "Epoch 1140/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8924 - val_loss: 0.1071 - val_acc: 0.8959\n",
            "Epoch 1141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8891 - val_loss: 0.1070 - val_acc: 0.8955\n",
            "Epoch 1142/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8836 - val_loss: 0.1069 - val_acc: 0.8950\n",
            "Epoch 1143/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8776 - val_loss: 0.1069 - val_acc: 0.8943\n",
            "Epoch 1144/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8853 - val_loss: 0.1068 - val_acc: 0.8938\n",
            "Epoch 1145/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8848 - val_loss: 0.1066 - val_acc: 0.8937\n",
            "Epoch 1146/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8824 - val_loss: 0.1065 - val_acc: 0.8937\n",
            "Epoch 1147/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8799 - val_loss: 0.1065 - val_acc: 0.8940\n",
            "Epoch 1148/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8802 - val_loss: 0.1066 - val_acc: 0.8941\n",
            "Epoch 1149/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8886 - val_loss: 0.1066 - val_acc: 0.8939\n",
            "Epoch 1150/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8926 - val_loss: 0.1064 - val_acc: 0.8936\n",
            "Epoch 1151/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2402 - acc: 0.8738 - val_loss: 0.1090 - val_acc: 0.8903\n",
            "Epoch 1152/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8763 - val_loss: 0.1122 - val_acc: 0.8886\n",
            "Epoch 1153/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8833 - val_loss: 0.1112 - val_acc: 0.8901\n",
            "Epoch 1154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8684 - val_loss: 0.1083 - val_acc: 0.8932\n",
            "Epoch 1155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8721 - val_loss: 0.1071 - val_acc: 0.8955\n",
            "Epoch 1156/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8841 - val_loss: 0.1081 - val_acc: 0.8967\n",
            "Epoch 1157/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8875 - val_loss: 0.1082 - val_acc: 0.8968\n",
            "Epoch 1158/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8894 - val_loss: 0.1074 - val_acc: 0.8963\n",
            "Epoch 1159/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8876 - val_loss: 0.1072 - val_acc: 0.8954\n",
            "Epoch 1160/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8875 - val_loss: 0.1077 - val_acc: 0.8945\n",
            "Epoch 1161/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8956 - val_loss: 0.1081 - val_acc: 0.8941\n",
            "Epoch 1162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8897 - val_loss: 0.1077 - val_acc: 0.8943\n",
            "Epoch 1163/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8900 - val_loss: 0.1070 - val_acc: 0.8950\n",
            "Epoch 1164/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8895 - val_loss: 0.1067 - val_acc: 0.8957\n",
            "Epoch 1165/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2892 - acc: 0.8642 - val_loss: 0.1079 - val_acc: 0.8951\n",
            "Epoch 1166/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8870 - val_loss: 0.1095 - val_acc: 0.8948\n",
            "Epoch 1167/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8867 - val_loss: 0.1103 - val_acc: 0.8951\n",
            "Epoch 1168/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8853 - val_loss: 0.1099 - val_acc: 0.8958\n",
            "Epoch 1169/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8829 - val_loss: 0.1091 - val_acc: 0.8965\n",
            "Epoch 1170/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8798 - val_loss: 0.1088 - val_acc: 0.8971\n",
            "Epoch 1171/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8802 - val_loss: 0.1090 - val_acc: 0.8974\n",
            "Epoch 1172/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8833 - val_loss: 0.1091 - val_acc: 0.8975\n",
            "Epoch 1173/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8834 - val_loss: 0.1089 - val_acc: 0.8973\n",
            "Epoch 1174/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8842 - val_loss: 0.1085 - val_acc: 0.8969\n",
            "Epoch 1175/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8907 - val_loss: 0.1083 - val_acc: 0.8964\n",
            "Epoch 1176/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8886 - val_loss: 0.1082 - val_acc: 0.8959\n",
            "Epoch 1177/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8753 - val_loss: 0.1081 - val_acc: 0.8955\n",
            "Epoch 1178/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8780 - val_loss: 0.1077 - val_acc: 0.8954\n",
            "Epoch 1179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2124 - acc: 0.8765 - val_loss: 0.1085 - val_acc: 0.8950\n",
            "Epoch 1180/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8824 - val_loss: 0.1089 - val_acc: 0.8950\n",
            "Epoch 1181/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1216 - acc: 0.8826 - val_loss: 0.1086 - val_acc: 0.8956\n",
            "Epoch 1182/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8871 - val_loss: 0.1081 - val_acc: 0.8962\n",
            "Epoch 1183/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8877 - val_loss: 0.1079 - val_acc: 0.8967\n",
            "Epoch 1184/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2152 - acc: 0.8790 - val_loss: 0.1084 - val_acc: 0.8969\n",
            "Epoch 1185/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8937 - val_loss: 0.1087 - val_acc: 0.8969\n",
            "Epoch 1186/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8801 - val_loss: 0.1088 - val_acc: 0.8967\n",
            "Epoch 1187/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8884 - val_loss: 0.1089 - val_acc: 0.8964\n",
            "Epoch 1188/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1259 - acc: 0.8795 - val_loss: 0.1089 - val_acc: 0.8962\n",
            "Epoch 1189/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1984 - acc: 0.8771 - val_loss: 0.1101 - val_acc: 0.8957\n",
            "Epoch 1190/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8862 - val_loss: 0.1107 - val_acc: 0.8956\n",
            "Epoch 1191/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2163 - acc: 0.8754 - val_loss: 0.1134 - val_acc: 0.8954\n",
            "Epoch 1192/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2071 - acc: 0.8757 - val_loss: 0.1177 - val_acc: 0.8954\n",
            "Epoch 1193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8925 - val_loss: 0.1189 - val_acc: 0.8961\n",
            "Epoch 1194/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8879 - val_loss: 0.1174 - val_acc: 0.8971\n",
            "Epoch 1195/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8809 - val_loss: 0.1155 - val_acc: 0.8979\n",
            "Epoch 1196/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8869 - val_loss: 0.1146 - val_acc: 0.8982\n",
            "Epoch 1197/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8839 - val_loss: 0.1145 - val_acc: 0.8984\n",
            "Epoch 1198/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8861 - val_loss: 0.1141 - val_acc: 0.8983\n",
            "Epoch 1199/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1343 - acc: 0.8783 - val_loss: 0.1133 - val_acc: 0.8979\n",
            "Epoch 1200/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8845 - val_loss: 0.1127 - val_acc: 0.8973\n",
            "Epoch 1201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8900 - val_loss: 0.1125 - val_acc: 0.8967\n",
            "Epoch 1202/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2018 - acc: 0.8775 - val_loss: 0.1141 - val_acc: 0.8956\n",
            "Epoch 1203/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8852 - val_loss: 0.1152 - val_acc: 0.8950\n",
            "Epoch 1204/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8851 - val_loss: 0.1147 - val_acc: 0.8952\n",
            "Epoch 1205/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8855 - val_loss: 0.1130 - val_acc: 0.8960\n",
            "Epoch 1206/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8856 - val_loss: 0.1113 - val_acc: 0.8969\n",
            "Epoch 1207/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8957 - val_loss: 0.1108 - val_acc: 0.8976\n",
            "Epoch 1208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8945 - val_loss: 0.1112 - val_acc: 0.8980\n",
            "Epoch 1209/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8869 - val_loss: 0.1110 - val_acc: 0.8981\n",
            "Epoch 1210/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1355 - acc: 0.8738 - val_loss: 0.1098 - val_acc: 0.8978\n",
            "Epoch 1211/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1330 - acc: 0.8735 - val_loss: 0.1090 - val_acc: 0.8973\n",
            "Epoch 1212/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8898 - val_loss: 0.1091 - val_acc: 0.8965\n",
            "Epoch 1213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8916 - val_loss: 0.1095 - val_acc: 0.8957\n",
            "Epoch 1214/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8797 - val_loss: 0.1095 - val_acc: 0.8952\n",
            "Epoch 1215/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8853 - val_loss: 0.1088 - val_acc: 0.8953\n",
            "Epoch 1216/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8814 - val_loss: 0.1077 - val_acc: 0.8957\n",
            "Epoch 1217/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8807 - val_loss: 0.1072 - val_acc: 0.8962\n",
            "Epoch 1218/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8818 - val_loss: 0.1073 - val_acc: 0.8965\n",
            "Epoch 1219/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1350 - acc: 0.8820 - val_loss: 0.1072 - val_acc: 0.8964\n",
            "Epoch 1220/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8925 - val_loss: 0.1067 - val_acc: 0.8960\n",
            "Epoch 1221/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8879 - val_loss: 0.1064 - val_acc: 0.8954\n",
            "Epoch 1222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8881 - val_loss: 0.1063 - val_acc: 0.8949\n",
            "Epoch 1223/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8834 - val_loss: 0.1062 - val_acc: 0.8946\n",
            "Epoch 1224/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8795 - val_loss: 0.1061 - val_acc: 0.8944\n",
            "Epoch 1225/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8793 - val_loss: 0.1060 - val_acc: 0.8943\n",
            "Epoch 1226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8828 - val_loss: 0.1059 - val_acc: 0.8943\n",
            "Epoch 1227/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8884 - val_loss: 0.1058 - val_acc: 0.8943\n",
            "Epoch 1228/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8877 - val_loss: 0.1057 - val_acc: 0.8943\n",
            "Epoch 1229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8847 - val_loss: 0.1056 - val_acc: 0.8942\n",
            "Epoch 1230/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8847 - val_loss: 0.1056 - val_acc: 0.8940\n",
            "Epoch 1231/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2673 - acc: 0.8693 - val_loss: 0.1076 - val_acc: 0.8916\n",
            "Epoch 1232/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8862 - val_loss: 0.1101 - val_acc: 0.8905\n",
            "Epoch 1233/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1642 - acc: 0.8721 - val_loss: 0.1109 - val_acc: 0.8911\n",
            "Epoch 1234/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8798 - val_loss: 0.1090 - val_acc: 0.8936\n",
            "Epoch 1235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1819 - acc: 0.8739 - val_loss: 0.1084 - val_acc: 0.8955\n",
            "Epoch 1236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8890 - val_loss: 0.1084 - val_acc: 0.8970\n",
            "Epoch 1237/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8847 - val_loss: 0.1092 - val_acc: 0.8976\n",
            "Epoch 1238/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8803 - val_loss: 0.1096 - val_acc: 0.8977\n",
            "Epoch 1239/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1255 - acc: 0.8804 - val_loss: 0.1094 - val_acc: 0.8974\n",
            "Epoch 1240/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8801 - val_loss: 0.1092 - val_acc: 0.8970\n",
            "Epoch 1241/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8970 - val_loss: 0.1092 - val_acc: 0.8966\n",
            "Epoch 1242/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8860 - val_loss: 0.1091 - val_acc: 0.8965\n",
            "Epoch 1243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8852 - val_loss: 0.1088 - val_acc: 0.8965\n",
            "Epoch 1244/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8821 - val_loss: 0.1085 - val_acc: 0.8966\n",
            "Epoch 1245/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8905 - val_loss: 0.1083 - val_acc: 0.8968\n",
            "Epoch 1246/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8883 - val_loss: 0.1082 - val_acc: 0.8969\n",
            "Epoch 1247/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8885 - val_loss: 0.1080 - val_acc: 0.8969\n",
            "Epoch 1248/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8860 - val_loss: 0.1077 - val_acc: 0.8969\n",
            "Epoch 1249/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8860 - val_loss: 0.1073 - val_acc: 0.8967\n",
            "Epoch 1250/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8911 - val_loss: 0.1070 - val_acc: 0.8963\n",
            "Epoch 1251/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8883 - val_loss: 0.1068 - val_acc: 0.8959\n",
            "Epoch 1252/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8878 - val_loss: 0.1067 - val_acc: 0.8955\n",
            "Epoch 1253/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8840 - val_loss: 0.1064 - val_acc: 0.8954\n",
            "Epoch 1254/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1349 - acc: 0.8670 - val_loss: 0.1062 - val_acc: 0.8954\n",
            "Epoch 1255/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8873 - val_loss: 0.1060 - val_acc: 0.8956\n",
            "Epoch 1256/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8812 - val_loss: 0.1058 - val_acc: 0.8958\n",
            "Epoch 1257/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8926 - val_loss: 0.1057 - val_acc: 0.8958\n",
            "Epoch 1258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8689 - val_loss: 0.1055 - val_acc: 0.8957\n",
            "Epoch 1259/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8838 - val_loss: 0.1054 - val_acc: 0.8952\n",
            "Epoch 1260/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8900 - val_loss: 0.1054 - val_acc: 0.8944\n",
            "Epoch 1261/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8859 - val_loss: 0.1054 - val_acc: 0.8938\n",
            "Epoch 1262/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8853 - val_loss: 0.1053 - val_acc: 0.8936\n",
            "Epoch 1263/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8873 - val_loss: 0.1052 - val_acc: 0.8939\n",
            "Epoch 1264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1388 - acc: 0.8796 - val_loss: 0.1053 - val_acc: 0.8939\n",
            "Epoch 1265/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8758 - val_loss: 0.1052 - val_acc: 0.8942\n",
            "Epoch 1266/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1859 - acc: 0.8782 - val_loss: 0.1055 - val_acc: 0.8939\n",
            "Epoch 1267/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8926 - val_loss: 0.1055 - val_acc: 0.8939\n",
            "Epoch 1268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2054 - acc: 0.8740 - val_loss: 0.1069 - val_acc: 0.8930\n",
            "Epoch 1269/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1277 - acc: 0.8811 - val_loss: 0.1082 - val_acc: 0.8929\n",
            "Epoch 1270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8810 - val_loss: 0.1079 - val_acc: 0.8941\n",
            "Epoch 1271/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1451 - acc: 0.8913 - val_loss: 0.1080 - val_acc: 0.8953\n",
            "Epoch 1272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8880 - val_loss: 0.1080 - val_acc: 0.8964\n",
            "Epoch 1273/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8860 - val_loss: 0.1081 - val_acc: 0.8970\n",
            "Epoch 1274/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8856 - val_loss: 0.1082 - val_acc: 0.8972\n",
            "Epoch 1275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2457 - acc: 0.8761 - val_loss: 0.1093 - val_acc: 0.8971\n",
            "Epoch 1276/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8897 - val_loss: 0.1111 - val_acc: 0.8969\n",
            "Epoch 1277/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8836 - val_loss: 0.1121 - val_acc: 0.8969\n",
            "Epoch 1278/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8875 - val_loss: 0.1120 - val_acc: 0.8971\n",
            "Epoch 1279/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8890 - val_loss: 0.1112 - val_acc: 0.8973\n",
            "Epoch 1280/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8960 - val_loss: 0.1106 - val_acc: 0.8976\n",
            "Epoch 1281/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8960 - val_loss: 0.1105 - val_acc: 0.8977\n",
            "Epoch 1282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8856 - val_loss: 0.1103 - val_acc: 0.8976\n",
            "Epoch 1283/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8873 - val_loss: 0.1099 - val_acc: 0.8975\n",
            "Epoch 1284/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8851 - val_loss: 0.1094 - val_acc: 0.8972\n",
            "Epoch 1285/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8810 - val_loss: 0.1091 - val_acc: 0.8967\n",
            "Epoch 1286/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8806 - val_loss: 0.1091 - val_acc: 0.8962\n",
            "Epoch 1287/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8805 - val_loss: 0.1091 - val_acc: 0.8959\n",
            "Epoch 1288/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8903 - val_loss: 0.1086 - val_acc: 0.8958\n",
            "Epoch 1289/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8838 - val_loss: 0.1078 - val_acc: 0.8960\n",
            "Epoch 1290/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8756 - val_loss: 0.1071 - val_acc: 0.8963\n",
            "Epoch 1291/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8939 - val_loss: 0.1067 - val_acc: 0.8965\n",
            "Epoch 1292/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8861 - val_loss: 0.1065 - val_acc: 0.8965\n",
            "Epoch 1293/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8821 - val_loss: 0.1063 - val_acc: 0.8964\n",
            "Epoch 1294/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1619 - acc: 0.8821 - val_loss: 0.1061 - val_acc: 0.8960\n",
            "Epoch 1295/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8786 - val_loss: 0.1061 - val_acc: 0.8957\n",
            "Epoch 1296/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8892 - val_loss: 0.1061 - val_acc: 0.8955\n",
            "Epoch 1297/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8889 - val_loss: 0.1060 - val_acc: 0.8956\n",
            "Epoch 1298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8805 - val_loss: 0.1057 - val_acc: 0.8957\n",
            "Epoch 1299/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8831 - val_loss: 0.1055 - val_acc: 0.8956\n",
            "Epoch 1300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8830 - val_loss: 0.1053 - val_acc: 0.8954\n",
            "Epoch 1301/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8904 - val_loss: 0.1053 - val_acc: 0.8950\n",
            "Epoch 1302/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8901 - val_loss: 0.1053 - val_acc: 0.8946\n",
            "Epoch 1303/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1279 - acc: 0.8705 - val_loss: 0.1053 - val_acc: 0.8941\n",
            "Epoch 1304/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2166 - acc: 0.8621 - val_loss: 0.1071 - val_acc: 0.8922\n",
            "Epoch 1305/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1253 - acc: 0.8717 - val_loss: 0.1081 - val_acc: 0.8917\n",
            "Epoch 1306/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8889 - val_loss: 0.1073 - val_acc: 0.8926\n",
            "Epoch 1307/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1326 - acc: 0.8861 - val_loss: 0.1061 - val_acc: 0.8943\n",
            "Epoch 1308/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8873 - val_loss: 0.1057 - val_acc: 0.8957\n",
            "Epoch 1309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8885 - val_loss: 0.1061 - val_acc: 0.8964\n",
            "Epoch 1310/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2386 - acc: 0.8727 - val_loss: 0.1060 - val_acc: 0.8960\n",
            "Epoch 1311/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2732 - acc: 0.8618 - val_loss: 0.1110 - val_acc: 0.8938\n",
            "Epoch 1312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2459 - acc: 0.8528 - val_loss: 0.1236 - val_acc: 0.8908\n",
            "Epoch 1313/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8751 - val_loss: 0.1309 - val_acc: 0.8906\n",
            "Epoch 1314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1456 - acc: 0.8740 - val_loss: 0.1290 - val_acc: 0.8933\n",
            "Epoch 1315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1363 - acc: 0.8833 - val_loss: 0.1218 - val_acc: 0.8963\n",
            "Epoch 1316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8856 - val_loss: 0.1164 - val_acc: 0.8979\n",
            "Epoch 1317/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8962 - val_loss: 0.1166 - val_acc: 0.8985\n",
            "Epoch 1318/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8929 - val_loss: 0.1196 - val_acc: 0.8987\n",
            "Epoch 1319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2008 - acc: 0.8912 - val_loss: 0.1202 - val_acc: 0.8987\n",
            "Epoch 1320/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8945 - val_loss: 0.1185 - val_acc: 0.8985\n",
            "Epoch 1321/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8897 - val_loss: 0.1170 - val_acc: 0.8981\n",
            "Epoch 1322/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1402 - acc: 0.8780 - val_loss: 0.1170 - val_acc: 0.8975\n",
            "Epoch 1323/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8876 - val_loss: 0.1181 - val_acc: 0.8969\n",
            "Epoch 1324/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1364 - acc: 0.8853 - val_loss: 0.1195 - val_acc: 0.8965\n",
            "Epoch 1325/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 0.8853 - val_loss: 0.1200 - val_acc: 0.8962\n",
            "Epoch 1326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1339 - acc: 0.8846 - val_loss: 0.1194 - val_acc: 0.8963\n",
            "Epoch 1327/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1465 - acc: 0.8746 - val_loss: 0.1179 - val_acc: 0.8967\n",
            "Epoch 1328/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8974 - val_loss: 0.1159 - val_acc: 0.8972\n",
            "Epoch 1329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8875 - val_loss: 0.1143 - val_acc: 0.8976\n",
            "Epoch 1330/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1234 - acc: 0.8891 - val_loss: 0.1135 - val_acc: 0.8980\n",
            "Epoch 1331/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8894 - val_loss: 0.1132 - val_acc: 0.8982\n",
            "Epoch 1332/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8908 - val_loss: 0.1129 - val_acc: 0.8983\n",
            "Epoch 1333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8848 - val_loss: 0.1120 - val_acc: 0.8982\n",
            "Epoch 1334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8903 - val_loss: 0.1108 - val_acc: 0.8981\n",
            "Epoch 1335/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8821 - val_loss: 0.1099 - val_acc: 0.8977\n",
            "Epoch 1336/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1587 - acc: 0.8862 - val_loss: 0.1102 - val_acc: 0.8972\n",
            "Epoch 1337/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8802 - val_loss: 0.1110 - val_acc: 0.8966\n",
            "Epoch 1338/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1312 - acc: 0.8812 - val_loss: 0.1116 - val_acc: 0.8962\n",
            "Epoch 1339/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1424 - acc: 0.8857 - val_loss: 0.1115 - val_acc: 0.8961\n",
            "Epoch 1340/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8871 - val_loss: 0.1106 - val_acc: 0.8963\n",
            "Epoch 1341/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8884 - val_loss: 0.1092 - val_acc: 0.8968\n",
            "Epoch 1342/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8876 - val_loss: 0.1082 - val_acc: 0.8972\n",
            "Epoch 1343/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8848 - val_loss: 0.1081 - val_acc: 0.8975\n",
            "Epoch 1344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8842 - val_loss: 0.1080 - val_acc: 0.8975\n",
            "Epoch 1345/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8832 - val_loss: 0.1074 - val_acc: 0.8972\n",
            "Epoch 1346/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1650 - acc: 0.8755 - val_loss: 0.1069 - val_acc: 0.8966\n",
            "Epoch 1347/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8778 - val_loss: 0.1070 - val_acc: 0.8959\n",
            "Epoch 1348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8836 - val_loss: 0.1075 - val_acc: 0.8952\n",
            "Epoch 1349/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8712 - val_loss: 0.1078 - val_acc: 0.8947\n",
            "Epoch 1350/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8867 - val_loss: 0.1074 - val_acc: 0.8947\n",
            "Epoch 1351/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8898 - val_loss: 0.1066 - val_acc: 0.8951\n",
            "Epoch 1352/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8902 - val_loss: 0.1060 - val_acc: 0.8956\n",
            "Epoch 1353/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8843 - val_loss: 0.1059 - val_acc: 0.8961\n",
            "Epoch 1354/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8797 - val_loss: 0.1059 - val_acc: 0.8961\n",
            "Epoch 1355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8868 - val_loss: 0.1058 - val_acc: 0.8960\n",
            "Epoch 1356/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1989 - acc: 0.8745 - val_loss: 0.1057 - val_acc: 0.8952\n",
            "Epoch 1357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8780 - val_loss: 0.1066 - val_acc: 0.8943\n",
            "Epoch 1358/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8767 - val_loss: 0.1074 - val_acc: 0.8936\n",
            "Epoch 1359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8762 - val_loss: 0.1074 - val_acc: 0.8937\n",
            "Epoch 1360/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8818 - val_loss: 0.1065 - val_acc: 0.8944\n",
            "Epoch 1361/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1611 - acc: 0.8794 - val_loss: 0.1060 - val_acc: 0.8955\n",
            "Epoch 1362/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8831 - val_loss: 0.1062 - val_acc: 0.8963\n",
            "Epoch 1363/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8903 - val_loss: 0.1066 - val_acc: 0.8967\n",
            "Epoch 1364/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8906 - val_loss: 0.1064 - val_acc: 0.8967\n",
            "Epoch 1365/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8859 - val_loss: 0.1058 - val_acc: 0.8962\n",
            "Epoch 1366/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8897 - val_loss: 0.1058 - val_acc: 0.8955\n",
            "Epoch 1367/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8765 - val_loss: 0.1061 - val_acc: 0.8949\n",
            "Epoch 1368/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1300 - acc: 0.8653 - val_loss: 0.1062 - val_acc: 0.8945\n",
            "Epoch 1369/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1298 - acc: 0.8648 - val_loss: 0.1060 - val_acc: 0.8945\n",
            "Epoch 1370/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1915 - acc: 0.8738 - val_loss: 0.1061 - val_acc: 0.8946\n",
            "Epoch 1371/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8865 - val_loss: 0.1060 - val_acc: 0.8950\n",
            "Epoch 1372/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8846 - val_loss: 0.1058 - val_acc: 0.8955\n",
            "Epoch 1373/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8919 - val_loss: 0.1057 - val_acc: 0.8961\n",
            "Epoch 1374/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8925 - val_loss: 0.1058 - val_acc: 0.8964\n",
            "Epoch 1375/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8870 - val_loss: 0.1058 - val_acc: 0.8965\n",
            "Epoch 1376/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8812 - val_loss: 0.1055 - val_acc: 0.8962\n",
            "Epoch 1377/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2428 - acc: 0.8671 - val_loss: 0.1064 - val_acc: 0.8953\n",
            "Epoch 1378/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8872 - val_loss: 0.1084 - val_acc: 0.8945\n",
            "Epoch 1379/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8715 - val_loss: 0.1094 - val_acc: 0.8944\n",
            "Epoch 1380/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8714 - val_loss: 0.1088 - val_acc: 0.8950\n",
            "Epoch 1381/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8831 - val_loss: 0.1074 - val_acc: 0.8961\n",
            "Epoch 1382/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8917 - val_loss: 0.1068 - val_acc: 0.8969\n",
            "Epoch 1383/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8924 - val_loss: 0.1071 - val_acc: 0.8974\n",
            "Epoch 1384/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8823 - val_loss: 0.1072 - val_acc: 0.8974\n",
            "Epoch 1385/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1741 - acc: 0.8790 - val_loss: 0.1068 - val_acc: 0.8971\n",
            "Epoch 1386/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1332 - acc: 0.8776 - val_loss: 0.1065 - val_acc: 0.8964\n",
            "Epoch 1387/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8779 - val_loss: 0.1070 - val_acc: 0.8956\n",
            "Epoch 1388/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8819 - val_loss: 0.1075 - val_acc: 0.8950\n",
            "Epoch 1389/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8798 - val_loss: 0.1074 - val_acc: 0.8949\n",
            "Epoch 1390/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8801 - val_loss: 0.1068 - val_acc: 0.8953\n",
            "Epoch 1391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8805 - val_loss: 0.1061 - val_acc: 0.8958\n",
            "Epoch 1392/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8831 - val_loss: 0.1059 - val_acc: 0.8963\n",
            "Epoch 1393/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8896 - val_loss: 0.1060 - val_acc: 0.8966\n",
            "Epoch 1394/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8871 - val_loss: 0.1059 - val_acc: 0.8966\n",
            "Epoch 1395/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8794 - val_loss: 0.1056 - val_acc: 0.8963\n",
            "Epoch 1396/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8796 - val_loss: 0.1052 - val_acc: 0.8954\n",
            "Epoch 1397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8791 - val_loss: 0.1055 - val_acc: 0.8943\n",
            "Epoch 1398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8820 - val_loss: 0.1059 - val_acc: 0.8936\n",
            "Epoch 1399/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8900 - val_loss: 0.1057 - val_acc: 0.8935\n",
            "Epoch 1400/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1397 - acc: 0.8794 - val_loss: 0.1051 - val_acc: 0.8943\n",
            "Epoch 1401/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8833 - val_loss: 0.1047 - val_acc: 0.8953\n",
            "Epoch 1402/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8845 - val_loss: 0.1050 - val_acc: 0.8961\n",
            "Epoch 1403/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8877 - val_loss: 0.1051 - val_acc: 0.8963\n",
            "Epoch 1404/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8885 - val_loss: 0.1045 - val_acc: 0.8959\n",
            "Epoch 1405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8929 - val_loss: 0.1042 - val_acc: 0.8951\n",
            "Epoch 1406/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8920 - val_loss: 0.1043 - val_acc: 0.8943\n",
            "Epoch 1407/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8818 - val_loss: 0.1045 - val_acc: 0.8938\n",
            "Epoch 1408/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8822 - val_loss: 0.1044 - val_acc: 0.8937\n",
            "Epoch 1409/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8882 - val_loss: 0.1041 - val_acc: 0.8942\n",
            "Epoch 1410/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8719 - val_loss: 0.1040 - val_acc: 0.8946\n",
            "Epoch 1411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8782 - val_loss: 0.1039 - val_acc: 0.8948\n",
            "Epoch 1412/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8836 - val_loss: 0.1039 - val_acc: 0.8949\n",
            "Epoch 1413/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8771 - val_loss: 0.1037 - val_acc: 0.8947\n",
            "Epoch 1414/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1285 - acc: 0.8823 - val_loss: 0.1038 - val_acc: 0.8943\n",
            "Epoch 1415/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1294 - acc: 0.8699 - val_loss: 0.1041 - val_acc: 0.8939\n",
            "Epoch 1416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8697 - val_loss: 0.1043 - val_acc: 0.8939\n",
            "Epoch 1417/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8885 - val_loss: 0.1040 - val_acc: 0.8944\n",
            "Epoch 1418/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8920 - val_loss: 0.1039 - val_acc: 0.8950\n",
            "Epoch 1419/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8852 - val_loss: 0.1040 - val_acc: 0.8954\n",
            "Epoch 1420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1597 - acc: 0.8773 - val_loss: 0.1040 - val_acc: 0.8950\n",
            "Epoch 1421/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8886 - val_loss: 0.1042 - val_acc: 0.8946\n",
            "Epoch 1422/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8858 - val_loss: 0.1044 - val_acc: 0.8943\n",
            "Epoch 1423/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8853 - val_loss: 0.1043 - val_acc: 0.8945\n",
            "Epoch 1424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8739 - val_loss: 0.1040 - val_acc: 0.8951\n",
            "Epoch 1425/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8724 - val_loss: 0.1040 - val_acc: 0.8957\n",
            "Epoch 1426/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2407 - acc: 0.8693 - val_loss: 0.1045 - val_acc: 0.8952\n",
            "Epoch 1427/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8817 - val_loss: 0.1054 - val_acc: 0.8948\n",
            "Epoch 1428/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8807 - val_loss: 0.1058 - val_acc: 0.8950\n",
            "Epoch 1429/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8815 - val_loss: 0.1056 - val_acc: 0.8956\n",
            "Epoch 1430/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2631 - acc: 0.8602 - val_loss: 0.1072 - val_acc: 0.8956\n",
            "Epoch 1431/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1756 - acc: 0.8759 - val_loss: 0.1096 - val_acc: 0.8959\n",
            "Epoch 1432/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8841 - val_loss: 0.1107 - val_acc: 0.8966\n",
            "Epoch 1433/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8811 - val_loss: 0.1110 - val_acc: 0.8973\n",
            "Epoch 1434/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8853 - val_loss: 0.1109 - val_acc: 0.8978\n",
            "Epoch 1435/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8961 - val_loss: 0.1109 - val_acc: 0.8981\n",
            "Epoch 1436/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8847 - val_loss: 0.1106 - val_acc: 0.8981\n",
            "Epoch 1437/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2159 - acc: 0.8756 - val_loss: 0.1108 - val_acc: 0.8978\n",
            "Epoch 1438/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8800 - val_loss: 0.1118 - val_acc: 0.8972\n",
            "Epoch 1439/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8825 - val_loss: 0.1128 - val_acc: 0.8967\n",
            "Epoch 1440/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1826 - acc: 0.8824 - val_loss: 0.1142 - val_acc: 0.8964\n",
            "Epoch 1441/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1702 - acc: 0.8786 - val_loss: 0.1156 - val_acc: 0.8963\n",
            "Epoch 1442/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1943 - acc: 0.8726 - val_loss: 0.1170 - val_acc: 0.8965\n",
            "Epoch 1443/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1626 - acc: 0.8816 - val_loss: 0.1173 - val_acc: 0.8971\n",
            "Epoch 1444/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8887 - val_loss: 0.1160 - val_acc: 0.8978\n",
            "Epoch 1445/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1288 - acc: 0.8812 - val_loss: 0.1147 - val_acc: 0.8983\n",
            "Epoch 1446/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1353 - acc: 0.8821 - val_loss: 0.1144 - val_acc: 0.8985\n",
            "Epoch 1447/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8911 - val_loss: 0.1145 - val_acc: 0.8985\n",
            "Epoch 1448/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8877 - val_loss: 0.1142 - val_acc: 0.8985\n",
            "Epoch 1449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8875 - val_loss: 0.1135 - val_acc: 0.8984\n",
            "Epoch 1450/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8849 - val_loss: 0.1125 - val_acc: 0.8982\n",
            "Epoch 1451/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1288 - acc: 0.8822 - val_loss: 0.1119 - val_acc: 0.8978\n",
            "Epoch 1452/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8913 - val_loss: 0.1116 - val_acc: 0.8974\n",
            "Epoch 1453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8910 - val_loss: 0.1113 - val_acc: 0.8971\n",
            "Epoch 1454/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8839 - val_loss: 0.1107 - val_acc: 0.8969\n",
            "Epoch 1455/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8919 - val_loss: 0.1097 - val_acc: 0.8970\n",
            "Epoch 1456/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8812 - val_loss: 0.1086 - val_acc: 0.8972\n",
            "Epoch 1457/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8812 - val_loss: 0.1077 - val_acc: 0.8974\n",
            "Epoch 1458/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8892 - val_loss: 0.1072 - val_acc: 0.8976\n",
            "Epoch 1459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8894 - val_loss: 0.1070 - val_acc: 0.8977\n",
            "Epoch 1460/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8806 - val_loss: 0.1065 - val_acc: 0.8975\n",
            "Epoch 1461/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8919 - val_loss: 0.1059 - val_acc: 0.8972\n",
            "Epoch 1462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1435 - acc: 0.8853 - val_loss: 0.1057 - val_acc: 0.8964\n",
            "Epoch 1463/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8868 - val_loss: 0.1061 - val_acc: 0.8956\n",
            "Epoch 1464/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1349 - acc: 0.8865 - val_loss: 0.1067 - val_acc: 0.8950\n",
            "Epoch 1465/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8937 - val_loss: 0.1063 - val_acc: 0.8950\n",
            "Epoch 1466/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1628 - acc: 0.8795 - val_loss: 0.1062 - val_acc: 0.8951\n",
            "Epoch 1467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2428 - acc: 0.8706 - val_loss: 0.1084 - val_acc: 0.8944\n",
            "Epoch 1468/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8892 - val_loss: 0.1093 - val_acc: 0.8945\n",
            "Epoch 1469/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2173 - acc: 0.8706 - val_loss: 0.1119 - val_acc: 0.8946\n",
            "Epoch 1470/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1839 - acc: 0.8753 - val_loss: 0.1144 - val_acc: 0.8949\n",
            "Epoch 1471/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8837 - val_loss: 0.1140 - val_acc: 0.8961\n",
            "Epoch 1472/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1832 - acc: 0.8726 - val_loss: 0.1136 - val_acc: 0.8970\n",
            "Epoch 1473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8875 - val_loss: 0.1125 - val_acc: 0.8978\n",
            "Epoch 1474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1219 - acc: 0.8879 - val_loss: 0.1120 - val_acc: 0.8982\n",
            "Epoch 1475/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8883 - val_loss: 0.1123 - val_acc: 0.8983\n",
            "Epoch 1476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8877 - val_loss: 0.1123 - val_acc: 0.8983\n",
            "Epoch 1477/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1815 - acc: 0.8830 - val_loss: 0.1119 - val_acc: 0.8982\n",
            "Epoch 1478/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1383 - acc: 0.8725 - val_loss: 0.1114 - val_acc: 0.8980\n",
            "Epoch 1479/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8916 - val_loss: 0.1115 - val_acc: 0.8977\n",
            "Epoch 1480/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8908 - val_loss: 0.1118 - val_acc: 0.8976\n",
            "Epoch 1481/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1310 - acc: 0.8792 - val_loss: 0.1119 - val_acc: 0.8974\n",
            "Epoch 1482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8886 - val_loss: 0.1116 - val_acc: 0.8974\n",
            "Epoch 1483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8942 - val_loss: 0.1109 - val_acc: 0.8975\n",
            "Epoch 1484/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8944 - val_loss: 0.1103 - val_acc: 0.8977\n",
            "Epoch 1485/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8947 - val_loss: 0.1098 - val_acc: 0.8979\n",
            "Epoch 1486/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2015 - acc: 0.8868 - val_loss: 0.1099 - val_acc: 0.8980\n",
            "Epoch 1487/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8972 - val_loss: 0.1098 - val_acc: 0.8980\n",
            "Epoch 1488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8892 - val_loss: 0.1094 - val_acc: 0.8980\n",
            "Epoch 1489/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8892 - val_loss: 0.1089 - val_acc: 0.8979\n",
            "Epoch 1490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8964 - val_loss: 0.1087 - val_acc: 0.8978\n",
            "Epoch 1491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8962 - val_loss: 0.1086 - val_acc: 0.8976\n",
            "Epoch 1492/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8830 - val_loss: 0.1085 - val_acc: 0.8974\n",
            "Epoch 1493/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8838 - val_loss: 0.1081 - val_acc: 0.8973\n",
            "Epoch 1494/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8901 - val_loss: 0.1077 - val_acc: 0.8972\n",
            "Epoch 1495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8946 - val_loss: 0.1071 - val_acc: 0.8971\n",
            "Epoch 1496/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1217 - acc: 0.8838 - val_loss: 0.1065 - val_acc: 0.8971\n",
            "Epoch 1497/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8880 - val_loss: 0.1062 - val_acc: 0.8971\n",
            "Epoch 1498/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8882 - val_loss: 0.1059 - val_acc: 0.8971\n",
            "Epoch 1499/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2282 - acc: 0.8739 - val_loss: 0.1065 - val_acc: 0.8966\n",
            "Epoch 1500/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8921 - val_loss: 0.1073 - val_acc: 0.8962\n",
            "Epoch 1501/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8918 - val_loss: 0.1075 - val_acc: 0.8961\n",
            "Epoch 1502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8885 - val_loss: 0.1069 - val_acc: 0.8963\n",
            "Epoch 1503/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8952 - val_loss: 0.1061 - val_acc: 0.8966\n",
            "Epoch 1504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1280 - acc: 0.8756 - val_loss: 0.1057 - val_acc: 0.8969\n",
            "Epoch 1505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8976 - val_loss: 0.1059 - val_acc: 0.8972\n",
            "Epoch 1506/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1305 - acc: 0.8731 - val_loss: 0.1058 - val_acc: 0.8971\n",
            "Epoch 1507/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8837 - val_loss: 0.1054 - val_acc: 0.8970\n",
            "Epoch 1508/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8919 - val_loss: 0.1049 - val_acc: 0.8966\n",
            "Epoch 1509/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8915 - val_loss: 0.1047 - val_acc: 0.8961\n",
            "Epoch 1510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2327 - acc: 0.8763 - val_loss: 0.1062 - val_acc: 0.8951\n",
            "Epoch 1511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8928 - val_loss: 0.1076 - val_acc: 0.8946\n",
            "Epoch 1512/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2378 - acc: 0.8665 - val_loss: 0.1121 - val_acc: 0.8934\n",
            "Epoch 1513/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1597 - acc: 0.8724 - val_loss: 0.1157 - val_acc: 0.8930\n",
            "Epoch 1514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2180 - acc: 0.8625 - val_loss: 0.1195 - val_acc: 0.8931\n",
            "Epoch 1515/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8877 - val_loss: 0.1184 - val_acc: 0.8948\n",
            "Epoch 1516/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2228 - acc: 0.8616 - val_loss: 0.1188 - val_acc: 0.8961\n",
            "Epoch 1517/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1876 - acc: 0.8616 - val_loss: 0.1190 - val_acc: 0.8971\n",
            "Epoch 1518/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1323 - acc: 0.8837 - val_loss: 0.1175 - val_acc: 0.8980\n",
            "Epoch 1519/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8862 - val_loss: 0.1162 - val_acc: 0.8985\n",
            "Epoch 1520/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1317 - acc: 0.8841 - val_loss: 0.1163 - val_acc: 0.8986\n",
            "Epoch 1521/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8876 - val_loss: 0.1167 - val_acc: 0.8987\n",
            "Epoch 1522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8956 - val_loss: 0.1164 - val_acc: 0.8987\n",
            "Epoch 1523/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1394 - acc: 0.8765 - val_loss: 0.1149 - val_acc: 0.8986\n",
            "Epoch 1524/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1338 - acc: 0.8803 - val_loss: 0.1134 - val_acc: 0.8984\n",
            "Epoch 1525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8801 - val_loss: 0.1130 - val_acc: 0.8981\n",
            "Epoch 1526/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.9006 - val_loss: 0.1133 - val_acc: 0.8977\n",
            "Epoch 1527/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1308 - acc: 0.8764 - val_loss: 0.1135 - val_acc: 0.8973\n",
            "Epoch 1528/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8871 - val_loss: 0.1133 - val_acc: 0.8970\n",
            "Epoch 1529/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8861 - val_loss: 0.1125 - val_acc: 0.8970\n",
            "Epoch 1530/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8839 - val_loss: 0.1112 - val_acc: 0.8972\n",
            "Epoch 1531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8840 - val_loss: 0.1099 - val_acc: 0.8974\n",
            "Epoch 1532/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8832 - val_loss: 0.1090 - val_acc: 0.8977\n",
            "Epoch 1533/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8930 - val_loss: 0.1086 - val_acc: 0.8979\n",
            "Epoch 1534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8875 - val_loss: 0.1083 - val_acc: 0.8980\n",
            "Epoch 1535/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8786 - val_loss: 0.1077 - val_acc: 0.8979\n",
            "Epoch 1536/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8766 - val_loss: 0.1069 - val_acc: 0.8977\n",
            "Epoch 1537/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8771 - val_loss: 0.1063 - val_acc: 0.8974\n",
            "Epoch 1538/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8820 - val_loss: 0.1062 - val_acc: 0.8969\n",
            "Epoch 1539/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8865 - val_loss: 0.1062 - val_acc: 0.8964\n",
            "Epoch 1540/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1762 - acc: 0.8671 - val_loss: 0.1070 - val_acc: 0.8957\n",
            "Epoch 1541/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8717 - val_loss: 0.1074 - val_acc: 0.8953\n",
            "Epoch 1542/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8851 - val_loss: 0.1068 - val_acc: 0.8954\n",
            "Epoch 1543/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2239 - acc: 0.8660 - val_loss: 0.1079 - val_acc: 0.8951\n",
            "Epoch 1544/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8833 - val_loss: 0.1080 - val_acc: 0.8951\n",
            "Epoch 1545/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8905 - val_loss: 0.1071 - val_acc: 0.8957\n",
            "Epoch 1546/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8861 - val_loss: 0.1064 - val_acc: 0.8964\n",
            "Epoch 1547/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8812 - val_loss: 0.1060 - val_acc: 0.8968\n",
            "Epoch 1548/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8883 - val_loss: 0.1057 - val_acc: 0.8971\n",
            "Epoch 1549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8905 - val_loss: 0.1056 - val_acc: 0.8971\n",
            "Epoch 1550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8906 - val_loss: 0.1054 - val_acc: 0.8969\n",
            "Epoch 1551/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8863 - val_loss: 0.1053 - val_acc: 0.8966\n",
            "Epoch 1552/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8811 - val_loss: 0.1052 - val_acc: 0.8962\n",
            "Epoch 1553/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8781 - val_loss: 0.1052 - val_acc: 0.8957\n",
            "Epoch 1554/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8904 - val_loss: 0.1052 - val_acc: 0.8954\n",
            "Epoch 1555/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1458 - acc: 0.8775 - val_loss: 0.1053 - val_acc: 0.8952\n",
            "Epoch 1556/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1446 - acc: 0.8860 - val_loss: 0.1058 - val_acc: 0.8949\n",
            "Epoch 1557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8771 - val_loss: 0.1059 - val_acc: 0.8949\n",
            "Epoch 1558/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1363 - acc: 0.8732 - val_loss: 0.1058 - val_acc: 0.8951\n",
            "Epoch 1559/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8744 - val_loss: 0.1055 - val_acc: 0.8955\n",
            "Epoch 1560/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8867 - val_loss: 0.1050 - val_acc: 0.8960\n",
            "Epoch 1561/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8874 - val_loss: 0.1049 - val_acc: 0.8965\n",
            "Epoch 1562/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8899 - val_loss: 0.1051 - val_acc: 0.8968\n",
            "Epoch 1563/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8892 - val_loss: 0.1050 - val_acc: 0.8967\n",
            "Epoch 1564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8974 - val_loss: 0.1047 - val_acc: 0.8965\n",
            "Epoch 1565/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8871 - val_loss: 0.1043 - val_acc: 0.8960\n",
            "Epoch 1566/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8867 - val_loss: 0.1042 - val_acc: 0.8955\n",
            "Epoch 1567/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2331 - acc: 0.8722 - val_loss: 0.1059 - val_acc: 0.8942\n",
            "Epoch 1568/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8891 - val_loss: 0.1077 - val_acc: 0.8934\n",
            "Epoch 1569/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8789 - val_loss: 0.1077 - val_acc: 0.8938\n",
            "Epoch 1570/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8775 - val_loss: 0.1063 - val_acc: 0.8950\n",
            "Epoch 1571/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8857 - val_loss: 0.1052 - val_acc: 0.8962\n",
            "Epoch 1572/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8854 - val_loss: 0.1054 - val_acc: 0.8970\n",
            "Epoch 1573/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2321 - acc: 0.8747 - val_loss: 0.1055 - val_acc: 0.8970\n",
            "Epoch 1574/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2574 - acc: 0.8671 - val_loss: 0.1071 - val_acc: 0.8963\n",
            "Epoch 1575/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8881 - val_loss: 0.1104 - val_acc: 0.8957\n",
            "Epoch 1576/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8874 - val_loss: 0.1126 - val_acc: 0.8956\n",
            "Epoch 1577/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8814 - val_loss: 0.1126 - val_acc: 0.8960\n",
            "Epoch 1578/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1426 - acc: 0.8826 - val_loss: 0.1113 - val_acc: 0.8969\n",
            "Epoch 1579/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8888 - val_loss: 0.1100 - val_acc: 0.8976\n",
            "Epoch 1580/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8779 - val_loss: 0.1099 - val_acc: 0.8981\n",
            "Epoch 1581/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2416 - acc: 0.8694 - val_loss: 0.1109 - val_acc: 0.8983\n",
            "Epoch 1582/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1322 - acc: 0.8802 - val_loss: 0.1115 - val_acc: 0.8983\n",
            "Epoch 1583/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8906 - val_loss: 0.1118 - val_acc: 0.8982\n",
            "Epoch 1584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8904 - val_loss: 0.1118 - val_acc: 0.8980\n",
            "Epoch 1585/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1245 - acc: 0.8849 - val_loss: 0.1116 - val_acc: 0.8978\n",
            "Epoch 1586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8896 - val_loss: 0.1113 - val_acc: 0.8976\n",
            "Epoch 1587/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8895 - val_loss: 0.1107 - val_acc: 0.8974\n",
            "Epoch 1588/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8836 - val_loss: 0.1100 - val_acc: 0.8973\n",
            "Epoch 1589/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8949 - val_loss: 0.1091 - val_acc: 0.8973\n",
            "Epoch 1590/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8895 - val_loss: 0.1084 - val_acc: 0.8974\n",
            "Epoch 1591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2079 - acc: 0.8733 - val_loss: 0.1083 - val_acc: 0.8973\n",
            "Epoch 1592/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1251 - acc: 0.8808 - val_loss: 0.1083 - val_acc: 0.8971\n",
            "Epoch 1593/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8941 - val_loss: 0.1082 - val_acc: 0.8971\n",
            "Epoch 1594/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8878 - val_loss: 0.1079 - val_acc: 0.8972\n",
            "Epoch 1595/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8980 - val_loss: 0.1074 - val_acc: 0.8973\n",
            "Epoch 1596/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8937 - val_loss: 0.1069 - val_acc: 0.8974\n",
            "Epoch 1597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8896 - val_loss: 0.1064 - val_acc: 0.8974\n",
            "Epoch 1598/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1875 - acc: 0.8774 - val_loss: 0.1064 - val_acc: 0.8969\n",
            "Epoch 1599/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1688 - acc: 0.8767 - val_loss: 0.1074 - val_acc: 0.8964\n",
            "Epoch 1600/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1248 - acc: 0.8836 - val_loss: 0.1083 - val_acc: 0.8961\n",
            "Epoch 1601/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2349 - acc: 0.8644 - val_loss: 0.1108 - val_acc: 0.8955\n",
            "Epoch 1602/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8801 - val_loss: 0.1119 - val_acc: 0.8955\n",
            "Epoch 1603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8745 - val_loss: 0.1109 - val_acc: 0.8961\n",
            "Epoch 1604/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8890 - val_loss: 0.1089 - val_acc: 0.8969\n",
            "Epoch 1605/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8855 - val_loss: 0.1077 - val_acc: 0.8977\n",
            "Epoch 1606/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8858 - val_loss: 0.1079 - val_acc: 0.8980\n",
            "Epoch 1607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8848 - val_loss: 0.1084 - val_acc: 0.8982\n",
            "Epoch 1608/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8848 - val_loss: 0.1081 - val_acc: 0.8981\n",
            "Epoch 1609/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8890 - val_loss: 0.1072 - val_acc: 0.8977\n",
            "Epoch 1610/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8888 - val_loss: 0.1065 - val_acc: 0.8972\n",
            "Epoch 1611/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8871 - val_loss: 0.1064 - val_acc: 0.8965\n",
            "Epoch 1612/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2050 - acc: 0.8753 - val_loss: 0.1080 - val_acc: 0.8955\n",
            "Epoch 1613/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8873 - val_loss: 0.1094 - val_acc: 0.8949\n",
            "Epoch 1614/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - acc: 0.8707 - val_loss: 0.1097 - val_acc: 0.8948\n",
            "Epoch 1615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8872 - val_loss: 0.1086 - val_acc: 0.8954\n",
            "Epoch 1616/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8885 - val_loss: 0.1070 - val_acc: 0.8962\n",
            "Epoch 1617/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8916 - val_loss: 0.1062 - val_acc: 0.8970\n",
            "Epoch 1618/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8817 - val_loss: 0.1065 - val_acc: 0.8975\n",
            "Epoch 1619/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8880 - val_loss: 0.1067 - val_acc: 0.8976\n",
            "Epoch 1620/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8832 - val_loss: 0.1061 - val_acc: 0.8974\n",
            "Epoch 1621/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1500 - acc: 0.8798 - val_loss: 0.1052 - val_acc: 0.8969\n",
            "Epoch 1622/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8835 - val_loss: 0.1051 - val_acc: 0.8961\n",
            "Epoch 1623/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8833 - val_loss: 0.1056 - val_acc: 0.8953\n",
            "Epoch 1624/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1308 - acc: 0.8871 - val_loss: 0.1063 - val_acc: 0.8947\n",
            "Epoch 1625/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8862 - val_loss: 0.1061 - val_acc: 0.8947\n",
            "Epoch 1626/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1514 - acc: 0.8774 - val_loss: 0.1058 - val_acc: 0.8949\n",
            "Epoch 1627/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8834 - val_loss: 0.1051 - val_acc: 0.8955\n",
            "Epoch 1628/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8806 - val_loss: 0.1046 - val_acc: 0.8961\n",
            "Epoch 1629/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8852 - val_loss: 0.1046 - val_acc: 0.8965\n",
            "Epoch 1630/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8856 - val_loss: 0.1044 - val_acc: 0.8966\n",
            "Epoch 1631/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8830 - val_loss: 0.1039 - val_acc: 0.8963\n",
            "Epoch 1632/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8901 - val_loss: 0.1037 - val_acc: 0.8958\n",
            "Epoch 1633/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8897 - val_loss: 0.1038 - val_acc: 0.8953\n",
            "Epoch 1634/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8858 - val_loss: 0.1040 - val_acc: 0.8947\n",
            "Epoch 1635/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8909 - val_loss: 0.1040 - val_acc: 0.8945\n",
            "Epoch 1636/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8899 - val_loss: 0.1036 - val_acc: 0.8946\n",
            "Epoch 1637/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8849 - val_loss: 0.1032 - val_acc: 0.8950\n",
            "Epoch 1638/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8851 - val_loss: 0.1031 - val_acc: 0.8953\n",
            "Epoch 1639/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2153 - acc: 0.8788 - val_loss: 0.1032 - val_acc: 0.8950\n",
            "Epoch 1640/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8888 - val_loss: 0.1036 - val_acc: 0.8948\n",
            "Epoch 1641/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8820 - val_loss: 0.1038 - val_acc: 0.8947\n",
            "Epoch 1642/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8777 - val_loss: 0.1037 - val_acc: 0.8949\n",
            "Epoch 1643/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8775 - val_loss: 0.1035 - val_acc: 0.8953\n",
            "Epoch 1644/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8777 - val_loss: 0.1034 - val_acc: 0.8957\n",
            "Epoch 1645/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8954 - val_loss: 0.1035 - val_acc: 0.8961\n",
            "Epoch 1646/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1514 - acc: 0.8788 - val_loss: 0.1035 - val_acc: 0.8961\n",
            "Epoch 1647/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8852 - val_loss: 0.1035 - val_acc: 0.8959\n",
            "Epoch 1648/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8819 - val_loss: 0.1035 - val_acc: 0.8956\n",
            "Epoch 1649/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8896 - val_loss: 0.1037 - val_acc: 0.8952\n",
            "Epoch 1650/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1491 - acc: 0.8803 - val_loss: 0.1041 - val_acc: 0.8949\n",
            "Epoch 1651/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8845 - val_loss: 0.1041 - val_acc: 0.8949\n",
            "Epoch 1652/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8842 - val_loss: 0.1038 - val_acc: 0.8953\n",
            "Epoch 1653/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8833 - val_loss: 0.1036 - val_acc: 0.8957\n",
            "Epoch 1654/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8901 - val_loss: 0.1035 - val_acc: 0.8961\n",
            "Epoch 1655/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1937 - acc: 0.8772 - val_loss: 0.1038 - val_acc: 0.8961\n",
            "Epoch 1656/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2470 - acc: 0.8655 - val_loss: 0.1061 - val_acc: 0.8953\n",
            "Epoch 1657/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8834 - val_loss: 0.1085 - val_acc: 0.8950\n",
            "Epoch 1658/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1487 - acc: 0.8743 - val_loss: 0.1098 - val_acc: 0.8954\n",
            "Epoch 1659/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2090 - acc: 0.8640 - val_loss: 0.1121 - val_acc: 0.8958\n",
            "Epoch 1660/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8925 - val_loss: 0.1124 - val_acc: 0.8967\n",
            "Epoch 1661/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8932 - val_loss: 0.1116 - val_acc: 0.8975\n",
            "Epoch 1662/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1336 - acc: 0.8715 - val_loss: 0.1109 - val_acc: 0.8981\n",
            "Epoch 1663/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8856 - val_loss: 0.1111 - val_acc: 0.8984\n",
            "Epoch 1664/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1464 - acc: 0.8895 - val_loss: 0.1115 - val_acc: 0.8985\n",
            "Epoch 1665/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1607 - acc: 0.8919 - val_loss: 0.1116 - val_acc: 0.8985\n",
            "Epoch 1666/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8899 - val_loss: 0.1111 - val_acc: 0.8984\n",
            "Epoch 1667/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8923 - val_loss: 0.1108 - val_acc: 0.8981\n",
            "Epoch 1668/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8887 - val_loss: 0.1108 - val_acc: 0.8977\n",
            "Epoch 1669/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8885 - val_loss: 0.1109 - val_acc: 0.8974\n",
            "Epoch 1670/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8962 - val_loss: 0.1106 - val_acc: 0.8971\n",
            "Epoch 1671/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8961 - val_loss: 0.1099 - val_acc: 0.8971\n",
            "Epoch 1672/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8866 - val_loss: 0.1091 - val_acc: 0.8971\n",
            "Epoch 1673/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8857 - val_loss: 0.1082 - val_acc: 0.8973\n",
            "Epoch 1674/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1222 - acc: 0.8859 - val_loss: 0.1075 - val_acc: 0.8974\n",
            "Epoch 1675/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.9013 - val_loss: 0.1071 - val_acc: 0.8975\n",
            "Epoch 1676/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8880 - val_loss: 0.1066 - val_acc: 0.8975\n",
            "Epoch 1677/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8782 - val_loss: 0.1061 - val_acc: 0.8975\n",
            "Epoch 1678/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2150 - acc: 0.8792 - val_loss: 0.1064 - val_acc: 0.8971\n",
            "Epoch 1679/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8902 - val_loss: 0.1072 - val_acc: 0.8968\n",
            "Epoch 1680/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8900 - val_loss: 0.1076 - val_acc: 0.8966\n",
            "Epoch 1681/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8868 - val_loss: 0.1072 - val_acc: 0.8967\n",
            "Epoch 1682/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8870 - val_loss: 0.1063 - val_acc: 0.8970\n",
            "Epoch 1683/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8882 - val_loss: 0.1055 - val_acc: 0.8973\n",
            "Epoch 1684/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8863 - val_loss: 0.1052 - val_acc: 0.8973\n",
            "Epoch 1685/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8957 - val_loss: 0.1051 - val_acc: 0.8973\n",
            "Epoch 1686/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8927 - val_loss: 0.1048 - val_acc: 0.8971\n",
            "Epoch 1687/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1169 - acc: 0.8865 - val_loss: 0.1044 - val_acc: 0.8968\n",
            "Epoch 1688/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8842 - val_loss: 0.1040 - val_acc: 0.8963\n",
            "Epoch 1689/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2563 - acc: 0.8639 - val_loss: 0.1054 - val_acc: 0.8951\n",
            "Epoch 1690/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8794 - val_loss: 0.1074 - val_acc: 0.8943\n",
            "Epoch 1691/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8795 - val_loss: 0.1079 - val_acc: 0.8943\n",
            "Epoch 1692/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1640 - acc: 0.8745 - val_loss: 0.1078 - val_acc: 0.8948\n",
            "Epoch 1693/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8827 - val_loss: 0.1065 - val_acc: 0.8958\n",
            "Epoch 1694/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8745 - val_loss: 0.1056 - val_acc: 0.8968\n",
            "Epoch 1695/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8950 - val_loss: 0.1059 - val_acc: 0.8975\n",
            "Epoch 1696/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8880 - val_loss: 0.1064 - val_acc: 0.8977\n",
            "Epoch 1697/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2483 - acc: 0.8743 - val_loss: 0.1060 - val_acc: 0.8974\n",
            "Epoch 1698/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8804 - val_loss: 0.1067 - val_acc: 0.8968\n",
            "Epoch 1699/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8798 - val_loss: 0.1079 - val_acc: 0.8962\n",
            "Epoch 1700/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8875 - val_loss: 0.1085 - val_acc: 0.8959\n",
            "Epoch 1701/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8890 - val_loss: 0.1080 - val_acc: 0.8960\n",
            "Epoch 1702/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1537 - acc: 0.8824 - val_loss: 0.1076 - val_acc: 0.8962\n",
            "Epoch 1703/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2276 - acc: 0.8664 - val_loss: 0.1089 - val_acc: 0.8963\n",
            "Epoch 1704/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8839 - val_loss: 0.1095 - val_acc: 0.8965\n",
            "Epoch 1705/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8782 - val_loss: 0.1096 - val_acc: 0.8969\n",
            "Epoch 1706/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8727 - val_loss: 0.1094 - val_acc: 0.8973\n",
            "Epoch 1707/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8731 - val_loss: 0.1091 - val_acc: 0.8976\n",
            "Epoch 1708/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8855 - val_loss: 0.1086 - val_acc: 0.8977\n",
            "Epoch 1709/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1257 - acc: 0.8781 - val_loss: 0.1081 - val_acc: 0.8977\n",
            "Epoch 1710/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8941 - val_loss: 0.1076 - val_acc: 0.8975\n",
            "Epoch 1711/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2202 - acc: 0.8762 - val_loss: 0.1082 - val_acc: 0.8972\n",
            "Epoch 1712/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8869 - val_loss: 0.1090 - val_acc: 0.8968\n",
            "Epoch 1713/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8896 - val_loss: 0.1092 - val_acc: 0.8967\n",
            "Epoch 1714/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8853 - val_loss: 0.1086 - val_acc: 0.8968\n",
            "Epoch 1715/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8845 - val_loss: 0.1076 - val_acc: 0.8971\n",
            "Epoch 1716/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1642 - acc: 0.8736 - val_loss: 0.1071 - val_acc: 0.8975\n",
            "Epoch 1717/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8819 - val_loss: 0.1069 - val_acc: 0.8977\n",
            "Epoch 1718/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8821 - val_loss: 0.1065 - val_acc: 0.8976\n",
            "Epoch 1719/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8876 - val_loss: 0.1060 - val_acc: 0.8974\n",
            "Epoch 1720/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8881 - val_loss: 0.1055 - val_acc: 0.8971\n",
            "Epoch 1721/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8940 - val_loss: 0.1051 - val_acc: 0.8966\n",
            "Epoch 1722/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8858 - val_loss: 0.1048 - val_acc: 0.8962\n",
            "Epoch 1723/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1460 - acc: 0.8863 - val_loss: 0.1049 - val_acc: 0.8957\n",
            "Epoch 1724/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8927 - val_loss: 0.1047 - val_acc: 0.8956\n",
            "Epoch 1725/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8934 - val_loss: 0.1043 - val_acc: 0.8957\n",
            "Epoch 1726/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8755 - val_loss: 0.1038 - val_acc: 0.8960\n",
            "Epoch 1727/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8856 - val_loss: 0.1035 - val_acc: 0.8962\n",
            "Epoch 1728/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8859 - val_loss: 0.1034 - val_acc: 0.8964\n",
            "Epoch 1729/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8852 - val_loss: 0.1032 - val_acc: 0.8964\n",
            "Epoch 1730/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8828 - val_loss: 0.1029 - val_acc: 0.8961\n",
            "Epoch 1731/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8849 - val_loss: 0.1027 - val_acc: 0.8957\n",
            "Epoch 1732/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8968 - val_loss: 0.1027 - val_acc: 0.8951\n",
            "Epoch 1733/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8962 - val_loss: 0.1027 - val_acc: 0.8948\n",
            "Epoch 1734/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8846 - val_loss: 0.1025 - val_acc: 0.8948\n",
            "Epoch 1735/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8864 - val_loss: 0.1023 - val_acc: 0.8950\n",
            "Epoch 1736/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8879 - val_loss: 0.1022 - val_acc: 0.8953\n",
            "Epoch 1737/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8811 - val_loss: 0.1022 - val_acc: 0.8955\n",
            "Epoch 1738/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8875 - val_loss: 0.1022 - val_acc: 0.8953\n",
            "Epoch 1739/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1283 - acc: 0.8770 - val_loss: 0.1021 - val_acc: 0.8948\n",
            "Epoch 1740/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8873 - val_loss: 0.1022 - val_acc: 0.8942\n",
            "Epoch 1741/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8788 - val_loss: 0.1022 - val_acc: 0.8939\n",
            "Epoch 1742/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8812 - val_loss: 0.1020 - val_acc: 0.8939\n",
            "Epoch 1743/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8875 - val_loss: 0.1018 - val_acc: 0.8944\n",
            "Epoch 1744/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8879 - val_loss: 0.1019 - val_acc: 0.8950\n",
            "Epoch 1745/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8867 - val_loss: 0.1021 - val_acc: 0.8953\n",
            "Epoch 1746/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1320 - acc: 0.8832 - val_loss: 0.1020 - val_acc: 0.8952\n",
            "Epoch 1747/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8944 - val_loss: 0.1018 - val_acc: 0.8948\n",
            "Epoch 1748/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8818 - val_loss: 0.1017 - val_acc: 0.8945\n",
            "Epoch 1749/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8807 - val_loss: 0.1017 - val_acc: 0.8943\n",
            "Epoch 1750/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1204 - acc: 0.8723 - val_loss: 0.1017 - val_acc: 0.8943\n",
            "Epoch 1751/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8736 - val_loss: 0.1018 - val_acc: 0.8944\n",
            "Epoch 1752/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8808 - val_loss: 0.1019 - val_acc: 0.8948\n",
            "Epoch 1753/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8833 - val_loss: 0.1017 - val_acc: 0.8950\n",
            "Epoch 1754/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8870 - val_loss: 0.1014 - val_acc: 0.8951\n",
            "Epoch 1755/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8872 - val_loss: 0.1013 - val_acc: 0.8950\n",
            "Epoch 1756/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8903 - val_loss: 0.1016 - val_acc: 0.8947\n",
            "Epoch 1757/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8832 - val_loss: 0.1018 - val_acc: 0.8946\n",
            "Epoch 1758/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8767 - val_loss: 0.1017 - val_acc: 0.8944\n",
            "Epoch 1759/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8831 - val_loss: 0.1015 - val_acc: 0.8945\n",
            "Epoch 1760/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8844 - val_loss: 0.1012 - val_acc: 0.8949\n",
            "Epoch 1761/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8832 - val_loss: 0.1013 - val_acc: 0.8953\n",
            "Epoch 1762/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8774 - val_loss: 0.1014 - val_acc: 0.8954\n",
            "Epoch 1763/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8837 - val_loss: 0.1013 - val_acc: 0.8952\n",
            "Epoch 1764/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8809 - val_loss: 0.1012 - val_acc: 0.8948\n",
            "Epoch 1765/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8839 - val_loss: 0.1012 - val_acc: 0.8946\n",
            "Epoch 1766/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8823 - val_loss: 0.1011 - val_acc: 0.8946\n",
            "Epoch 1767/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8824 - val_loss: 0.1011 - val_acc: 0.8949\n",
            "Epoch 1768/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8887 - val_loss: 0.1012 - val_acc: 0.8951\n",
            "Epoch 1769/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2976 - acc: 0.8626 - val_loss: 0.1025 - val_acc: 0.8940\n",
            "Epoch 1770/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8874 - val_loss: 0.1047 - val_acc: 0.8934\n",
            "Epoch 1771/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8871 - val_loss: 0.1051 - val_acc: 0.8940\n",
            "Epoch 1772/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8749 - val_loss: 0.1038 - val_acc: 0.8954\n",
            "Epoch 1773/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8653 - val_loss: 0.1032 - val_acc: 0.8967\n",
            "Epoch 1774/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8821 - val_loss: 0.1044 - val_acc: 0.8974\n",
            "Epoch 1775/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8889 - val_loss: 0.1048 - val_acc: 0.8975\n",
            "Epoch 1776/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8862 - val_loss: 0.1038 - val_acc: 0.8971\n",
            "Epoch 1777/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8859 - val_loss: 0.1032 - val_acc: 0.8965\n",
            "Epoch 1778/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8868 - val_loss: 0.1036 - val_acc: 0.8956\n",
            "Epoch 1779/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1757 - acc: 0.8713 - val_loss: 0.1059 - val_acc: 0.8942\n",
            "Epoch 1780/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2379 - acc: 0.8611 - val_loss: 0.1114 - val_acc: 0.8924\n",
            "Epoch 1781/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8775 - val_loss: 0.1135 - val_acc: 0.8924\n",
            "Epoch 1782/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8764 - val_loss: 0.1113 - val_acc: 0.8941\n",
            "Epoch 1783/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1928 - acc: 0.8718 - val_loss: 0.1098 - val_acc: 0.8957\n",
            "Epoch 1784/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8883 - val_loss: 0.1079 - val_acc: 0.8972\n",
            "Epoch 1785/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8854 - val_loss: 0.1080 - val_acc: 0.8980\n",
            "Epoch 1786/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8863 - val_loss: 0.1097 - val_acc: 0.8984\n",
            "Epoch 1787/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8934 - val_loss: 0.1107 - val_acc: 0.8985\n",
            "Epoch 1788/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2426 - acc: 0.8766 - val_loss: 0.1100 - val_acc: 0.8984\n",
            "Epoch 1789/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8854 - val_loss: 0.1101 - val_acc: 0.8981\n",
            "Epoch 1790/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8832 - val_loss: 0.1116 - val_acc: 0.8977\n",
            "Epoch 1791/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8840 - val_loss: 0.1130 - val_acc: 0.8973\n",
            "Epoch 1792/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8828 - val_loss: 0.1133 - val_acc: 0.8971\n",
            "Epoch 1793/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8827 - val_loss: 0.1120 - val_acc: 0.8972\n",
            "Epoch 1794/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8820 - val_loss: 0.1100 - val_acc: 0.8974\n",
            "Epoch 1795/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1246 - acc: 0.8823 - val_loss: 0.1084 - val_acc: 0.8977\n",
            "Epoch 1796/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8910 - val_loss: 0.1077 - val_acc: 0.8979\n",
            "Epoch 1797/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8850 - val_loss: 0.1074 - val_acc: 0.8980\n",
            "Epoch 1798/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8888 - val_loss: 0.1068 - val_acc: 0.8979\n",
            "Epoch 1799/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1709 - acc: 0.8828 - val_loss: 0.1059 - val_acc: 0.8976\n",
            "Epoch 1800/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1221 - acc: 0.8810 - val_loss: 0.1056 - val_acc: 0.8970\n",
            "Epoch 1801/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1359 - acc: 0.8769 - val_loss: 0.1063 - val_acc: 0.8962\n",
            "Epoch 1802/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8924 - val_loss: 0.1070 - val_acc: 0.8956\n",
            "Epoch 1803/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8829 - val_loss: 0.1066 - val_acc: 0.8954\n",
            "Epoch 1804/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8827 - val_loss: 0.1052 - val_acc: 0.8959\n",
            "Epoch 1805/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8895 - val_loss: 0.1040 - val_acc: 0.8965\n",
            "Epoch 1806/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8888 - val_loss: 0.1036 - val_acc: 0.8970\n",
            "Epoch 1807/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8988 - val_loss: 0.1039 - val_acc: 0.8973\n",
            "Epoch 1808/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8898 - val_loss: 0.1037 - val_acc: 0.8972\n",
            "Epoch 1809/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8939 - val_loss: 0.1029 - val_acc: 0.8968\n",
            "Epoch 1810/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8936 - val_loss: 0.1023 - val_acc: 0.8961\n",
            "Epoch 1811/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8825 - val_loss: 0.1023 - val_acc: 0.8951\n",
            "Epoch 1812/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1990 - acc: 0.8702 - val_loss: 0.1041 - val_acc: 0.8935\n",
            "Epoch 1813/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8878 - val_loss: 0.1054 - val_acc: 0.8927\n",
            "Epoch 1814/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8706 - val_loss: 0.1049 - val_acc: 0.8930\n",
            "Epoch 1815/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8770 - val_loss: 0.1034 - val_acc: 0.8942\n",
            "Epoch 1816/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8832 - val_loss: 0.1023 - val_acc: 0.8956\n",
            "Epoch 1817/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8808 - val_loss: 0.1028 - val_acc: 0.8965\n",
            "Epoch 1818/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8846 - val_loss: 0.1032 - val_acc: 0.8967\n",
            "Epoch 1819/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3461 - acc: 0.8543 - val_loss: 0.1031 - val_acc: 0.8956\n",
            "Epoch 1820/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1262 - acc: 0.8714 - val_loss: 0.1065 - val_acc: 0.8942\n",
            "Epoch 1821/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8894 - val_loss: 0.1094 - val_acc: 0.8936\n",
            "Epoch 1822/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8912 - val_loss: 0.1095 - val_acc: 0.8942\n",
            "Epoch 1823/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8847 - val_loss: 0.1076 - val_acc: 0.8956\n",
            "Epoch 1824/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2319 - acc: 0.8665 - val_loss: 0.1082 - val_acc: 0.8964\n",
            "Epoch 1825/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1307 - acc: 0.8887 - val_loss: 0.1086 - val_acc: 0.8971\n",
            "Epoch 1826/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8886 - val_loss: 0.1088 - val_acc: 0.8976\n",
            "Epoch 1827/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1316 - acc: 0.8838 - val_loss: 0.1089 - val_acc: 0.8978\n",
            "Epoch 1828/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1260 - acc: 0.8774 - val_loss: 0.1086 - val_acc: 0.8979\n",
            "Epoch 1829/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1302 - acc: 0.8778 - val_loss: 0.1081 - val_acc: 0.8979\n",
            "Epoch 1830/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8942 - val_loss: 0.1076 - val_acc: 0.8977\n",
            "Epoch 1831/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8845 - val_loss: 0.1072 - val_acc: 0.8975\n",
            "Epoch 1832/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8839 - val_loss: 0.1068 - val_acc: 0.8972\n",
            "Epoch 1833/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8836 - val_loss: 0.1065 - val_acc: 0.8971\n",
            "Epoch 1834/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2045 - acc: 0.8743 - val_loss: 0.1069 - val_acc: 0.8968\n",
            "Epoch 1835/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8824 - val_loss: 0.1071 - val_acc: 0.8966\n",
            "Epoch 1836/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1766 - acc: 0.8738 - val_loss: 0.1080 - val_acc: 0.8964\n",
            "Epoch 1837/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8815 - val_loss: 0.1083 - val_acc: 0.8965\n",
            "Epoch 1838/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8849 - val_loss: 0.1079 - val_acc: 0.8967\n",
            "Epoch 1839/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8836 - val_loss: 0.1071 - val_acc: 0.8971\n",
            "Epoch 1840/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8909 - val_loss: 0.1063 - val_acc: 0.8975\n",
            "Epoch 1841/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8796 - val_loss: 0.1058 - val_acc: 0.8977\n",
            "Epoch 1842/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1177 - acc: 0.8832 - val_loss: 0.1054 - val_acc: 0.8978\n",
            "Epoch 1843/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8904 - val_loss: 0.1049 - val_acc: 0.8977\n",
            "Epoch 1844/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8911 - val_loss: 0.1043 - val_acc: 0.8975\n",
            "Epoch 1845/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8931 - val_loss: 0.1038 - val_acc: 0.8971\n",
            "Epoch 1846/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8791 - val_loss: 0.1036 - val_acc: 0.8966\n",
            "Epoch 1847/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8877 - val_loss: 0.1034 - val_acc: 0.8961\n",
            "Epoch 1848/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8883 - val_loss: 0.1032 - val_acc: 0.8957\n",
            "Epoch 1849/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8791 - val_loss: 0.1028 - val_acc: 0.8956\n",
            "Epoch 1850/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8791 - val_loss: 0.1024 - val_acc: 0.8955\n",
            "Epoch 1851/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8885 - val_loss: 0.1021 - val_acc: 0.8956\n",
            "Epoch 1852/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8886 - val_loss: 0.1019 - val_acc: 0.8956\n",
            "Epoch 1853/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8847 - val_loss: 0.1017 - val_acc: 0.8957\n",
            "Epoch 1854/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8842 - val_loss: 0.1016 - val_acc: 0.8956\n",
            "Epoch 1855/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8820 - val_loss: 0.1014 - val_acc: 0.8953\n",
            "Epoch 1856/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8795 - val_loss: 0.1013 - val_acc: 0.8949\n",
            "Epoch 1857/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8885 - val_loss: 0.1013 - val_acc: 0.8946\n",
            "Epoch 1858/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8820 - val_loss: 0.1014 - val_acc: 0.8943\n",
            "Epoch 1859/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8895 - val_loss: 0.1013 - val_acc: 0.8942\n",
            "Epoch 1860/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8893 - val_loss: 0.1012 - val_acc: 0.8943\n",
            "Epoch 1861/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2183 - acc: 0.8607 - val_loss: 0.1018 - val_acc: 0.8938\n",
            "Epoch 1862/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8850 - val_loss: 0.1019 - val_acc: 0.8940\n",
            "Epoch 1863/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8782 - val_loss: 0.1016 - val_acc: 0.8947\n",
            "Epoch 1864/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8774 - val_loss: 0.1013 - val_acc: 0.8954\n",
            "Epoch 1865/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8782 - val_loss: 0.1013 - val_acc: 0.8958\n",
            "Epoch 1866/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8844 - val_loss: 0.1014 - val_acc: 0.8959\n",
            "Epoch 1867/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8865 - val_loss: 0.1013 - val_acc: 0.8956\n",
            "Epoch 1868/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8862 - val_loss: 0.1013 - val_acc: 0.8950\n",
            "Epoch 1869/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8810 - val_loss: 0.1013 - val_acc: 0.8947\n",
            "Epoch 1870/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1667 - acc: 0.8786 - val_loss: 0.1020 - val_acc: 0.8941\n",
            "Epoch 1871/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8820 - val_loss: 0.1030 - val_acc: 0.8938\n",
            "Epoch 1872/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1658 - acc: 0.8753 - val_loss: 0.1044 - val_acc: 0.8935\n",
            "Epoch 1873/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1945 - acc: 0.8720 - val_loss: 0.1065 - val_acc: 0.8935\n",
            "Epoch 1874/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8892 - val_loss: 0.1062 - val_acc: 0.8947\n",
            "Epoch 1875/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8863 - val_loss: 0.1050 - val_acc: 0.8963\n",
            "Epoch 1876/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1792 - acc: 0.8707 - val_loss: 0.1053 - val_acc: 0.8971\n",
            "Epoch 1877/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8872 - val_loss: 0.1058 - val_acc: 0.8977\n",
            "Epoch 1878/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8840 - val_loss: 0.1063 - val_acc: 0.8979\n",
            "Epoch 1879/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1838 - acc: 0.8781 - val_loss: 0.1070 - val_acc: 0.8979\n",
            "Epoch 1880/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8873 - val_loss: 0.1075 - val_acc: 0.8979\n",
            "Epoch 1881/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8841 - val_loss: 0.1080 - val_acc: 0.8977\n",
            "Epoch 1882/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8854 - val_loss: 0.1083 - val_acc: 0.8976\n",
            "Epoch 1883/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1309 - acc: 0.8717 - val_loss: 0.1084 - val_acc: 0.8974\n",
            "Epoch 1884/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8910 - val_loss: 0.1079 - val_acc: 0.8974\n",
            "Epoch 1885/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8910 - val_loss: 0.1072 - val_acc: 0.8975\n",
            "Epoch 1886/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8791 - val_loss: 0.1065 - val_acc: 0.8976\n",
            "Epoch 1887/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8887 - val_loss: 0.1059 - val_acc: 0.8976\n",
            "Epoch 1888/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8937 - val_loss: 0.1056 - val_acc: 0.8976\n",
            "Epoch 1889/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8955 - val_loss: 0.1053 - val_acc: 0.8975\n",
            "Epoch 1890/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8970 - val_loss: 0.1049 - val_acc: 0.8975\n",
            "Epoch 1891/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8970 - val_loss: 0.1046 - val_acc: 0.8973\n",
            "Epoch 1892/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8910 - val_loss: 0.1041 - val_acc: 0.8971\n",
            "Epoch 1893/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8886 - val_loss: 0.1037 - val_acc: 0.8969\n",
            "Epoch 1894/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8957 - val_loss: 0.1034 - val_acc: 0.8966\n",
            "Epoch 1895/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8956 - val_loss: 0.1030 - val_acc: 0.8964\n",
            "Epoch 1896/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8817 - val_loss: 0.1025 - val_acc: 0.8962\n",
            "Epoch 1897/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1468 - acc: 0.8785 - val_loss: 0.1024 - val_acc: 0.8960\n",
            "Epoch 1898/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8909 - val_loss: 0.1023 - val_acc: 0.8960\n",
            "Epoch 1899/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2315 - acc: 0.8685 - val_loss: 0.1039 - val_acc: 0.8951\n",
            "Epoch 1900/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8806 - val_loss: 0.1053 - val_acc: 0.8947\n",
            "Epoch 1901/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1671 - acc: 0.8778 - val_loss: 0.1068 - val_acc: 0.8945\n",
            "Epoch 1902/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8854 - val_loss: 0.1063 - val_acc: 0.8952\n",
            "Epoch 1903/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8810 - val_loss: 0.1049 - val_acc: 0.8963\n",
            "Epoch 1904/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8858 - val_loss: 0.1042 - val_acc: 0.8972\n",
            "Epoch 1905/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1683 - acc: 0.8831 - val_loss: 0.1044 - val_acc: 0.8976\n",
            "Epoch 1906/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8902 - val_loss: 0.1043 - val_acc: 0.8977\n",
            "Epoch 1907/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8963 - val_loss: 0.1039 - val_acc: 0.8975\n",
            "Epoch 1908/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2190 - acc: 0.8794 - val_loss: 0.1043 - val_acc: 0.8973\n",
            "Epoch 1909/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8733 - val_loss: 0.1052 - val_acc: 0.8969\n",
            "Epoch 1910/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8832 - val_loss: 0.1059 - val_acc: 0.8966\n",
            "Epoch 1911/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1395 - acc: 0.8773 - val_loss: 0.1065 - val_acc: 0.8964\n",
            "Epoch 1912/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8912 - val_loss: 0.1064 - val_acc: 0.8965\n",
            "Epoch 1913/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8902 - val_loss: 0.1058 - val_acc: 0.8968\n",
            "Epoch 1914/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8907 - val_loss: 0.1053 - val_acc: 0.8972\n",
            "Epoch 1915/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8953 - val_loss: 0.1051 - val_acc: 0.8975\n",
            "Epoch 1916/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8986 - val_loss: 0.1052 - val_acc: 0.8976\n",
            "Epoch 1917/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8847 - val_loss: 0.1049 - val_acc: 0.8976\n",
            "Epoch 1918/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1540 - acc: 0.8869 - val_loss: 0.1044 - val_acc: 0.8974\n",
            "Epoch 1919/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8889 - val_loss: 0.1041 - val_acc: 0.8969\n",
            "Epoch 1920/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8807 - val_loss: 0.1044 - val_acc: 0.8964\n",
            "Epoch 1921/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8768 - val_loss: 0.1047 - val_acc: 0.8960\n",
            "Epoch 1922/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8833 - val_loss: 0.1046 - val_acc: 0.8958\n",
            "Epoch 1923/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8847 - val_loss: 0.1039 - val_acc: 0.8960\n",
            "Epoch 1924/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8977 - val_loss: 0.1030 - val_acc: 0.8965\n",
            "Epoch 1925/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8855 - val_loss: 0.1026 - val_acc: 0.8970\n",
            "Epoch 1926/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8860 - val_loss: 0.1026 - val_acc: 0.8973\n",
            "Epoch 1927/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8752 - val_loss: 0.1025 - val_acc: 0.8973\n",
            "Epoch 1928/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1208 - acc: 0.8751 - val_loss: 0.1020 - val_acc: 0.8970\n",
            "Epoch 1929/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1299 - acc: 0.8800 - val_loss: 0.1017 - val_acc: 0.8965\n",
            "Epoch 1930/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8998 - val_loss: 0.1016 - val_acc: 0.8959\n",
            "Epoch 1931/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8750 - val_loss: 0.1017 - val_acc: 0.8952\n",
            "Epoch 1932/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8847 - val_loss: 0.1015 - val_acc: 0.8949\n",
            "Epoch 1933/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8830 - val_loss: 0.1011 - val_acc: 0.8950\n",
            "Epoch 1934/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8810 - val_loss: 0.1008 - val_acc: 0.8954\n",
            "Epoch 1935/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1346 - acc: 0.8823 - val_loss: 0.1009 - val_acc: 0.8958\n",
            "Epoch 1936/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8817 - val_loss: 0.1010 - val_acc: 0.8960\n",
            "Epoch 1937/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8915 - val_loss: 0.1010 - val_acc: 0.8960\n",
            "Epoch 1938/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8878 - val_loss: 0.1007 - val_acc: 0.8957\n",
            "Epoch 1939/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2738 - acc: 0.8574 - val_loss: 0.1025 - val_acc: 0.8937\n",
            "Epoch 1940/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8747 - val_loss: 0.1055 - val_acc: 0.8922\n",
            "Epoch 1941/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8695 - val_loss: 0.1058 - val_acc: 0.8926\n",
            "Epoch 1942/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8773 - val_loss: 0.1036 - val_acc: 0.8945\n",
            "Epoch 1943/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8796 - val_loss: 0.1023 - val_acc: 0.8964\n",
            "Epoch 1944/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8859 - val_loss: 0.1033 - val_acc: 0.8974\n",
            "Epoch 1945/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8942 - val_loss: 0.1042 - val_acc: 0.8978\n",
            "Epoch 1946/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2538 - acc: 0.8757 - val_loss: 0.1038 - val_acc: 0.8976\n",
            "Epoch 1947/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8859 - val_loss: 0.1045 - val_acc: 0.8969\n",
            "Epoch 1948/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8855 - val_loss: 0.1062 - val_acc: 0.8961\n",
            "Epoch 1949/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8896 - val_loss: 0.1075 - val_acc: 0.8956\n",
            "Epoch 1950/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8892 - val_loss: 0.1073 - val_acc: 0.8957\n",
            "Epoch 1951/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8826 - val_loss: 0.1063 - val_acc: 0.8962\n",
            "Epoch 1952/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8795 - val_loss: 0.1052 - val_acc: 0.8967\n",
            "Epoch 1953/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8908 - val_loss: 0.1048 - val_acc: 0.8972\n",
            "Epoch 1954/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8865 - val_loss: 0.1050 - val_acc: 0.8975\n",
            "Epoch 1955/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8856 - val_loss: 0.1048 - val_acc: 0.8975\n",
            "Epoch 1956/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8841 - val_loss: 0.1041 - val_acc: 0.8973\n",
            "Epoch 1957/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1809 - acc: 0.8797 - val_loss: 0.1039 - val_acc: 0.8969\n",
            "Epoch 1958/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8914 - val_loss: 0.1040 - val_acc: 0.8964\n",
            "Epoch 1959/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8954 - val_loss: 0.1042 - val_acc: 0.8962\n",
            "Epoch 1960/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8909 - val_loss: 0.1041 - val_acc: 0.8961\n",
            "Epoch 1961/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8909 - val_loss: 0.1036 - val_acc: 0.8963\n",
            "Epoch 1962/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8784 - val_loss: 0.1031 - val_acc: 0.8965\n",
            "Epoch 1963/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8761 - val_loss: 0.1027 - val_acc: 0.8966\n",
            "Epoch 1964/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8841 - val_loss: 0.1023 - val_acc: 0.8967\n",
            "Epoch 1965/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8894 - val_loss: 0.1021 - val_acc: 0.8967\n",
            "Epoch 1966/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8894 - val_loss: 0.1020 - val_acc: 0.8967\n",
            "Epoch 1967/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8886 - val_loss: 0.1017 - val_acc: 0.8966\n",
            "Epoch 1968/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8979 - val_loss: 0.1015 - val_acc: 0.8963\n",
            "Epoch 1969/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8873 - val_loss: 0.1012 - val_acc: 0.8961\n",
            "Epoch 1970/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8918 - val_loss: 0.1009 - val_acc: 0.8957\n",
            "Epoch 1971/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8906 - val_loss: 0.1007 - val_acc: 0.8955\n",
            "Epoch 1972/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8906 - val_loss: 0.1006 - val_acc: 0.8953\n",
            "Epoch 1973/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8798 - val_loss: 0.1005 - val_acc: 0.8952\n",
            "Epoch 1974/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8875 - val_loss: 0.1004 - val_acc: 0.8951\n",
            "Epoch 1975/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8874 - val_loss: 0.1004 - val_acc: 0.8951\n",
            "Epoch 1976/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1667 - acc: 0.8764 - val_loss: 0.1006 - val_acc: 0.8944\n",
            "Epoch 1977/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2483 - acc: 0.8607 - val_loss: 0.1033 - val_acc: 0.8925\n",
            "Epoch 1978/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8804 - val_loss: 0.1052 - val_acc: 0.8917\n",
            "Epoch 1979/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8749 - val_loss: 0.1041 - val_acc: 0.8928\n",
            "Epoch 1980/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8848 - val_loss: 0.1019 - val_acc: 0.8949\n",
            "Epoch 1981/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2680 - acc: 0.8533 - val_loss: 0.1026 - val_acc: 0.8959\n",
            "Epoch 1982/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1290 - acc: 0.8838 - val_loss: 0.1037 - val_acc: 0.8967\n",
            "Epoch 1983/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8886 - val_loss: 0.1048 - val_acc: 0.8972\n",
            "Epoch 1984/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8891 - val_loss: 0.1053 - val_acc: 0.8975\n",
            "Epoch 1985/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1367 - acc: 0.8799 - val_loss: 0.1056 - val_acc: 0.8975\n",
            "Epoch 1986/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8847 - val_loss: 0.1057 - val_acc: 0.8974\n",
            "Epoch 1987/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 0.8805 - val_loss: 0.1067 - val_acc: 0.8972\n",
            "Epoch 1988/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2410 - acc: 0.8666 - val_loss: 0.1098 - val_acc: 0.8970\n",
            "Epoch 1989/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8841 - val_loss: 0.1121 - val_acc: 0.8969\n",
            "Epoch 1990/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1188 - acc: 0.8841 - val_loss: 0.1126 - val_acc: 0.8972\n",
            "Epoch 1991/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8889 - val_loss: 0.1118 - val_acc: 0.8977\n",
            "Epoch 1992/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1385 - acc: 0.8855 - val_loss: 0.1108 - val_acc: 0.8981\n",
            "Epoch 1993/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8946 - val_loss: 0.1104 - val_acc: 0.8984\n",
            "Epoch 1994/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8823 - val_loss: 0.1104 - val_acc: 0.8985\n",
            "Epoch 1995/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1239 - acc: 0.8891 - val_loss: 0.1101 - val_acc: 0.8984\n",
            "Epoch 1996/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1278 - acc: 0.8820 - val_loss: 0.1093 - val_acc: 0.8982\n",
            "Epoch 1997/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8949 - val_loss: 0.1086 - val_acc: 0.8979\n",
            "Epoch 1998/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1802 - acc: 0.8867 - val_loss: 0.1087 - val_acc: 0.8976\n",
            "Epoch 1999/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8886 - val_loss: 0.1087 - val_acc: 0.8973\n",
            "Epoch 2000/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8938 - val_loss: 0.1085 - val_acc: 0.8972\n",
            "Epoch 2001/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8938 - val_loss: 0.1079 - val_acc: 0.8972\n",
            "Epoch 2002/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8894 - val_loss: 0.1071 - val_acc: 0.8973\n",
            "Epoch 2003/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8815 - val_loss: 0.1062 - val_acc: 0.8975\n",
            "Epoch 2004/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8834 - val_loss: 0.1055 - val_acc: 0.8977\n",
            "Epoch 2005/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8836 - val_loss: 0.1050 - val_acc: 0.8979\n",
            "Epoch 2006/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2487 - acc: 0.8673 - val_loss: 0.1052 - val_acc: 0.8977\n",
            "Epoch 2007/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8777 - val_loss: 0.1059 - val_acc: 0.8974\n",
            "Epoch 2008/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8839 - val_loss: 0.1066 - val_acc: 0.8972\n",
            "Epoch 2009/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8858 - val_loss: 0.1068 - val_acc: 0.8970\n",
            "Epoch 2010/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8857 - val_loss: 0.1064 - val_acc: 0.8971\n",
            "Epoch 2011/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8874 - val_loss: 0.1055 - val_acc: 0.8973\n",
            "Epoch 2012/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8842 - val_loss: 0.1045 - val_acc: 0.8976\n",
            "Epoch 2013/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8848 - val_loss: 0.1040 - val_acc: 0.8977\n",
            "Epoch 2014/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8890 - val_loss: 0.1036 - val_acc: 0.8976\n",
            "Epoch 2015/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8873 - val_loss: 0.1031 - val_acc: 0.8973\n",
            "Epoch 2016/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8935 - val_loss: 0.1028 - val_acc: 0.8967\n",
            "Epoch 2017/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8890 - val_loss: 0.1026 - val_acc: 0.8960\n",
            "Epoch 2018/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8884 - val_loss: 0.1026 - val_acc: 0.8953\n",
            "Epoch 2019/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8716 - val_loss: 0.1026 - val_acc: 0.8948\n",
            "Epoch 2020/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8877 - val_loss: 0.1022 - val_acc: 0.8947\n",
            "Epoch 2021/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8901 - val_loss: 0.1016 - val_acc: 0.8951\n",
            "Epoch 2022/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8804 - val_loss: 0.1013 - val_acc: 0.8956\n",
            "Epoch 2023/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8827 - val_loss: 0.1011 - val_acc: 0.8960\n",
            "Epoch 2024/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8831 - val_loss: 0.1010 - val_acc: 0.8961\n",
            "Epoch 2025/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8829 - val_loss: 0.1007 - val_acc: 0.8958\n",
            "Epoch 2026/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8826 - val_loss: 0.1007 - val_acc: 0.8953\n",
            "Epoch 2027/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8917 - val_loss: 0.1009 - val_acc: 0.8947\n",
            "Epoch 2028/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8911 - val_loss: 0.1010 - val_acc: 0.8943\n",
            "Epoch 2029/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8871 - val_loss: 0.1006 - val_acc: 0.8946\n",
            "Epoch 2030/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8875 - val_loss: 0.1004 - val_acc: 0.8953\n",
            "Epoch 2031/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8807 - val_loss: 0.1003 - val_acc: 0.8955\n",
            "Epoch 2032/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8807 - val_loss: 0.1002 - val_acc: 0.8954\n",
            "Epoch 2033/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8846 - val_loss: 0.1002 - val_acc: 0.8949\n",
            "Epoch 2034/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8842 - val_loss: 0.1003 - val_acc: 0.8943\n",
            "Epoch 2035/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8882 - val_loss: 0.1004 - val_acc: 0.8939\n",
            "Epoch 2036/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8874 - val_loss: 0.1003 - val_acc: 0.8939\n",
            "Epoch 2037/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8842 - val_loss: 0.1000 - val_acc: 0.8942\n",
            "Epoch 2038/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8899 - val_loss: 0.0999 - val_acc: 0.8947\n",
            "Epoch 2039/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8903 - val_loss: 0.1000 - val_acc: 0.8950\n",
            "Epoch 2040/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8846 - val_loss: 0.0999 - val_acc: 0.8952\n",
            "Epoch 2041/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8857 - val_loss: 0.0998 - val_acc: 0.8951\n",
            "Epoch 2042/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3175 - acc: 0.8588 - val_loss: 0.1013 - val_acc: 0.8934\n",
            "Epoch 2043/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8847 - val_loss: 0.1039 - val_acc: 0.8925\n",
            "Epoch 2044/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 0.8802 - val_loss: 0.1047 - val_acc: 0.8929\n",
            "Epoch 2045/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8763 - val_loss: 0.1034 - val_acc: 0.8945\n",
            "Epoch 2046/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1287 - acc: 0.8775 - val_loss: 0.1023 - val_acc: 0.8960\n",
            "Epoch 2047/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8781 - val_loss: 0.1023 - val_acc: 0.8971\n",
            "Epoch 2048/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8968 - val_loss: 0.1033 - val_acc: 0.8977\n",
            "Epoch 2049/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8974 - val_loss: 0.1041 - val_acc: 0.8979\n",
            "Epoch 2050/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8872 - val_loss: 0.1036 - val_acc: 0.8977\n",
            "Epoch 2051/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8870 - val_loss: 0.1028 - val_acc: 0.8973\n",
            "Epoch 2052/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8827 - val_loss: 0.1027 - val_acc: 0.8967\n",
            "Epoch 2053/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8953 - val_loss: 0.1031 - val_acc: 0.8961\n",
            "Epoch 2054/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8900 - val_loss: 0.1035 - val_acc: 0.8957\n",
            "Epoch 2055/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8867 - val_loss: 0.1034 - val_acc: 0.8957\n",
            "Epoch 2056/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8849 - val_loss: 0.1027 - val_acc: 0.8960\n",
            "Epoch 2057/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8904 - val_loss: 0.1020 - val_acc: 0.8965\n",
            "Epoch 2058/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8904 - val_loss: 0.1018 - val_acc: 0.8969\n",
            "Epoch 2059/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1265 - acc: 0.8890 - val_loss: 0.1018 - val_acc: 0.8970\n",
            "Epoch 2060/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8853 - val_loss: 0.1016 - val_acc: 0.8970\n",
            "Epoch 2061/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8853 - val_loss: 0.1013 - val_acc: 0.8967\n",
            "Epoch 2062/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8890 - val_loss: 0.1011 - val_acc: 0.8964\n",
            "Epoch 2063/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8886 - val_loss: 0.1010 - val_acc: 0.8961\n",
            "Epoch 2064/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8932 - val_loss: 0.1009 - val_acc: 0.8958\n",
            "Epoch 2065/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8930 - val_loss: 0.1008 - val_acc: 0.8957\n",
            "Epoch 2066/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8841 - val_loss: 0.1005 - val_acc: 0.8958\n",
            "Epoch 2067/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8818 - val_loss: 0.1003 - val_acc: 0.8960\n",
            "Epoch 2068/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8907 - val_loss: 0.1001 - val_acc: 0.8960\n",
            "Epoch 2069/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8908 - val_loss: 0.0999 - val_acc: 0.8958\n",
            "Epoch 2070/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8874 - val_loss: 0.0998 - val_acc: 0.8955\n",
            "Epoch 2071/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8859 - val_loss: 0.0998 - val_acc: 0.8950\n",
            "Epoch 2072/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8777 - val_loss: 0.0999 - val_acc: 0.8947\n",
            "Epoch 2073/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8783 - val_loss: 0.0998 - val_acc: 0.8947\n",
            "Epoch 2074/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8934 - val_loss: 0.0997 - val_acc: 0.8949\n",
            "Epoch 2075/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1514 - acc: 0.8851 - val_loss: 0.0997 - val_acc: 0.8949\n",
            "Epoch 2076/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8900 - val_loss: 0.0997 - val_acc: 0.8949\n",
            "Epoch 2077/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1723 - acc: 0.8751 - val_loss: 0.1001 - val_acc: 0.8946\n",
            "Epoch 2078/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8833 - val_loss: 0.1004 - val_acc: 0.8947\n",
            "Epoch 2079/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8972 - val_loss: 0.1004 - val_acc: 0.8952\n",
            "Epoch 2080/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8759 - val_loss: 0.1002 - val_acc: 0.8959\n",
            "Epoch 2081/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8758 - val_loss: 0.1003 - val_acc: 0.8964\n",
            "Epoch 2082/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1263 - acc: 0.8821 - val_loss: 0.1001 - val_acc: 0.8964\n",
            "Epoch 2083/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1446 - acc: 0.8837 - val_loss: 0.1002 - val_acc: 0.8963\n",
            "Epoch 2084/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8878 - val_loss: 0.1006 - val_acc: 0.8961\n",
            "Epoch 2085/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8830 - val_loss: 0.1009 - val_acc: 0.8961\n",
            "Epoch 2086/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2567 - acc: 0.8639 - val_loss: 0.1027 - val_acc: 0.8955\n",
            "Epoch 2087/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1697 - acc: 0.8738 - val_loss: 0.1057 - val_acc: 0.8950\n",
            "Epoch 2088/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8871 - val_loss: 0.1070 - val_acc: 0.8953\n",
            "Epoch 2089/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8943 - val_loss: 0.1063 - val_acc: 0.8963\n",
            "Epoch 2090/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8913 - val_loss: 0.1051 - val_acc: 0.8973\n",
            "Epoch 2091/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8851 - val_loss: 0.1051 - val_acc: 0.8979\n",
            "Epoch 2092/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8875 - val_loss: 0.1060 - val_acc: 0.8982\n",
            "Epoch 2093/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8858 - val_loss: 0.1064 - val_acc: 0.8982\n",
            "Epoch 2094/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8826 - val_loss: 0.1055 - val_acc: 0.8980\n",
            "Epoch 2095/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8829 - val_loss: 0.1044 - val_acc: 0.8977\n",
            "Epoch 2096/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1507 - acc: 0.8816 - val_loss: 0.1046 - val_acc: 0.8971\n",
            "Epoch 2097/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8848 - val_loss: 0.1053 - val_acc: 0.8966\n",
            "Epoch 2098/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8763 - val_loss: 0.1054 - val_acc: 0.8964\n",
            "Epoch 2099/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8941 - val_loss: 0.1048 - val_acc: 0.8965\n",
            "Epoch 2100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8868 - val_loss: 0.1039 - val_acc: 0.8968\n",
            "Epoch 2101/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8821 - val_loss: 0.1031 - val_acc: 0.8972\n",
            "Epoch 2102/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8835 - val_loss: 0.1027 - val_acc: 0.8975\n",
            "Epoch 2103/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1820 - acc: 0.8783 - val_loss: 0.1027 - val_acc: 0.8976\n",
            "Epoch 2104/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8909 - val_loss: 0.1025 - val_acc: 0.8974\n",
            "Epoch 2105/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8829 - val_loss: 0.1023 - val_acc: 0.8971\n",
            "Epoch 2106/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8827 - val_loss: 0.1021 - val_acc: 0.8967\n",
            "Epoch 2107/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2471 - acc: 0.8651 - val_loss: 0.1038 - val_acc: 0.8958\n",
            "Epoch 2108/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8776 - val_loss: 0.1054 - val_acc: 0.8954\n",
            "Epoch 2109/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8772 - val_loss: 0.1052 - val_acc: 0.8958\n",
            "Epoch 2110/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8909 - val_loss: 0.1042 - val_acc: 0.8966\n",
            "Epoch 2111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8721 - val_loss: 0.1035 - val_acc: 0.8974\n",
            "Epoch 2112/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8778 - val_loss: 0.1038 - val_acc: 0.8978\n",
            "Epoch 2113/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8781 - val_loss: 0.1038 - val_acc: 0.8978\n",
            "Epoch 2114/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8945 - val_loss: 0.1031 - val_acc: 0.8976\n",
            "Epoch 2115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8907 - val_loss: 0.1022 - val_acc: 0.8971\n",
            "Epoch 2116/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8860 - val_loss: 0.1018 - val_acc: 0.8964\n",
            "Epoch 2117/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8892 - val_loss: 0.1021 - val_acc: 0.8956\n",
            "Epoch 2118/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8846 - val_loss: 0.1020 - val_acc: 0.8952\n",
            "Epoch 2119/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8757 - val_loss: 0.1015 - val_acc: 0.8953\n",
            "Epoch 2120/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8770 - val_loss: 0.1008 - val_acc: 0.8958\n",
            "Epoch 2121/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8805 - val_loss: 0.1003 - val_acc: 0.8962\n",
            "Epoch 2122/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8813 - val_loss: 0.1004 - val_acc: 0.8964\n",
            "Epoch 2123/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8864 - val_loss: 0.1005 - val_acc: 0.8964\n",
            "Epoch 2124/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8863 - val_loss: 0.1002 - val_acc: 0.8963\n",
            "Epoch 2125/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8935 - val_loss: 0.0999 - val_acc: 0.8960\n",
            "Epoch 2126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8896 - val_loss: 0.0998 - val_acc: 0.8957\n",
            "Epoch 2127/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8834 - val_loss: 0.0998 - val_acc: 0.8956\n",
            "Epoch 2128/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8938 - val_loss: 0.0997 - val_acc: 0.8957\n",
            "Epoch 2129/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8872 - val_loss: 0.0996 - val_acc: 0.8959\n",
            "Epoch 2130/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3008 - acc: 0.8532 - val_loss: 0.1012 - val_acc: 0.8945\n",
            "Epoch 2131/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1494 - acc: 0.8793 - val_loss: 0.1048 - val_acc: 0.8933\n",
            "Epoch 2132/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8816 - val_loss: 0.1060 - val_acc: 0.8936\n",
            "Epoch 2133/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8822 - val_loss: 0.1046 - val_acc: 0.8951\n",
            "Epoch 2134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8815 - val_loss: 0.1029 - val_acc: 0.8967\n",
            "Epoch 2135/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8854 - val_loss: 0.1032 - val_acc: 0.8976\n",
            "Epoch 2136/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8990 - val_loss: 0.1042 - val_acc: 0.8979\n",
            "Epoch 2137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8991 - val_loss: 0.1042 - val_acc: 0.8979\n",
            "Epoch 2138/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1268 - acc: 0.8835 - val_loss: 0.1031 - val_acc: 0.8975\n",
            "Epoch 2139/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8904 - val_loss: 0.1025 - val_acc: 0.8968\n",
            "Epoch 2140/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8830 - val_loss: 0.1028 - val_acc: 0.8961\n",
            "Epoch 2141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8821 - val_loss: 0.1032 - val_acc: 0.8956\n",
            "Epoch 2142/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8796 - val_loss: 0.1030 - val_acc: 0.8955\n",
            "Epoch 2143/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8883 - val_loss: 0.1023 - val_acc: 0.8958\n",
            "Epoch 2144/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8888 - val_loss: 0.1016 - val_acc: 0.8963\n",
            "Epoch 2145/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8790 - val_loss: 0.1013 - val_acc: 0.8968\n",
            "Epoch 2146/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1695 - acc: 0.8746 - val_loss: 0.1014 - val_acc: 0.8970\n",
            "Epoch 2147/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8889 - val_loss: 0.1013 - val_acc: 0.8970\n",
            "Epoch 2148/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8888 - val_loss: 0.1011 - val_acc: 0.8970\n",
            "Epoch 2149/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8890 - val_loss: 0.1008 - val_acc: 0.8968\n",
            "Epoch 2150/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8963 - val_loss: 0.1008 - val_acc: 0.8967\n",
            "Epoch 2151/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8843 - val_loss: 0.1007 - val_acc: 0.8965\n",
            "Epoch 2152/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8841 - val_loss: 0.1006 - val_acc: 0.8963\n",
            "Epoch 2153/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2836 - acc: 0.8507 - val_loss: 0.1030 - val_acc: 0.8952\n",
            "Epoch 2154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1672 - acc: 0.8675 - val_loss: 0.1067 - val_acc: 0.8943\n",
            "Epoch 2155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8749 - val_loss: 0.1078 - val_acc: 0.8945\n",
            "Epoch 2156/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8741 - val_loss: 0.1076 - val_acc: 0.8952\n",
            "Epoch 2157/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8709 - val_loss: 0.1058 - val_acc: 0.8961\n",
            "Epoch 2158/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8880 - val_loss: 0.1045 - val_acc: 0.8970\n",
            "Epoch 2159/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8923 - val_loss: 0.1046 - val_acc: 0.8976\n",
            "Epoch 2160/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8929 - val_loss: 0.1054 - val_acc: 0.8978\n",
            "Epoch 2161/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8863 - val_loss: 0.1052 - val_acc: 0.8978\n",
            "Epoch 2162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8870 - val_loss: 0.1039 - val_acc: 0.8975\n",
            "Epoch 2163/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8868 - val_loss: 0.1030 - val_acc: 0.8969\n",
            "Epoch 2164/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8796 - val_loss: 0.1033 - val_acc: 0.8962\n",
            "Epoch 2165/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8789 - val_loss: 0.1039 - val_acc: 0.8955\n",
            "Epoch 2166/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8784 - val_loss: 0.1039 - val_acc: 0.8953\n",
            "Epoch 2167/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1231 - acc: 0.8766 - val_loss: 0.1034 - val_acc: 0.8954\n",
            "Epoch 2168/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1624 - acc: 0.8745 - val_loss: 0.1031 - val_acc: 0.8955\n",
            "Epoch 2169/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8813 - val_loss: 0.1025 - val_acc: 0.8959\n",
            "Epoch 2170/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8852 - val_loss: 0.1018 - val_acc: 0.8964\n",
            "Epoch 2171/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8846 - val_loss: 0.1013 - val_acc: 0.8969\n",
            "Epoch 2172/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8913 - val_loss: 0.1011 - val_acc: 0.8971\n",
            "Epoch 2173/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8864 - val_loss: 0.1008 - val_acc: 0.8970\n",
            "Epoch 2174/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2263 - acc: 0.8745 - val_loss: 0.1008 - val_acc: 0.8964\n",
            "Epoch 2175/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8904 - val_loss: 0.1018 - val_acc: 0.8956\n",
            "Epoch 2176/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8769 - val_loss: 0.1027 - val_acc: 0.8952\n",
            "Epoch 2177/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1690 - acc: 0.8701 - val_loss: 0.1038 - val_acc: 0.8951\n",
            "Epoch 2178/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8808 - val_loss: 0.1036 - val_acc: 0.8955\n",
            "Epoch 2179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8874 - val_loss: 0.1027 - val_acc: 0.8963\n",
            "Epoch 2180/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8849 - val_loss: 0.1022 - val_acc: 0.8970\n",
            "Epoch 2181/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2140 - acc: 0.8746 - val_loss: 0.1029 - val_acc: 0.8973\n",
            "Epoch 2182/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8882 - val_loss: 0.1032 - val_acc: 0.8974\n",
            "Epoch 2183/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8869 - val_loss: 0.1029 - val_acc: 0.8973\n",
            "Epoch 2184/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8875 - val_loss: 0.1026 - val_acc: 0.8971\n",
            "Epoch 2185/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8824 - val_loss: 0.1026 - val_acc: 0.8967\n",
            "Epoch 2186/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8819 - val_loss: 0.1028 - val_acc: 0.8963\n",
            "Epoch 2187/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8884 - val_loss: 0.1029 - val_acc: 0.8961\n",
            "Epoch 2188/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2269 - acc: 0.8644 - val_loss: 0.1035 - val_acc: 0.8961\n",
            "Epoch 2189/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8895 - val_loss: 0.1037 - val_acc: 0.8964\n",
            "Epoch 2190/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8850 - val_loss: 0.1034 - val_acc: 0.8968\n",
            "Epoch 2191/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8924 - val_loss: 0.1030 - val_acc: 0.8972\n",
            "Epoch 2192/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8823 - val_loss: 0.1028 - val_acc: 0.8974\n",
            "Epoch 2193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8825 - val_loss: 0.1026 - val_acc: 0.8974\n",
            "Epoch 2194/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8845 - val_loss: 0.1024 - val_acc: 0.8972\n",
            "Epoch 2195/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8785 - val_loss: 0.1022 - val_acc: 0.8970\n",
            "Epoch 2196/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8828 - val_loss: 0.1020 - val_acc: 0.8967\n",
            "Epoch 2197/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8827 - val_loss: 0.1017 - val_acc: 0.8964\n",
            "Epoch 2198/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8814 - val_loss: 0.1014 - val_acc: 0.8963\n",
            "Epoch 2199/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8813 - val_loss: 0.1009 - val_acc: 0.8964\n",
            "Epoch 2200/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8837 - val_loss: 0.1005 - val_acc: 0.8965\n",
            "Epoch 2201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8837 - val_loss: 0.1003 - val_acc: 0.8966\n",
            "Epoch 2202/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8873 - val_loss: 0.1001 - val_acc: 0.8967\n",
            "Epoch 2203/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1223 - acc: 0.8850 - val_loss: 0.0999 - val_acc: 0.8967\n",
            "Epoch 2204/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8797 - val_loss: 0.0995 - val_acc: 0.8963\n",
            "Epoch 2205/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8799 - val_loss: 0.0994 - val_acc: 0.8957\n",
            "Epoch 2206/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8834 - val_loss: 0.0995 - val_acc: 0.8951\n",
            "Epoch 2207/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8918 - val_loss: 0.0996 - val_acc: 0.8947\n",
            "Epoch 2208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8827 - val_loss: 0.0993 - val_acc: 0.8949\n",
            "Epoch 2209/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8885 - val_loss: 0.0990 - val_acc: 0.8952\n",
            "Epoch 2210/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8879 - val_loss: 0.0989 - val_acc: 0.8957\n",
            "Epoch 2211/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8885 - val_loss: 0.0991 - val_acc: 0.8959\n",
            "Epoch 2212/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8963 - val_loss: 0.0991 - val_acc: 0.8956\n",
            "Epoch 2213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8882 - val_loss: 0.0990 - val_acc: 0.8951\n",
            "Epoch 2214/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8817 - val_loss: 0.0991 - val_acc: 0.8943\n",
            "Epoch 2215/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8810 - val_loss: 0.0994 - val_acc: 0.8937\n",
            "Epoch 2216/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8818 - val_loss: 0.0991 - val_acc: 0.8939\n",
            "Epoch 2217/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1928 - acc: 0.8679 - val_loss: 0.1001 - val_acc: 0.8931\n",
            "Epoch 2218/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8712 - val_loss: 0.1002 - val_acc: 0.8935\n",
            "Epoch 2219/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8781 - val_loss: 0.0995 - val_acc: 0.8946\n",
            "Epoch 2220/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8842 - val_loss: 0.0990 - val_acc: 0.8959\n",
            "Epoch 2221/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1870 - acc: 0.8701 - val_loss: 0.0991 - val_acc: 0.8962\n",
            "Epoch 2222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8839 - val_loss: 0.0993 - val_acc: 0.8963\n",
            "Epoch 2223/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8829 - val_loss: 0.0994 - val_acc: 0.8962\n",
            "Epoch 2224/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8718 - val_loss: 0.0994 - val_acc: 0.8960\n",
            "Epoch 2225/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8877 - val_loss: 0.0995 - val_acc: 0.8959\n",
            "Epoch 2226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8934 - val_loss: 0.0995 - val_acc: 0.8959\n",
            "Epoch 2227/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8936 - val_loss: 0.0995 - val_acc: 0.8961\n",
            "Epoch 2228/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8868 - val_loss: 0.0995 - val_acc: 0.8963\n",
            "Epoch 2229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8893 - val_loss: 0.0994 - val_acc: 0.8965\n",
            "Epoch 2230/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8881 - val_loss: 0.0993 - val_acc: 0.8965\n",
            "Epoch 2231/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8880 - val_loss: 0.0992 - val_acc: 0.8963\n",
            "Epoch 2232/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8763 - val_loss: 0.0991 - val_acc: 0.8962\n",
            "Epoch 2233/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8738 - val_loss: 0.0991 - val_acc: 0.8962\n",
            "Epoch 2234/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8930 - val_loss: 0.0991 - val_acc: 0.8961\n",
            "Epoch 2235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1335 - acc: 0.8796 - val_loss: 0.0990 - val_acc: 0.8960\n",
            "Epoch 2236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1655 - acc: 0.8756 - val_loss: 0.0993 - val_acc: 0.8956\n",
            "Epoch 2237/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8818 - val_loss: 0.0995 - val_acc: 0.8956\n",
            "Epoch 2238/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8821 - val_loss: 0.0995 - val_acc: 0.8960\n",
            "Epoch 2239/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8814 - val_loss: 0.0994 - val_acc: 0.8964\n",
            "Epoch 2240/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8854 - val_loss: 0.0995 - val_acc: 0.8968\n",
            "Epoch 2241/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8848 - val_loss: 0.0994 - val_acc: 0.8968\n",
            "Epoch 2242/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8849 - val_loss: 0.0991 - val_acc: 0.8966\n",
            "Epoch 2243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8836 - val_loss: 0.0990 - val_acc: 0.8959\n",
            "Epoch 2244/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8832 - val_loss: 0.0992 - val_acc: 0.8952\n",
            "Epoch 2245/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8770 - val_loss: 0.0992 - val_acc: 0.8948\n",
            "Epoch 2246/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8764 - val_loss: 0.0989 - val_acc: 0.8950\n",
            "Epoch 2247/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8885 - val_loss: 0.0986 - val_acc: 0.8954\n",
            "Epoch 2248/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8889 - val_loss: 0.0987 - val_acc: 0.8957\n",
            "Epoch 2249/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8916 - val_loss: 0.0987 - val_acc: 0.8958\n",
            "Epoch 2250/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8872 - val_loss: 0.0985 - val_acc: 0.8955\n",
            "Epoch 2251/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 0.8738 - val_loss: 0.0992 - val_acc: 0.8941\n",
            "Epoch 2252/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8844 - val_loss: 0.1006 - val_acc: 0.8934\n",
            "Epoch 2253/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8853 - val_loss: 0.1001 - val_acc: 0.8941\n",
            "Epoch 2254/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8776 - val_loss: 0.0990 - val_acc: 0.8956\n",
            "Epoch 2255/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2749 - acc: 0.8622 - val_loss: 0.0997 - val_acc: 0.8957\n",
            "Epoch 2256/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8888 - val_loss: 0.1002 - val_acc: 0.8960\n",
            "Epoch 2257/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8852 - val_loss: 0.1006 - val_acc: 0.8964\n",
            "Epoch 2258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2678 - acc: 0.8581 - val_loss: 0.1031 - val_acc: 0.8961\n",
            "Epoch 2259/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8804 - val_loss: 0.1050 - val_acc: 0.8963\n",
            "Epoch 2260/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8897 - val_loss: 0.1058 - val_acc: 0.8967\n",
            "Epoch 2261/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8883 - val_loss: 0.1056 - val_acc: 0.8974\n",
            "Epoch 2262/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1164 - acc: 0.8848 - val_loss: 0.1053 - val_acc: 0.8978\n",
            "Epoch 2263/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8852 - val_loss: 0.1052 - val_acc: 0.8980\n",
            "Epoch 2264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8926 - val_loss: 0.1050 - val_acc: 0.8980\n",
            "Epoch 2265/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2351 - acc: 0.8694 - val_loss: 0.1057 - val_acc: 0.8978\n",
            "Epoch 2266/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8896 - val_loss: 0.1066 - val_acc: 0.8975\n",
            "Epoch 2267/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8825 - val_loss: 0.1073 - val_acc: 0.8972\n",
            "Epoch 2268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2218 - acc: 0.8620 - val_loss: 0.1096 - val_acc: 0.8969\n",
            "Epoch 2269/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1994 - acc: 0.8701 - val_loss: 0.1122 - val_acc: 0.8969\n",
            "Epoch 2270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8915 - val_loss: 0.1127 - val_acc: 0.8974\n",
            "Epoch 2271/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8861 - val_loss: 0.1120 - val_acc: 0.8979\n",
            "Epoch 2272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8880 - val_loss: 0.1111 - val_acc: 0.8983\n",
            "Epoch 2273/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1232 - acc: 0.8843 - val_loss: 0.1107 - val_acc: 0.8986\n",
            "Epoch 2274/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8843 - val_loss: 0.1102 - val_acc: 0.8986\n",
            "Epoch 2275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8941 - val_loss: 0.1093 - val_acc: 0.8986\n",
            "Epoch 2276/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1421 - acc: 0.8906 - val_loss: 0.1083 - val_acc: 0.8985\n",
            "Epoch 2277/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8936 - val_loss: 0.1074 - val_acc: 0.8982\n",
            "Epoch 2278/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8937 - val_loss: 0.1070 - val_acc: 0.8978\n",
            "Epoch 2279/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8898 - val_loss: 0.1067 - val_acc: 0.8975\n",
            "Epoch 2280/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8866 - val_loss: 0.1062 - val_acc: 0.8973\n",
            "Epoch 2281/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8874 - val_loss: 0.1052 - val_acc: 0.8973\n",
            "Epoch 2282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8839 - val_loss: 0.1041 - val_acc: 0.8975\n",
            "Epoch 2283/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8875 - val_loss: 0.1031 - val_acc: 0.8977\n",
            "Epoch 2284/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8839 - val_loss: 0.1024 - val_acc: 0.8978\n",
            "Epoch 2285/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8840 - val_loss: 0.1019 - val_acc: 0.8978\n",
            "Epoch 2286/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1261 - acc: 0.8720 - val_loss: 0.1013 - val_acc: 0.8976\n",
            "Epoch 2287/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1337 - acc: 0.8711 - val_loss: 0.1008 - val_acc: 0.8972\n",
            "Epoch 2288/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8909 - val_loss: 0.1006 - val_acc: 0.8968\n",
            "Epoch 2289/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2975 - acc: 0.8588 - val_loss: 0.1048 - val_acc: 0.8949\n",
            "Epoch 2290/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8872 - val_loss: 0.1091 - val_acc: 0.8933\n",
            "Epoch 2291/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8841 - val_loss: 0.1094 - val_acc: 0.8934\n",
            "Epoch 2292/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8902 - val_loss: 0.1057 - val_acc: 0.8951\n",
            "Epoch 2293/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8794 - val_loss: 0.1025 - val_acc: 0.8970\n",
            "Epoch 2294/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8834 - val_loss: 0.1034 - val_acc: 0.8980\n",
            "Epoch 2295/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8971 - val_loss: 0.1059 - val_acc: 0.8982\n",
            "Epoch 2296/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8933 - val_loss: 0.1056 - val_acc: 0.8982\n",
            "Epoch 2297/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2121 - acc: 0.8778 - val_loss: 0.1025 - val_acc: 0.8976\n",
            "Epoch 2298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8920 - val_loss: 0.1023 - val_acc: 0.8965\n",
            "Epoch 2299/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8817 - val_loss: 0.1043 - val_acc: 0.8951\n",
            "Epoch 2300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8801 - val_loss: 0.1059 - val_acc: 0.8942\n",
            "Epoch 2301/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1224 - acc: 0.8800 - val_loss: 0.1057 - val_acc: 0.8943\n",
            "Epoch 2302/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8886 - val_loss: 0.1039 - val_acc: 0.8953\n",
            "Epoch 2303/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8810 - val_loss: 0.1024 - val_acc: 0.8964\n",
            "Epoch 2304/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8837 - val_loss: 0.1021 - val_acc: 0.8972\n",
            "Epoch 2305/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8886 - val_loss: 0.1028 - val_acc: 0.8976\n",
            "Epoch 2306/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1972 - acc: 0.8752 - val_loss: 0.1028 - val_acc: 0.8976\n",
            "Epoch 2307/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8873 - val_loss: 0.1024 - val_acc: 0.8975\n",
            "Epoch 2308/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8870 - val_loss: 0.1021 - val_acc: 0.8971\n",
            "Epoch 2309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8896 - val_loss: 0.1025 - val_acc: 0.8967\n",
            "Epoch 2310/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8892 - val_loss: 0.1029 - val_acc: 0.8963\n",
            "Epoch 2311/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8922 - val_loss: 0.1029 - val_acc: 0.8962\n",
            "Epoch 2312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1236 - acc: 0.8751 - val_loss: 0.1023 - val_acc: 0.8964\n",
            "Epoch 2313/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8951 - val_loss: 0.1015 - val_acc: 0.8969\n",
            "Epoch 2314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8734 - val_loss: 0.1012 - val_acc: 0.8973\n",
            "Epoch 2315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8841 - val_loss: 0.1012 - val_acc: 0.8975\n",
            "Epoch 2316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8812 - val_loss: 0.1008 - val_acc: 0.8974\n",
            "Epoch 2317/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1853 - acc: 0.8835 - val_loss: 0.1005 - val_acc: 0.8972\n",
            "Epoch 2318/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8893 - val_loss: 0.1007 - val_acc: 0.8967\n",
            "Epoch 2319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8947 - val_loss: 0.1012 - val_acc: 0.8963\n",
            "Epoch 2320/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8977 - val_loss: 0.1014 - val_acc: 0.8961\n",
            "Epoch 2321/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8835 - val_loss: 0.1010 - val_acc: 0.8961\n",
            "Epoch 2322/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1228 - acc: 0.8816 - val_loss: 0.1005 - val_acc: 0.8963\n",
            "Epoch 2323/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8911 - val_loss: 0.1000 - val_acc: 0.8966\n",
            "Epoch 2324/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8771 - val_loss: 0.0997 - val_acc: 0.8968\n",
            "Epoch 2325/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8773 - val_loss: 0.0997 - val_acc: 0.8969\n",
            "Epoch 2326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8843 - val_loss: 0.0996 - val_acc: 0.8967\n",
            "Epoch 2327/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8831 - val_loss: 0.0994 - val_acc: 0.8964\n",
            "Epoch 2328/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8829 - val_loss: 0.0993 - val_acc: 0.8959\n",
            "Epoch 2329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8974 - val_loss: 0.0992 - val_acc: 0.8956\n",
            "Epoch 2330/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8851 - val_loss: 0.0990 - val_acc: 0.8954\n",
            "Epoch 2331/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3325 - acc: 0.8459 - val_loss: 0.1020 - val_acc: 0.8937\n",
            "Epoch 2332/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8704 - val_loss: 0.1047 - val_acc: 0.8931\n",
            "Epoch 2333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8750 - val_loss: 0.1044 - val_acc: 0.8942\n",
            "Epoch 2334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8981 - val_loss: 0.1026 - val_acc: 0.8960\n",
            "Epoch 2335/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1276 - acc: 0.8733 - val_loss: 0.1020 - val_acc: 0.8972\n",
            "Epoch 2336/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8868 - val_loss: 0.1025 - val_acc: 0.8978\n",
            "Epoch 2337/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8840 - val_loss: 0.1026 - val_acc: 0.8978\n",
            "Epoch 2338/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8849 - val_loss: 0.1020 - val_acc: 0.8975\n",
            "Epoch 2339/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8837 - val_loss: 0.1013 - val_acc: 0.8969\n",
            "Epoch 2340/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8926 - val_loss: 0.1014 - val_acc: 0.8962\n",
            "Epoch 2341/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8919 - val_loss: 0.1017 - val_acc: 0.8955\n",
            "Epoch 2342/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8879 - val_loss: 0.1016 - val_acc: 0.8953\n",
            "Epoch 2343/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8848 - val_loss: 0.1010 - val_acc: 0.8956\n",
            "Epoch 2344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8771 - val_loss: 0.1004 - val_acc: 0.8960\n",
            "Epoch 2345/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1690 - acc: 0.8709 - val_loss: 0.1003 - val_acc: 0.8961\n",
            "Epoch 2346/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8817 - val_loss: 0.1004 - val_acc: 0.8963\n",
            "Epoch 2347/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8862 - val_loss: 0.1003 - val_acc: 0.8966\n",
            "Epoch 2348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8726 - val_loss: 0.0999 - val_acc: 0.8967\n",
            "Epoch 2349/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8934 - val_loss: 0.0996 - val_acc: 0.8967\n",
            "Epoch 2350/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8935 - val_loss: 0.0994 - val_acc: 0.8967\n",
            "Epoch 2351/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8856 - val_loss: 0.0993 - val_acc: 0.8965\n",
            "Epoch 2352/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8851 - val_loss: 0.0993 - val_acc: 0.8964\n",
            "Epoch 2353/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8898 - val_loss: 0.0991 - val_acc: 0.8962\n",
            "Epoch 2354/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8852 - val_loss: 0.0989 - val_acc: 0.8960\n",
            "Epoch 2355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8850 - val_loss: 0.0987 - val_acc: 0.8960\n",
            "Epoch 2356/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8791 - val_loss: 0.0985 - val_acc: 0.8959\n",
            "Epoch 2357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8867 - val_loss: 0.0985 - val_acc: 0.8959\n",
            "Epoch 2358/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2132 - acc: 0.8711 - val_loss: 0.0989 - val_acc: 0.8955\n",
            "Epoch 2359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8817 - val_loss: 0.0992 - val_acc: 0.8954\n",
            "Epoch 2360/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8815 - val_loss: 0.0990 - val_acc: 0.8957\n",
            "Epoch 2361/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8775 - val_loss: 0.0987 - val_acc: 0.8960\n",
            "Epoch 2362/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8906 - val_loss: 0.0986 - val_acc: 0.8962\n",
            "Epoch 2363/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8953 - val_loss: 0.0989 - val_acc: 0.8964\n",
            "Epoch 2364/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8834 - val_loss: 0.0989 - val_acc: 0.8963\n",
            "Epoch 2365/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8912 - val_loss: 0.0988 - val_acc: 0.8961\n",
            "Epoch 2366/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8785 - val_loss: 0.0986 - val_acc: 0.8958\n",
            "Epoch 2367/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8757 - val_loss: 0.0986 - val_acc: 0.8953\n",
            "Epoch 2368/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8850 - val_loss: 0.0986 - val_acc: 0.8952\n",
            "Epoch 2369/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8863 - val_loss: 0.0984 - val_acc: 0.8955\n",
            "Epoch 2370/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8881 - val_loss: 0.0983 - val_acc: 0.8958\n",
            "Epoch 2371/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8881 - val_loss: 0.0982 - val_acc: 0.8961\n",
            "Epoch 2372/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8884 - val_loss: 0.0980 - val_acc: 0.8961\n",
            "Epoch 2373/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8975 - val_loss: 0.0979 - val_acc: 0.8960\n",
            "Epoch 2374/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2616 - acc: 0.8640 - val_loss: 0.0984 - val_acc: 0.8953\n",
            "Epoch 2375/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8906 - val_loss: 0.0994 - val_acc: 0.8948\n",
            "Epoch 2376/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2734 - acc: 0.8527 - val_loss: 0.1040 - val_acc: 0.8933\n",
            "Epoch 2377/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1827 - acc: 0.8629 - val_loss: 0.1085 - val_acc: 0.8927\n",
            "Epoch 2378/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1471 - acc: 0.8691 - val_loss: 0.1100 - val_acc: 0.8939\n",
            "Epoch 2379/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8804 - val_loss: 0.1088 - val_acc: 0.8959\n",
            "Epoch 2380/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8873 - val_loss: 0.1070 - val_acc: 0.8975\n",
            "Epoch 2381/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8855 - val_loss: 0.1067 - val_acc: 0.8983\n",
            "Epoch 2382/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8817 - val_loss: 0.1075 - val_acc: 0.8985\n",
            "Epoch 2383/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8901 - val_loss: 0.1077 - val_acc: 0.8985\n",
            "Epoch 2384/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8847 - val_loss: 0.1069 - val_acc: 0.8984\n",
            "Epoch 2385/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8845 - val_loss: 0.1059 - val_acc: 0.8981\n",
            "Epoch 2386/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8855 - val_loss: 0.1055 - val_acc: 0.8977\n",
            "Epoch 2387/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8917 - val_loss: 0.1056 - val_acc: 0.8972\n",
            "Epoch 2388/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8774 - val_loss: 0.1057 - val_acc: 0.8968\n",
            "Epoch 2389/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8770 - val_loss: 0.1054 - val_acc: 0.8965\n",
            "Epoch 2390/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1198 - acc: 0.8793 - val_loss: 0.1048 - val_acc: 0.8966\n",
            "Epoch 2391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8885 - val_loss: 0.1038 - val_acc: 0.8969\n",
            "Epoch 2392/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1153 - acc: 0.8844 - val_loss: 0.1028 - val_acc: 0.8972\n",
            "Epoch 2393/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1314 - acc: 0.8822 - val_loss: 0.1023 - val_acc: 0.8975\n",
            "Epoch 2394/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8851 - val_loss: 0.1019 - val_acc: 0.8976\n",
            "Epoch 2395/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8897 - val_loss: 0.1013 - val_acc: 0.8976\n",
            "Epoch 2396/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8840 - val_loss: 0.1008 - val_acc: 0.8974\n",
            "Epoch 2397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1168 - acc: 0.8807 - val_loss: 0.1003 - val_acc: 0.8971\n",
            "Epoch 2398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8802 - val_loss: 0.0999 - val_acc: 0.8967\n",
            "Epoch 2399/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8799 - val_loss: 0.0997 - val_acc: 0.8964\n",
            "Epoch 2400/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8931 - val_loss: 0.0995 - val_acc: 0.8962\n",
            "Epoch 2401/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8875 - val_loss: 0.0991 - val_acc: 0.8962\n",
            "Epoch 2402/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1656 - acc: 0.8795 - val_loss: 0.0991 - val_acc: 0.8961\n",
            "Epoch 2403/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8872 - val_loss: 0.0990 - val_acc: 0.8960\n",
            "Epoch 2404/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8873 - val_loss: 0.0990 - val_acc: 0.8960\n",
            "Epoch 2405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8927 - val_loss: 0.0988 - val_acc: 0.8960\n",
            "Epoch 2406/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8887 - val_loss: 0.0985 - val_acc: 0.8959\n",
            "Epoch 2407/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8852 - val_loss: 0.0983 - val_acc: 0.8958\n",
            "Epoch 2408/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1235 - acc: 0.8776 - val_loss: 0.0983 - val_acc: 0.8957\n",
            "Epoch 2409/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2421 - acc: 0.8599 - val_loss: 0.0993 - val_acc: 0.8948\n",
            "Epoch 2410/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8807 - val_loss: 0.1003 - val_acc: 0.8945\n",
            "Epoch 2411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8746 - val_loss: 0.1001 - val_acc: 0.8949\n",
            "Epoch 2412/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8877 - val_loss: 0.0993 - val_acc: 0.8959\n",
            "Epoch 2413/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8848 - val_loss: 0.0990 - val_acc: 0.8967\n",
            "Epoch 2414/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8867 - val_loss: 0.0995 - val_acc: 0.8971\n",
            "Epoch 2415/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8872 - val_loss: 0.0998 - val_acc: 0.8972\n",
            "Epoch 2416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8880 - val_loss: 0.0996 - val_acc: 0.8971\n",
            "Epoch 2417/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8864 - val_loss: 0.0991 - val_acc: 0.8968\n",
            "Epoch 2418/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8884 - val_loss: 0.0990 - val_acc: 0.8964\n",
            "Epoch 2419/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8949 - val_loss: 0.0991 - val_acc: 0.8961\n",
            "Epoch 2420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2570 - acc: 0.8639 - val_loss: 0.1015 - val_acc: 0.8951\n",
            "Epoch 2421/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8871 - val_loss: 0.1033 - val_acc: 0.8947\n",
            "Epoch 2422/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8827 - val_loss: 0.1037 - val_acc: 0.8951\n",
            "Epoch 2423/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8710 - val_loss: 0.1025 - val_acc: 0.8961\n",
            "Epoch 2424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8979 - val_loss: 0.1013 - val_acc: 0.8972\n",
            "Epoch 2425/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8926 - val_loss: 0.1016 - val_acc: 0.8979\n",
            "Epoch 2426/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8830 - val_loss: 0.1021 - val_acc: 0.8981\n",
            "Epoch 2427/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8886 - val_loss: 0.1017 - val_acc: 0.8979\n",
            "Epoch 2428/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8852 - val_loss: 0.1008 - val_acc: 0.8974\n",
            "Epoch 2429/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8837 - val_loss: 0.1005 - val_acc: 0.8965\n",
            "Epoch 2430/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8832 - val_loss: 0.1009 - val_acc: 0.8958\n",
            "Epoch 2431/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2164 - acc: 0.8682 - val_loss: 0.1026 - val_acc: 0.8950\n",
            "Epoch 2432/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2002 - acc: 0.8667 - val_loss: 0.1058 - val_acc: 0.8943\n",
            "Epoch 2433/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8864 - val_loss: 0.1066 - val_acc: 0.8946\n",
            "Epoch 2434/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8879 - val_loss: 0.1048 - val_acc: 0.8959\n",
            "Epoch 2435/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8840 - val_loss: 0.1027 - val_acc: 0.8973\n",
            "Epoch 2436/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8828 - val_loss: 0.1022 - val_acc: 0.8980\n",
            "Epoch 2437/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8874 - val_loss: 0.1030 - val_acc: 0.8983\n",
            "Epoch 2438/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8858 - val_loss: 0.1034 - val_acc: 0.8984\n",
            "Epoch 2439/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8851 - val_loss: 0.1027 - val_acc: 0.8981\n",
            "Epoch 2440/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1655 - acc: 0.8864 - val_loss: 0.1020 - val_acc: 0.8976\n",
            "Epoch 2441/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8914 - val_loss: 0.1023 - val_acc: 0.8969\n",
            "Epoch 2442/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8892 - val_loss: 0.1033 - val_acc: 0.8962\n",
            "Epoch 2443/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8919 - val_loss: 0.1038 - val_acc: 0.8959\n",
            "Epoch 2444/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8912 - val_loss: 0.1033 - val_acc: 0.8960\n",
            "Epoch 2445/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8854 - val_loss: 0.1020 - val_acc: 0.8966\n",
            "Epoch 2446/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8873 - val_loss: 0.1009 - val_acc: 0.8972\n",
            "Epoch 2447/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8883 - val_loss: 0.1005 - val_acc: 0.8976\n",
            "Epoch 2448/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8916 - val_loss: 0.1005 - val_acc: 0.8977\n",
            "Epoch 2449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1304 - acc: 0.8825 - val_loss: 0.1002 - val_acc: 0.8976\n",
            "Epoch 2450/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8809 - val_loss: 0.0997 - val_acc: 0.8971\n",
            "Epoch 2451/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8800 - val_loss: 0.0995 - val_acc: 0.8965\n",
            "Epoch 2452/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8795 - val_loss: 0.0996 - val_acc: 0.8960\n",
            "Epoch 2453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8964 - val_loss: 0.0995 - val_acc: 0.8957\n",
            "Epoch 2454/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8833 - val_loss: 0.0992 - val_acc: 0.8957\n",
            "Epoch 2455/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8852 - val_loss: 0.0987 - val_acc: 0.8960\n",
            "Epoch 2456/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8820 - val_loss: 0.0983 - val_acc: 0.8963\n",
            "Epoch 2457/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8946 - val_loss: 0.0982 - val_acc: 0.8966\n",
            "Epoch 2458/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8904 - val_loss: 0.0980 - val_acc: 0.8965\n",
            "Epoch 2459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2000 - acc: 0.8719 - val_loss: 0.0981 - val_acc: 0.8957\n",
            "Epoch 2460/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8855 - val_loss: 0.0991 - val_acc: 0.8948\n",
            "Epoch 2461/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2441 - acc: 0.8571 - val_loss: 0.1019 - val_acc: 0.8936\n",
            "Epoch 2462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - acc: 0.8774 - val_loss: 0.1040 - val_acc: 0.8932\n",
            "Epoch 2463/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8868 - val_loss: 0.1034 - val_acc: 0.8944\n",
            "Epoch 2464/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8871 - val_loss: 0.1015 - val_acc: 0.8960\n",
            "Epoch 2465/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1431 - acc: 0.8658 - val_loss: 0.1009 - val_acc: 0.8972\n",
            "Epoch 2466/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8897 - val_loss: 0.1015 - val_acc: 0.8977\n",
            "Epoch 2467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2488 - acc: 0.8684 - val_loss: 0.1025 - val_acc: 0.8978\n",
            "Epoch 2468/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8842 - val_loss: 0.1030 - val_acc: 0.8977\n",
            "Epoch 2469/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1889 - acc: 0.8667 - val_loss: 0.1050 - val_acc: 0.8972\n",
            "Epoch 2470/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8845 - val_loss: 0.1072 - val_acc: 0.8967\n",
            "Epoch 2471/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1301 - acc: 0.8832 - val_loss: 0.1084 - val_acc: 0.8966\n",
            "Epoch 2472/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8831 - val_loss: 0.1079 - val_acc: 0.8969\n",
            "Epoch 2473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8917 - val_loss: 0.1066 - val_acc: 0.8973\n",
            "Epoch 2474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8915 - val_loss: 0.1057 - val_acc: 0.8978\n",
            "Epoch 2475/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1802 - acc: 0.8824 - val_loss: 0.1061 - val_acc: 0.8981\n",
            "Epoch 2476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8888 - val_loss: 0.1063 - val_acc: 0.8981\n",
            "Epoch 2477/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8816 - val_loss: 0.1060 - val_acc: 0.8981\n",
            "Epoch 2478/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8971 - val_loss: 0.1053 - val_acc: 0.8981\n",
            "Epoch 2479/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8972 - val_loss: 0.1046 - val_acc: 0.8979\n",
            "Epoch 2480/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8931 - val_loss: 0.1041 - val_acc: 0.8977\n",
            "Epoch 2481/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8867 - val_loss: 0.1038 - val_acc: 0.8974\n",
            "Epoch 2482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.9014 - val_loss: 0.1034 - val_acc: 0.8973\n",
            "Epoch 2483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.9014 - val_loss: 0.1028 - val_acc: 0.8972\n",
            "Epoch 2484/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8900 - val_loss: 0.1020 - val_acc: 0.8973\n",
            "Epoch 2485/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8788 - val_loss: 0.1013 - val_acc: 0.8974\n",
            "Epoch 2486/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8873 - val_loss: 0.1007 - val_acc: 0.8974\n",
            "Epoch 2487/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8904 - val_loss: 0.1002 - val_acc: 0.8974\n",
            "Epoch 2488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8905 - val_loss: 0.0998 - val_acc: 0.8973\n",
            "Epoch 2489/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8846 - val_loss: 0.0995 - val_acc: 0.8971\n",
            "Epoch 2490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8878 - val_loss: 0.0991 - val_acc: 0.8969\n",
            "Epoch 2491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2403 - acc: 0.8687 - val_loss: 0.0999 - val_acc: 0.8962\n",
            "Epoch 2492/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8886 - val_loss: 0.1015 - val_acc: 0.8955\n",
            "Epoch 2493/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1972 - acc: 0.8708 - val_loss: 0.1047 - val_acc: 0.8945\n",
            "Epoch 2494/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8901 - val_loss: 0.1056 - val_acc: 0.8946\n",
            "Epoch 2495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1296 - acc: 0.8790 - val_loss: 0.1043 - val_acc: 0.8955\n",
            "Epoch 2496/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8850 - val_loss: 0.1023 - val_acc: 0.8968\n",
            "Epoch 2497/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8812 - val_loss: 0.1015 - val_acc: 0.8976\n",
            "Epoch 2498/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8825 - val_loss: 0.1020 - val_acc: 0.8979\n",
            "Epoch 2499/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8827 - val_loss: 0.1021 - val_acc: 0.8978\n",
            "Epoch 2500/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8924 - val_loss: 0.1012 - val_acc: 0.8974\n",
            "Epoch 2501/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8853 - val_loss: 0.1003 - val_acc: 0.8968\n",
            "Epoch 2502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8768 - val_loss: 0.1002 - val_acc: 0.8960\n",
            "Epoch 2503/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8863 - val_loss: 0.1007 - val_acc: 0.8952\n",
            "Epoch 2504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8858 - val_loss: 0.1011 - val_acc: 0.8948\n",
            "Epoch 2505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8856 - val_loss: 0.1008 - val_acc: 0.8950\n",
            "Epoch 2506/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8810 - val_loss: 0.1000 - val_acc: 0.8957\n",
            "Epoch 2507/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8787 - val_loss: 0.0994 - val_acc: 0.8964\n",
            "Epoch 2508/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8878 - val_loss: 0.0992 - val_acc: 0.8968\n",
            "Epoch 2509/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8901 - val_loss: 0.0993 - val_acc: 0.8970\n",
            "Epoch 2510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8828 - val_loss: 0.0991 - val_acc: 0.8969\n",
            "Epoch 2511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8910 - val_loss: 0.0986 - val_acc: 0.8965\n",
            "Epoch 2512/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8785 - val_loss: 0.0982 - val_acc: 0.8959\n",
            "Epoch 2513/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8780 - val_loss: 0.0981 - val_acc: 0.8954\n",
            "Epoch 2514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1687 - acc: 0.8764 - val_loss: 0.0990 - val_acc: 0.8944\n",
            "Epoch 2515/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8701 - val_loss: 0.0996 - val_acc: 0.8939\n",
            "Epoch 2516/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8812 - val_loss: 0.0992 - val_acc: 0.8943\n",
            "Epoch 2517/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2422 - acc: 0.8568 - val_loss: 0.0995 - val_acc: 0.8952\n",
            "Epoch 2518/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8890 - val_loss: 0.1000 - val_acc: 0.8960\n",
            "Epoch 2519/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2794 - acc: 0.8601 - val_loss: 0.1022 - val_acc: 0.8961\n",
            "Epoch 2520/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8856 - val_loss: 0.1037 - val_acc: 0.8963\n",
            "Epoch 2521/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8893 - val_loss: 0.1042 - val_acc: 0.8968\n",
            "Epoch 2522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8838 - val_loss: 0.1041 - val_acc: 0.8973\n",
            "Epoch 2523/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8848 - val_loss: 0.1040 - val_acc: 0.8977\n",
            "Epoch 2524/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1197 - acc: 0.8786 - val_loss: 0.1041 - val_acc: 0.8978\n",
            "Epoch 2525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8831 - val_loss: 0.1040 - val_acc: 0.8978\n",
            "Epoch 2526/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8878 - val_loss: 0.1035 - val_acc: 0.8978\n",
            "Epoch 2527/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8875 - val_loss: 0.1028 - val_acc: 0.8977\n",
            "Epoch 2528/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8874 - val_loss: 0.1023 - val_acc: 0.8975\n",
            "Epoch 2529/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8960 - val_loss: 0.1021 - val_acc: 0.8973\n",
            "Epoch 2530/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2173 - acc: 0.8746 - val_loss: 0.1028 - val_acc: 0.8970\n",
            "Epoch 2531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8862 - val_loss: 0.1036 - val_acc: 0.8968\n",
            "Epoch 2532/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8922 - val_loss: 0.1038 - val_acc: 0.8968\n",
            "Epoch 2533/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1745 - acc: 0.8782 - val_loss: 0.1046 - val_acc: 0.8968\n",
            "Epoch 2534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8885 - val_loss: 0.1045 - val_acc: 0.8971\n",
            "Epoch 2535/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8869 - val_loss: 0.1037 - val_acc: 0.8975\n",
            "Epoch 2536/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8859 - val_loss: 0.1030 - val_acc: 0.8979\n",
            "Epoch 2537/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8866 - val_loss: 0.1027 - val_acc: 0.8981\n",
            "Epoch 2538/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8849 - val_loss: 0.1025 - val_acc: 0.8982\n",
            "Epoch 2539/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8869 - val_loss: 0.1022 - val_acc: 0.8981\n",
            "Epoch 2540/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8757 - val_loss: 0.1016 - val_acc: 0.8979\n",
            "Epoch 2541/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8992 - val_loss: 0.1010 - val_acc: 0.8976\n",
            "Epoch 2542/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1727 - acc: 0.8784 - val_loss: 0.1010 - val_acc: 0.8972\n",
            "Epoch 2543/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8887 - val_loss: 0.1013 - val_acc: 0.8968\n",
            "Epoch 2544/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8898 - val_loss: 0.1013 - val_acc: 0.8967\n",
            "Epoch 2545/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1692 - acc: 0.8753 - val_loss: 0.1015 - val_acc: 0.8966\n",
            "Epoch 2546/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2081 - acc: 0.8644 - val_loss: 0.1029 - val_acc: 0.8963\n",
            "Epoch 2547/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8890 - val_loss: 0.1034 - val_acc: 0.8964\n",
            "Epoch 2548/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8891 - val_loss: 0.1030 - val_acc: 0.8968\n",
            "Epoch 2549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8824 - val_loss: 0.1022 - val_acc: 0.8973\n",
            "Epoch 2550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8858 - val_loss: 0.1017 - val_acc: 0.8977\n",
            "Epoch 2551/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8862 - val_loss: 0.1015 - val_acc: 0.8979\n",
            "Epoch 2552/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8917 - val_loss: 0.1013 - val_acc: 0.8980\n",
            "Epoch 2553/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8897 - val_loss: 0.1008 - val_acc: 0.8978\n",
            "Epoch 2554/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1610 - acc: 0.8919 - val_loss: 0.1005 - val_acc: 0.8974\n",
            "Epoch 2555/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1699 - acc: 0.8776 - val_loss: 0.1010 - val_acc: 0.8968\n",
            "Epoch 2556/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8845 - val_loss: 0.1017 - val_acc: 0.8963\n",
            "Epoch 2557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8829 - val_loss: 0.1018 - val_acc: 0.8961\n",
            "Epoch 2558/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8750 - val_loss: 0.1014 - val_acc: 0.8963\n",
            "Epoch 2559/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8774 - val_loss: 0.1007 - val_acc: 0.8966\n",
            "Epoch 2560/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8844 - val_loss: 0.1003 - val_acc: 0.8970\n",
            "Epoch 2561/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8838 - val_loss: 0.1002 - val_acc: 0.8972\n",
            "Epoch 2562/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8735 - val_loss: 0.0999 - val_acc: 0.8973\n",
            "Epoch 2563/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8891 - val_loss: 0.0994 - val_acc: 0.8971\n",
            "Epoch 2564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8924 - val_loss: 0.0990 - val_acc: 0.8968\n",
            "Epoch 2565/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8820 - val_loss: 0.0989 - val_acc: 0.8963\n",
            "Epoch 2566/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8852 - val_loss: 0.0990 - val_acc: 0.8958\n",
            "Epoch 2567/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8848 - val_loss: 0.0989 - val_acc: 0.8956\n",
            "Epoch 2568/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1852 - acc: 0.8702 - val_loss: 0.0992 - val_acc: 0.8954\n",
            "Epoch 2569/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8843 - val_loss: 0.0991 - val_acc: 0.8956\n",
            "Epoch 2570/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1249 - acc: 0.8798 - val_loss: 0.0990 - val_acc: 0.8959\n",
            "Epoch 2571/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8845 - val_loss: 0.0989 - val_acc: 0.8964\n",
            "Epoch 2572/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8822 - val_loss: 0.0988 - val_acc: 0.8968\n",
            "Epoch 2573/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8828 - val_loss: 0.0985 - val_acc: 0.8970\n",
            "Epoch 2574/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2217 - acc: 0.8707 - val_loss: 0.0987 - val_acc: 0.8968\n",
            "Epoch 2575/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2411 - acc: 0.8651 - val_loss: 0.1001 - val_acc: 0.8963\n",
            "Epoch 2576/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1708 - acc: 0.8734 - val_loss: 0.1030 - val_acc: 0.8957\n",
            "Epoch 2577/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8883 - val_loss: 0.1047 - val_acc: 0.8958\n",
            "Epoch 2578/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1404 - acc: 0.8822 - val_loss: 0.1055 - val_acc: 0.8963\n",
            "Epoch 2579/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8787 - val_loss: 0.1052 - val_acc: 0.8971\n",
            "Epoch 2580/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1207 - acc: 0.8798 - val_loss: 0.1048 - val_acc: 0.8977\n",
            "Epoch 2581/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8836 - val_loss: 0.1050 - val_acc: 0.8981\n",
            "Epoch 2582/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2184 - acc: 0.8742 - val_loss: 0.1066 - val_acc: 0.8983\n",
            "Epoch 2583/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1403 - acc: 0.8846 - val_loss: 0.1076 - val_acc: 0.8983\n",
            "Epoch 2584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8871 - val_loss: 0.1077 - val_acc: 0.8982\n",
            "Epoch 2585/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8871 - val_loss: 0.1075 - val_acc: 0.8981\n",
            "Epoch 2586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8946 - val_loss: 0.1073 - val_acc: 0.8979\n",
            "Epoch 2587/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8888 - val_loss: 0.1070 - val_acc: 0.8977\n",
            "Epoch 2588/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8886 - val_loss: 0.1064 - val_acc: 0.8977\n",
            "Epoch 2589/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8828 - val_loss: 0.1055 - val_acc: 0.8977\n",
            "Epoch 2590/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1213 - acc: 0.8809 - val_loss: 0.1047 - val_acc: 0.8977\n",
            "Epoch 2591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8897 - val_loss: 0.1038 - val_acc: 0.8977\n",
            "Epoch 2592/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1289 - acc: 0.8862 - val_loss: 0.1032 - val_acc: 0.8979\n",
            "Epoch 2593/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8868 - val_loss: 0.1026 - val_acc: 0.8979\n",
            "Epoch 2594/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8869 - val_loss: 0.1020 - val_acc: 0.8979\n",
            "Epoch 2595/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8852 - val_loss: 0.1013 - val_acc: 0.8978\n",
            "Epoch 2596/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8850 - val_loss: 0.1006 - val_acc: 0.8975\n",
            "Epoch 2597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8826 - val_loss: 0.1000 - val_acc: 0.8972\n",
            "Epoch 2598/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8786 - val_loss: 0.0996 - val_acc: 0.8969\n",
            "Epoch 2599/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8783 - val_loss: 0.0992 - val_acc: 0.8968\n",
            "Epoch 2600/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8829 - val_loss: 0.0988 - val_acc: 0.8968\n",
            "Epoch 2601/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8831 - val_loss: 0.0985 - val_acc: 0.8967\n",
            "Epoch 2602/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8816 - val_loss: 0.0982 - val_acc: 0.8968\n",
            "Epoch 2603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 0.8701 - val_loss: 0.0981 - val_acc: 0.8965\n",
            "Epoch 2604/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8838 - val_loss: 0.0981 - val_acc: 0.8961\n",
            "Epoch 2605/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8895 - val_loss: 0.0980 - val_acc: 0.8960\n",
            "Epoch 2606/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8828 - val_loss: 0.0978 - val_acc: 0.8960\n",
            "Epoch 2607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1266 - acc: 0.8830 - val_loss: 0.0976 - val_acc: 0.8961\n",
            "Epoch 2608/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8791 - val_loss: 0.0975 - val_acc: 0.8962\n",
            "Epoch 2609/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8798 - val_loss: 0.0974 - val_acc: 0.8960\n",
            "Epoch 2610/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8930 - val_loss: 0.0973 - val_acc: 0.8959\n",
            "Epoch 2611/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8928 - val_loss: 0.0972 - val_acc: 0.8957\n",
            "Epoch 2612/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8893 - val_loss: 0.0972 - val_acc: 0.8955\n",
            "Epoch 2613/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8851 - val_loss: 0.0971 - val_acc: 0.8955\n",
            "Epoch 2614/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8885 - val_loss: 0.0970 - val_acc: 0.8957\n",
            "Epoch 2615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8887 - val_loss: 0.0971 - val_acc: 0.8959\n",
            "Epoch 2616/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8876 - val_loss: 0.0971 - val_acc: 0.8957\n",
            "Epoch 2617/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8923 - val_loss: 0.0970 - val_acc: 0.8956\n",
            "Epoch 2618/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8822 - val_loss: 0.0969 - val_acc: 0.8953\n",
            "Epoch 2619/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8819 - val_loss: 0.0970 - val_acc: 0.8950\n",
            "Epoch 2620/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1635 - acc: 0.8761 - val_loss: 0.0972 - val_acc: 0.8947\n",
            "Epoch 2621/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8898 - val_loss: 0.0972 - val_acc: 0.8949\n",
            "Epoch 2622/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8730 - val_loss: 0.0972 - val_acc: 0.8953\n",
            "Epoch 2623/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8793 - val_loss: 0.0971 - val_acc: 0.8957\n",
            "Epoch 2624/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1233 - acc: 0.8773 - val_loss: 0.0970 - val_acc: 0.8959\n",
            "Epoch 2625/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1767 - acc: 0.8718 - val_loss: 0.0970 - val_acc: 0.8958\n",
            "Epoch 2626/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8837 - val_loss: 0.0972 - val_acc: 0.8957\n",
            "Epoch 2627/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8825 - val_loss: 0.0973 - val_acc: 0.8958\n",
            "Epoch 2628/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8716 - val_loss: 0.0973 - val_acc: 0.8961\n",
            "Epoch 2629/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8916 - val_loss: 0.0973 - val_acc: 0.8965\n",
            "Epoch 2630/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8885 - val_loss: 0.0973 - val_acc: 0.8968\n",
            "Epoch 2631/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8876 - val_loss: 0.0974 - val_acc: 0.8970\n",
            "Epoch 2632/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8878 - val_loss: 0.0974 - val_acc: 0.8970\n",
            "Epoch 2633/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8902 - val_loss: 0.0973 - val_acc: 0.8968\n",
            "Epoch 2634/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8884 - val_loss: 0.0973 - val_acc: 0.8966\n",
            "Epoch 2635/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8772 - val_loss: 0.0973 - val_acc: 0.8964\n",
            "Epoch 2636/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8740 - val_loss: 0.0972 - val_acc: 0.8963\n",
            "Epoch 2637/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8729 - val_loss: 0.0972 - val_acc: 0.8963\n",
            "Epoch 2638/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1445 - acc: 0.8772 - val_loss: 0.0973 - val_acc: 0.8963\n",
            "Epoch 2639/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2648 - acc: 0.8566 - val_loss: 0.0985 - val_acc: 0.8957\n",
            "Epoch 2640/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2345 - acc: 0.8575 - val_loss: 0.1018 - val_acc: 0.8950\n",
            "Epoch 2641/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8815 - val_loss: 0.1036 - val_acc: 0.8953\n",
            "Epoch 2642/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8817 - val_loss: 0.1034 - val_acc: 0.8963\n",
            "Epoch 2643/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8820 - val_loss: 0.1026 - val_acc: 0.8975\n",
            "Epoch 2644/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1703 - acc: 0.8719 - val_loss: 0.1032 - val_acc: 0.8980\n",
            "Epoch 2645/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8862 - val_loss: 0.1039 - val_acc: 0.8983\n",
            "Epoch 2646/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8961 - val_loss: 0.1045 - val_acc: 0.8984\n",
            "Epoch 2647/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8965 - val_loss: 0.1044 - val_acc: 0.8984\n",
            "Epoch 2648/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8852 - val_loss: 0.1037 - val_acc: 0.8982\n",
            "Epoch 2649/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8919 - val_loss: 0.1032 - val_acc: 0.8978\n",
            "Epoch 2650/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8833 - val_loss: 0.1030 - val_acc: 0.8974\n",
            "Epoch 2651/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8828 - val_loss: 0.1031 - val_acc: 0.8970\n",
            "Epoch 2652/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8841 - val_loss: 0.1032 - val_acc: 0.8968\n",
            "Epoch 2653/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8930 - val_loss: 0.1026 - val_acc: 0.8970\n",
            "Epoch 2654/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1170 - acc: 0.8791 - val_loss: 0.1019 - val_acc: 0.8972\n",
            "Epoch 2655/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1452 - acc: 0.8836 - val_loss: 0.1015 - val_acc: 0.8974\n",
            "Epoch 2656/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8903 - val_loss: 0.1012 - val_acc: 0.8976\n",
            "Epoch 2657/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8901 - val_loss: 0.1010 - val_acc: 0.8978\n",
            "Epoch 2658/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8813 - val_loss: 0.1005 - val_acc: 0.8978\n",
            "Epoch 2659/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8906 - val_loss: 0.1000 - val_acc: 0.8977\n",
            "Epoch 2660/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8870 - val_loss: 0.0995 - val_acc: 0.8974\n",
            "Epoch 2661/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8863 - val_loss: 0.0991 - val_acc: 0.8971\n",
            "Epoch 2662/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8877 - val_loss: 0.0989 - val_acc: 0.8970\n",
            "Epoch 2663/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8817 - val_loss: 0.0985 - val_acc: 0.8969\n",
            "Epoch 2664/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8906 - val_loss: 0.0982 - val_acc: 0.8968\n",
            "Epoch 2665/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8822 - val_loss: 0.0980 - val_acc: 0.8967\n",
            "Epoch 2666/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8841 - val_loss: 0.0978 - val_acc: 0.8965\n",
            "Epoch 2667/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8914 - val_loss: 0.0976 - val_acc: 0.8964\n",
            "Epoch 2668/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2251 - acc: 0.8711 - val_loss: 0.0986 - val_acc: 0.8957\n",
            "Epoch 2669/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8798 - val_loss: 0.0995 - val_acc: 0.8952\n",
            "Epoch 2670/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8793 - val_loss: 0.0996 - val_acc: 0.8952\n",
            "Epoch 2671/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8800 - val_loss: 0.0987 - val_acc: 0.8959\n",
            "Epoch 2672/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8788 - val_loss: 0.0980 - val_acc: 0.8966\n",
            "Epoch 2673/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8913 - val_loss: 0.0981 - val_acc: 0.8971\n",
            "Epoch 2674/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8920 - val_loss: 0.0985 - val_acc: 0.8972\n",
            "Epoch 2675/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8868 - val_loss: 0.0984 - val_acc: 0.8970\n",
            "Epoch 2676/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8880 - val_loss: 0.0978 - val_acc: 0.8965\n",
            "Epoch 2677/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8822 - val_loss: 0.0976 - val_acc: 0.8957\n",
            "Epoch 2678/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8818 - val_loss: 0.0978 - val_acc: 0.8950\n",
            "Epoch 2679/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8907 - val_loss: 0.0979 - val_acc: 0.8948\n",
            "Epoch 2680/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2217 - acc: 0.8640 - val_loss: 0.0986 - val_acc: 0.8945\n",
            "Epoch 2681/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8902 - val_loss: 0.0985 - val_acc: 0.8949\n",
            "Epoch 2682/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8888 - val_loss: 0.0981 - val_acc: 0.8959\n",
            "Epoch 2683/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8881 - val_loss: 0.0982 - val_acc: 0.8967\n",
            "Epoch 2684/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8871 - val_loss: 0.0983 - val_acc: 0.8971\n",
            "Epoch 2685/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8876 - val_loss: 0.0981 - val_acc: 0.8972\n",
            "Epoch 2686/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8839 - val_loss: 0.0978 - val_acc: 0.8969\n",
            "Epoch 2687/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8869 - val_loss: 0.0978 - val_acc: 0.8965\n",
            "Epoch 2688/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8823 - val_loss: 0.0980 - val_acc: 0.8961\n",
            "Epoch 2689/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8820 - val_loss: 0.0981 - val_acc: 0.8959\n",
            "Epoch 2690/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8849 - val_loss: 0.0978 - val_acc: 0.8961\n",
            "Epoch 2691/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1919 - acc: 0.8600 - val_loss: 0.0980 - val_acc: 0.8963\n",
            "Epoch 2692/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8897 - val_loss: 0.0979 - val_acc: 0.8966\n",
            "Epoch 2693/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8905 - val_loss: 0.0977 - val_acc: 0.8969\n",
            "Epoch 2694/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1662 - acc: 0.8726 - val_loss: 0.0979 - val_acc: 0.8970\n",
            "Epoch 2695/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8884 - val_loss: 0.0982 - val_acc: 0.8968\n",
            "Epoch 2696/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8938 - val_loss: 0.0983 - val_acc: 0.8968\n",
            "Epoch 2697/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8817 - val_loss: 0.0982 - val_acc: 0.8967\n",
            "Epoch 2698/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8959 - val_loss: 0.0980 - val_acc: 0.8968\n",
            "Epoch 2699/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8961 - val_loss: 0.0978 - val_acc: 0.8971\n",
            "Epoch 2700/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8883 - val_loss: 0.0977 - val_acc: 0.8972\n",
            "Epoch 2701/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8887 - val_loss: 0.0978 - val_acc: 0.8973\n",
            "Epoch 2702/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1303 - acc: 0.8861 - val_loss: 0.0977 - val_acc: 0.8971\n",
            "Epoch 2703/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2644 - acc: 0.8644 - val_loss: 0.1002 - val_acc: 0.8958\n",
            "Epoch 2704/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8802 - val_loss: 0.1032 - val_acc: 0.8948\n",
            "Epoch 2705/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8805 - val_loss: 0.1038 - val_acc: 0.8950\n",
            "Epoch 2706/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8891 - val_loss: 0.1019 - val_acc: 0.8962\n",
            "Epoch 2707/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8941 - val_loss: 0.1003 - val_acc: 0.8974\n",
            "Epoch 2708/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8832 - val_loss: 0.1005 - val_acc: 0.8979\n",
            "Epoch 2709/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8891 - val_loss: 0.1015 - val_acc: 0.8981\n",
            "Epoch 2710/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8893 - val_loss: 0.1012 - val_acc: 0.8980\n",
            "Epoch 2711/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8841 - val_loss: 0.0998 - val_acc: 0.8977\n",
            "Epoch 2712/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1557 - acc: 0.8853 - val_loss: 0.0992 - val_acc: 0.8971\n",
            "Epoch 2713/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8928 - val_loss: 0.0999 - val_acc: 0.8964\n",
            "Epoch 2714/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8887 - val_loss: 0.1008 - val_acc: 0.8958\n",
            "Epoch 2715/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8947 - val_loss: 0.1005 - val_acc: 0.8959\n",
            "Epoch 2716/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1206 - acc: 0.8744 - val_loss: 0.0995 - val_acc: 0.8965\n",
            "Epoch 2717/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8951 - val_loss: 0.0986 - val_acc: 0.8971\n",
            "Epoch 2718/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1196 - acc: 0.8739 - val_loss: 0.0985 - val_acc: 0.8975\n",
            "Epoch 2719/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8842 - val_loss: 0.0987 - val_acc: 0.8977\n",
            "Epoch 2720/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1703 - acc: 0.8807 - val_loss: 0.0984 - val_acc: 0.8977\n",
            "Epoch 2721/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8928 - val_loss: 0.0980 - val_acc: 0.8974\n",
            "Epoch 2722/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1408 - acc: 0.8894 - val_loss: 0.0982 - val_acc: 0.8971\n",
            "Epoch 2723/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1311 - acc: 0.8924 - val_loss: 0.0987 - val_acc: 0.8967\n",
            "Epoch 2724/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8980 - val_loss: 0.0990 - val_acc: 0.8966\n",
            "Epoch 2725/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8843 - val_loss: 0.0988 - val_acc: 0.8966\n",
            "Epoch 2726/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8853 - val_loss: 0.0983 - val_acc: 0.8968\n",
            "Epoch 2727/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8915 - val_loss: 0.0981 - val_acc: 0.8970\n",
            "Epoch 2728/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8815 - val_loss: 0.0981 - val_acc: 0.8971\n",
            "Epoch 2729/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8848 - val_loss: 0.0980 - val_acc: 0.8970\n",
            "Epoch 2730/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8859 - val_loss: 0.0976 - val_acc: 0.8968\n",
            "Epoch 2731/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8837 - val_loss: 0.0973 - val_acc: 0.8964\n",
            "Epoch 2732/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8982 - val_loss: 0.0973 - val_acc: 0.8961\n",
            "Epoch 2733/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8857 - val_loss: 0.0973 - val_acc: 0.8960\n",
            "Epoch 2734/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8857 - val_loss: 0.0970 - val_acc: 0.8961\n",
            "Epoch 2735/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2589 - acc: 0.8562 - val_loss: 0.0983 - val_acc: 0.8953\n",
            "Epoch 2736/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8729 - val_loss: 0.0993 - val_acc: 0.8950\n",
            "Epoch 2737/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1875 - acc: 0.8645 - val_loss: 0.0993 - val_acc: 0.8958\n",
            "Epoch 2738/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8930 - val_loss: 0.0991 - val_acc: 0.8968\n",
            "Epoch 2739/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1417 - acc: 0.8787 - val_loss: 0.0996 - val_acc: 0.8975\n",
            "Epoch 2740/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8870 - val_loss: 0.0999 - val_acc: 0.8978\n",
            "Epoch 2741/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2133 - acc: 0.8702 - val_loss: 0.1011 - val_acc: 0.8978\n",
            "Epoch 2742/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2072 - acc: 0.8700 - val_loss: 0.1036 - val_acc: 0.8977\n",
            "Epoch 2743/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8837 - val_loss: 0.1058 - val_acc: 0.8976\n",
            "Epoch 2744/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8837 - val_loss: 0.1067 - val_acc: 0.8977\n",
            "Epoch 2745/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8935 - val_loss: 0.1063 - val_acc: 0.8979\n",
            "Epoch 2746/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8869 - val_loss: 0.1056 - val_acc: 0.8980\n",
            "Epoch 2747/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8881 - val_loss: 0.1048 - val_acc: 0.8981\n",
            "Epoch 2748/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8794 - val_loss: 0.1043 - val_acc: 0.8981\n",
            "Epoch 2749/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1938 - acc: 0.8728 - val_loss: 0.1044 - val_acc: 0.8980\n",
            "Epoch 2750/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8829 - val_loss: 0.1043 - val_acc: 0.8979\n",
            "Epoch 2751/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8876 - val_loss: 0.1042 - val_acc: 0.8977\n",
            "Epoch 2752/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1321 - acc: 0.8792 - val_loss: 0.1040 - val_acc: 0.8976\n",
            "Epoch 2753/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1202 - acc: 0.8736 - val_loss: 0.1039 - val_acc: 0.8976\n",
            "Epoch 2754/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8879 - val_loss: 0.1035 - val_acc: 0.8976\n",
            "Epoch 2755/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8879 - val_loss: 0.1028 - val_acc: 0.8977\n",
            "Epoch 2756/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8942 - val_loss: 0.1020 - val_acc: 0.8979\n",
            "Epoch 2757/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8945 - val_loss: 0.1013 - val_acc: 0.8981\n",
            "Epoch 2758/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8868 - val_loss: 0.1007 - val_acc: 0.8981\n",
            "Epoch 2759/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8814 - val_loss: 0.1000 - val_acc: 0.8980\n",
            "Epoch 2760/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8814 - val_loss: 0.0995 - val_acc: 0.8977\n",
            "Epoch 2761/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8891 - val_loss: 0.0990 - val_acc: 0.8974\n",
            "Epoch 2762/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8913 - val_loss: 0.0986 - val_acc: 0.8970\n",
            "Epoch 2763/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8860 - val_loss: 0.0982 - val_acc: 0.8968\n",
            "Epoch 2764/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1342 - acc: 0.8796 - val_loss: 0.0978 - val_acc: 0.8967\n",
            "Epoch 2765/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8788 - val_loss: 0.0976 - val_acc: 0.8966\n",
            "Epoch 2766/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8912 - val_loss: 0.0974 - val_acc: 0.8966\n",
            "Epoch 2767/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8938 - val_loss: 0.0974 - val_acc: 0.8967\n",
            "Epoch 2768/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8843 - val_loss: 0.0972 - val_acc: 0.8967\n",
            "Epoch 2769/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8789 - val_loss: 0.0968 - val_acc: 0.8963\n",
            "Epoch 2770/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8786 - val_loss: 0.0967 - val_acc: 0.8959\n",
            "Epoch 2771/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8757 - val_loss: 0.0968 - val_acc: 0.8954\n",
            "Epoch 2772/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8853 - val_loss: 0.0968 - val_acc: 0.8954\n",
            "Epoch 2773/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2207 - acc: 0.8669 - val_loss: 0.0973 - val_acc: 0.8951\n",
            "Epoch 2774/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8875 - val_loss: 0.0976 - val_acc: 0.8952\n",
            "Epoch 2775/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1880 - acc: 0.8721 - val_loss: 0.0984 - val_acc: 0.8951\n",
            "Epoch 2776/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8963 - val_loss: 0.0983 - val_acc: 0.8955\n",
            "Epoch 2777/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8861 - val_loss: 0.0978 - val_acc: 0.8963\n",
            "Epoch 2778/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8871 - val_loss: 0.0977 - val_acc: 0.8969\n",
            "Epoch 2779/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8925 - val_loss: 0.0982 - val_acc: 0.8972\n",
            "Epoch 2780/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2247 - acc: 0.8702 - val_loss: 0.0987 - val_acc: 0.8968\n",
            "Epoch 2781/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8819 - val_loss: 0.0996 - val_acc: 0.8962\n",
            "Epoch 2782/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8811 - val_loss: 0.1005 - val_acc: 0.8958\n",
            "Epoch 2783/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8859 - val_loss: 0.1008 - val_acc: 0.8959\n",
            "Epoch 2784/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8850 - val_loss: 0.1003 - val_acc: 0.8964\n",
            "Epoch 2785/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8858 - val_loss: 0.0998 - val_acc: 0.8971\n",
            "Epoch 2786/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2382 - acc: 0.8600 - val_loss: 0.1007 - val_acc: 0.8973\n",
            "Epoch 2787/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8809 - val_loss: 0.1013 - val_acc: 0.8974\n",
            "Epoch 2788/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2080 - acc: 0.8678 - val_loss: 0.1030 - val_acc: 0.8974\n",
            "Epoch 2789/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8839 - val_loss: 0.1042 - val_acc: 0.8974\n",
            "Epoch 2790/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8846 - val_loss: 0.1045 - val_acc: 0.8976\n",
            "Epoch 2791/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8915 - val_loss: 0.1043 - val_acc: 0.8978\n",
            "Epoch 2792/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8897 - val_loss: 0.1038 - val_acc: 0.8980\n",
            "Epoch 2793/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2468 - acc: 0.8585 - val_loss: 0.1048 - val_acc: 0.8981\n",
            "Epoch 2794/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8809 - val_loss: 0.1054 - val_acc: 0.8981\n",
            "Epoch 2795/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8848 - val_loss: 0.1055 - val_acc: 0.8981\n",
            "Epoch 2796/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2093 - acc: 0.8735 - val_loss: 0.1066 - val_acc: 0.8981\n",
            "Epoch 2797/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8855 - val_loss: 0.1072 - val_acc: 0.8981\n",
            "Epoch 2798/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8901 - val_loss: 0.1070 - val_acc: 0.8981\n",
            "Epoch 2799/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8901 - val_loss: 0.1062 - val_acc: 0.8982\n",
            "Epoch 2800/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8949 - val_loss: 0.1051 - val_acc: 0.8982\n",
            "Epoch 2801/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8951 - val_loss: 0.1042 - val_acc: 0.8983\n",
            "Epoch 2802/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1295 - acc: 0.8803 - val_loss: 0.1037 - val_acc: 0.8982\n",
            "Epoch 2803/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8905 - val_loss: 0.1030 - val_acc: 0.8981\n",
            "Epoch 2804/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1184 - acc: 0.8817 - val_loss: 0.1023 - val_acc: 0.8978\n",
            "Epoch 2805/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8947 - val_loss: 0.1016 - val_acc: 0.8975\n",
            "Epoch 2806/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1609 - acc: 0.8872 - val_loss: 0.1013 - val_acc: 0.8973\n",
            "Epoch 2807/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8980 - val_loss: 0.1010 - val_acc: 0.8972\n",
            "Epoch 2808/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8868 - val_loss: 0.1005 - val_acc: 0.8972\n",
            "Epoch 2809/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8934 - val_loss: 0.0999 - val_acc: 0.8972\n",
            "Epoch 2810/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1267 - acc: 0.8853 - val_loss: 0.0995 - val_acc: 0.8972\n",
            "Epoch 2811/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8863 - val_loss: 0.0992 - val_acc: 0.8973\n",
            "Epoch 2812/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8864 - val_loss: 0.0989 - val_acc: 0.8973\n",
            "Epoch 2813/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8838 - val_loss: 0.0986 - val_acc: 0.8973\n",
            "Epoch 2814/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2267 - acc: 0.8615 - val_loss: 0.0992 - val_acc: 0.8969\n",
            "Epoch 2815/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2435 - acc: 0.8582 - val_loss: 0.1018 - val_acc: 0.8962\n",
            "Epoch 2816/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8891 - val_loss: 0.1038 - val_acc: 0.8960\n",
            "Epoch 2817/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8891 - val_loss: 0.1039 - val_acc: 0.8964\n",
            "Epoch 2818/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8853 - val_loss: 0.1030 - val_acc: 0.8972\n",
            "Epoch 2819/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8839 - val_loss: 0.1021 - val_acc: 0.8978\n",
            "Epoch 2820/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8850 - val_loss: 0.1021 - val_acc: 0.8982\n",
            "Epoch 2821/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8891 - val_loss: 0.1022 - val_acc: 0.8983\n",
            "Epoch 2822/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8894 - val_loss: 0.1013 - val_acc: 0.8981\n",
            "Epoch 2823/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8875 - val_loss: 0.1001 - val_acc: 0.8976\n",
            "Epoch 2824/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8961 - val_loss: 0.0997 - val_acc: 0.8969\n",
            "Epoch 2825/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8868 - val_loss: 0.0999 - val_acc: 0.8962\n",
            "Epoch 2826/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1631 - acc: 0.8756 - val_loss: 0.1011 - val_acc: 0.8953\n",
            "Epoch 2827/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8879 - val_loss: 0.1018 - val_acc: 0.8948\n",
            "Epoch 2828/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8879 - val_loss: 0.1013 - val_acc: 0.8951\n",
            "Epoch 2829/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8906 - val_loss: 0.0998 - val_acc: 0.8961\n",
            "Epoch 2830/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8817 - val_loss: 0.0988 - val_acc: 0.8970\n",
            "Epoch 2831/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8870 - val_loss: 0.0987 - val_acc: 0.8975\n",
            "Epoch 2832/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8848 - val_loss: 0.0987 - val_acc: 0.8977\n",
            "Epoch 2833/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8844 - val_loss: 0.0981 - val_acc: 0.8976\n",
            "Epoch 2834/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8851 - val_loss: 0.0975 - val_acc: 0.8971\n",
            "Epoch 2835/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8938 - val_loss: 0.0975 - val_acc: 0.8963\n",
            "Epoch 2836/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8932 - val_loss: 0.0978 - val_acc: 0.8956\n",
            "Epoch 2837/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8879 - val_loss: 0.0978 - val_acc: 0.8954\n",
            "Epoch 2838/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8882 - val_loss: 0.0971 - val_acc: 0.8958\n",
            "Epoch 2839/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2209 - acc: 0.8577 - val_loss: 0.0975 - val_acc: 0.8958\n",
            "Epoch 2840/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8811 - val_loss: 0.0975 - val_acc: 0.8960\n",
            "Epoch 2841/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8818 - val_loss: 0.0973 - val_acc: 0.8964\n",
            "Epoch 2842/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1162 - acc: 0.8831 - val_loss: 0.0972 - val_acc: 0.8968\n",
            "Epoch 2843/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8847 - val_loss: 0.0972 - val_acc: 0.8968\n",
            "Epoch 2844/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8911 - val_loss: 0.0971 - val_acc: 0.8968\n",
            "Epoch 2845/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1392 - acc: 0.8858 - val_loss: 0.0971 - val_acc: 0.8966\n",
            "Epoch 2846/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8922 - val_loss: 0.0971 - val_acc: 0.8963\n",
            "Epoch 2847/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8919 - val_loss: 0.0970 - val_acc: 0.8962\n",
            "Epoch 2848/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8917 - val_loss: 0.0969 - val_acc: 0.8961\n",
            "Epoch 2849/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8860 - val_loss: 0.0967 - val_acc: 0.8962\n",
            "Epoch 2850/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8873 - val_loss: 0.0966 - val_acc: 0.8964\n",
            "Epoch 2851/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8874 - val_loss: 0.0965 - val_acc: 0.8964\n",
            "Epoch 2852/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1699 - acc: 0.8760 - val_loss: 0.0966 - val_acc: 0.8961\n",
            "Epoch 2853/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8798 - val_loss: 0.0969 - val_acc: 0.8958\n",
            "Epoch 2854/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8791 - val_loss: 0.0969 - val_acc: 0.8958\n",
            "Epoch 2855/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1993 - acc: 0.8626 - val_loss: 0.0973 - val_acc: 0.8958\n",
            "Epoch 2856/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8787 - val_loss: 0.0976 - val_acc: 0.8962\n",
            "Epoch 2857/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1275 - acc: 0.8875 - val_loss: 0.0981 - val_acc: 0.8965\n",
            "Epoch 2858/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8860 - val_loss: 0.0984 - val_acc: 0.8969\n",
            "Epoch 2859/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8826 - val_loss: 0.0983 - val_acc: 0.8972\n",
            "Epoch 2860/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8831 - val_loss: 0.0983 - val_acc: 0.8973\n",
            "Epoch 2861/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8956 - val_loss: 0.0982 - val_acc: 0.8973\n",
            "Epoch 2862/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8912 - val_loss: 0.0982 - val_acc: 0.8971\n",
            "Epoch 2863/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8891 - val_loss: 0.0981 - val_acc: 0.8967\n",
            "Epoch 2864/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8865 - val_loss: 0.0979 - val_acc: 0.8964\n",
            "Epoch 2865/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2277 - acc: 0.8649 - val_loss: 0.0987 - val_acc: 0.8960\n",
            "Epoch 2866/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8903 - val_loss: 0.0992 - val_acc: 0.8959\n",
            "Epoch 2867/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1872 - acc: 0.8693 - val_loss: 0.1005 - val_acc: 0.8960\n",
            "Epoch 2868/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8883 - val_loss: 0.1009 - val_acc: 0.8964\n",
            "Epoch 2869/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8826 - val_loss: 0.1004 - val_acc: 0.8971\n",
            "Epoch 2870/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1194 - acc: 0.8704 - val_loss: 0.1000 - val_acc: 0.8977\n",
            "Epoch 2871/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8903 - val_loss: 0.0999 - val_acc: 0.8979\n",
            "Epoch 2872/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1981 - acc: 0.8724 - val_loss: 0.1005 - val_acc: 0.8981\n",
            "Epoch 2873/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1400 - acc: 0.8860 - val_loss: 0.1010 - val_acc: 0.8980\n",
            "Epoch 2874/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1398 - acc: 0.8731 - val_loss: 0.1017 - val_acc: 0.8978\n",
            "Epoch 2875/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8843 - val_loss: 0.1023 - val_acc: 0.8976\n",
            "Epoch 2876/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8838 - val_loss: 0.1024 - val_acc: 0.8974\n",
            "Epoch 2877/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8912 - val_loss: 0.1022 - val_acc: 0.8974\n",
            "Epoch 2878/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8896 - val_loss: 0.1018 - val_acc: 0.8974\n",
            "Epoch 2879/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8915 - val_loss: 0.1014 - val_acc: 0.8976\n",
            "Epoch 2880/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8885 - val_loss: 0.1011 - val_acc: 0.8976\n",
            "Epoch 2881/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1140 - acc: 0.8812 - val_loss: 0.1006 - val_acc: 0.8976\n",
            "Epoch 2882/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1902 - acc: 0.8808 - val_loss: 0.1006 - val_acc: 0.8975\n",
            "Epoch 2883/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8963 - val_loss: 0.1005 - val_acc: 0.8975\n",
            "Epoch 2884/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8878 - val_loss: 0.1003 - val_acc: 0.8973\n",
            "Epoch 2885/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8863 - val_loss: 0.1000 - val_acc: 0.8973\n",
            "Epoch 2886/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8864 - val_loss: 0.0996 - val_acc: 0.8974\n",
            "Epoch 2887/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8904 - val_loss: 0.0992 - val_acc: 0.8974\n",
            "Epoch 2888/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8905 - val_loss: 0.0988 - val_acc: 0.8975\n",
            "Epoch 2889/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8789 - val_loss: 0.0984 - val_acc: 0.8975\n",
            "Epoch 2890/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8874 - val_loss: 0.0980 - val_acc: 0.8975\n",
            "Epoch 2891/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8900 - val_loss: 0.0977 - val_acc: 0.8974\n",
            "Epoch 2892/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8904 - val_loss: 0.0974 - val_acc: 0.8972\n",
            "Epoch 2893/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8850 - val_loss: 0.0971 - val_acc: 0.8970\n",
            "Epoch 2894/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1242 - acc: 0.8844 - val_loss: 0.0970 - val_acc: 0.8967\n",
            "Epoch 2895/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8881 - val_loss: 0.0968 - val_acc: 0.8964\n",
            "Epoch 2896/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8885 - val_loss: 0.0965 - val_acc: 0.8964\n",
            "Epoch 2897/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2055 - acc: 0.8729 - val_loss: 0.0969 - val_acc: 0.8962\n",
            "Epoch 2898/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8916 - val_loss: 0.0973 - val_acc: 0.8962\n",
            "Epoch 2899/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2503 - acc: 0.8588 - val_loss: 0.0994 - val_acc: 0.8960\n",
            "Epoch 2900/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8852 - val_loss: 0.1006 - val_acc: 0.8963\n",
            "Epoch 2901/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8840 - val_loss: 0.1006 - val_acc: 0.8969\n",
            "Epoch 2902/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8818 - val_loss: 0.1000 - val_acc: 0.8974\n",
            "Epoch 2903/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8917 - val_loss: 0.0995 - val_acc: 0.8976\n",
            "Epoch 2904/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8920 - val_loss: 0.0994 - val_acc: 0.8976\n",
            "Epoch 2905/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8854 - val_loss: 0.0993 - val_acc: 0.8973\n",
            "Epoch 2906/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8773 - val_loss: 0.0990 - val_acc: 0.8970\n",
            "Epoch 2907/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8874 - val_loss: 0.0986 - val_acc: 0.8966\n",
            "Epoch 2908/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8871 - val_loss: 0.0984 - val_acc: 0.8963\n",
            "Epoch 2909/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8869 - val_loss: 0.0982 - val_acc: 0.8962\n",
            "Epoch 2910/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8820 - val_loss: 0.0979 - val_acc: 0.8964\n",
            "Epoch 2911/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8792 - val_loss: 0.0977 - val_acc: 0.8967\n",
            "Epoch 2912/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8874 - val_loss: 0.0975 - val_acc: 0.8969\n",
            "Epoch 2913/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2343 - acc: 0.8678 - val_loss: 0.0977 - val_acc: 0.8968\n",
            "Epoch 2914/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8826 - val_loss: 0.0981 - val_acc: 0.8966\n",
            "Epoch 2915/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8838 - val_loss: 0.0984 - val_acc: 0.8966\n",
            "Epoch 2916/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8839 - val_loss: 0.0983 - val_acc: 0.8967\n",
            "Epoch 2917/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8920 - val_loss: 0.0981 - val_acc: 0.8971\n",
            "Epoch 2918/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8923 - val_loss: 0.0980 - val_acc: 0.8974\n",
            "Epoch 2919/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8853 - val_loss: 0.0979 - val_acc: 0.8975\n",
            "Epoch 2920/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2695 - acc: 0.8557 - val_loss: 0.0985 - val_acc: 0.8971\n",
            "Epoch 2921/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8777 - val_loss: 0.0996 - val_acc: 0.8967\n",
            "Epoch 2922/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8936 - val_loss: 0.1003 - val_acc: 0.8965\n",
            "Epoch 2923/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8858 - val_loss: 0.1002 - val_acc: 0.8968\n",
            "Epoch 2924/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8863 - val_loss: 0.0998 - val_acc: 0.8972\n",
            "Epoch 2925/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8866 - val_loss: 0.0995 - val_acc: 0.8975\n",
            "Epoch 2926/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8869 - val_loss: 0.0992 - val_acc: 0.8977\n",
            "Epoch 2927/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1749 - acc: 0.8732 - val_loss: 0.0990 - val_acc: 0.8974\n",
            "Epoch 2928/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1945 - acc: 0.8681 - val_loss: 0.0999 - val_acc: 0.8969\n",
            "Epoch 2929/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8819 - val_loss: 0.1010 - val_acc: 0.8965\n",
            "Epoch 2930/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8816 - val_loss: 0.1013 - val_acc: 0.8965\n",
            "Epoch 2931/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8861 - val_loss: 0.1007 - val_acc: 0.8969\n",
            "Epoch 2932/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8869 - val_loss: 0.1000 - val_acc: 0.8974\n",
            "Epoch 2933/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8959 - val_loss: 0.0998 - val_acc: 0.8978\n",
            "Epoch 2934/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2280 - acc: 0.8728 - val_loss: 0.1007 - val_acc: 0.8981\n",
            "Epoch 2935/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8876 - val_loss: 0.1011 - val_acc: 0.8981\n",
            "Epoch 2936/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8947 - val_loss: 0.1011 - val_acc: 0.8979\n",
            "Epoch 2937/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8957 - val_loss: 0.1009 - val_acc: 0.8977\n",
            "Epoch 2938/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8895 - val_loss: 0.1008 - val_acc: 0.8973\n",
            "Epoch 2939/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8775 - val_loss: 0.1004 - val_acc: 0.8971\n",
            "Epoch 2940/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8873 - val_loss: 0.0998 - val_acc: 0.8970\n",
            "Epoch 2941/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8856 - val_loss: 0.0990 - val_acc: 0.8972\n",
            "Epoch 2942/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8842 - val_loss: 0.0985 - val_acc: 0.8974\n",
            "Epoch 2943/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8749 - val_loss: 0.0981 - val_acc: 0.8974\n",
            "Epoch 2944/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8753 - val_loss: 0.0977 - val_acc: 0.8974\n",
            "Epoch 2945/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8880 - val_loss: 0.0973 - val_acc: 0.8973\n",
            "Epoch 2946/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8890 - val_loss: 0.0970 - val_acc: 0.8970\n",
            "Epoch 2947/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8889 - val_loss: 0.0967 - val_acc: 0.8967\n",
            "Epoch 2948/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8830 - val_loss: 0.0964 - val_acc: 0.8965\n",
            "Epoch 2949/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8827 - val_loss: 0.0962 - val_acc: 0.8964\n",
            "Epoch 2950/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8808 - val_loss: 0.0961 - val_acc: 0.8963\n",
            "Epoch 2951/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8809 - val_loss: 0.0960 - val_acc: 0.8963\n",
            "Epoch 2952/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8889 - val_loss: 0.0958 - val_acc: 0.8963\n",
            "Epoch 2953/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1186 - acc: 0.8777 - val_loss: 0.0957 - val_acc: 0.8964\n",
            "Epoch 2954/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8817 - val_loss: 0.0956 - val_acc: 0.8962\n",
            "Epoch 2955/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2657 - acc: 0.8604 - val_loss: 0.0961 - val_acc: 0.8956\n",
            "Epoch 2956/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1165 - acc: 0.8855 - val_loss: 0.0969 - val_acc: 0.8954\n",
            "Epoch 2957/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8859 - val_loss: 0.0970 - val_acc: 0.8958\n",
            "Epoch 2958/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8948 - val_loss: 0.0967 - val_acc: 0.8965\n",
            "Epoch 2959/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8956 - val_loss: 0.0967 - val_acc: 0.8970\n",
            "Epoch 2960/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8836 - val_loss: 0.0967 - val_acc: 0.8973\n",
            "Epoch 2961/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2138 - acc: 0.8628 - val_loss: 0.0972 - val_acc: 0.8967\n",
            "Epoch 2962/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8780 - val_loss: 0.0981 - val_acc: 0.8963\n",
            "Epoch 2963/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1908 - acc: 0.8638 - val_loss: 0.0995 - val_acc: 0.8960\n",
            "Epoch 2964/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8841 - val_loss: 0.0999 - val_acc: 0.8964\n",
            "Epoch 2965/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8860 - val_loss: 0.0995 - val_acc: 0.8971\n",
            "Epoch 2966/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1254 - acc: 0.8771 - val_loss: 0.0994 - val_acc: 0.8977\n",
            "Epoch 2967/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8930 - val_loss: 0.0999 - val_acc: 0.8980\n",
            "Epoch 2968/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8933 - val_loss: 0.1004 - val_acc: 0.8981\n",
            "Epoch 2969/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8867 - val_loss: 0.1001 - val_acc: 0.8980\n",
            "Epoch 2970/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8831 - val_loss: 0.0994 - val_acc: 0.8977\n",
            "Epoch 2971/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8864 - val_loss: 0.0993 - val_acc: 0.8971\n",
            "Epoch 2972/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8796 - val_loss: 0.0994 - val_acc: 0.8966\n",
            "Epoch 2973/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8855 - val_loss: 0.0992 - val_acc: 0.8964\n",
            "Epoch 2974/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1626 - acc: 0.8661 - val_loss: 0.0992 - val_acc: 0.8964\n",
            "Epoch 2975/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8795 - val_loss: 0.0986 - val_acc: 0.8968\n",
            "Epoch 2976/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8855 - val_loss: 0.0981 - val_acc: 0.8972\n",
            "Epoch 2977/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8868 - val_loss: 0.0978 - val_acc: 0.8976\n",
            "Epoch 2978/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8872 - val_loss: 0.0978 - val_acc: 0.8979\n",
            "Epoch 2979/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8919 - val_loss: 0.0975 - val_acc: 0.8978\n",
            "Epoch 2980/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1452 - acc: 0.8848 - val_loss: 0.0970 - val_acc: 0.8975\n",
            "Epoch 2981/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8905 - val_loss: 0.0969 - val_acc: 0.8970\n",
            "Epoch 2982/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8897 - val_loss: 0.0971 - val_acc: 0.8965\n",
            "Epoch 2983/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8782 - val_loss: 0.0970 - val_acc: 0.8963\n",
            "Epoch 2984/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8782 - val_loss: 0.0966 - val_acc: 0.8964\n",
            "Epoch 2985/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8675 - val_loss: 0.0962 - val_acc: 0.8967\n",
            "Epoch 2986/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8831 - val_loss: 0.0962 - val_acc: 0.8970\n",
            "Epoch 2987/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8892 - val_loss: 0.0961 - val_acc: 0.8970\n",
            "Epoch 2988/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8857 - val_loss: 0.0958 - val_acc: 0.8968\n",
            "Epoch 2989/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8814 - val_loss: 0.0955 - val_acc: 0.8965\n",
            "Epoch 2990/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8876 - val_loss: 0.0955 - val_acc: 0.8961\n",
            "Epoch 2991/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8873 - val_loss: 0.0955 - val_acc: 0.8958\n",
            "Epoch 2992/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8860 - val_loss: 0.0954 - val_acc: 0.8958\n",
            "Epoch 2993/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8818 - val_loss: 0.0953 - val_acc: 0.8961\n",
            "Epoch 2994/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8810 - val_loss: 0.0952 - val_acc: 0.8963\n",
            "Epoch 2995/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3607 - acc: 0.8474 - val_loss: 0.0971 - val_acc: 0.8947\n",
            "Epoch 2996/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1174 - acc: 0.8713 - val_loss: 0.1003 - val_acc: 0.8935\n",
            "Epoch 2997/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8867 - val_loss: 0.1006 - val_acc: 0.8942\n",
            "Epoch 2998/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2594 - acc: 0.8501 - val_loss: 0.1022 - val_acc: 0.8952\n",
            "Epoch 2999/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2505 - acc: 0.8533 - val_loss: 0.1072 - val_acc: 0.8954\n",
            "Epoch 3000/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2211 - acc: 0.8560 - val_loss: 0.1136 - val_acc: 0.8959\n",
            "Epoch 3001/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1318 - acc: 0.8775 - val_loss: 0.1167 - val_acc: 0.8971\n",
            "Epoch 3002/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8837 - val_loss: 0.1164 - val_acc: 0.8982\n",
            "Epoch 3003/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1284 - acc: 0.8794 - val_loss: 0.1149 - val_acc: 0.8987\n",
            "Epoch 3004/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1378 - acc: 0.8835 - val_loss: 0.1139 - val_acc: 0.8988\n",
            "Epoch 3005/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1237 - acc: 0.8842 - val_loss: 0.1131 - val_acc: 0.8988\n",
            "Epoch 3006/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1230 - acc: 0.8842 - val_loss: 0.1120 - val_acc: 0.8987\n",
            "Epoch 3007/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1241 - acc: 0.8859 - val_loss: 0.1108 - val_acc: 0.8985\n",
            "Epoch 3008/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1229 - acc: 0.8858 - val_loss: 0.1098 - val_acc: 0.8982\n",
            "Epoch 3009/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1449 - acc: 0.8821 - val_loss: 0.1094 - val_acc: 0.8978\n",
            "Epoch 3010/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1215 - acc: 0.8851 - val_loss: 0.1095 - val_acc: 0.8974\n",
            "Epoch 3011/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8875 - val_loss: 0.1096 - val_acc: 0.8970\n",
            "Epoch 3012/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1243 - acc: 0.8803 - val_loss: 0.1095 - val_acc: 0.8968\n",
            "Epoch 3013/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1240 - acc: 0.8802 - val_loss: 0.1090 - val_acc: 0.8967\n",
            "Epoch 3014/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8930 - val_loss: 0.1080 - val_acc: 0.8968\n",
            "Epoch 3015/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8932 - val_loss: 0.1067 - val_acc: 0.8972\n",
            "Epoch 3016/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8814 - val_loss: 0.1056 - val_acc: 0.8976\n",
            "Epoch 3017/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1885 - acc: 0.8774 - val_loss: 0.1050 - val_acc: 0.8978\n",
            "Epoch 3018/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1678 - acc: 0.8809 - val_loss: 0.1047 - val_acc: 0.8980\n",
            "Epoch 3019/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8903 - val_loss: 0.1044 - val_acc: 0.8981\n",
            "Epoch 3020/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.9000 - val_loss: 0.1041 - val_acc: 0.8983\n",
            "Epoch 3021/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8948 - val_loss: 0.1038 - val_acc: 0.8983\n",
            "Epoch 3022/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8949 - val_loss: 0.1036 - val_acc: 0.8984\n",
            "Epoch 3023/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8859 - val_loss: 0.1033 - val_acc: 0.8984\n",
            "Epoch 3024/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8861 - val_loss: 0.1028 - val_acc: 0.8984\n",
            "Epoch 3025/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8932 - val_loss: 0.1021 - val_acc: 0.8983\n",
            "Epoch 3026/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8770 - val_loss: 0.1012 - val_acc: 0.8982\n",
            "Epoch 3027/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8823 - val_loss: 0.1005 - val_acc: 0.8979\n",
            "Epoch 3028/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1135 - acc: 0.8861 - val_loss: 0.1000 - val_acc: 0.8975\n",
            "Epoch 3029/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8829 - val_loss: 0.0995 - val_acc: 0.8971\n",
            "Epoch 3030/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8846 - val_loss: 0.0990 - val_acc: 0.8969\n",
            "Epoch 3031/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1211 - acc: 0.8735 - val_loss: 0.0983 - val_acc: 0.8969\n",
            "Epoch 3032/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1645 - acc: 0.8698 - val_loss: 0.0980 - val_acc: 0.8969\n",
            "Epoch 3033/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8926 - val_loss: 0.0976 - val_acc: 0.8971\n",
            "Epoch 3034/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1189 - acc: 0.8875 - val_loss: 0.0973 - val_acc: 0.8971\n",
            "Epoch 3035/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8946 - val_loss: 0.0971 - val_acc: 0.8971\n",
            "Epoch 3036/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8878 - val_loss: 0.0969 - val_acc: 0.8969\n",
            "Epoch 3037/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1771 - acc: 0.8763 - val_loss: 0.0972 - val_acc: 0.8965\n",
            "Epoch 3038/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8855 - val_loss: 0.0976 - val_acc: 0.8961\n",
            "Epoch 3039/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8876 - val_loss: 0.0977 - val_acc: 0.8960\n",
            "Epoch 3040/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8766 - val_loss: 0.0973 - val_acc: 0.8962\n",
            "Epoch 3041/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8936 - val_loss: 0.0968 - val_acc: 0.8967\n",
            "Epoch 3042/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8942 - val_loss: 0.0968 - val_acc: 0.8970\n",
            "Epoch 3043/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2592 - acc: 0.8606 - val_loss: 0.0969 - val_acc: 0.8969\n",
            "Epoch 3044/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8847 - val_loss: 0.0972 - val_acc: 0.8966\n",
            "Epoch 3045/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8832 - val_loss: 0.0977 - val_acc: 0.8964\n",
            "Epoch 3046/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2630 - acc: 0.8534 - val_loss: 0.0998 - val_acc: 0.8958\n",
            "Epoch 3047/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8848 - val_loss: 0.1012 - val_acc: 0.8958\n",
            "Epoch 3048/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8848 - val_loss: 0.1013 - val_acc: 0.8964\n",
            "Epoch 3049/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8815 - val_loss: 0.1009 - val_acc: 0.8971\n",
            "Epoch 3050/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8852 - val_loss: 0.1007 - val_acc: 0.8977\n",
            "Epoch 3051/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8953 - val_loss: 0.1010 - val_acc: 0.8980\n",
            "Epoch 3052/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8919 - val_loss: 0.1010 - val_acc: 0.8981\n",
            "Epoch 3053/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8808 - val_loss: 0.1004 - val_acc: 0.8980\n",
            "Epoch 3054/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1274 - acc: 0.8839 - val_loss: 0.0998 - val_acc: 0.8977\n",
            "Epoch 3055/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8835 - val_loss: 0.0998 - val_acc: 0.8972\n",
            "Epoch 3056/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8905 - val_loss: 0.1000 - val_acc: 0.8968\n",
            "Epoch 3057/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8932 - val_loss: 0.0997 - val_acc: 0.8967\n",
            "Epoch 3058/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8881 - val_loss: 0.0991 - val_acc: 0.8968\n",
            "Epoch 3059/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1205 - acc: 0.8846 - val_loss: 0.0985 - val_acc: 0.8971\n",
            "Epoch 3060/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1941 - acc: 0.8748 - val_loss: 0.0987 - val_acc: 0.8972\n",
            "Epoch 3061/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8900 - val_loss: 0.0986 - val_acc: 0.8973\n",
            "Epoch 3062/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8915 - val_loss: 0.0985 - val_acc: 0.8976\n",
            "Epoch 3063/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8906 - val_loss: 0.0983 - val_acc: 0.8976\n",
            "Epoch 3064/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1683 - acc: 0.8782 - val_loss: 0.0984 - val_acc: 0.8975\n",
            "Epoch 3065/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8872 - val_loss: 0.0986 - val_acc: 0.8974\n",
            "Epoch 3066/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8865 - val_loss: 0.0989 - val_acc: 0.8972\n",
            "Epoch 3067/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8846 - val_loss: 0.0988 - val_acc: 0.8972\n",
            "Epoch 3068/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8817 - val_loss: 0.0985 - val_acc: 0.8972\n",
            "Epoch 3069/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8911 - val_loss: 0.0980 - val_acc: 0.8973\n",
            "Epoch 3070/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8887 - val_loss: 0.0976 - val_acc: 0.8974\n",
            "Epoch 3071/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.0972 - val_acc: 0.8974\n",
            "Epoch 3072/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8911 - val_loss: 0.0970 - val_acc: 0.8974\n",
            "Epoch 3073/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8814 - val_loss: 0.0967 - val_acc: 0.8972\n",
            "Epoch 3074/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8814 - val_loss: 0.0965 - val_acc: 0.8969\n",
            "Epoch 3075/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8822 - val_loss: 0.0963 - val_acc: 0.8967\n",
            "Epoch 3076/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1994 - acc: 0.8613 - val_loss: 0.0967 - val_acc: 0.8963\n",
            "Epoch 3077/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8792 - val_loss: 0.0970 - val_acc: 0.8962\n",
            "Epoch 3078/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8914 - val_loss: 0.0970 - val_acc: 0.8963\n",
            "Epoch 3079/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8849 - val_loss: 0.0968 - val_acc: 0.8966\n",
            "Epoch 3080/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8878 - val_loss: 0.0965 - val_acc: 0.8969\n",
            "Epoch 3081/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8965 - val_loss: 0.0962 - val_acc: 0.8971\n",
            "Epoch 3082/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1495 - acc: 0.8838 - val_loss: 0.0961 - val_acc: 0.8969\n",
            "Epoch 3083/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8845 - val_loss: 0.0964 - val_acc: 0.8966\n",
            "Epoch 3084/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1653 - acc: 0.8764 - val_loss: 0.0972 - val_acc: 0.8961\n",
            "Epoch 3085/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2163 - acc: 0.8706 - val_loss: 0.0994 - val_acc: 0.8954\n",
            "Epoch 3086/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1435 - acc: 0.8797 - val_loss: 0.1010 - val_acc: 0.8955\n",
            "Epoch 3087/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8880 - val_loss: 0.1009 - val_acc: 0.8964\n",
            "Epoch 3088/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8860 - val_loss: 0.1003 - val_acc: 0.8974\n",
            "Epoch 3089/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8880 - val_loss: 0.1001 - val_acc: 0.8980\n",
            "Epoch 3090/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8848 - val_loss: 0.1004 - val_acc: 0.8982\n",
            "Epoch 3091/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8883 - val_loss: 0.1002 - val_acc: 0.8982\n",
            "Epoch 3092/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8882 - val_loss: 0.0997 - val_acc: 0.8979\n",
            "Epoch 3093/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1568 - acc: 0.8777 - val_loss: 0.0996 - val_acc: 0.8975\n",
            "Epoch 3094/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8866 - val_loss: 0.1000 - val_acc: 0.8971\n",
            "Epoch 3095/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8908 - val_loss: 0.1003 - val_acc: 0.8968\n",
            "Epoch 3096/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8910 - val_loss: 0.1003 - val_acc: 0.8967\n",
            "Epoch 3097/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8788 - val_loss: 0.0997 - val_acc: 0.8969\n",
            "Epoch 3098/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8793 - val_loss: 0.0989 - val_acc: 0.8972\n",
            "Epoch 3099/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8928 - val_loss: 0.0986 - val_acc: 0.8975\n",
            "Epoch 3100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8954 - val_loss: 0.0985 - val_acc: 0.8977\n",
            "Epoch 3101/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1435 - acc: 0.8793 - val_loss: 0.0984 - val_acc: 0.8977\n",
            "Epoch 3102/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8829 - val_loss: 0.0980 - val_acc: 0.8976\n",
            "Epoch 3103/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8912 - val_loss: 0.0977 - val_acc: 0.8974\n",
            "Epoch 3104/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8911 - val_loss: 0.0974 - val_acc: 0.8972\n",
            "Epoch 3105/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1966 - acc: 0.8695 - val_loss: 0.0982 - val_acc: 0.8968\n",
            "Epoch 3106/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8909 - val_loss: 0.0989 - val_acc: 0.8965\n",
            "Epoch 3107/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8955 - val_loss: 0.0990 - val_acc: 0.8966\n",
            "Epoch 3108/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8815 - val_loss: 0.0983 - val_acc: 0.8971\n",
            "Epoch 3109/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8837 - val_loss: 0.0977 - val_acc: 0.8974\n",
            "Epoch 3110/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8909 - val_loss: 0.0976 - val_acc: 0.8977\n",
            "Epoch 3111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8952 - val_loss: 0.0975 - val_acc: 0.8978\n",
            "Epoch 3112/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8850 - val_loss: 0.0972 - val_acc: 0.8976\n",
            "Epoch 3113/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8889 - val_loss: 0.0968 - val_acc: 0.8973\n",
            "Epoch 3114/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8830 - val_loss: 0.0965 - val_acc: 0.8969\n",
            "Epoch 3115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8865 - val_loss: 0.0964 - val_acc: 0.8966\n",
            "Epoch 3116/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1201 - acc: 0.8878 - val_loss: 0.0962 - val_acc: 0.8964\n",
            "Epoch 3117/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8924 - val_loss: 0.0960 - val_acc: 0.8965\n",
            "Epoch 3118/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8886 - val_loss: 0.0957 - val_acc: 0.8967\n",
            "Epoch 3119/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8958 - val_loss: 0.0956 - val_acc: 0.8970\n",
            "Epoch 3120/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8760 - val_loss: 0.0955 - val_acc: 0.8971\n",
            "Epoch 3121/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8958 - val_loss: 0.0954 - val_acc: 0.8971\n",
            "Epoch 3122/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8837 - val_loss: 0.0952 - val_acc: 0.8968\n",
            "Epoch 3123/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8835 - val_loss: 0.0951 - val_acc: 0.8965\n",
            "Epoch 3124/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8791 - val_loss: 0.0951 - val_acc: 0.8961\n",
            "Epoch 3125/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8901 - val_loss: 0.0950 - val_acc: 0.8960\n",
            "Epoch 3126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8909 - val_loss: 0.0948 - val_acc: 0.8960\n",
            "Epoch 3127/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8938 - val_loss: 0.0947 - val_acc: 0.8962\n",
            "Epoch 3128/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8838 - val_loss: 0.0947 - val_acc: 0.8964\n",
            "Epoch 3129/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8840 - val_loss: 0.0948 - val_acc: 0.8964\n",
            "Epoch 3130/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8913 - val_loss: 0.0947 - val_acc: 0.8962\n",
            "Epoch 3131/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8911 - val_loss: 0.0946 - val_acc: 0.8959\n",
            "Epoch 3132/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8801 - val_loss: 0.0947 - val_acc: 0.8955\n",
            "Epoch 3133/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8763 - val_loss: 0.0947 - val_acc: 0.8955\n",
            "Epoch 3134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2688 - acc: 0.8600 - val_loss: 0.0957 - val_acc: 0.8947\n",
            "Epoch 3135/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8836 - val_loss: 0.0962 - val_acc: 0.8948\n",
            "Epoch 3136/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8808 - val_loss: 0.0956 - val_acc: 0.8958\n",
            "Epoch 3137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8858 - val_loss: 0.0954 - val_acc: 0.8968\n",
            "Epoch 3138/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8935 - val_loss: 0.0958 - val_acc: 0.8973\n",
            "Epoch 3139/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8752 - val_loss: 0.0957 - val_acc: 0.8973\n",
            "Epoch 3140/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8803 - val_loss: 0.0955 - val_acc: 0.8967\n",
            "Epoch 3141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.9003 - val_loss: 0.0958 - val_acc: 0.8961\n",
            "Epoch 3142/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0927 - acc: 0.8998 - val_loss: 0.0959 - val_acc: 0.8959\n",
            "Epoch 3143/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2288 - acc: 0.8555 - val_loss: 0.0971 - val_acc: 0.8956\n",
            "Epoch 3144/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8850 - val_loss: 0.0974 - val_acc: 0.8959\n",
            "Epoch 3145/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1281 - acc: 0.8824 - val_loss: 0.0971 - val_acc: 0.8967\n",
            "Epoch 3146/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8829 - val_loss: 0.0969 - val_acc: 0.8975\n",
            "Epoch 3147/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8842 - val_loss: 0.0973 - val_acc: 0.8980\n",
            "Epoch 3148/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8838 - val_loss: 0.0977 - val_acc: 0.8982\n",
            "Epoch 3149/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8938 - val_loss: 0.0974 - val_acc: 0.8981\n",
            "Epoch 3150/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1138 - acc: 0.8869 - val_loss: 0.0969 - val_acc: 0.8976\n",
            "Epoch 3151/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8879 - val_loss: 0.0971 - val_acc: 0.8971\n",
            "Epoch 3152/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8785 - val_loss: 0.0975 - val_acc: 0.8966\n",
            "Epoch 3153/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1122 - acc: 0.8764 - val_loss: 0.0976 - val_acc: 0.8965\n",
            "Epoch 3154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8809 - val_loss: 0.0970 - val_acc: 0.8967\n",
            "Epoch 3155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8830 - val_loss: 0.0966 - val_acc: 0.8972\n",
            "Epoch 3156/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8870 - val_loss: 0.0966 - val_acc: 0.8975\n",
            "Epoch 3157/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8738 - val_loss: 0.0965 - val_acc: 0.8976\n",
            "Epoch 3158/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8941 - val_loss: 0.0960 - val_acc: 0.8975\n",
            "Epoch 3159/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2478 - acc: 0.8649 - val_loss: 0.0962 - val_acc: 0.8968\n",
            "Epoch 3160/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8850 - val_loss: 0.0976 - val_acc: 0.8960\n",
            "Epoch 3161/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1500 - acc: 0.8783 - val_loss: 0.0997 - val_acc: 0.8953\n",
            "Epoch 3162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2637 - acc: 0.8484 - val_loss: 0.1049 - val_acc: 0.8942\n",
            "Epoch 3163/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1461 - acc: 0.8691 - val_loss: 0.1075 - val_acc: 0.8944\n",
            "Epoch 3164/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1175 - acc: 0.8777 - val_loss: 0.1060 - val_acc: 0.8962\n",
            "Epoch 3165/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8869 - val_loss: 0.1037 - val_acc: 0.8978\n",
            "Epoch 3166/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8868 - val_loss: 0.1038 - val_acc: 0.8985\n",
            "Epoch 3167/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8852 - val_loss: 0.1048 - val_acc: 0.8987\n",
            "Epoch 3168/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8854 - val_loss: 0.1041 - val_acc: 0.8987\n",
            "Epoch 3169/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1273 - acc: 0.8842 - val_loss: 0.1025 - val_acc: 0.8984\n",
            "Epoch 3170/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8933 - val_loss: 0.1018 - val_acc: 0.8979\n",
            "Epoch 3171/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8968 - val_loss: 0.1023 - val_acc: 0.8971\n",
            "Epoch 3172/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1554 - acc: 0.8740 - val_loss: 0.1038 - val_acc: 0.8961\n",
            "Epoch 3173/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1146 - acc: 0.8789 - val_loss: 0.1046 - val_acc: 0.8955\n",
            "Epoch 3174/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1149 - acc: 0.8784 - val_loss: 0.1038 - val_acc: 0.8956\n",
            "Epoch 3175/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8753 - val_loss: 0.1020 - val_acc: 0.8962\n",
            "Epoch 3176/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8856 - val_loss: 0.1002 - val_acc: 0.8970\n",
            "Epoch 3177/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8883 - val_loss: 0.0996 - val_acc: 0.8977\n",
            "Epoch 3178/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8906 - val_loss: 0.1000 - val_acc: 0.8981\n",
            "Epoch 3179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8907 - val_loss: 0.0998 - val_acc: 0.8982\n",
            "Epoch 3180/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8903 - val_loss: 0.0986 - val_acc: 0.8981\n",
            "Epoch 3181/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8992 - val_loss: 0.0974 - val_acc: 0.8978\n",
            "Epoch 3182/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2168 - acc: 0.8747 - val_loss: 0.0980 - val_acc: 0.8971\n",
            "Epoch 3183/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8922 - val_loss: 0.0996 - val_acc: 0.8962\n",
            "Epoch 3184/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1492 - acc: 0.8778 - val_loss: 0.1013 - val_acc: 0.8954\n",
            "Epoch 3185/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8825 - val_loss: 0.1011 - val_acc: 0.8956\n",
            "Epoch 3186/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1098 - acc: 0.8876 - val_loss: 0.0992 - val_acc: 0.8966\n",
            "Epoch 3187/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8887 - val_loss: 0.0978 - val_acc: 0.8974\n",
            "Epoch 3188/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8868 - val_loss: 0.0981 - val_acc: 0.8979\n",
            "Epoch 3189/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8868 - val_loss: 0.0989 - val_acc: 0.8980\n",
            "Epoch 3190/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8847 - val_loss: 0.0981 - val_acc: 0.8978\n",
            "Epoch 3191/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8820 - val_loss: 0.0969 - val_acc: 0.8972\n",
            "Epoch 3192/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8892 - val_loss: 0.0969 - val_acc: 0.8963\n",
            "Epoch 3193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8833 - val_loss: 0.0976 - val_acc: 0.8953\n",
            "Epoch 3194/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1837 - acc: 0.8717 - val_loss: 0.0988 - val_acc: 0.8947\n",
            "Epoch 3195/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8889 - val_loss: 0.0984 - val_acc: 0.8951\n",
            "Epoch 3196/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8754 - val_loss: 0.0973 - val_acc: 0.8960\n",
            "Epoch 3197/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8763 - val_loss: 0.0965 - val_acc: 0.8968\n",
            "Epoch 3198/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8843 - val_loss: 0.0966 - val_acc: 0.8975\n",
            "Epoch 3199/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8899 - val_loss: 0.0969 - val_acc: 0.8978\n",
            "Epoch 3200/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1676 - acc: 0.8770 - val_loss: 0.0965 - val_acc: 0.8976\n",
            "Epoch 3201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8856 - val_loss: 0.0962 - val_acc: 0.8972\n",
            "Epoch 3202/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8853 - val_loss: 0.0964 - val_acc: 0.8966\n",
            "Epoch 3203/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8886 - val_loss: 0.0969 - val_acc: 0.8961\n",
            "Epoch 3204/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8824 - val_loss: 0.0969 - val_acc: 0.8960\n",
            "Epoch 3205/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8924 - val_loss: 0.0962 - val_acc: 0.8964\n",
            "Epoch 3206/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2013 - acc: 0.8639 - val_loss: 0.0963 - val_acc: 0.8967\n",
            "Epoch 3207/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8797 - val_loss: 0.0965 - val_acc: 0.8970\n",
            "Epoch 3208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8803 - val_loss: 0.0967 - val_acc: 0.8973\n",
            "Epoch 3209/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1876 - acc: 0.8781 - val_loss: 0.0972 - val_acc: 0.8973\n",
            "Epoch 3210/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8979 - val_loss: 0.0974 - val_acc: 0.8973\n",
            "Epoch 3211/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8887 - val_loss: 0.0974 - val_acc: 0.8972\n",
            "Epoch 3212/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8888 - val_loss: 0.0973 - val_acc: 0.8971\n",
            "Epoch 3213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8941 - val_loss: 0.0973 - val_acc: 0.8971\n",
            "Epoch 3214/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8893 - val_loss: 0.0973 - val_acc: 0.8972\n",
            "Epoch 3215/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8812 - val_loss: 0.0971 - val_acc: 0.8973\n",
            "Epoch 3216/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8845 - val_loss: 0.0970 - val_acc: 0.8975\n",
            "Epoch 3217/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1727 - acc: 0.8729 - val_loss: 0.0974 - val_acc: 0.8975\n",
            "Epoch 3218/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8858 - val_loss: 0.0975 - val_acc: 0.8975\n",
            "Epoch 3219/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8773 - val_loss: 0.0974 - val_acc: 0.8975\n",
            "Epoch 3220/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8842 - val_loss: 0.0973 - val_acc: 0.8975\n",
            "Epoch 3221/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8903 - val_loss: 0.0970 - val_acc: 0.8975\n",
            "Epoch 3222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8864 - val_loss: 0.0968 - val_acc: 0.8974\n",
            "Epoch 3223/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8878 - val_loss: 0.0965 - val_acc: 0.8972\n",
            "Epoch 3224/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8850 - val_loss: 0.0962 - val_acc: 0.8972\n",
            "Epoch 3225/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8879 - val_loss: 0.0959 - val_acc: 0.8971\n",
            "Epoch 3226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8892 - val_loss: 0.0957 - val_acc: 0.8970\n",
            "Epoch 3227/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8871 - val_loss: 0.0955 - val_acc: 0.8969\n",
            "Epoch 3228/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2600 - acc: 0.8640 - val_loss: 0.0965 - val_acc: 0.8963\n",
            "Epoch 3229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8864 - val_loss: 0.0977 - val_acc: 0.8959\n",
            "Epoch 3230/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1227 - acc: 0.8838 - val_loss: 0.0985 - val_acc: 0.8958\n",
            "Epoch 3231/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8715 - val_loss: 0.0979 - val_acc: 0.8964\n",
            "Epoch 3232/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8976 - val_loss: 0.0970 - val_acc: 0.8973\n",
            "Epoch 3233/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8925 - val_loss: 0.0971 - val_acc: 0.8979\n",
            "Epoch 3234/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8830 - val_loss: 0.0976 - val_acc: 0.8980\n",
            "Epoch 3235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8884 - val_loss: 0.0973 - val_acc: 0.8979\n",
            "Epoch 3236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8834 - val_loss: 0.0965 - val_acc: 0.8974\n",
            "Epoch 3237/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8843 - val_loss: 0.0963 - val_acc: 0.8966\n",
            "Epoch 3238/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1131 - acc: 0.8820 - val_loss: 0.0968 - val_acc: 0.8958\n",
            "Epoch 3239/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8832 - val_loss: 0.0968 - val_acc: 0.8955\n",
            "Epoch 3240/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8926 - val_loss: 0.0962 - val_acc: 0.8959\n",
            "Epoch 3241/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8885 - val_loss: 0.0955 - val_acc: 0.8965\n",
            "Epoch 3242/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8850 - val_loss: 0.0954 - val_acc: 0.8971\n",
            "Epoch 3243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8827 - val_loss: 0.0954 - val_acc: 0.8975\n",
            "Epoch 3244/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8834 - val_loss: 0.0951 - val_acc: 0.8974\n",
            "Epoch 3245/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8834 - val_loss: 0.0947 - val_acc: 0.8969\n",
            "Epoch 3246/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8867 - val_loss: 0.0948 - val_acc: 0.8964\n",
            "Epoch 3247/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8846 - val_loss: 0.0951 - val_acc: 0.8959\n",
            "Epoch 3248/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8859 - val_loss: 0.0950 - val_acc: 0.8958\n",
            "Epoch 3249/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8886 - val_loss: 0.0946 - val_acc: 0.8962\n",
            "Epoch 3250/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8918 - val_loss: 0.0944 - val_acc: 0.8966\n",
            "Epoch 3251/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8923 - val_loss: 0.0946 - val_acc: 0.8969\n",
            "Epoch 3252/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1203 - acc: 0.8894 - val_loss: 0.0945 - val_acc: 0.8968\n",
            "Epoch 3253/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8874 - val_loss: 0.0942 - val_acc: 0.8965\n",
            "Epoch 3254/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8872 - val_loss: 0.0943 - val_acc: 0.8959\n",
            "Epoch 3255/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8874 - val_loss: 0.0945 - val_acc: 0.8955\n",
            "Epoch 3256/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8892 - val_loss: 0.0945 - val_acc: 0.8955\n",
            "Epoch 3257/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8826 - val_loss: 0.0942 - val_acc: 0.8958\n",
            "Epoch 3258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8794 - val_loss: 0.0941 - val_acc: 0.8963\n",
            "Epoch 3259/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8790 - val_loss: 0.0942 - val_acc: 0.8965\n",
            "Epoch 3260/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8794 - val_loss: 0.0942 - val_acc: 0.8964\n",
            "Epoch 3261/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8945 - val_loss: 0.0942 - val_acc: 0.8962\n",
            "Epoch 3262/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2948 - acc: 0.8559 - val_loss: 0.0954 - val_acc: 0.8949\n",
            "Epoch 3263/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1982 - acc: 0.8659 - val_loss: 0.0996 - val_acc: 0.8932\n",
            "Epoch 3264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8793 - val_loss: 0.1009 - val_acc: 0.8935\n",
            "Epoch 3265/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8874 - val_loss: 0.0995 - val_acc: 0.8952\n",
            "Epoch 3266/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8873 - val_loss: 0.0979 - val_acc: 0.8969\n",
            "Epoch 3267/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8892 - val_loss: 0.0983 - val_acc: 0.8979\n",
            "Epoch 3268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8876 - val_loss: 0.0993 - val_acc: 0.8983\n",
            "Epoch 3269/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8881 - val_loss: 0.0994 - val_acc: 0.8982\n",
            "Epoch 3270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8926 - val_loss: 0.0988 - val_acc: 0.8980\n",
            "Epoch 3271/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8900 - val_loss: 0.0984 - val_acc: 0.8975\n",
            "Epoch 3272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8857 - val_loss: 0.0985 - val_acc: 0.8970\n",
            "Epoch 3273/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8704 - val_loss: 0.0988 - val_acc: 0.8966\n",
            "Epoch 3274/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1171 - acc: 0.8701 - val_loss: 0.0986 - val_acc: 0.8965\n",
            "Epoch 3275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8832 - val_loss: 0.0980 - val_acc: 0.8968\n",
            "Epoch 3276/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1503 - acc: 0.8754 - val_loss: 0.0977 - val_acc: 0.8972\n",
            "Epoch 3277/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8940 - val_loss: 0.0974 - val_acc: 0.8976\n",
            "Epoch 3278/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8725 - val_loss: 0.0971 - val_acc: 0.8979\n",
            "Epoch 3279/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8860 - val_loss: 0.0968 - val_acc: 0.8979\n",
            "Epoch 3280/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8845 - val_loss: 0.0964 - val_acc: 0.8978\n",
            "Epoch 3281/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8898 - val_loss: 0.0961 - val_acc: 0.8976\n",
            "Epoch 3282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8917 - val_loss: 0.0960 - val_acc: 0.8972\n",
            "Epoch 3283/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8914 - val_loss: 0.0957 - val_acc: 0.8969\n",
            "Epoch 3284/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8884 - val_loss: 0.0955 - val_acc: 0.8966\n",
            "Epoch 3285/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8802 - val_loss: 0.0952 - val_acc: 0.8965\n",
            "Epoch 3286/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8877 - val_loss: 0.0949 - val_acc: 0.8964\n",
            "Epoch 3287/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8958 - val_loss: 0.0947 - val_acc: 0.8966\n",
            "Epoch 3288/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8919 - val_loss: 0.0945 - val_acc: 0.8967\n",
            "Epoch 3289/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8870 - val_loss: 0.0944 - val_acc: 0.8968\n",
            "Epoch 3290/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8857 - val_loss: 0.0943 - val_acc: 0.8968\n",
            "Epoch 3291/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0889 - acc: 0.9013 - val_loss: 0.0942 - val_acc: 0.8967\n",
            "Epoch 3292/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1605 - acc: 0.8799 - val_loss: 0.0946 - val_acc: 0.8960\n",
            "Epoch 3293/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8772 - val_loss: 0.0950 - val_acc: 0.8957\n",
            "Epoch 3294/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8856 - val_loss: 0.0948 - val_acc: 0.8958\n",
            "Epoch 3295/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8849 - val_loss: 0.0944 - val_acc: 0.8962\n",
            "Epoch 3296/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8891 - val_loss: 0.0942 - val_acc: 0.8967\n",
            "Epoch 3297/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8873 - val_loss: 0.0944 - val_acc: 0.8970\n",
            "Epoch 3298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8885 - val_loss: 0.0944 - val_acc: 0.8969\n",
            "Epoch 3299/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8902 - val_loss: 0.0941 - val_acc: 0.8965\n",
            "Epoch 3300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8954 - val_loss: 0.0942 - val_acc: 0.8959\n",
            "Epoch 3301/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8949 - val_loss: 0.0944 - val_acc: 0.8955\n",
            "Epoch 3302/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8911 - val_loss: 0.0943 - val_acc: 0.8956\n",
            "Epoch 3303/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8840 - val_loss: 0.0940 - val_acc: 0.8961\n",
            "Epoch 3304/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8857 - val_loss: 0.0940 - val_acc: 0.8967\n",
            "Epoch 3305/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8846 - val_loss: 0.0941 - val_acc: 0.8970\n",
            "Epoch 3306/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8820 - val_loss: 0.0938 - val_acc: 0.8969\n",
            "Epoch 3307/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8819 - val_loss: 0.0936 - val_acc: 0.8967\n",
            "Epoch 3308/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8908 - val_loss: 0.0937 - val_acc: 0.8964\n",
            "Epoch 3309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8843 - val_loss: 0.0938 - val_acc: 0.8962\n",
            "Epoch 3310/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8759 - val_loss: 0.0937 - val_acc: 0.8963\n",
            "Epoch 3311/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0893 - acc: 0.8942 - val_loss: 0.0936 - val_acc: 0.8966\n",
            "Epoch 3312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8870 - val_loss: 0.0937 - val_acc: 0.8968\n",
            "Epoch 3313/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8876 - val_loss: 0.0937 - val_acc: 0.8968\n",
            "Epoch 3314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8829 - val_loss: 0.0935 - val_acc: 0.8967\n",
            "Epoch 3315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1478 - acc: 0.8793 - val_loss: 0.0935 - val_acc: 0.8963\n",
            "Epoch 3316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8889 - val_loss: 0.0938 - val_acc: 0.8960\n",
            "Epoch 3317/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8887 - val_loss: 0.0938 - val_acc: 0.8960\n",
            "Epoch 3318/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8815 - val_loss: 0.0936 - val_acc: 0.8964\n",
            "Epoch 3319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8905 - val_loss: 0.0936 - val_acc: 0.8967\n",
            "Epoch 3320/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8842 - val_loss: 0.0937 - val_acc: 0.8969\n",
            "Epoch 3321/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8789 - val_loss: 0.0936 - val_acc: 0.8969\n",
            "Epoch 3322/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8923 - val_loss: 0.0935 - val_acc: 0.8967\n",
            "Epoch 3323/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2012 - acc: 0.8648 - val_loss: 0.0938 - val_acc: 0.8963\n",
            "Epoch 3324/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3107 - acc: 0.8455 - val_loss: 0.0978 - val_acc: 0.8943\n",
            "Epoch 3325/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8743 - val_loss: 0.1005 - val_acc: 0.8938\n",
            "Epoch 3326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8912 - val_loss: 0.0996 - val_acc: 0.8953\n",
            "Epoch 3327/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8881 - val_loss: 0.0976 - val_acc: 0.8971\n",
            "Epoch 3328/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1324 - acc: 0.8842 - val_loss: 0.0980 - val_acc: 0.8981\n",
            "Epoch 3329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8913 - val_loss: 0.0994 - val_acc: 0.8985\n",
            "Epoch 3330/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8883 - val_loss: 0.0999 - val_acc: 0.8986\n",
            "Epoch 3331/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8868 - val_loss: 0.0991 - val_acc: 0.8984\n",
            "Epoch 3332/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1143 - acc: 0.8794 - val_loss: 0.0987 - val_acc: 0.8979\n",
            "Epoch 3333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8832 - val_loss: 0.0993 - val_acc: 0.8973\n",
            "Epoch 3334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8871 - val_loss: 0.0999 - val_acc: 0.8967\n",
            "Epoch 3335/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8839 - val_loss: 0.1000 - val_acc: 0.8966\n",
            "Epoch 3336/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8951 - val_loss: 0.0990 - val_acc: 0.8969\n",
            "Epoch 3337/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8954 - val_loss: 0.0981 - val_acc: 0.8975\n",
            "Epoch 3338/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8867 - val_loss: 0.0979 - val_acc: 0.8979\n",
            "Epoch 3339/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8872 - val_loss: 0.0981 - val_acc: 0.8982\n",
            "Epoch 3340/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8958 - val_loss: 0.0978 - val_acc: 0.8982\n",
            "Epoch 3341/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8959 - val_loss: 0.0968 - val_acc: 0.8981\n",
            "Epoch 3342/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1212 - acc: 0.8875 - val_loss: 0.0961 - val_acc: 0.8976\n",
            "Epoch 3343/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8778 - val_loss: 0.0963 - val_acc: 0.8969\n",
            "Epoch 3344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8874 - val_loss: 0.0966 - val_acc: 0.8963\n",
            "Epoch 3345/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8851 - val_loss: 0.0962 - val_acc: 0.8963\n",
            "Epoch 3346/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8835 - val_loss: 0.0953 - val_acc: 0.8968\n",
            "Epoch 3347/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8858 - val_loss: 0.0947 - val_acc: 0.8972\n",
            "Epoch 3348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0920 - acc: 0.8985 - val_loss: 0.0948 - val_acc: 0.8975\n",
            "Epoch 3349/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8989 - val_loss: 0.0949 - val_acc: 0.8976\n",
            "Epoch 3350/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8882 - val_loss: 0.0946 - val_acc: 0.8975\n",
            "Epoch 3351/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8901 - val_loss: 0.0942 - val_acc: 0.8971\n",
            "Epoch 3352/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8905 - val_loss: 0.0940 - val_acc: 0.8966\n",
            "Epoch 3353/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8830 - val_loss: 0.0941 - val_acc: 0.8960\n",
            "Epoch 3354/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8886 - val_loss: 0.0942 - val_acc: 0.8957\n",
            "Epoch 3355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8803 - val_loss: 0.0939 - val_acc: 0.8958\n",
            "Epoch 3356/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8882 - val_loss: 0.0936 - val_acc: 0.8962\n",
            "Epoch 3357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8789 - val_loss: 0.0936 - val_acc: 0.8966\n",
            "Epoch 3358/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8847 - val_loss: 0.0937 - val_acc: 0.8968\n",
            "Epoch 3359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2728 - acc: 0.8628 - val_loss: 0.0937 - val_acc: 0.8964\n",
            "Epoch 3360/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8898 - val_loss: 0.0945 - val_acc: 0.8960\n",
            "Epoch 3361/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8880 - val_loss: 0.0948 - val_acc: 0.8960\n",
            "Epoch 3362/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8835 - val_loss: 0.0948 - val_acc: 0.8964\n",
            "Epoch 3363/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8954 - val_loss: 0.0945 - val_acc: 0.8969\n",
            "Epoch 3364/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2141 - acc: 0.8648 - val_loss: 0.0952 - val_acc: 0.8969\n",
            "Epoch 3365/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8837 - val_loss: 0.0958 - val_acc: 0.8970\n",
            "Epoch 3366/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1218 - acc: 0.8742 - val_loss: 0.0962 - val_acc: 0.8971\n",
            "Epoch 3367/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8787 - val_loss: 0.0963 - val_acc: 0.8974\n",
            "Epoch 3368/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8856 - val_loss: 0.0963 - val_acc: 0.8975\n",
            "Epoch 3369/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1136 - acc: 0.8741 - val_loss: 0.0963 - val_acc: 0.8975\n",
            "Epoch 3370/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8737 - val_loss: 0.0962 - val_acc: 0.8975\n",
            "Epoch 3371/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8885 - val_loss: 0.0963 - val_acc: 0.8974\n",
            "Epoch 3372/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8928 - val_loss: 0.0964 - val_acc: 0.8973\n",
            "Epoch 3373/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8862 - val_loss: 0.0963 - val_acc: 0.8973\n",
            "Epoch 3374/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8862 - val_loss: 0.0961 - val_acc: 0.8972\n",
            "Epoch 3375/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8862 - val_loss: 0.0959 - val_acc: 0.8972\n",
            "Epoch 3376/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8903 - val_loss: 0.0957 - val_acc: 0.8972\n",
            "Epoch 3377/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8799 - val_loss: 0.0954 - val_acc: 0.8973\n",
            "Epoch 3378/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8863 - val_loss: 0.0951 - val_acc: 0.8973\n",
            "Epoch 3379/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8805 - val_loss: 0.0948 - val_acc: 0.8971\n",
            "Epoch 3380/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1286 - acc: 0.8814 - val_loss: 0.0948 - val_acc: 0.8968\n",
            "Epoch 3381/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8823 - val_loss: 0.0948 - val_acc: 0.8967\n",
            "Epoch 3382/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8862 - val_loss: 0.0945 - val_acc: 0.8968\n",
            "Epoch 3383/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1959 - acc: 0.8721 - val_loss: 0.0948 - val_acc: 0.8968\n",
            "Epoch 3384/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8915 - val_loss: 0.0950 - val_acc: 0.8968\n",
            "Epoch 3385/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8860 - val_loss: 0.0949 - val_acc: 0.8970\n",
            "Epoch 3386/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8908 - val_loss: 0.0948 - val_acc: 0.8971\n",
            "Epoch 3387/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8912 - val_loss: 0.0948 - val_acc: 0.8972\n",
            "Epoch 3388/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8683 - val_loss: 0.0945 - val_acc: 0.8972\n",
            "Epoch 3389/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8837 - val_loss: 0.0943 - val_acc: 0.8971\n",
            "Epoch 3390/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8893 - val_loss: 0.0941 - val_acc: 0.8969\n",
            "Epoch 3391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8894 - val_loss: 0.0941 - val_acc: 0.8966\n",
            "Epoch 3392/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8870 - val_loss: 0.0940 - val_acc: 0.8967\n",
            "Epoch 3393/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2092 - acc: 0.8717 - val_loss: 0.0945 - val_acc: 0.8968\n",
            "Epoch 3394/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8938 - val_loss: 0.0948 - val_acc: 0.8968\n",
            "Epoch 3395/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1606 - acc: 0.8798 - val_loss: 0.0951 - val_acc: 0.8966\n",
            "Epoch 3396/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8889 - val_loss: 0.0955 - val_acc: 0.8964\n",
            "Epoch 3397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8818 - val_loss: 0.0956 - val_acc: 0.8966\n",
            "Epoch 3398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8821 - val_loss: 0.0955 - val_acc: 0.8970\n",
            "Epoch 3399/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8744 - val_loss: 0.0954 - val_acc: 0.8973\n",
            "Epoch 3400/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8749 - val_loss: 0.0954 - val_acc: 0.8974\n",
            "Epoch 3401/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8913 - val_loss: 0.0954 - val_acc: 0.8975\n",
            "Epoch 3402/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8866 - val_loss: 0.0953 - val_acc: 0.8974\n",
            "Epoch 3403/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8852 - val_loss: 0.0952 - val_acc: 0.8972\n",
            "Epoch 3404/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8823 - val_loss: 0.0951 - val_acc: 0.8971\n",
            "Epoch 3405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8822 - val_loss: 0.0949 - val_acc: 0.8969\n",
            "Epoch 3406/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1757 - acc: 0.8675 - val_loss: 0.0954 - val_acc: 0.8966\n",
            "Epoch 3407/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8777 - val_loss: 0.0956 - val_acc: 0.8966\n",
            "Epoch 3408/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8827 - val_loss: 0.0952 - val_acc: 0.8969\n",
            "Epoch 3409/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1137 - acc: 0.8805 - val_loss: 0.0949 - val_acc: 0.8972\n",
            "Epoch 3410/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8825 - val_loss: 0.0950 - val_acc: 0.8975\n",
            "Epoch 3411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8848 - val_loss: 0.0951 - val_acc: 0.8976\n",
            "Epoch 3412/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8850 - val_loss: 0.0951 - val_acc: 0.8975\n",
            "Epoch 3413/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8912 - val_loss: 0.0948 - val_acc: 0.8972\n",
            "Epoch 3414/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8840 - val_loss: 0.0945 - val_acc: 0.8968\n",
            "Epoch 3415/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8876 - val_loss: 0.0945 - val_acc: 0.8963\n",
            "Epoch 3416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8798 - val_loss: 0.0945 - val_acc: 0.8960\n",
            "Epoch 3417/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8842 - val_loss: 0.0942 - val_acc: 0.8960\n",
            "Epoch 3418/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8842 - val_loss: 0.0940 - val_acc: 0.8963\n",
            "Epoch 3419/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8845 - val_loss: 0.0939 - val_acc: 0.8966\n",
            "Epoch 3420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8848 - val_loss: 0.0939 - val_acc: 0.8968\n",
            "Epoch 3421/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8900 - val_loss: 0.0937 - val_acc: 0.8969\n",
            "Epoch 3422/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8871 - val_loss: 0.0935 - val_acc: 0.8969\n",
            "Epoch 3423/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8900 - val_loss: 0.0933 - val_acc: 0.8967\n",
            "Epoch 3424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0897 - acc: 0.8983 - val_loss: 0.0933 - val_acc: 0.8965\n",
            "Epoch 3425/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8893 - val_loss: 0.0934 - val_acc: 0.8963\n",
            "Epoch 3426/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0928 - acc: 0.8929 - val_loss: 0.0934 - val_acc: 0.8964\n",
            "Epoch 3427/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8826 - val_loss: 0.0932 - val_acc: 0.8965\n",
            "Epoch 3428/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8914 - val_loss: 0.0931 - val_acc: 0.8965\n",
            "Epoch 3429/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8914 - val_loss: 0.0933 - val_acc: 0.8964\n",
            "Epoch 3430/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8741 - val_loss: 0.0934 - val_acc: 0.8962\n",
            "Epoch 3431/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8801 - val_loss: 0.0935 - val_acc: 0.8958\n",
            "Epoch 3432/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8861 - val_loss: 0.0933 - val_acc: 0.8957\n",
            "Epoch 3433/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8836 - val_loss: 0.0930 - val_acc: 0.8960\n",
            "Epoch 3434/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8840 - val_loss: 0.0932 - val_acc: 0.8966\n",
            "Epoch 3435/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8726 - val_loss: 0.0934 - val_acc: 0.8967\n",
            "Epoch 3436/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2417 - acc: 0.8602 - val_loss: 0.0939 - val_acc: 0.8962\n",
            "Epoch 3437/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8914 - val_loss: 0.0945 - val_acc: 0.8959\n",
            "Epoch 3438/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8930 - val_loss: 0.0943 - val_acc: 0.8961\n",
            "Epoch 3439/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8935 - val_loss: 0.0939 - val_acc: 0.8968\n",
            "Epoch 3440/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8874 - val_loss: 0.0940 - val_acc: 0.8972\n",
            "Epoch 3441/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8897 - val_loss: 0.0944 - val_acc: 0.8973\n",
            "Epoch 3442/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8892 - val_loss: 0.0943 - val_acc: 0.8972\n",
            "Epoch 3443/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8782 - val_loss: 0.0940 - val_acc: 0.8969\n",
            "Epoch 3444/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1113 - acc: 0.8743 - val_loss: 0.0940 - val_acc: 0.8967\n",
            "Epoch 3445/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8742 - val_loss: 0.0941 - val_acc: 0.8966\n",
            "Epoch 3446/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8940 - val_loss: 0.0942 - val_acc: 0.8966\n",
            "Epoch 3447/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8837 - val_loss: 0.0940 - val_acc: 0.8968\n",
            "Epoch 3448/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8826 - val_loss: 0.0938 - val_acc: 0.8971\n",
            "Epoch 3449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8839 - val_loss: 0.0936 - val_acc: 0.8973\n",
            "Epoch 3450/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8841 - val_loss: 0.0936 - val_acc: 0.8973\n",
            "Epoch 3451/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8864 - val_loss: 0.0936 - val_acc: 0.8973\n",
            "Epoch 3452/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8864 - val_loss: 0.0936 - val_acc: 0.8972\n",
            "Epoch 3453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8821 - val_loss: 0.0935 - val_acc: 0.8969\n",
            "Epoch 3454/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8849 - val_loss: 0.0934 - val_acc: 0.8967\n",
            "Epoch 3455/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8938 - val_loss: 0.0932 - val_acc: 0.8967\n",
            "Epoch 3456/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8842 - val_loss: 0.0931 - val_acc: 0.8968\n",
            "Epoch 3457/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8910 - val_loss: 0.0931 - val_acc: 0.8968\n",
            "Epoch 3458/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8821 - val_loss: 0.0930 - val_acc: 0.8966\n",
            "Epoch 3459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8820 - val_loss: 0.0928 - val_acc: 0.8964\n",
            "Epoch 3460/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8901 - val_loss: 0.0928 - val_acc: 0.8962\n",
            "Epoch 3461/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8927 - val_loss: 0.0928 - val_acc: 0.8962\n",
            "Epoch 3462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8879 - val_loss: 0.0928 - val_acc: 0.8963\n",
            "Epoch 3463/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8880 - val_loss: 0.0927 - val_acc: 0.8964\n",
            "Epoch 3464/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8898 - val_loss: 0.0927 - val_acc: 0.8966\n",
            "Epoch 3465/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8802 - val_loss: 0.0928 - val_acc: 0.8965\n",
            "Epoch 3466/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8802 - val_loss: 0.0928 - val_acc: 0.8963\n",
            "Epoch 3467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8888 - val_loss: 0.0928 - val_acc: 0.8960\n",
            "Epoch 3468/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8852 - val_loss: 0.0926 - val_acc: 0.8960\n",
            "Epoch 3469/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8848 - val_loss: 0.0925 - val_acc: 0.8961\n",
            "Epoch 3470/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1725 - acc: 0.8708 - val_loss: 0.0928 - val_acc: 0.8958\n",
            "Epoch 3471/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8830 - val_loss: 0.0929 - val_acc: 0.8959\n",
            "Epoch 3472/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2342 - acc: 0.8605 - val_loss: 0.0940 - val_acc: 0.8956\n",
            "Epoch 3473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8896 - val_loss: 0.0947 - val_acc: 0.8957\n",
            "Epoch 3474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8863 - val_loss: 0.0945 - val_acc: 0.8964\n",
            "Epoch 3475/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1344 - acc: 0.8855 - val_loss: 0.0944 - val_acc: 0.8970\n",
            "Epoch 3476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8923 - val_loss: 0.0944 - val_acc: 0.8974\n",
            "Epoch 3477/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1955 - acc: 0.8680 - val_loss: 0.0954 - val_acc: 0.8973\n",
            "Epoch 3478/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8817 - val_loss: 0.0963 - val_acc: 0.8973\n",
            "Epoch 3479/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8888 - val_loss: 0.0967 - val_acc: 0.8974\n",
            "Epoch 3480/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2493 - acc: 0.8546 - val_loss: 0.0987 - val_acc: 0.8972\n",
            "Epoch 3481/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8919 - val_loss: 0.1000 - val_acc: 0.8974\n",
            "Epoch 3482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8922 - val_loss: 0.1005 - val_acc: 0.8978\n",
            "Epoch 3483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8861 - val_loss: 0.1006 - val_acc: 0.8982\n",
            "Epoch 3484/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8979 - val_loss: 0.1008 - val_acc: 0.8985\n",
            "Epoch 3485/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8981 - val_loss: 0.1008 - val_acc: 0.8987\n",
            "Epoch 3486/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8840 - val_loss: 0.1004 - val_acc: 0.8987\n",
            "Epoch 3487/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2203 - acc: 0.8799 - val_loss: 0.1009 - val_acc: 0.8986\n",
            "Epoch 3488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8937 - val_loss: 0.1018 - val_acc: 0.8983\n",
            "Epoch 3489/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8937 - val_loss: 0.1025 - val_acc: 0.8980\n",
            "Epoch 3490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8934 - val_loss: 0.1023 - val_acc: 0.8980\n",
            "Epoch 3491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8874 - val_loss: 0.1015 - val_acc: 0.8981\n",
            "Epoch 3492/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1643 - acc: 0.8744 - val_loss: 0.1010 - val_acc: 0.8983\n",
            "Epoch 3493/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8888 - val_loss: 0.1006 - val_acc: 0.8984\n",
            "Epoch 3494/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8853 - val_loss: 0.1004 - val_acc: 0.8984\n",
            "Epoch 3495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8888 - val_loss: 0.1001 - val_acc: 0.8985\n",
            "Epoch 3496/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8849 - val_loss: 0.0994 - val_acc: 0.8984\n",
            "Epoch 3497/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8875 - val_loss: 0.0987 - val_acc: 0.8982\n",
            "Epoch 3498/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8873 - val_loss: 0.0981 - val_acc: 0.8981\n",
            "Epoch 3499/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1868 - acc: 0.8653 - val_loss: 0.0984 - val_acc: 0.8978\n",
            "Epoch 3500/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8914 - val_loss: 0.0987 - val_acc: 0.8976\n",
            "Epoch 3501/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8801 - val_loss: 0.0984 - val_acc: 0.8976\n",
            "Epoch 3502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8801 - val_loss: 0.0974 - val_acc: 0.8978\n",
            "Epoch 3503/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8958 - val_loss: 0.0965 - val_acc: 0.8980\n",
            "Epoch 3504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8949 - val_loss: 0.0963 - val_acc: 0.8982\n",
            "Epoch 3505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8833 - val_loss: 0.0962 - val_acc: 0.8981\n",
            "Epoch 3506/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8826 - val_loss: 0.0955 - val_acc: 0.8978\n",
            "Epoch 3507/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2376 - acc: 0.8755 - val_loss: 0.0957 - val_acc: 0.8971\n",
            "Epoch 3508/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8911 - val_loss: 0.0972 - val_acc: 0.8962\n",
            "Epoch 3509/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8873 - val_loss: 0.0981 - val_acc: 0.8959\n",
            "Epoch 3510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8900 - val_loss: 0.0973 - val_acc: 0.8963\n",
            "Epoch 3511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8816 - val_loss: 0.0958 - val_acc: 0.8971\n",
            "Epoch 3512/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8835 - val_loss: 0.0954 - val_acc: 0.8977\n",
            "Epoch 3513/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8923 - val_loss: 0.0959 - val_acc: 0.8980\n",
            "Epoch 3514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8928 - val_loss: 0.0962 - val_acc: 0.8980\n",
            "Epoch 3515/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1067 - acc: 0.8846 - val_loss: 0.0953 - val_acc: 0.8978\n",
            "Epoch 3516/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8844 - val_loss: 0.0947 - val_acc: 0.8973\n",
            "Epoch 3517/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8845 - val_loss: 0.0948 - val_acc: 0.8967\n",
            "Epoch 3518/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8827 - val_loss: 0.0950 - val_acc: 0.8963\n",
            "Epoch 3519/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8824 - val_loss: 0.0947 - val_acc: 0.8965\n",
            "Epoch 3520/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8862 - val_loss: 0.0941 - val_acc: 0.8970\n",
            "Epoch 3521/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8929 - val_loss: 0.0939 - val_acc: 0.8974\n",
            "Epoch 3522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8896 - val_loss: 0.0939 - val_acc: 0.8976\n",
            "Epoch 3523/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8970 - val_loss: 0.0938 - val_acc: 0.8974\n",
            "Epoch 3524/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8764 - val_loss: 0.0935 - val_acc: 0.8970\n",
            "Epoch 3525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8959 - val_loss: 0.0934 - val_acc: 0.8965\n",
            "Epoch 3526/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8731 - val_loss: 0.0934 - val_acc: 0.8961\n",
            "Epoch 3527/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1319 - acc: 0.8767 - val_loss: 0.0937 - val_acc: 0.8957\n",
            "Epoch 3528/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8908 - val_loss: 0.0934 - val_acc: 0.8959\n",
            "Epoch 3529/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8911 - val_loss: 0.0932 - val_acc: 0.8965\n",
            "Epoch 3530/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8941 - val_loss: 0.0935 - val_acc: 0.8971\n",
            "Epoch 3531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2331 - acc: 0.8761 - val_loss: 0.0934 - val_acc: 0.8971\n",
            "Epoch 3532/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1114 - acc: 0.8957 - val_loss: 0.0937 - val_acc: 0.8967\n",
            "Epoch 3533/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8810 - val_loss: 0.0943 - val_acc: 0.8963\n",
            "Epoch 3534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8846 - val_loss: 0.0944 - val_acc: 0.8963\n",
            "Epoch 3535/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8907 - val_loss: 0.0942 - val_acc: 0.8965\n",
            "Epoch 3536/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8809 - val_loss: 0.0942 - val_acc: 0.8968\n",
            "Epoch 3537/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8777 - val_loss: 0.0944 - val_acc: 0.8971\n",
            "Epoch 3538/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8846 - val_loss: 0.0944 - val_acc: 0.8973\n",
            "Epoch 3539/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8865 - val_loss: 0.0942 - val_acc: 0.8973\n",
            "Epoch 3540/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2494 - acc: 0.8667 - val_loss: 0.0947 - val_acc: 0.8973\n",
            "Epoch 3541/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0911 - acc: 0.8991 - val_loss: 0.0955 - val_acc: 0.8973\n",
            "Epoch 3542/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8871 - val_loss: 0.0961 - val_acc: 0.8974\n",
            "Epoch 3543/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8752 - val_loss: 0.0962 - val_acc: 0.8975\n",
            "Epoch 3544/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1120 - acc: 0.8755 - val_loss: 0.0961 - val_acc: 0.8976\n",
            "Epoch 3545/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.9011 - val_loss: 0.0960 - val_acc: 0.8978\n",
            "Epoch 3546/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8772 - val_loss: 0.0961 - val_acc: 0.8978\n",
            "Epoch 3547/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8772 - val_loss: 0.0961 - val_acc: 0.8976\n",
            "Epoch 3548/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8864 - val_loss: 0.0961 - val_acc: 0.8974\n",
            "Epoch 3549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8870 - val_loss: 0.0959 - val_acc: 0.8974\n",
            "Epoch 3550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8841 - val_loss: 0.0955 - val_acc: 0.8974\n",
            "Epoch 3551/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8842 - val_loss: 0.0950 - val_acc: 0.8975\n",
            "Epoch 3552/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2187 - acc: 0.8711 - val_loss: 0.0954 - val_acc: 0.8975\n",
            "Epoch 3553/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8933 - val_loss: 0.0958 - val_acc: 0.8974\n",
            "Epoch 3554/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8865 - val_loss: 0.0959 - val_acc: 0.8974\n",
            "Epoch 3555/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8886 - val_loss: 0.0959 - val_acc: 0.8975\n",
            "Epoch 3556/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8792 - val_loss: 0.0956 - val_acc: 0.8976\n",
            "Epoch 3557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8769 - val_loss: 0.0953 - val_acc: 0.8976\n",
            "Epoch 3558/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8828 - val_loss: 0.0952 - val_acc: 0.8977\n",
            "Epoch 3559/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8873 - val_loss: 0.0951 - val_acc: 0.8977\n",
            "Epoch 3560/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8737 - val_loss: 0.0949 - val_acc: 0.8976\n",
            "Epoch 3561/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1096 - acc: 0.8757 - val_loss: 0.0946 - val_acc: 0.8973\n",
            "Epoch 3562/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8939 - val_loss: 0.0944 - val_acc: 0.8971\n",
            "Epoch 3563/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8874 - val_loss: 0.0941 - val_acc: 0.8970\n",
            "Epoch 3564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8858 - val_loss: 0.0939 - val_acc: 0.8971\n",
            "Epoch 3565/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8938 - val_loss: 0.0937 - val_acc: 0.8972\n",
            "Epoch 3566/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8863 - val_loss: 0.0935 - val_acc: 0.8972\n",
            "Epoch 3567/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8807 - val_loss: 0.0932 - val_acc: 0.8971\n",
            "Epoch 3568/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8806 - val_loss: 0.0931 - val_acc: 0.8968\n",
            "Epoch 3569/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8879 - val_loss: 0.0930 - val_acc: 0.8966\n",
            "Epoch 3570/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8914 - val_loss: 0.0930 - val_acc: 0.8965\n",
            "Epoch 3571/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8851 - val_loss: 0.0928 - val_acc: 0.8966\n",
            "Epoch 3572/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8834 - val_loss: 0.0928 - val_acc: 0.8968\n",
            "Epoch 3573/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8916 - val_loss: 0.0928 - val_acc: 0.8969\n",
            "Epoch 3574/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8958 - val_loss: 0.0928 - val_acc: 0.8968\n",
            "Epoch 3575/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8958 - val_loss: 0.0927 - val_acc: 0.8966\n",
            "Epoch 3576/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8848 - val_loss: 0.0927 - val_acc: 0.8961\n",
            "Epoch 3577/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8912 - val_loss: 0.0927 - val_acc: 0.8958\n",
            "Epoch 3578/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8759 - val_loss: 0.0927 - val_acc: 0.8957\n",
            "Epoch 3579/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8757 - val_loss: 0.0927 - val_acc: 0.8958\n",
            "Epoch 3580/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8875 - val_loss: 0.0925 - val_acc: 0.8963\n",
            "Epoch 3581/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8888 - val_loss: 0.0925 - val_acc: 0.8968\n",
            "Epoch 3582/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8892 - val_loss: 0.0926 - val_acc: 0.8970\n",
            "Epoch 3583/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8893 - val_loss: 0.0926 - val_acc: 0.8967\n",
            "Epoch 3584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8886 - val_loss: 0.0926 - val_acc: 0.8963\n",
            "Epoch 3585/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3278 - acc: 0.8583 - val_loss: 0.0972 - val_acc: 0.8932\n",
            "Epoch 3586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8888 - val_loss: 0.1002 - val_acc: 0.8920\n",
            "Epoch 3587/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8877 - val_loss: 0.0975 - val_acc: 0.8943\n",
            "Epoch 3588/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1926 - acc: 0.8682 - val_loss: 0.0962 - val_acc: 0.8961\n",
            "Epoch 3589/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8829 - val_loss: 0.0959 - val_acc: 0.8975\n",
            "Epoch 3590/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8823 - val_loss: 0.0969 - val_acc: 0.8980\n",
            "Epoch 3591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8900 - val_loss: 0.0976 - val_acc: 0.8981\n",
            "Epoch 3592/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8895 - val_loss: 0.0973 - val_acc: 0.8980\n",
            "Epoch 3593/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8858 - val_loss: 0.0970 - val_acc: 0.8976\n",
            "Epoch 3594/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8819 - val_loss: 0.0973 - val_acc: 0.8972\n",
            "Epoch 3595/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1068 - acc: 0.8815 - val_loss: 0.0979 - val_acc: 0.8968\n",
            "Epoch 3596/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8887 - val_loss: 0.0979 - val_acc: 0.8968\n",
            "Epoch 3597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8837 - val_loss: 0.0974 - val_acc: 0.8970\n",
            "Epoch 3598/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8915 - val_loss: 0.0969 - val_acc: 0.8974\n",
            "Epoch 3599/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8919 - val_loss: 0.0967 - val_acc: 0.8977\n",
            "Epoch 3600/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8782 - val_loss: 0.0965 - val_acc: 0.8978\n",
            "Epoch 3601/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8786 - val_loss: 0.0961 - val_acc: 0.8978\n",
            "Epoch 3602/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8850 - val_loss: 0.0956 - val_acc: 0.8977\n",
            "Epoch 3603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8847 - val_loss: 0.0951 - val_acc: 0.8975\n",
            "Epoch 3604/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8852 - val_loss: 0.0948 - val_acc: 0.8973\n",
            "Epoch 3605/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2600 - acc: 0.8563 - val_loss: 0.0957 - val_acc: 0.8968\n",
            "Epoch 3606/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8849 - val_loss: 0.0966 - val_acc: 0.8965\n",
            "Epoch 3607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8887 - val_loss: 0.0967 - val_acc: 0.8967\n",
            "Epoch 3608/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8831 - val_loss: 0.0962 - val_acc: 0.8972\n",
            "Epoch 3609/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8938 - val_loss: 0.0959 - val_acc: 0.8978\n",
            "Epoch 3610/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8809 - val_loss: 0.0959 - val_acc: 0.8981\n",
            "Epoch 3611/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2235 - acc: 0.8670 - val_loss: 0.0961 - val_acc: 0.8980\n",
            "Epoch 3612/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8811 - val_loss: 0.0963 - val_acc: 0.8978\n",
            "Epoch 3613/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8953 - val_loss: 0.0967 - val_acc: 0.8975\n",
            "Epoch 3614/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8887 - val_loss: 0.0969 - val_acc: 0.8972\n",
            "Epoch 3615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8979 - val_loss: 0.0967 - val_acc: 0.8973\n",
            "Epoch 3616/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8889 - val_loss: 0.0961 - val_acc: 0.8975\n",
            "Epoch 3617/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8944 - val_loss: 0.0955 - val_acc: 0.8977\n",
            "Epoch 3618/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8900 - val_loss: 0.0952 - val_acc: 0.8979\n",
            "Epoch 3619/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8823 - val_loss: 0.0950 - val_acc: 0.8978\n",
            "Epoch 3620/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8869 - val_loss: 0.0947 - val_acc: 0.8976\n",
            "Epoch 3621/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8836 - val_loss: 0.0944 - val_acc: 0.8973\n",
            "Epoch 3622/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2666 - acc: 0.8546 - val_loss: 0.0962 - val_acc: 0.8961\n",
            "Epoch 3623/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8763 - val_loss: 0.0985 - val_acc: 0.8953\n",
            "Epoch 3624/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8820 - val_loss: 0.0988 - val_acc: 0.8956\n",
            "Epoch 3625/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8885 - val_loss: 0.0973 - val_acc: 0.8966\n",
            "Epoch 3626/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8872 - val_loss: 0.0960 - val_acc: 0.8977\n",
            "Epoch 3627/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8883 - val_loss: 0.0961 - val_acc: 0.8982\n",
            "Epoch 3628/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2412 - acc: 0.8656 - val_loss: 0.0972 - val_acc: 0.8984\n",
            "Epoch 3629/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8869 - val_loss: 0.0974 - val_acc: 0.8983\n",
            "Epoch 3630/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8900 - val_loss: 0.0975 - val_acc: 0.8979\n",
            "Epoch 3631/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8875 - val_loss: 0.0979 - val_acc: 0.8973\n",
            "Epoch 3632/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8959 - val_loss: 0.0982 - val_acc: 0.8970\n",
            "Epoch 3633/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8870 - val_loss: 0.0980 - val_acc: 0.8969\n",
            "Epoch 3634/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8901 - val_loss: 0.0973 - val_acc: 0.8971\n",
            "Epoch 3635/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8732 - val_loss: 0.0966 - val_acc: 0.8975\n",
            "Epoch 3636/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8993 - val_loss: 0.0962 - val_acc: 0.8979\n",
            "Epoch 3637/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8831 - val_loss: 0.0960 - val_acc: 0.8981\n",
            "Epoch 3638/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8883 - val_loss: 0.0957 - val_acc: 0.8981\n",
            "Epoch 3639/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8856 - val_loss: 0.0952 - val_acc: 0.8979\n",
            "Epoch 3640/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8834 - val_loss: 0.0948 - val_acc: 0.8975\n",
            "Epoch 3641/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8828 - val_loss: 0.0947 - val_acc: 0.8970\n",
            "Epoch 3642/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8843 - val_loss: 0.0947 - val_acc: 0.8966\n",
            "Epoch 3643/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8824 - val_loss: 0.0943 - val_acc: 0.8966\n",
            "Epoch 3644/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8917 - val_loss: 0.0937 - val_acc: 0.8968\n",
            "Epoch 3645/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8899 - val_loss: 0.0934 - val_acc: 0.8973\n",
            "Epoch 3646/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8863 - val_loss: 0.0935 - val_acc: 0.8976\n",
            "Epoch 3647/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8866 - val_loss: 0.0934 - val_acc: 0.8976\n",
            "Epoch 3648/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8832 - val_loss: 0.0929 - val_acc: 0.8974\n",
            "Epoch 3649/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8836 - val_loss: 0.0927 - val_acc: 0.8968\n",
            "Epoch 3650/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8864 - val_loss: 0.0929 - val_acc: 0.8962\n",
            "Epoch 3651/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8843 - val_loss: 0.0931 - val_acc: 0.8957\n",
            "Epoch 3652/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8896 - val_loss: 0.0929 - val_acc: 0.8958\n",
            "Epoch 3653/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8893 - val_loss: 0.0926 - val_acc: 0.8962\n",
            "Epoch 3654/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8863 - val_loss: 0.0925 - val_acc: 0.8966\n",
            "Epoch 3655/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8914 - val_loss: 0.0926 - val_acc: 0.8967\n",
            "Epoch 3656/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0935 - acc: 0.8923 - val_loss: 0.0926 - val_acc: 0.8967\n",
            "Epoch 3657/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8850 - val_loss: 0.0925 - val_acc: 0.8966\n",
            "Epoch 3658/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8876 - val_loss: 0.0924 - val_acc: 0.8964\n",
            "Epoch 3659/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1641 - acc: 0.8770 - val_loss: 0.0927 - val_acc: 0.8958\n",
            "Epoch 3660/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8900 - val_loss: 0.0929 - val_acc: 0.8958\n",
            "Epoch 3661/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2906 - acc: 0.8465 - val_loss: 0.0947 - val_acc: 0.8952\n",
            "Epoch 3662/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8787 - val_loss: 0.0954 - val_acc: 0.8955\n",
            "Epoch 3663/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8781 - val_loss: 0.0949 - val_acc: 0.8964\n",
            "Epoch 3664/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8793 - val_loss: 0.0948 - val_acc: 0.8973\n",
            "Epoch 3665/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0914 - acc: 0.8980 - val_loss: 0.0953 - val_acc: 0.8977\n",
            "Epoch 3666/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8873 - val_loss: 0.0955 - val_acc: 0.8978\n",
            "Epoch 3667/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8839 - val_loss: 0.0950 - val_acc: 0.8977\n",
            "Epoch 3668/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8839 - val_loss: 0.0947 - val_acc: 0.8974\n",
            "Epoch 3669/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0940 - acc: 0.8959 - val_loss: 0.0950 - val_acc: 0.8969\n",
            "Epoch 3670/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8907 - val_loss: 0.0955 - val_acc: 0.8966\n",
            "Epoch 3671/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1118 - acc: 0.8827 - val_loss: 0.0956 - val_acc: 0.8967\n",
            "Epoch 3672/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1209 - acc: 0.8827 - val_loss: 0.0954 - val_acc: 0.8969\n",
            "Epoch 3673/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8920 - val_loss: 0.0951 - val_acc: 0.8973\n",
            "Epoch 3674/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8923 - val_loss: 0.0950 - val_acc: 0.8977\n",
            "Epoch 3675/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8921 - val_loss: 0.0950 - val_acc: 0.8979\n",
            "Epoch 3676/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8901 - val_loss: 0.0947 - val_acc: 0.8978\n",
            "Epoch 3677/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8859 - val_loss: 0.0941 - val_acc: 0.8976\n",
            "Epoch 3678/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8708 - val_loss: 0.0939 - val_acc: 0.8972\n",
            "Epoch 3679/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8895 - val_loss: 0.0941 - val_acc: 0.8967\n",
            "Epoch 3680/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1881 - acc: 0.8744 - val_loss: 0.0950 - val_acc: 0.8963\n",
            "Epoch 3681/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8931 - val_loss: 0.0951 - val_acc: 0.8965\n",
            "Epoch 3682/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1124 - acc: 0.8707 - val_loss: 0.0944 - val_acc: 0.8972\n",
            "Epoch 3683/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8854 - val_loss: 0.0942 - val_acc: 0.8978\n",
            "Epoch 3684/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8928 - val_loss: 0.0945 - val_acc: 0.8981\n",
            "Epoch 3685/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8932 - val_loss: 0.0944 - val_acc: 0.8979\n",
            "Epoch 3686/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8920 - val_loss: 0.0938 - val_acc: 0.8975\n",
            "Epoch 3687/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2642 - acc: 0.8651 - val_loss: 0.0945 - val_acc: 0.8964\n",
            "Epoch 3688/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8877 - val_loss: 0.0966 - val_acc: 0.8953\n",
            "Epoch 3689/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8870 - val_loss: 0.0975 - val_acc: 0.8950\n",
            "Epoch 3690/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8869 - val_loss: 0.0965 - val_acc: 0.8958\n",
            "Epoch 3691/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8941 - val_loss: 0.0952 - val_acc: 0.8970\n",
            "Epoch 3692/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8920 - val_loss: 0.0951 - val_acc: 0.8979\n",
            "Epoch 3693/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2741 - acc: 0.8601 - val_loss: 0.0965 - val_acc: 0.8983\n",
            "Epoch 3694/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8874 - val_loss: 0.0978 - val_acc: 0.8984\n",
            "Epoch 3695/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2409 - acc: 0.8750 - val_loss: 0.1007 - val_acc: 0.8981\n",
            "Epoch 3696/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1330 - acc: 0.8842 - val_loss: 0.1047 - val_acc: 0.8977\n",
            "Epoch 3697/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8791 - val_loss: 0.1070 - val_acc: 0.8976\n",
            "Epoch 3698/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1127 - acc: 0.8877 - val_loss: 0.1070 - val_acc: 0.8979\n",
            "Epoch 3699/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8867 - val_loss: 0.1054 - val_acc: 0.8981\n",
            "Epoch 3700/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8913 - val_loss: 0.1040 - val_acc: 0.8983\n",
            "Epoch 3701/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1130 - acc: 0.8856 - val_loss: 0.1032 - val_acc: 0.8983\n",
            "Epoch 3702/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1583 - acc: 0.8835 - val_loss: 0.1031 - val_acc: 0.8983\n",
            "Epoch 3703/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8908 - val_loss: 0.1023 - val_acc: 0.8982\n",
            "Epoch 3704/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8907 - val_loss: 0.1012 - val_acc: 0.8981\n",
            "Epoch 3705/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8939 - val_loss: 0.1005 - val_acc: 0.8977\n",
            "Epoch 3706/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8861 - val_loss: 0.1001 - val_acc: 0.8974\n",
            "Epoch 3707/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1107 - acc: 0.8871 - val_loss: 0.0998 - val_acc: 0.8972\n",
            "Epoch 3708/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8850 - val_loss: 0.0992 - val_acc: 0.8972\n",
            "Epoch 3709/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8820 - val_loss: 0.0983 - val_acc: 0.8974\n",
            "Epoch 3710/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8809 - val_loss: 0.0974 - val_acc: 0.8977\n",
            "Epoch 3711/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8828 - val_loss: 0.0966 - val_acc: 0.8980\n",
            "Epoch 3712/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8917 - val_loss: 0.0960 - val_acc: 0.8981\n",
            "Epoch 3713/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8784 - val_loss: 0.0955 - val_acc: 0.8981\n",
            "Epoch 3714/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8961 - val_loss: 0.0949 - val_acc: 0.8980\n",
            "Epoch 3715/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8882 - val_loss: 0.0944 - val_acc: 0.8977\n",
            "Epoch 3716/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8879 - val_loss: 0.0941 - val_acc: 0.8972\n",
            "Epoch 3717/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8884 - val_loss: 0.0940 - val_acc: 0.8967\n",
            "Epoch 3718/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8794 - val_loss: 0.0938 - val_acc: 0.8964\n",
            "Epoch 3719/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8793 - val_loss: 0.0935 - val_acc: 0.8964\n",
            "Epoch 3720/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8875 - val_loss: 0.0933 - val_acc: 0.8964\n",
            "Epoch 3721/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8826 - val_loss: 0.0932 - val_acc: 0.8965\n",
            "Epoch 3722/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8825 - val_loss: 0.0930 - val_acc: 0.8964\n",
            "Epoch 3723/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8911 - val_loss: 0.0929 - val_acc: 0.8964\n",
            "Epoch 3724/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8787 - val_loss: 0.0927 - val_acc: 0.8963\n",
            "Epoch 3725/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8918 - val_loss: 0.0927 - val_acc: 0.8962\n",
            "Epoch 3726/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8876 - val_loss: 0.0929 - val_acc: 0.8960\n",
            "Epoch 3727/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8727 - val_loss: 0.0931 - val_acc: 0.8956\n",
            "Epoch 3728/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2507 - acc: 0.8542 - val_loss: 0.0953 - val_acc: 0.8937\n",
            "Epoch 3729/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8912 - val_loss: 0.0964 - val_acc: 0.8932\n",
            "Epoch 3730/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8871 - val_loss: 0.0945 - val_acc: 0.8948\n",
            "Epoch 3731/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8837 - val_loss: 0.0933 - val_acc: 0.8966\n",
            "Epoch 3732/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8900 - val_loss: 0.0943 - val_acc: 0.8975\n",
            "Epoch 3733/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8869 - val_loss: 0.0945 - val_acc: 0.8977\n",
            "Epoch 3734/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8849 - val_loss: 0.0933 - val_acc: 0.8972\n",
            "Epoch 3735/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8785 - val_loss: 0.0932 - val_acc: 0.8962\n",
            "Epoch 3736/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1411 - acc: 0.8714 - val_loss: 0.0943 - val_acc: 0.8953\n",
            "Epoch 3737/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8803 - val_loss: 0.0947 - val_acc: 0.8951\n",
            "Epoch 3738/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8852 - val_loss: 0.0939 - val_acc: 0.8959\n",
            "Epoch 3739/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8860 - val_loss: 0.0932 - val_acc: 0.8969\n",
            "Epoch 3740/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8869 - val_loss: 0.0935 - val_acc: 0.8976\n",
            "Epoch 3741/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8963 - val_loss: 0.0940 - val_acc: 0.8979\n",
            "Epoch 3742/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8872 - val_loss: 0.0937 - val_acc: 0.8978\n",
            "Epoch 3743/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2101 - acc: 0.8725 - val_loss: 0.0935 - val_acc: 0.8971\n",
            "Epoch 3744/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8940 - val_loss: 0.0945 - val_acc: 0.8963\n",
            "Epoch 3745/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0921 - acc: 0.8943 - val_loss: 0.0952 - val_acc: 0.8959\n",
            "Epoch 3746/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8881 - val_loss: 0.0950 - val_acc: 0.8962\n",
            "Epoch 3747/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1999 - acc: 0.8632 - val_loss: 0.0949 - val_acc: 0.8969\n",
            "Epoch 3748/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8875 - val_loss: 0.0949 - val_acc: 0.8976\n",
            "Epoch 3749/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8865 - val_loss: 0.0952 - val_acc: 0.8982\n",
            "Epoch 3750/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8856 - val_loss: 0.0955 - val_acc: 0.8984\n",
            "Epoch 3751/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8870 - val_loss: 0.0955 - val_acc: 0.8984\n",
            "Epoch 3752/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8761 - val_loss: 0.0953 - val_acc: 0.8983\n",
            "Epoch 3753/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0923 - acc: 0.8997 - val_loss: 0.0952 - val_acc: 0.8980\n",
            "Epoch 3754/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1521 - acc: 0.8818 - val_loss: 0.0958 - val_acc: 0.8976\n",
            "Epoch 3755/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8895 - val_loss: 0.0962 - val_acc: 0.8973\n",
            "Epoch 3756/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8839 - val_loss: 0.0959 - val_acc: 0.8973\n",
            "Epoch 3757/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8839 - val_loss: 0.0953 - val_acc: 0.8977\n",
            "Epoch 3758/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8902 - val_loss: 0.0949 - val_acc: 0.8979\n",
            "Epoch 3759/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8802 - val_loss: 0.0948 - val_acc: 0.8980\n",
            "Epoch 3760/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8812 - val_loss: 0.0945 - val_acc: 0.8980\n",
            "Epoch 3761/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8812 - val_loss: 0.0942 - val_acc: 0.8979\n",
            "Epoch 3762/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1064 - acc: 0.8837 - val_loss: 0.0938 - val_acc: 0.8976\n",
            "Epoch 3763/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8861 - val_loss: 0.0936 - val_acc: 0.8973\n",
            "Epoch 3764/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8897 - val_loss: 0.0935 - val_acc: 0.8971\n",
            "Epoch 3765/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8881 - val_loss: 0.0933 - val_acc: 0.8970\n",
            "Epoch 3766/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8963 - val_loss: 0.0930 - val_acc: 0.8971\n",
            "Epoch 3767/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1604 - acc: 0.8761 - val_loss: 0.0930 - val_acc: 0.8969\n",
            "Epoch 3768/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8840 - val_loss: 0.0930 - val_acc: 0.8968\n",
            "Epoch 3769/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8841 - val_loss: 0.0929 - val_acc: 0.8968\n",
            "Epoch 3770/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8758 - val_loss: 0.0927 - val_acc: 0.8968\n",
            "Epoch 3771/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8852 - val_loss: 0.0926 - val_acc: 0.8968\n",
            "Epoch 3772/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8852 - val_loss: 0.0925 - val_acc: 0.8966\n",
            "Epoch 3773/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8733 - val_loss: 0.0924 - val_acc: 0.8965\n",
            "Epoch 3774/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8733 - val_loss: 0.0925 - val_acc: 0.8965\n",
            "Epoch 3775/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8892 - val_loss: 0.0925 - val_acc: 0.8965\n",
            "Epoch 3776/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8921 - val_loss: 0.0924 - val_acc: 0.8965\n",
            "Epoch 3777/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8818 - val_loss: 0.0923 - val_acc: 0.8965\n",
            "Epoch 3778/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8855 - val_loss: 0.0924 - val_acc: 0.8964\n",
            "Epoch 3779/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8868 - val_loss: 0.0923 - val_acc: 0.8966\n",
            "Epoch 3780/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8870 - val_loss: 0.0924 - val_acc: 0.8969\n",
            "Epoch 3781/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8801 - val_loss: 0.0923 - val_acc: 0.8969\n",
            "Epoch 3782/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8801 - val_loss: 0.0921 - val_acc: 0.8967\n",
            "Epoch 3783/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8856 - val_loss: 0.0921 - val_acc: 0.8963\n",
            "Epoch 3784/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8853 - val_loss: 0.0921 - val_acc: 0.8961\n",
            "Epoch 3785/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8859 - val_loss: 0.0919 - val_acc: 0.8963\n",
            "Epoch 3786/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8861 - val_loss: 0.0918 - val_acc: 0.8967\n",
            "Epoch 3787/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8852 - val_loss: 0.0919 - val_acc: 0.8969\n",
            "Epoch 3788/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8862 - val_loss: 0.0918 - val_acc: 0.8968\n",
            "Epoch 3789/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8897 - val_loss: 0.0918 - val_acc: 0.8967\n",
            "Epoch 3790/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0935 - acc: 0.8904 - val_loss: 0.0917 - val_acc: 0.8964\n",
            "Epoch 3791/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8779 - val_loss: 0.0916 - val_acc: 0.8964\n",
            "Epoch 3792/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8673 - val_loss: 0.0915 - val_acc: 0.8966\n",
            "Epoch 3793/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8676 - val_loss: 0.0916 - val_acc: 0.8969\n",
            "Epoch 3794/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8831 - val_loss: 0.0918 - val_acc: 0.8970\n",
            "Epoch 3795/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8897 - val_loss: 0.0917 - val_acc: 0.8969\n",
            "Epoch 3796/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2219 - acc: 0.8671 - val_loss: 0.0920 - val_acc: 0.8960\n",
            "Epoch 3797/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8851 - val_loss: 0.0930 - val_acc: 0.8955\n",
            "Epoch 3798/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8927 - val_loss: 0.0929 - val_acc: 0.8959\n",
            "Epoch 3799/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1200 - acc: 0.8748 - val_loss: 0.0924 - val_acc: 0.8967\n",
            "Epoch 3800/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8830 - val_loss: 0.0923 - val_acc: 0.8974\n",
            "Epoch 3801/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8834 - val_loss: 0.0925 - val_acc: 0.8976\n",
            "Epoch 3802/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8899 - val_loss: 0.0925 - val_acc: 0.8975\n",
            "Epoch 3803/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8900 - val_loss: 0.0925 - val_acc: 0.8971\n",
            "Epoch 3804/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1091 - acc: 0.8741 - val_loss: 0.0927 - val_acc: 0.8967\n",
            "Epoch 3805/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8862 - val_loss: 0.0927 - val_acc: 0.8965\n",
            "Epoch 3806/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8860 - val_loss: 0.0925 - val_acc: 0.8967\n",
            "Epoch 3807/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0912 - acc: 0.8930 - val_loss: 0.0924 - val_acc: 0.8968\n",
            "Epoch 3808/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8845 - val_loss: 0.0924 - val_acc: 0.8971\n",
            "Epoch 3809/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8844 - val_loss: 0.0923 - val_acc: 0.8973\n",
            "Epoch 3810/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8848 - val_loss: 0.0922 - val_acc: 0.8973\n",
            "Epoch 3811/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1226 - acc: 0.8758 - val_loss: 0.0921 - val_acc: 0.8970\n",
            "Epoch 3812/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1673 - acc: 0.8728 - val_loss: 0.0929 - val_acc: 0.8965\n",
            "Epoch 3813/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8832 - val_loss: 0.0936 - val_acc: 0.8962\n",
            "Epoch 3814/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8813 - val_loss: 0.0934 - val_acc: 0.8965\n",
            "Epoch 3815/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8802 - val_loss: 0.0931 - val_acc: 0.8971\n",
            "Epoch 3816/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8913 - val_loss: 0.0932 - val_acc: 0.8975\n",
            "Epoch 3817/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8845 - val_loss: 0.0934 - val_acc: 0.8975\n",
            "Epoch 3818/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8847 - val_loss: 0.0930 - val_acc: 0.8974\n",
            "Epoch 3819/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8882 - val_loss: 0.0926 - val_acc: 0.8970\n",
            "Epoch 3820/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8804 - val_loss: 0.0927 - val_acc: 0.8964\n",
            "Epoch 3821/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8784 - val_loss: 0.0931 - val_acc: 0.8958\n",
            "Epoch 3822/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8843 - val_loss: 0.0931 - val_acc: 0.8959\n",
            "Epoch 3823/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0900 - acc: 0.8934 - val_loss: 0.0926 - val_acc: 0.8964\n",
            "Epoch 3824/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8893 - val_loss: 0.0922 - val_acc: 0.8970\n",
            "Epoch 3825/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8875 - val_loss: 0.0924 - val_acc: 0.8975\n",
            "Epoch 3826/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8879 - val_loss: 0.0925 - val_acc: 0.8976\n",
            "Epoch 3827/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8909 - val_loss: 0.0922 - val_acc: 0.8973\n",
            "Epoch 3828/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0881 - acc: 0.8992 - val_loss: 0.0919 - val_acc: 0.8969\n",
            "Epoch 3829/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8899 - val_loss: 0.0921 - val_acc: 0.8962\n",
            "Epoch 3830/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - acc: 0.8888 - val_loss: 0.0924 - val_acc: 0.8957\n",
            "Epoch 3831/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8825 - val_loss: 0.0922 - val_acc: 0.8958\n",
            "Epoch 3832/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0929 - acc: 0.8913 - val_loss: 0.0916 - val_acc: 0.8965\n",
            "Epoch 3833/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8919 - val_loss: 0.0918 - val_acc: 0.8971\n",
            "Epoch 3834/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8751 - val_loss: 0.0921 - val_acc: 0.8973\n",
            "Epoch 3835/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8815 - val_loss: 0.0919 - val_acc: 0.8970\n",
            "Epoch 3836/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8870 - val_loss: 0.0916 - val_acc: 0.8965\n",
            "Epoch 3837/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8845 - val_loss: 0.0917 - val_acc: 0.8962\n",
            "Epoch 3838/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8831 - val_loss: 0.0917 - val_acc: 0.8961\n",
            "Epoch 3839/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8825 - val_loss: 0.0916 - val_acc: 0.8965\n",
            "Epoch 3840/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1134 - acc: 0.8731 - val_loss: 0.0917 - val_acc: 0.8969\n",
            "Epoch 3841/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8925 - val_loss: 0.0918 - val_acc: 0.8972\n",
            "Epoch 3842/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1369 - acc: 0.8873 - val_loss: 0.0917 - val_acc: 0.8971\n",
            "Epoch 3843/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8878 - val_loss: 0.0917 - val_acc: 0.8969\n",
            "Epoch 3844/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8895 - val_loss: 0.0918 - val_acc: 0.8966\n",
            "Epoch 3845/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8892 - val_loss: 0.0918 - val_acc: 0.8964\n",
            "Epoch 3846/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8874 - val_loss: 0.0917 - val_acc: 0.8964\n",
            "Epoch 3847/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8775 - val_loss: 0.0916 - val_acc: 0.8966\n",
            "Epoch 3848/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8778 - val_loss: 0.0917 - val_acc: 0.8969\n",
            "Epoch 3849/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8747 - val_loss: 0.0918 - val_acc: 0.8971\n",
            "Epoch 3850/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1726 - acc: 0.8743 - val_loss: 0.0916 - val_acc: 0.8968\n",
            "Epoch 3851/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8850 - val_loss: 0.0919 - val_acc: 0.8964\n",
            "Epoch 3852/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2717 - acc: 0.8541 - val_loss: 0.0946 - val_acc: 0.8954\n",
            "Epoch 3853/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8812 - val_loss: 0.0962 - val_acc: 0.8955\n",
            "Epoch 3854/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8819 - val_loss: 0.0956 - val_acc: 0.8968\n",
            "Epoch 3855/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8858 - val_loss: 0.0951 - val_acc: 0.8980\n",
            "Epoch 3856/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2925 - acc: 0.8538 - val_loss: 0.0972 - val_acc: 0.8982\n",
            "Epoch 3857/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8829 - val_loss: 0.0988 - val_acc: 0.8982\n",
            "Epoch 3858/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2224 - acc: 0.8733 - val_loss: 0.1022 - val_acc: 0.8983\n",
            "Epoch 3859/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1282 - acc: 0.8886 - val_loss: 0.1056 - val_acc: 0.8983\n",
            "Epoch 3860/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8853 - val_loss: 0.1073 - val_acc: 0.8985\n",
            "Epoch 3861/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8923 - val_loss: 0.1072 - val_acc: 0.8987\n",
            "Epoch 3862/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1193 - acc: 0.8813 - val_loss: 0.1063 - val_acc: 0.8988\n",
            "Epoch 3863/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8922 - val_loss: 0.1051 - val_acc: 0.8988\n",
            "Epoch 3864/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8950 - val_loss: 0.1042 - val_acc: 0.8987\n",
            "Epoch 3865/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8950 - val_loss: 0.1034 - val_acc: 0.8985\n",
            "Epoch 3866/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8807 - val_loss: 0.1024 - val_acc: 0.8982\n",
            "Epoch 3867/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8910 - val_loss: 0.1016 - val_acc: 0.8980\n",
            "Epoch 3868/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8908 - val_loss: 0.1010 - val_acc: 0.8977\n",
            "Epoch 3869/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1154 - acc: 0.8892 - val_loss: 0.1004 - val_acc: 0.8975\n",
            "Epoch 3870/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8809 - val_loss: 0.0998 - val_acc: 0.8974\n",
            "Epoch 3871/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8921 - val_loss: 0.0990 - val_acc: 0.8975\n",
            "Epoch 3872/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1334 - acc: 0.8850 - val_loss: 0.0983 - val_acc: 0.8977\n",
            "Epoch 3873/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1942 - acc: 0.8751 - val_loss: 0.0983 - val_acc: 0.8977\n",
            "Epoch 3874/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8868 - val_loss: 0.0980 - val_acc: 0.8978\n",
            "Epoch 3875/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1073 - acc: 0.8854 - val_loss: 0.0975 - val_acc: 0.8980\n",
            "Epoch 3876/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8825 - val_loss: 0.0969 - val_acc: 0.8980\n",
            "Epoch 3877/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8915 - val_loss: 0.0966 - val_acc: 0.8980\n",
            "Epoch 3878/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8893 - val_loss: 0.0964 - val_acc: 0.8980\n",
            "Epoch 3879/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8855 - val_loss: 0.0959 - val_acc: 0.8979\n",
            "Epoch 3880/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8932 - val_loss: 0.0953 - val_acc: 0.8978\n",
            "Epoch 3881/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8820 - val_loss: 0.0947 - val_acc: 0.8975\n",
            "Epoch 3882/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8817 - val_loss: 0.0944 - val_acc: 0.8971\n",
            "Epoch 3883/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8888 - val_loss: 0.0942 - val_acc: 0.8967\n",
            "Epoch 3884/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1070 - acc: 0.8817 - val_loss: 0.0939 - val_acc: 0.8965\n",
            "Epoch 3885/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8797 - val_loss: 0.0934 - val_acc: 0.8966\n",
            "Epoch 3886/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8910 - val_loss: 0.0929 - val_acc: 0.8969\n",
            "Epoch 3887/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8857 - val_loss: 0.0925 - val_acc: 0.8971\n",
            "Epoch 3888/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8882 - val_loss: 0.0924 - val_acc: 0.8971\n",
            "Epoch 3889/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1554 - acc: 0.8844 - val_loss: 0.0925 - val_acc: 0.8967\n",
            "Epoch 3890/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2506 - acc: 0.8602 - val_loss: 0.0941 - val_acc: 0.8958\n",
            "Epoch 3891/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8892 - val_loss: 0.0955 - val_acc: 0.8953\n",
            "Epoch 3892/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1525 - acc: 0.8761 - val_loss: 0.0960 - val_acc: 0.8957\n",
            "Epoch 3893/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8915 - val_loss: 0.0950 - val_acc: 0.8969\n",
            "Epoch 3894/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1256 - acc: 0.8856 - val_loss: 0.0947 - val_acc: 0.8978\n",
            "Epoch 3895/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8907 - val_loss: 0.0954 - val_acc: 0.8982\n",
            "Epoch 3896/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8876 - val_loss: 0.0957 - val_acc: 0.8983\n",
            "Epoch 3897/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1214 - acc: 0.8872 - val_loss: 0.0952 - val_acc: 0.8981\n",
            "Epoch 3898/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8882 - val_loss: 0.0948 - val_acc: 0.8978\n",
            "Epoch 3899/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8880 - val_loss: 0.0949 - val_acc: 0.8974\n",
            "Epoch 3900/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1586 - acc: 0.8752 - val_loss: 0.0960 - val_acc: 0.8969\n",
            "Epoch 3901/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8859 - val_loss: 0.0965 - val_acc: 0.8968\n",
            "Epoch 3902/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8860 - val_loss: 0.0961 - val_acc: 0.8972\n",
            "Epoch 3903/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1151 - acc: 0.8722 - val_loss: 0.0954 - val_acc: 0.8976\n",
            "Epoch 3904/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8915 - val_loss: 0.0951 - val_acc: 0.8980\n",
            "Epoch 3905/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8921 - val_loss: 0.0952 - val_acc: 0.8982\n",
            "Epoch 3906/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8810 - val_loss: 0.0949 - val_acc: 0.8983\n",
            "Epoch 3907/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8902 - val_loss: 0.0943 - val_acc: 0.8981\n",
            "Epoch 3908/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8961 - val_loss: 0.0939 - val_acc: 0.8977\n",
            "Epoch 3909/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8826 - val_loss: 0.0938 - val_acc: 0.8972\n",
            "Epoch 3910/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8821 - val_loss: 0.0937 - val_acc: 0.8969\n",
            "Epoch 3911/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2399 - acc: 0.8668 - val_loss: 0.0953 - val_acc: 0.8963\n",
            "Epoch 3912/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8901 - val_loss: 0.0960 - val_acc: 0.8963\n",
            "Epoch 3913/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1180 - acc: 0.8825 - val_loss: 0.0956 - val_acc: 0.8969\n",
            "Epoch 3914/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8911 - val_loss: 0.0948 - val_acc: 0.8977\n",
            "Epoch 3915/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8963 - val_loss: 0.0945 - val_acc: 0.8982\n",
            "Epoch 3916/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8848 - val_loss: 0.0947 - val_acc: 0.8983\n",
            "Epoch 3917/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8931 - val_loss: 0.0947 - val_acc: 0.8981\n",
            "Epoch 3918/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8930 - val_loss: 0.0944 - val_acc: 0.8978\n",
            "Epoch 3919/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8955 - val_loss: 0.0940 - val_acc: 0.8974\n",
            "Epoch 3920/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1119 - acc: 0.8813 - val_loss: 0.0937 - val_acc: 0.8970\n",
            "Epoch 3921/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2630 - acc: 0.8574 - val_loss: 0.0952 - val_acc: 0.8964\n",
            "Epoch 3922/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8875 - val_loss: 0.0961 - val_acc: 0.8963\n",
            "Epoch 3923/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8824 - val_loss: 0.0957 - val_acc: 0.8969\n",
            "Epoch 3924/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8870 - val_loss: 0.0948 - val_acc: 0.8977\n",
            "Epoch 3925/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8939 - val_loss: 0.0949 - val_acc: 0.8982\n",
            "Epoch 3926/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8906 - val_loss: 0.0954 - val_acc: 0.8984\n",
            "Epoch 3927/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8775 - val_loss: 0.0953 - val_acc: 0.8984\n",
            "Epoch 3928/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1128 - acc: 0.8777 - val_loss: 0.0946 - val_acc: 0.8982\n",
            "Epoch 3929/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8971 - val_loss: 0.0942 - val_acc: 0.8978\n",
            "Epoch 3930/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8751 - val_loss: 0.0941 - val_acc: 0.8974\n",
            "Epoch 3931/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8810 - val_loss: 0.0942 - val_acc: 0.8969\n",
            "Epoch 3932/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8805 - val_loss: 0.0940 - val_acc: 0.8969\n",
            "Epoch 3933/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1437 - acc: 0.8822 - val_loss: 0.0939 - val_acc: 0.8968\n",
            "Epoch 3934/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1491 - acc: 0.8822 - val_loss: 0.0937 - val_acc: 0.8972\n",
            "Epoch 3935/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8951 - val_loss: 0.0937 - val_acc: 0.8977\n",
            "Epoch 3936/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0935 - acc: 0.8992 - val_loss: 0.0939 - val_acc: 0.8980\n",
            "Epoch 3937/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8857 - val_loss: 0.0938 - val_acc: 0.8981\n",
            "Epoch 3938/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8867 - val_loss: 0.0933 - val_acc: 0.8980\n",
            "Epoch 3939/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8928 - val_loss: 0.0929 - val_acc: 0.8976\n",
            "Epoch 3940/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8825 - val_loss: 0.0929 - val_acc: 0.8970\n",
            "Epoch 3941/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8776 - val_loss: 0.0931 - val_acc: 0.8966\n",
            "Epoch 3942/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8859 - val_loss: 0.0929 - val_acc: 0.8964\n",
            "Epoch 3943/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8858 - val_loss: 0.0925 - val_acc: 0.8966\n",
            "Epoch 3944/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8836 - val_loss: 0.0921 - val_acc: 0.8970\n",
            "Epoch 3945/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0881 - acc: 0.8990 - val_loss: 0.0921 - val_acc: 0.8973\n",
            "Epoch 3946/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8875 - val_loss: 0.0922 - val_acc: 0.8975\n",
            "Epoch 3947/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8939 - val_loss: 0.0920 - val_acc: 0.8974\n",
            "Epoch 3948/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8755 - val_loss: 0.0916 - val_acc: 0.8970\n",
            "Epoch 3949/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1657 - acc: 0.8811 - val_loss: 0.0917 - val_acc: 0.8968\n",
            "Epoch 3950/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1503 - acc: 0.8714 - val_loss: 0.0924 - val_acc: 0.8962\n",
            "Epoch 3951/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8759 - val_loss: 0.0929 - val_acc: 0.8959\n",
            "Epoch 3952/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8859 - val_loss: 0.0925 - val_acc: 0.8964\n",
            "Epoch 3953/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1108 - acc: 0.8832 - val_loss: 0.0921 - val_acc: 0.8970\n",
            "Epoch 3954/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8838 - val_loss: 0.0922 - val_acc: 0.8974\n",
            "Epoch 3955/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8843 - val_loss: 0.0925 - val_acc: 0.8976\n",
            "Epoch 3956/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8935 - val_loss: 0.0925 - val_acc: 0.8975\n",
            "Epoch 3957/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8901 - val_loss: 0.0922 - val_acc: 0.8972\n",
            "Epoch 3958/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8874 - val_loss: 0.0920 - val_acc: 0.8969\n",
            "Epoch 3959/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8873 - val_loss: 0.0920 - val_acc: 0.8968\n",
            "Epoch 3960/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8785 - val_loss: 0.0919 - val_acc: 0.8968\n",
            "Epoch 3961/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8764 - val_loss: 0.0919 - val_acc: 0.8969\n",
            "Epoch 3962/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3196 - acc: 0.8461 - val_loss: 0.0937 - val_acc: 0.8963\n",
            "Epoch 3963/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8858 - val_loss: 0.0952 - val_acc: 0.8963\n",
            "Epoch 3964/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2857 - acc: 0.8414 - val_loss: 0.1004 - val_acc: 0.8950\n",
            "Epoch 3965/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8708 - val_loss: 0.1019 - val_acc: 0.8956\n",
            "Epoch 3966/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8920 - val_loss: 0.1003 - val_acc: 0.8973\n",
            "Epoch 3967/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1774 - acc: 0.8707 - val_loss: 0.1004 - val_acc: 0.8982\n",
            "Epoch 3968/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8867 - val_loss: 0.1014 - val_acc: 0.8986\n",
            "Epoch 3969/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8954 - val_loss: 0.1025 - val_acc: 0.8987\n",
            "Epoch 3970/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8870 - val_loss: 0.1025 - val_acc: 0.8987\n",
            "Epoch 3971/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8870 - val_loss: 0.1017 - val_acc: 0.8985\n",
            "Epoch 3972/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1125 - acc: 0.8819 - val_loss: 0.1012 - val_acc: 0.8982\n",
            "Epoch 3973/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8897 - val_loss: 0.1013 - val_acc: 0.8978\n",
            "Epoch 3974/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8921 - val_loss: 0.1014 - val_acc: 0.8975\n",
            "Epoch 3975/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1088 - acc: 0.8840 - val_loss: 0.1008 - val_acc: 0.8975\n",
            "Epoch 3976/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8842 - val_loss: 0.0997 - val_acc: 0.8977\n",
            "Epoch 3977/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1132 - acc: 0.8798 - val_loss: 0.0987 - val_acc: 0.8980\n",
            "Epoch 3978/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1365 - acc: 0.8898 - val_loss: 0.0982 - val_acc: 0.8983\n",
            "Epoch 3979/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8973 - val_loss: 0.0980 - val_acc: 0.8985\n",
            "Epoch 3980/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8857 - val_loss: 0.0973 - val_acc: 0.8985\n",
            "Epoch 3981/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8931 - val_loss: 0.0964 - val_acc: 0.8983\n",
            "Epoch 3982/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8810 - val_loss: 0.0955 - val_acc: 0.8980\n",
            "Epoch 3983/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8775 - val_loss: 0.0953 - val_acc: 0.8975\n",
            "Epoch 3984/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8889 - val_loss: 0.0953 - val_acc: 0.8971\n",
            "Epoch 3985/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8900 - val_loss: 0.0948 - val_acc: 0.8970\n",
            "Epoch 3986/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8914 - val_loss: 0.0941 - val_acc: 0.8973\n",
            "Epoch 3987/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8901 - val_loss: 0.0935 - val_acc: 0.8976\n",
            "Epoch 3988/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8892 - val_loss: 0.0933 - val_acc: 0.8979\n",
            "Epoch 3989/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0901 - acc: 0.8990 - val_loss: 0.0932 - val_acc: 0.8979\n",
            "Epoch 3990/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8889 - val_loss: 0.0926 - val_acc: 0.8977\n",
            "Epoch 3991/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8932 - val_loss: 0.0920 - val_acc: 0.8973\n",
            "Epoch 3992/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8847 - val_loss: 0.0919 - val_acc: 0.8967\n",
            "Epoch 3993/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8842 - val_loss: 0.0921 - val_acc: 0.8962\n",
            "Epoch 3994/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8814 - val_loss: 0.0922 - val_acc: 0.8959\n",
            "Epoch 3995/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8884 - val_loss: 0.0920 - val_acc: 0.8960\n",
            "Epoch 3996/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8880 - val_loss: 0.0917 - val_acc: 0.8965\n",
            "Epoch 3997/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8845 - val_loss: 0.0916 - val_acc: 0.8967\n",
            "Epoch 3998/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8814 - val_loss: 0.0915 - val_acc: 0.8968\n",
            "Epoch 3999/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8814 - val_loss: 0.0914 - val_acc: 0.8965\n",
            "Epoch 4000/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8834 - val_loss: 0.0915 - val_acc: 0.8961\n",
            "Epoch 4001/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8830 - val_loss: 0.0917 - val_acc: 0.8959\n",
            "Epoch 4002/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8835 - val_loss: 0.0916 - val_acc: 0.8960\n",
            "Epoch 4003/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0935 - acc: 0.8903 - val_loss: 0.0914 - val_acc: 0.8963\n",
            "Epoch 4004/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8767 - val_loss: 0.0913 - val_acc: 0.8967\n",
            "Epoch 4005/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8773 - val_loss: 0.0916 - val_acc: 0.8968\n",
            "Epoch 4006/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8839 - val_loss: 0.0916 - val_acc: 0.8968\n",
            "Epoch 4007/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8840 - val_loss: 0.0914 - val_acc: 0.8968\n",
            "Epoch 4008/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8897 - val_loss: 0.0912 - val_acc: 0.8966\n",
            "Epoch 4009/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8847 - val_loss: 0.0911 - val_acc: 0.8965\n",
            "Epoch 4010/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8850 - val_loss: 0.0912 - val_acc: 0.8965\n",
            "Epoch 4011/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8892 - val_loss: 0.0913 - val_acc: 0.8964\n",
            "Epoch 4012/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8829 - val_loss: 0.0913 - val_acc: 0.8963\n",
            "Epoch 4013/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1156 - acc: 0.8793 - val_loss: 0.0913 - val_acc: 0.8963\n",
            "Epoch 4014/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8792 - val_loss: 0.0911 - val_acc: 0.8964\n",
            "Epoch 4015/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8884 - val_loss: 0.0910 - val_acc: 0.8965\n",
            "Epoch 4016/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8796 - val_loss: 0.0911 - val_acc: 0.8967\n",
            "Epoch 4017/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8928 - val_loss: 0.0910 - val_acc: 0.8968\n",
            "Epoch 4018/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0924 - acc: 0.8884 - val_loss: 0.0909 - val_acc: 0.8968\n",
            "Epoch 4019/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0905 - acc: 0.8975 - val_loss: 0.0907 - val_acc: 0.8968\n",
            "Epoch 4020/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8882 - val_loss: 0.0907 - val_acc: 0.8968\n",
            "Epoch 4021/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0888 - acc: 0.8940 - val_loss: 0.0907 - val_acc: 0.8968\n",
            "Epoch 4022/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8883 - val_loss: 0.0907 - val_acc: 0.8968\n",
            "Epoch 4023/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8859 - val_loss: 0.0906 - val_acc: 0.8968\n",
            "Epoch 4024/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8829 - val_loss: 0.0906 - val_acc: 0.8969\n",
            "Epoch 4025/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8853 - val_loss: 0.0906 - val_acc: 0.8968\n",
            "Epoch 4026/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8852 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4027/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8772 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4028/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8837 - val_loss: 0.0905 - val_acc: 0.8967\n",
            "Epoch 4029/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0918 - acc: 0.8893 - val_loss: 0.0905 - val_acc: 0.8969\n",
            "Epoch 4030/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8851 - val_loss: 0.0906 - val_acc: 0.8971\n",
            "Epoch 4031/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8844 - val_loss: 0.0906 - val_acc: 0.8971\n",
            "Epoch 4032/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8845 - val_loss: 0.0907 - val_acc: 0.8972\n",
            "Epoch 4033/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8883 - val_loss: 0.0906 - val_acc: 0.8971\n",
            "Epoch 4034/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8878 - val_loss: 0.0906 - val_acc: 0.8968\n",
            "Epoch 4035/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8868 - val_loss: 0.0907 - val_acc: 0.8965\n",
            "Epoch 4036/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0912 - acc: 0.8947 - val_loss: 0.0908 - val_acc: 0.8964\n",
            "Epoch 4037/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8867 - val_loss: 0.0907 - val_acc: 0.8967\n",
            "Epoch 4038/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1545 - acc: 0.8820 - val_loss: 0.0908 - val_acc: 0.8966\n",
            "Epoch 4039/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1918 - acc: 0.8603 - val_loss: 0.0917 - val_acc: 0.8961\n",
            "Epoch 4040/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8844 - val_loss: 0.0929 - val_acc: 0.8958\n",
            "Epoch 4041/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8812 - val_loss: 0.0928 - val_acc: 0.8964\n",
            "Epoch 4042/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8819 - val_loss: 0.0922 - val_acc: 0.8973\n",
            "Epoch 4043/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8860 - val_loss: 0.0922 - val_acc: 0.8979\n",
            "Epoch 4044/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8853 - val_loss: 0.0923 - val_acc: 0.8980\n",
            "Epoch 4045/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8851 - val_loss: 0.0921 - val_acc: 0.8978\n",
            "Epoch 4046/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8854 - val_loss: 0.0921 - val_acc: 0.8975\n",
            "Epoch 4047/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0918 - acc: 0.8944 - val_loss: 0.0922 - val_acc: 0.8971\n",
            "Epoch 4048/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8924 - val_loss: 0.0923 - val_acc: 0.8970\n",
            "Epoch 4049/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8897 - val_loss: 0.0921 - val_acc: 0.8971\n",
            "Epoch 4050/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8900 - val_loss: 0.0919 - val_acc: 0.8976\n",
            "Epoch 4051/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1258 - acc: 0.8836 - val_loss: 0.0920 - val_acc: 0.8980\n",
            "Epoch 4052/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8843 - val_loss: 0.0922 - val_acc: 0.8981\n",
            "Epoch 4053/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8844 - val_loss: 0.0920 - val_acc: 0.8981\n",
            "Epoch 4054/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8855 - val_loss: 0.0917 - val_acc: 0.8976\n",
            "Epoch 4055/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8854 - val_loss: 0.0919 - val_acc: 0.8970\n",
            "Epoch 4056/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8906 - val_loss: 0.0922 - val_acc: 0.8966\n",
            "Epoch 4057/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8866 - val_loss: 0.0919 - val_acc: 0.8968\n",
            "Epoch 4058/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8868 - val_loss: 0.0915 - val_acc: 0.8972\n",
            "Epoch 4059/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8927 - val_loss: 0.0915 - val_acc: 0.8976\n",
            "Epoch 4060/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8877 - val_loss: 0.0916 - val_acc: 0.8978\n",
            "Epoch 4061/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8887 - val_loss: 0.0913 - val_acc: 0.8978\n",
            "Epoch 4062/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8870 - val_loss: 0.0910 - val_acc: 0.8975\n",
            "Epoch 4063/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8890 - val_loss: 0.0911 - val_acc: 0.8969\n",
            "Epoch 4064/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8908 - val_loss: 0.0912 - val_acc: 0.8965\n",
            "Epoch 4065/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1715 - acc: 0.8672 - val_loss: 0.0914 - val_acc: 0.8964\n",
            "Epoch 4066/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8793 - val_loss: 0.0911 - val_acc: 0.8968\n",
            "Epoch 4067/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8798 - val_loss: 0.0911 - val_acc: 0.8973\n",
            "Epoch 4068/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8806 - val_loss: 0.0913 - val_acc: 0.8976\n",
            "Epoch 4069/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8875 - val_loss: 0.0913 - val_acc: 0.8976\n",
            "Epoch 4070/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8871 - val_loss: 0.0910 - val_acc: 0.8974\n",
            "Epoch 4071/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8838 - val_loss: 0.0909 - val_acc: 0.8971\n",
            "Epoch 4072/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1093 - acc: 0.8814 - val_loss: 0.0910 - val_acc: 0.8967\n",
            "Epoch 4073/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0900 - acc: 0.8951 - val_loss: 0.0912 - val_acc: 0.8965\n",
            "Epoch 4074/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8883 - val_loss: 0.0910 - val_acc: 0.8966\n",
            "Epoch 4075/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8885 - val_loss: 0.0907 - val_acc: 0.8969\n",
            "Epoch 4076/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8873 - val_loss: 0.0907 - val_acc: 0.8973\n",
            "Epoch 4077/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8878 - val_loss: 0.0909 - val_acc: 0.8976\n",
            "Epoch 4078/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0916 - acc: 0.8926 - val_loss: 0.0908 - val_acc: 0.8975\n",
            "Epoch 4079/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - acc: 0.8918 - val_loss: 0.0906 - val_acc: 0.8972\n",
            "Epoch 4080/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8895 - val_loss: 0.0907 - val_acc: 0.8967\n",
            "Epoch 4081/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8704 - val_loss: 0.0910 - val_acc: 0.8963\n",
            "Epoch 4082/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8702 - val_loss: 0.0909 - val_acc: 0.8964\n",
            "Epoch 4083/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8891 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4084/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8840 - val_loss: 0.0906 - val_acc: 0.8971\n",
            "Epoch 4085/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0912 - acc: 0.8940 - val_loss: 0.0908 - val_acc: 0.8972\n",
            "Epoch 4086/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1110 - acc: 0.8708 - val_loss: 0.0907 - val_acc: 0.8971\n",
            "Epoch 4087/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2007 - acc: 0.8716 - val_loss: 0.0909 - val_acc: 0.8962\n",
            "Epoch 4088/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8827 - val_loss: 0.0916 - val_acc: 0.8958\n",
            "Epoch 4089/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8908 - val_loss: 0.0913 - val_acc: 0.8961\n",
            "Epoch 4090/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8906 - val_loss: 0.0908 - val_acc: 0.8970\n",
            "Epoch 4091/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8889 - val_loss: 0.0911 - val_acc: 0.8975\n",
            "Epoch 4092/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8893 - val_loss: 0.0914 - val_acc: 0.8976\n",
            "Epoch 4093/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8810 - val_loss: 0.0910 - val_acc: 0.8974\n",
            "Epoch 4094/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2771 - acc: 0.8636 - val_loss: 0.0918 - val_acc: 0.8967\n",
            "Epoch 4095/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2553 - acc: 0.8637 - val_loss: 0.0970 - val_acc: 0.8950\n",
            "Epoch 4096/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8902 - val_loss: 0.1003 - val_acc: 0.8948\n",
            "Epoch 4097/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1749 - acc: 0.8640 - val_loss: 0.1007 - val_acc: 0.8963\n",
            "Epoch 4098/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8847 - val_loss: 0.0993 - val_acc: 0.8982\n",
            "Epoch 4099/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2303 - acc: 0.8711 - val_loss: 0.1023 - val_acc: 0.8987\n",
            "Epoch 4100/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1183 - acc: 0.8891 - val_loss: 0.1050 - val_acc: 0.8989\n",
            "Epoch 4101/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8801 - val_loss: 0.1065 - val_acc: 0.8989\n",
            "Epoch 4102/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2210 - acc: 0.8737 - val_loss: 0.1093 - val_acc: 0.8989\n",
            "Epoch 4103/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1161 - acc: 0.8873 - val_loss: 0.1110 - val_acc: 0.8988\n",
            "Epoch 4104/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1238 - acc: 0.8874 - val_loss: 0.1118 - val_acc: 0.8987\n",
            "Epoch 4105/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8893 - val_loss: 0.1114 - val_acc: 0.8986\n",
            "Epoch 4106/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2069 - acc: 0.8757 - val_loss: 0.1121 - val_acc: 0.8985\n",
            "Epoch 4107/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1423 - acc: 0.8832 - val_loss: 0.1124 - val_acc: 0.8985\n",
            "Epoch 4108/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8906 - val_loss: 0.1118 - val_acc: 0.8985\n",
            "Epoch 4109/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1144 - acc: 0.8945 - val_loss: 0.1108 - val_acc: 0.8985\n",
            "Epoch 4110/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1195 - acc: 0.8867 - val_loss: 0.1096 - val_acc: 0.8986\n",
            "Epoch 4111/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1429 - acc: 0.8827 - val_loss: 0.1086 - val_acc: 0.8986\n",
            "Epoch 4112/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1172 - acc: 0.8864 - val_loss: 0.1075 - val_acc: 0.8986\n",
            "Epoch 4113/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1158 - acc: 0.8864 - val_loss: 0.1064 - val_acc: 0.8986\n",
            "Epoch 4114/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1179 - acc: 0.8829 - val_loss: 0.1055 - val_acc: 0.8985\n",
            "Epoch 4115/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1167 - acc: 0.8831 - val_loss: 0.1046 - val_acc: 0.8985\n",
            "Epoch 4116/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1530 - acc: 0.8806 - val_loss: 0.1040 - val_acc: 0.8985\n",
            "Epoch 4117/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8862 - val_loss: 0.1032 - val_acc: 0.8985\n",
            "Epoch 4118/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1192 - acc: 0.8785 - val_loss: 0.1020 - val_acc: 0.8985\n",
            "Epoch 4119/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8964 - val_loss: 0.1006 - val_acc: 0.8986\n",
            "Epoch 4120/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8890 - val_loss: 0.0994 - val_acc: 0.8987\n",
            "Epoch 4121/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1094 - acc: 0.8846 - val_loss: 0.0984 - val_acc: 0.8986\n",
            "Epoch 4122/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8817 - val_loss: 0.0976 - val_acc: 0.8985\n",
            "Epoch 4123/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8814 - val_loss: 0.0968 - val_acc: 0.8983\n",
            "Epoch 4124/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8894 - val_loss: 0.0961 - val_acc: 0.8980\n",
            "Epoch 4125/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8842 - val_loss: 0.0955 - val_acc: 0.8977\n",
            "Epoch 4126/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8840 - val_loss: 0.0951 - val_acc: 0.8973\n",
            "Epoch 4127/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8844 - val_loss: 0.0948 - val_acc: 0.8969\n",
            "Epoch 4128/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8841 - val_loss: 0.0943 - val_acc: 0.8967\n",
            "Epoch 4129/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8923 - val_loss: 0.0937 - val_acc: 0.8967\n",
            "Epoch 4130/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1115 - acc: 0.8730 - val_loss: 0.0930 - val_acc: 0.8967\n",
            "Epoch 4131/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1102 - acc: 0.8732 - val_loss: 0.0925 - val_acc: 0.8967\n",
            "Epoch 4132/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8846 - val_loss: 0.0923 - val_acc: 0.8968\n",
            "Epoch 4133/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8776 - val_loss: 0.0921 - val_acc: 0.8968\n",
            "Epoch 4134/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8940 - val_loss: 0.0921 - val_acc: 0.8967\n",
            "Epoch 4135/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8861 - val_loss: 0.0921 - val_acc: 0.8965\n",
            "Epoch 4136/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8796 - val_loss: 0.0922 - val_acc: 0.8962\n",
            "Epoch 4137/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2172 - acc: 0.8697 - val_loss: 0.0931 - val_acc: 0.8954\n",
            "Epoch 4138/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8848 - val_loss: 0.0932 - val_acc: 0.8954\n",
            "Epoch 4139/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1065 - acc: 0.8765 - val_loss: 0.0922 - val_acc: 0.8964\n",
            "Epoch 4140/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8777 - val_loss: 0.0919 - val_acc: 0.8972\n",
            "Epoch 4141/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3349 - acc: 0.8482 - val_loss: 0.0932 - val_acc: 0.8966\n",
            "Epoch 4142/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2040 - acc: 0.8621 - val_loss: 0.0968 - val_acc: 0.8954\n",
            "Epoch 4143/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1590 - acc: 0.8747 - val_loss: 0.1011 - val_acc: 0.8945\n",
            "Epoch 4144/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1046 - acc: 0.8849 - val_loss: 0.1022 - val_acc: 0.8952\n",
            "Epoch 4145/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8933 - val_loss: 0.1007 - val_acc: 0.8968\n",
            "Epoch 4146/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8905 - val_loss: 0.0998 - val_acc: 0.8979\n",
            "Epoch 4147/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1100 - acc: 0.8872 - val_loss: 0.1004 - val_acc: 0.8984\n",
            "Epoch 4148/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8960 - val_loss: 0.1014 - val_acc: 0.8986\n",
            "Epoch 4149/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8905 - val_loss: 0.1011 - val_acc: 0.8986\n",
            "Epoch 4150/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1182 - acc: 0.8786 - val_loss: 0.0998 - val_acc: 0.8985\n",
            "Epoch 4151/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1210 - acc: 0.8785 - val_loss: 0.0990 - val_acc: 0.8982\n",
            "Epoch 4152/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8871 - val_loss: 0.0992 - val_acc: 0.8977\n",
            "Epoch 4153/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8848 - val_loss: 0.0996 - val_acc: 0.8972\n",
            "Epoch 4154/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8842 - val_loss: 0.0996 - val_acc: 0.8970\n",
            "Epoch 4155/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1181 - acc: 0.8742 - val_loss: 0.0988 - val_acc: 0.8972\n",
            "Epoch 4156/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8984 - val_loss: 0.0978 - val_acc: 0.8976\n",
            "Epoch 4157/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8880 - val_loss: 0.0972 - val_acc: 0.8980\n",
            "Epoch 4158/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8884 - val_loss: 0.0969 - val_acc: 0.8982\n",
            "Epoch 4159/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1760 - acc: 0.8790 - val_loss: 0.0966 - val_acc: 0.8982\n",
            "Epoch 4160/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8912 - val_loss: 0.0960 - val_acc: 0.8982\n",
            "Epoch 4161/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8905 - val_loss: 0.0955 - val_acc: 0.8980\n",
            "Epoch 4162/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8824 - val_loss: 0.0952 - val_acc: 0.8978\n",
            "Epoch 4163/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8822 - val_loss: 0.0951 - val_acc: 0.8975\n",
            "Epoch 4164/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8898 - val_loss: 0.0948 - val_acc: 0.8974\n",
            "Epoch 4165/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1077 - acc: 0.8805 - val_loss: 0.0942 - val_acc: 0.8975\n",
            "Epoch 4166/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8858 - val_loss: 0.0936 - val_acc: 0.8977\n",
            "Epoch 4167/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8863 - val_loss: 0.0933 - val_acc: 0.8980\n",
            "Epoch 4168/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8917 - val_loss: 0.0932 - val_acc: 0.8981\n",
            "Epoch 4169/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8904 - val_loss: 0.0929 - val_acc: 0.8980\n",
            "Epoch 4170/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8971 - val_loss: 0.0924 - val_acc: 0.8978\n",
            "Epoch 4171/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8971 - val_loss: 0.0920 - val_acc: 0.8973\n",
            "Epoch 4172/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8844 - val_loss: 0.0920 - val_acc: 0.8967\n",
            "Epoch 4173/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8842 - val_loss: 0.0921 - val_acc: 0.8963\n",
            "Epoch 4174/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8755 - val_loss: 0.0921 - val_acc: 0.8961\n",
            "Epoch 4175/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8775 - val_loss: 0.0917 - val_acc: 0.8963\n",
            "Epoch 4176/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8847 - val_loss: 0.0914 - val_acc: 0.8967\n",
            "Epoch 4177/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3560 - acc: 0.8425 - val_loss: 0.0935 - val_acc: 0.8954\n",
            "Epoch 4178/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8884 - val_loss: 0.0957 - val_acc: 0.8946\n",
            "Epoch 4179/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8877 - val_loss: 0.0953 - val_acc: 0.8954\n",
            "Epoch 4180/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1809 - acc: 0.8672 - val_loss: 0.0952 - val_acc: 0.8963\n",
            "Epoch 4181/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1084 - acc: 0.8838 - val_loss: 0.0948 - val_acc: 0.8974\n",
            "Epoch 4182/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8823 - val_loss: 0.0951 - val_acc: 0.8980\n",
            "Epoch 4183/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8890 - val_loss: 0.0955 - val_acc: 0.8982\n",
            "Epoch 4184/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1660 - acc: 0.8755 - val_loss: 0.0955 - val_acc: 0.8981\n",
            "Epoch 4185/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8870 - val_loss: 0.0956 - val_acc: 0.8978\n",
            "Epoch 4186/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8869 - val_loss: 0.0961 - val_acc: 0.8973\n",
            "Epoch 4187/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8802 - val_loss: 0.0965 - val_acc: 0.8970\n",
            "Epoch 4188/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8829 - val_loss: 0.0964 - val_acc: 0.8969\n",
            "Epoch 4189/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1038 - acc: 0.8868 - val_loss: 0.0958 - val_acc: 0.8973\n",
            "Epoch 4190/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8872 - val_loss: 0.0954 - val_acc: 0.8978\n",
            "Epoch 4191/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8920 - val_loss: 0.0953 - val_acc: 0.8981\n",
            "Epoch 4192/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8874 - val_loss: 0.0951 - val_acc: 0.8982\n",
            "Epoch 4193/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8898 - val_loss: 0.0948 - val_acc: 0.8982\n",
            "Epoch 4194/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8920 - val_loss: 0.0942 - val_acc: 0.8980\n",
            "Epoch 4195/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1656 - acc: 0.8807 - val_loss: 0.0941 - val_acc: 0.8974\n",
            "Epoch 4196/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1074 - acc: 0.8793 - val_loss: 0.0946 - val_acc: 0.8969\n",
            "Epoch 4197/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8676 - val_loss: 0.0948 - val_acc: 0.8968\n",
            "Epoch 4198/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8832 - val_loss: 0.0943 - val_acc: 0.8971\n",
            "Epoch 4199/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8859 - val_loss: 0.0936 - val_acc: 0.8976\n",
            "Epoch 4200/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8868 - val_loss: 0.0933 - val_acc: 0.8979\n",
            "Epoch 4201/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8874 - val_loss: 0.0933 - val_acc: 0.8981\n",
            "Epoch 4202/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8949 - val_loss: 0.0931 - val_acc: 0.8980\n",
            "Epoch 4203/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8892 - val_loss: 0.0927 - val_acc: 0.8977\n",
            "Epoch 4204/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8840 - val_loss: 0.0924 - val_acc: 0.8972\n",
            "Epoch 4205/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8824 - val_loss: 0.0923 - val_acc: 0.8966\n",
            "Epoch 4206/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8892 - val_loss: 0.0921 - val_acc: 0.8964\n",
            "Epoch 4207/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8891 - val_loss: 0.0918 - val_acc: 0.8964\n",
            "Epoch 4208/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8739 - val_loss: 0.0916 - val_acc: 0.8967\n",
            "Epoch 4209/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3064 - acc: 0.8545 - val_loss: 0.0925 - val_acc: 0.8962\n",
            "Epoch 4210/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8856 - val_loss: 0.0933 - val_acc: 0.8961\n",
            "Epoch 4211/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2308 - acc: 0.8651 - val_loss: 0.0960 - val_acc: 0.8955\n",
            "Epoch 4212/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8830 - val_loss: 0.0973 - val_acc: 0.8958\n",
            "Epoch 4213/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - acc: 0.8807 - val_loss: 0.0969 - val_acc: 0.8968\n",
            "Epoch 4214/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8840 - val_loss: 0.0963 - val_acc: 0.8978\n",
            "Epoch 4215/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8793 - val_loss: 0.0966 - val_acc: 0.8983\n",
            "Epoch 4216/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8849 - val_loss: 0.0969 - val_acc: 0.8984\n",
            "Epoch 4217/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8849 - val_loss: 0.0965 - val_acc: 0.8983\n",
            "Epoch 4218/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8838 - val_loss: 0.0958 - val_acc: 0.8980\n",
            "Epoch 4219/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8834 - val_loss: 0.0955 - val_acc: 0.8974\n",
            "Epoch 4220/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8850 - val_loss: 0.0956 - val_acc: 0.8969\n",
            "Epoch 4221/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1577 - acc: 0.8746 - val_loss: 0.0962 - val_acc: 0.8964\n",
            "Epoch 4222/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1083 - acc: 0.8823 - val_loss: 0.0962 - val_acc: 0.8964\n",
            "Epoch 4223/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8859 - val_loss: 0.0956 - val_acc: 0.8968\n",
            "Epoch 4224/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8801 - val_loss: 0.0948 - val_acc: 0.8974\n",
            "Epoch 4225/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1061 - acc: 0.8806 - val_loss: 0.0944 - val_acc: 0.8978\n",
            "Epoch 4226/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8864 - val_loss: 0.0942 - val_acc: 0.8980\n",
            "Epoch 4227/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8952 - val_loss: 0.0940 - val_acc: 0.8982\n",
            "Epoch 4228/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1487 - acc: 0.8793 - val_loss: 0.0938 - val_acc: 0.8982\n",
            "Epoch 4229/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8913 - val_loss: 0.0936 - val_acc: 0.8981\n",
            "Epoch 4230/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8913 - val_loss: 0.0935 - val_acc: 0.8978\n",
            "Epoch 4231/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8913 - val_loss: 0.0933 - val_acc: 0.8976\n",
            "Epoch 4232/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8906 - val_loss: 0.0931 - val_acc: 0.8974\n",
            "Epoch 4233/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0927 - acc: 0.8941 - val_loss: 0.0927 - val_acc: 0.8975\n",
            "Epoch 4234/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8908 - val_loss: 0.0924 - val_acc: 0.8976\n",
            "Epoch 4235/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8858 - val_loss: 0.0922 - val_acc: 0.8977\n",
            "Epoch 4236/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8860 - val_loss: 0.0920 - val_acc: 0.8976\n",
            "Epoch 4237/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0929 - acc: 0.8930 - val_loss: 0.0918 - val_acc: 0.8975\n",
            "Epoch 4238/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8816 - val_loss: 0.0915 - val_acc: 0.8973\n",
            "Epoch 4239/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8815 - val_loss: 0.0913 - val_acc: 0.8970\n",
            "Epoch 4240/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8874 - val_loss: 0.0913 - val_acc: 0.8968\n",
            "Epoch 4241/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8834 - val_loss: 0.0912 - val_acc: 0.8969\n",
            "Epoch 4242/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8852 - val_loss: 0.0910 - val_acc: 0.8971\n",
            "Epoch 4243/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8846 - val_loss: 0.0910 - val_acc: 0.8973\n",
            "Epoch 4244/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8742 - val_loss: 0.0909 - val_acc: 0.8972\n",
            "Epoch 4245/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - acc: 0.8932 - val_loss: 0.0908 - val_acc: 0.8970\n",
            "Epoch 4246/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8893 - val_loss: 0.0909 - val_acc: 0.8968\n",
            "Epoch 4247/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0895 - acc: 0.8942 - val_loss: 0.0909 - val_acc: 0.8967\n",
            "Epoch 4248/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8872 - val_loss: 0.0908 - val_acc: 0.8967\n",
            "Epoch 4249/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8895 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4250/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8892 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4251/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2672 - acc: 0.8595 - val_loss: 0.0921 - val_acc: 0.8955\n",
            "Epoch 4252/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8765 - val_loss: 0.0934 - val_acc: 0.8951\n",
            "Epoch 4253/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8694 - val_loss: 0.0930 - val_acc: 0.8959\n",
            "Epoch 4254/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8935 - val_loss: 0.0921 - val_acc: 0.8971\n",
            "Epoch 4255/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8841 - val_loss: 0.0921 - val_acc: 0.8978\n",
            "Epoch 4256/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8861 - val_loss: 0.0923 - val_acc: 0.8979\n",
            "Epoch 4257/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8843 - val_loss: 0.0921 - val_acc: 0.8977\n",
            "Epoch 4258/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8847 - val_loss: 0.0919 - val_acc: 0.8973\n",
            "Epoch 4259/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8829 - val_loss: 0.0919 - val_acc: 0.8968\n",
            "Epoch 4260/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8860 - val_loss: 0.0919 - val_acc: 0.8967\n",
            "Epoch 4261/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8815 - val_loss: 0.0916 - val_acc: 0.8969\n",
            "Epoch 4262/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8851 - val_loss: 0.0915 - val_acc: 0.8972\n",
            "Epoch 4263/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2950 - acc: 0.8556 - val_loss: 0.0938 - val_acc: 0.8964\n",
            "Epoch 4264/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8835 - val_loss: 0.0957 - val_acc: 0.8960\n",
            "Epoch 4265/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8899 - val_loss: 0.0955 - val_acc: 0.8965\n",
            "Epoch 4266/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8822 - val_loss: 0.0944 - val_acc: 0.8974\n",
            "Epoch 4267/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8914 - val_loss: 0.0941 - val_acc: 0.8981\n",
            "Epoch 4268/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8948 - val_loss: 0.0948 - val_acc: 0.8984\n",
            "Epoch 4269/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8950 - val_loss: 0.0954 - val_acc: 0.8984\n",
            "Epoch 4270/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1078 - acc: 0.8807 - val_loss: 0.0948 - val_acc: 0.8983\n",
            "Epoch 4271/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8898 - val_loss: 0.0940 - val_acc: 0.8979\n",
            "Epoch 4272/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8907 - val_loss: 0.0940 - val_acc: 0.8975\n",
            "Epoch 4273/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8903 - val_loss: 0.0942 - val_acc: 0.8972\n",
            "Epoch 4274/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8807 - val_loss: 0.0940 - val_acc: 0.8972\n",
            "Epoch 4275/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8916 - val_loss: 0.0934 - val_acc: 0.8975\n",
            "Epoch 4276/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8908 - val_loss: 0.0930 - val_acc: 0.8978\n",
            "Epoch 4277/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8875 - val_loss: 0.0928 - val_acc: 0.8980\n",
            "Epoch 4278/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8871 - val_loss: 0.0926 - val_acc: 0.8980\n",
            "Epoch 4279/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8856 - val_loss: 0.0921 - val_acc: 0.8978\n",
            "Epoch 4280/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8824 - val_loss: 0.0917 - val_acc: 0.8975\n",
            "Epoch 4281/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8912 - val_loss: 0.0919 - val_acc: 0.8970\n",
            "Epoch 4282/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8879 - val_loss: 0.0920 - val_acc: 0.8967\n",
            "Epoch 4283/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8845 - val_loss: 0.0916 - val_acc: 0.8968\n",
            "Epoch 4284/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8921 - val_loss: 0.0911 - val_acc: 0.8971\n",
            "Epoch 4285/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8814 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4286/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8900 - val_loss: 0.0910 - val_acc: 0.8977\n",
            "Epoch 4287/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8832 - val_loss: 0.0909 - val_acc: 0.8976\n",
            "Epoch 4288/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8807 - val_loss: 0.0906 - val_acc: 0.8972\n",
            "Epoch 4289/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8814 - val_loss: 0.0906 - val_acc: 0.8967\n",
            "Epoch 4290/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0923 - acc: 0.8921 - val_loss: 0.0907 - val_acc: 0.8964\n",
            "Epoch 4291/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8852 - val_loss: 0.0906 - val_acc: 0.8964\n",
            "Epoch 4292/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8876 - val_loss: 0.0905 - val_acc: 0.8966\n",
            "Epoch 4293/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3158 - acc: 0.8576 - val_loss: 0.0920 - val_acc: 0.8954\n",
            "Epoch 4294/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1145 - acc: 0.8790 - val_loss: 0.0933 - val_acc: 0.8951\n",
            "Epoch 4295/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8883 - val_loss: 0.0928 - val_acc: 0.8961\n",
            "Epoch 4296/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1493 - acc: 0.8800 - val_loss: 0.0927 - val_acc: 0.8970\n",
            "Epoch 4297/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8930 - val_loss: 0.0929 - val_acc: 0.8978\n",
            "Epoch 4298/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8937 - val_loss: 0.0933 - val_acc: 0.8981\n",
            "Epoch 4299/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8911 - val_loss: 0.0932 - val_acc: 0.8981\n",
            "Epoch 4300/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8868 - val_loss: 0.0929 - val_acc: 0.8979\n",
            "Epoch 4301/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8884 - val_loss: 0.0929 - val_acc: 0.8975\n",
            "Epoch 4302/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8880 - val_loss: 0.0932 - val_acc: 0.8971\n",
            "Epoch 4303/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0972 - acc: 0.8878 - val_loss: 0.0934 - val_acc: 0.8969\n",
            "Epoch 4304/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.1053 - acc: 0.8825 - val_loss: 0.0933 - val_acc: 0.8969\n",
            "Epoch 4305/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8827 - val_loss: 0.0929 - val_acc: 0.8973\n",
            "Epoch 4306/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8873 - val_loss: 0.0927 - val_acc: 0.8976\n",
            "Epoch 4307/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8731 - val_loss: 0.0926 - val_acc: 0.8978\n",
            "Epoch 4308/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8923 - val_loss: 0.0925 - val_acc: 0.8979\n",
            "Epoch 4309/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8924 - val_loss: 0.0922 - val_acc: 0.8979\n",
            "Epoch 4310/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8805 - val_loss: 0.0919 - val_acc: 0.8978\n",
            "Epoch 4311/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0915 - acc: 0.8959 - val_loss: 0.0917 - val_acc: 0.8976\n",
            "Epoch 4312/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8943 - val_loss: 0.0915 - val_acc: 0.8973\n",
            "Epoch 4313/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8943 - val_loss: 0.0914 - val_acc: 0.8973\n",
            "Epoch 4314/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8823 - val_loss: 0.0912 - val_acc: 0.8973\n",
            "Epoch 4315/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8914 - val_loss: 0.0911 - val_acc: 0.8975\n",
            "Epoch 4316/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8905 - val_loss: 0.0910 - val_acc: 0.8975\n",
            "Epoch 4317/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8901 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4318/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8919 - val_loss: 0.0908 - val_acc: 0.8974\n",
            "Epoch 4319/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8959 - val_loss: 0.0907 - val_acc: 0.8972\n",
            "Epoch 4320/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0993 - acc: 0.8835 - val_loss: 0.0907 - val_acc: 0.8970\n",
            "Epoch 4321/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8834 - val_loss: 0.0906 - val_acc: 0.8969\n",
            "Epoch 4322/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0889 - acc: 0.8945 - val_loss: 0.0905 - val_acc: 0.8969\n",
            "Epoch 4323/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0885 - acc: 0.8948 - val_loss: 0.0906 - val_acc: 0.8970\n",
            "Epoch 4324/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1225 - acc: 0.8816 - val_loss: 0.0906 - val_acc: 0.8969\n",
            "Epoch 4325/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2775 - acc: 0.8603 - val_loss: 0.0914 - val_acc: 0.8962\n",
            "Epoch 4326/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8825 - val_loss: 0.0920 - val_acc: 0.8962\n",
            "Epoch 4327/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8824 - val_loss: 0.0916 - val_acc: 0.8968\n",
            "Epoch 4328/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8868 - val_loss: 0.0914 - val_acc: 0.8977\n",
            "Epoch 4329/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8899 - val_loss: 0.0919 - val_acc: 0.8981\n",
            "Epoch 4330/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1199 - acc: 0.8867 - val_loss: 0.0923 - val_acc: 0.8982\n",
            "Epoch 4331/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2849 - acc: 0.8629 - val_loss: 0.0933 - val_acc: 0.8976\n",
            "Epoch 4332/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8766 - val_loss: 0.0961 - val_acc: 0.8968\n",
            "Epoch 4333/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8956 - val_loss: 0.0975 - val_acc: 0.8968\n",
            "Epoch 4334/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1160 - acc: 0.8733 - val_loss: 0.0969 - val_acc: 0.8975\n",
            "Epoch 4335/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8843 - val_loss: 0.0961 - val_acc: 0.8982\n",
            "Epoch 4336/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8819 - val_loss: 0.0963 - val_acc: 0.8985\n",
            "Epoch 4337/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8938 - val_loss: 0.0967 - val_acc: 0.8986\n",
            "Epoch 4338/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8929 - val_loss: 0.0963 - val_acc: 0.8986\n",
            "Epoch 4339/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1159 - acc: 0.8954 - val_loss: 0.0956 - val_acc: 0.8985\n",
            "Epoch 4340/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1191 - acc: 0.8911 - val_loss: 0.0953 - val_acc: 0.8981\n",
            "Epoch 4341/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8855 - val_loss: 0.0956 - val_acc: 0.8975\n",
            "Epoch 4342/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8860 - val_loss: 0.0958 - val_acc: 0.8972\n",
            "Epoch 4343/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8915 - val_loss: 0.0953 - val_acc: 0.8971\n",
            "Epoch 4344/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1558 - acc: 0.8692 - val_loss: 0.0950 - val_acc: 0.8972\n",
            "Epoch 4345/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8782 - val_loss: 0.0946 - val_acc: 0.8975\n",
            "Epoch 4346/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8853 - val_loss: 0.0941 - val_acc: 0.8978\n",
            "Epoch 4347/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8869 - val_loss: 0.0938 - val_acc: 0.8980\n",
            "Epoch 4348/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8849 - val_loss: 0.0934 - val_acc: 0.8981\n",
            "Epoch 4349/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0894 - acc: 0.8999 - val_loss: 0.0930 - val_acc: 0.8982\n",
            "Epoch 4350/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8924 - val_loss: 0.0926 - val_acc: 0.8981\n",
            "Epoch 4351/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8951 - val_loss: 0.0924 - val_acc: 0.8980\n",
            "Epoch 4352/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1072 - acc: 0.8763 - val_loss: 0.0922 - val_acc: 0.8977\n",
            "Epoch 4353/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8809 - val_loss: 0.0920 - val_acc: 0.8974\n",
            "Epoch 4354/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8999 - val_loss: 0.0917 - val_acc: 0.8972\n",
            "Epoch 4355/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8764 - val_loss: 0.0914 - val_acc: 0.8971\n",
            "Epoch 4356/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8876 - val_loss: 0.0911 - val_acc: 0.8972\n",
            "Epoch 4357/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8867 - val_loss: 0.0910 - val_acc: 0.8972\n",
            "Epoch 4358/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2104 - acc: 0.8672 - val_loss: 0.0911 - val_acc: 0.8972\n",
            "Epoch 4359/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8841 - val_loss: 0.0912 - val_acc: 0.8972\n",
            "Epoch 4360/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8833 - val_loss: 0.0912 - val_acc: 0.8973\n",
            "Epoch 4361/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8933 - val_loss: 0.0910 - val_acc: 0.8974\n",
            "Epoch 4362/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8901 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4363/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8879 - val_loss: 0.0908 - val_acc: 0.8975\n",
            "Epoch 4364/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8794 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4365/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1027 - acc: 0.8771 - val_loss: 0.0909 - val_acc: 0.8974\n",
            "Epoch 4366/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1272 - acc: 0.8783 - val_loss: 0.0908 - val_acc: 0.8973\n",
            "Epoch 4367/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8873 - val_loss: 0.0907 - val_acc: 0.8973\n",
            "Epoch 4368/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1173 - acc: 0.8733 - val_loss: 0.0908 - val_acc: 0.8971\n",
            "Epoch 4369/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8734 - val_loss: 0.0909 - val_acc: 0.8970\n",
            "Epoch 4370/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8875 - val_loss: 0.0908 - val_acc: 0.8971\n",
            "Epoch 4371/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8861 - val_loss: 0.0908 - val_acc: 0.8973\n",
            "Epoch 4372/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8864 - val_loss: 0.0907 - val_acc: 0.8974\n",
            "Epoch 4373/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2206 - acc: 0.8704 - val_loss: 0.0914 - val_acc: 0.8970\n",
            "Epoch 4374/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8895 - val_loss: 0.0922 - val_acc: 0.8968\n",
            "Epoch 4375/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8861 - val_loss: 0.0924 - val_acc: 0.8969\n",
            "Epoch 4376/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1071 - acc: 0.8800 - val_loss: 0.0920 - val_acc: 0.8973\n",
            "Epoch 4377/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8883 - val_loss: 0.0916 - val_acc: 0.8978\n",
            "Epoch 4378/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8867 - val_loss: 0.0917 - val_acc: 0.8981\n",
            "Epoch 4379/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8849 - val_loss: 0.0919 - val_acc: 0.8982\n",
            "Epoch 4380/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8850 - val_loss: 0.0918 - val_acc: 0.8981\n",
            "Epoch 4381/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8806 - val_loss: 0.0915 - val_acc: 0.8979\n",
            "Epoch 4382/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0920 - acc: 0.8933 - val_loss: 0.0914 - val_acc: 0.8975\n",
            "Epoch 4383/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8855 - val_loss: 0.0915 - val_acc: 0.8971\n",
            "Epoch 4384/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8853 - val_loss: 0.0915 - val_acc: 0.8969\n",
            "Epoch 4385/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8918 - val_loss: 0.0912 - val_acc: 0.8970\n",
            "Epoch 4386/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8792 - val_loss: 0.0909 - val_acc: 0.8973\n",
            "Epoch 4387/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8774 - val_loss: 0.0908 - val_acc: 0.8974\n",
            "Epoch 4388/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8871 - val_loss: 0.0907 - val_acc: 0.8976\n",
            "Epoch 4389/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1139 - acc: 0.8836 - val_loss: 0.0906 - val_acc: 0.8976\n",
            "Epoch 4390/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8900 - val_loss: 0.0905 - val_acc: 0.8975\n",
            "Epoch 4391/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8900 - val_loss: 0.0906 - val_acc: 0.8973\n",
            "Epoch 4392/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8893 - val_loss: 0.0905 - val_acc: 0.8972\n",
            "Epoch 4393/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8885 - val_loss: 0.0905 - val_acc: 0.8971\n",
            "Epoch 4394/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1147 - acc: 0.8848 - val_loss: 0.0904 - val_acc: 0.8971\n",
            "Epoch 4395/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8929 - val_loss: 0.0902 - val_acc: 0.8972\n",
            "Epoch 4396/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0877 - acc: 0.8930 - val_loss: 0.0901 - val_acc: 0.8972\n",
            "Epoch 4397/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1404 - acc: 0.8771 - val_loss: 0.0903 - val_acc: 0.8970\n",
            "Epoch 4398/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8822 - val_loss: 0.0905 - val_acc: 0.8968\n",
            "Epoch 4399/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8887 - val_loss: 0.0905 - val_acc: 0.8967\n",
            "Epoch 4400/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8885 - val_loss: 0.0902 - val_acc: 0.8969\n",
            "Epoch 4401/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8868 - val_loss: 0.0901 - val_acc: 0.8972\n",
            "Epoch 4402/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8853 - val_loss: 0.0902 - val_acc: 0.8972\n",
            "Epoch 4403/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8819 - val_loss: 0.0902 - val_acc: 0.8972\n",
            "Epoch 4404/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2383 - acc: 0.8659 - val_loss: 0.0908 - val_acc: 0.8967\n",
            "Epoch 4405/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8834 - val_loss: 0.0920 - val_acc: 0.8962\n",
            "Epoch 4406/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8838 - val_loss: 0.0920 - val_acc: 0.8966\n",
            "Epoch 4407/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8907 - val_loss: 0.0913 - val_acc: 0.8974\n",
            "Epoch 4408/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8893 - val_loss: 0.0910 - val_acc: 0.8979\n",
            "Epoch 4409/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8787 - val_loss: 0.0915 - val_acc: 0.8981\n",
            "Epoch 4410/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1024 - acc: 0.8810 - val_loss: 0.0917 - val_acc: 0.8979\n",
            "Epoch 4411/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8851 - val_loss: 0.0915 - val_acc: 0.8976\n",
            "Epoch 4412/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8904 - val_loss: 0.0912 - val_acc: 0.8974\n",
            "Epoch 4413/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8851 - val_loss: 0.0910 - val_acc: 0.8971\n",
            "Epoch 4414/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8856 - val_loss: 0.0909 - val_acc: 0.8972\n",
            "Epoch 4415/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8897 - val_loss: 0.0908 - val_acc: 0.8974\n",
            "Epoch 4416/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8840 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4417/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8935 - val_loss: 0.0908 - val_acc: 0.8978\n",
            "Epoch 4418/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8810 - val_loss: 0.0906 - val_acc: 0.8978\n",
            "Epoch 4419/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0929 - acc: 0.8899 - val_loss: 0.0903 - val_acc: 0.8976\n",
            "Epoch 4420/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0892 - acc: 0.8953 - val_loss: 0.0903 - val_acc: 0.8973\n",
            "Epoch 4421/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0889 - acc: 0.8951 - val_loss: 0.0904 - val_acc: 0.8970\n",
            "Epoch 4422/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0898 - acc: 0.8977 - val_loss: 0.0903 - val_acc: 0.8970\n",
            "Epoch 4423/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0895 - acc: 0.8976 - val_loss: 0.0901 - val_acc: 0.8971\n",
            "Epoch 4424/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8888 - val_loss: 0.0899 - val_acc: 0.8974\n",
            "Epoch 4425/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0878 - acc: 0.8945 - val_loss: 0.0898 - val_acc: 0.8976\n",
            "Epoch 4426/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8896 - val_loss: 0.0900 - val_acc: 0.8976\n",
            "Epoch 4427/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2827 - acc: 0.8539 - val_loss: 0.0913 - val_acc: 0.8963\n",
            "Epoch 4428/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8854 - val_loss: 0.0932 - val_acc: 0.8953\n",
            "Epoch 4429/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8815 - val_loss: 0.0928 - val_acc: 0.8957\n",
            "Epoch 4430/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2934 - acc: 0.8404 - val_loss: 0.0957 - val_acc: 0.8950\n",
            "Epoch 4431/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8752 - val_loss: 0.0962 - val_acc: 0.8958\n",
            "Epoch 4432/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8827 - val_loss: 0.0955 - val_acc: 0.8972\n",
            "Epoch 4433/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8901 - val_loss: 0.0954 - val_acc: 0.8982\n",
            "Epoch 4434/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8873 - val_loss: 0.0959 - val_acc: 0.8986\n",
            "Epoch 4435/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1049 - acc: 0.8903 - val_loss: 0.0963 - val_acc: 0.8987\n",
            "Epoch 4436/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8862 - val_loss: 0.0958 - val_acc: 0.8986\n",
            "Epoch 4437/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8884 - val_loss: 0.0955 - val_acc: 0.8984\n",
            "Epoch 4438/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8906 - val_loss: 0.0954 - val_acc: 0.8980\n",
            "Epoch 4439/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8876 - val_loss: 0.0956 - val_acc: 0.8976\n",
            "Epoch 4440/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8875 - val_loss: 0.0955 - val_acc: 0.8973\n",
            "Epoch 4441/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8902 - val_loss: 0.0951 - val_acc: 0.8973\n",
            "Epoch 4442/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1126 - acc: 0.8733 - val_loss: 0.0945 - val_acc: 0.8976\n",
            "Epoch 4443/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8899 - val_loss: 0.0939 - val_acc: 0.8978\n",
            "Epoch 4444/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8908 - val_loss: 0.0936 - val_acc: 0.8980\n",
            "Epoch 4445/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8931 - val_loss: 0.0934 - val_acc: 0.8981\n",
            "Epoch 4446/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8830 - val_loss: 0.0930 - val_acc: 0.8980\n",
            "Epoch 4447/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8858 - val_loss: 0.0924 - val_acc: 0.8979\n",
            "Epoch 4448/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1361 - acc: 0.8781 - val_loss: 0.0923 - val_acc: 0.8976\n",
            "Epoch 4449/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8828 - val_loss: 0.0920 - val_acc: 0.8974\n",
            "Epoch 4450/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8850 - val_loss: 0.0917 - val_acc: 0.8974\n",
            "Epoch 4451/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8851 - val_loss: 0.0915 - val_acc: 0.8976\n",
            "Epoch 4452/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8937 - val_loss: 0.0913 - val_acc: 0.8977\n",
            "Epoch 4453/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8903 - val_loss: 0.0912 - val_acc: 0.8978\n",
            "Epoch 4454/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8869 - val_loss: 0.0909 - val_acc: 0.8979\n",
            "Epoch 4455/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8836 - val_loss: 0.0905 - val_acc: 0.8977\n",
            "Epoch 4456/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8841 - val_loss: 0.0904 - val_acc: 0.8973\n",
            "Epoch 4457/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2108 - acc: 0.8609 - val_loss: 0.0914 - val_acc: 0.8964\n",
            "Epoch 4458/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8846 - val_loss: 0.0924 - val_acc: 0.8959\n",
            "Epoch 4459/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8843 - val_loss: 0.0920 - val_acc: 0.8962\n",
            "Epoch 4460/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0967 - acc: 0.8894 - val_loss: 0.0911 - val_acc: 0.8970\n",
            "Epoch 4461/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8904 - val_loss: 0.0911 - val_acc: 0.8976\n",
            "Epoch 4462/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8932 - val_loss: 0.0915 - val_acc: 0.8979\n",
            "Epoch 4463/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0924 - acc: 0.8934 - val_loss: 0.0913 - val_acc: 0.8979\n",
            "Epoch 4464/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8877 - val_loss: 0.0907 - val_acc: 0.8976\n",
            "Epoch 4465/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3122 - acc: 0.8569 - val_loss: 0.0922 - val_acc: 0.8964\n",
            "Epoch 4466/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8873 - val_loss: 0.0945 - val_acc: 0.8957\n",
            "Epoch 4467/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8876 - val_loss: 0.0947 - val_acc: 0.8962\n",
            "Epoch 4468/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8899 - val_loss: 0.0933 - val_acc: 0.8975\n",
            "Epoch 4469/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8806 - val_loss: 0.0929 - val_acc: 0.8983\n",
            "Epoch 4470/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8816 - val_loss: 0.0934 - val_acc: 0.8986\n",
            "Epoch 4471/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1039 - acc: 0.8818 - val_loss: 0.0937 - val_acc: 0.8985\n",
            "Epoch 4472/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0903 - acc: 0.8990 - val_loss: 0.0933 - val_acc: 0.8983\n",
            "Epoch 4473/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0895 - acc: 0.8990 - val_loss: 0.0929 - val_acc: 0.8979\n",
            "Epoch 4474/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2529 - acc: 0.8615 - val_loss: 0.0939 - val_acc: 0.8972\n",
            "Epoch 4475/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1006 - acc: 0.8867 - val_loss: 0.0953 - val_acc: 0.8967\n",
            "Epoch 4476/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8834 - val_loss: 0.0958 - val_acc: 0.8968\n",
            "Epoch 4477/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1008 - acc: 0.8916 - val_loss: 0.0955 - val_acc: 0.8972\n",
            "Epoch 4478/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8913 - val_loss: 0.0949 - val_acc: 0.8978\n",
            "Epoch 4479/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8880 - val_loss: 0.0946 - val_acc: 0.8983\n",
            "Epoch 4480/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8881 - val_loss: 0.0946 - val_acc: 0.8985\n",
            "Epoch 4481/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8891 - val_loss: 0.0945 - val_acc: 0.8986\n",
            "Epoch 4482/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0955 - acc: 0.8937 - val_loss: 0.0941 - val_acc: 0.8986\n",
            "Epoch 4483/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8905 - val_loss: 0.0935 - val_acc: 0.8984\n",
            "Epoch 4484/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8903 - val_loss: 0.0931 - val_acc: 0.8980\n",
            "Epoch 4485/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8862 - val_loss: 0.0930 - val_acc: 0.8976\n",
            "Epoch 4486/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8903 - val_loss: 0.0928 - val_acc: 0.8974\n",
            "Epoch 4487/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8903 - val_loss: 0.0924 - val_acc: 0.8974\n",
            "Epoch 4488/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2466 - acc: 0.8590 - val_loss: 0.0928 - val_acc: 0.8975\n",
            "Epoch 4489/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0936 - acc: 0.8948 - val_loss: 0.0930 - val_acc: 0.8978\n",
            "Epoch 4490/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1090 - acc: 0.8729 - val_loss: 0.0929 - val_acc: 0.8981\n",
            "Epoch 4491/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8849 - val_loss: 0.0927 - val_acc: 0.8983\n",
            "Epoch 4492/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8934 - val_loss: 0.0924 - val_acc: 0.8983\n",
            "Epoch 4493/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8901 - val_loss: 0.0922 - val_acc: 0.8981\n",
            "Epoch 4494/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8922 - val_loss: 0.0921 - val_acc: 0.8978\n",
            "Epoch 4495/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8895 - val_loss: 0.0920 - val_acc: 0.8975\n",
            "Epoch 4496/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2189 - acc: 0.8628 - val_loss: 0.0930 - val_acc: 0.8968\n",
            "Epoch 4497/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8885 - val_loss: 0.0940 - val_acc: 0.8965\n",
            "Epoch 4498/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0914 - acc: 0.8963 - val_loss: 0.0937 - val_acc: 0.8969\n",
            "Epoch 4499/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8920 - val_loss: 0.0927 - val_acc: 0.8976\n",
            "Epoch 4500/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8881 - val_loss: 0.0923 - val_acc: 0.8982\n",
            "Epoch 4501/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2722 - acc: 0.8591 - val_loss: 0.0933 - val_acc: 0.8985\n",
            "Epoch 4502/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8875 - val_loss: 0.0942 - val_acc: 0.8986\n",
            "Epoch 4503/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0893 - acc: 0.9025 - val_loss: 0.0947 - val_acc: 0.8986\n",
            "Epoch 4504/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8800 - val_loss: 0.0948 - val_acc: 0.8985\n",
            "Epoch 4505/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1109 - acc: 0.8788 - val_loss: 0.0949 - val_acc: 0.8983\n",
            "Epoch 4506/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2233 - acc: 0.8645 - val_loss: 0.0960 - val_acc: 0.8981\n",
            "Epoch 4507/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1009 - acc: 0.8870 - val_loss: 0.0969 - val_acc: 0.8979\n",
            "Epoch 4508/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8913 - val_loss: 0.0971 - val_acc: 0.8979\n",
            "Epoch 4509/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8853 - val_loss: 0.0968 - val_acc: 0.8981\n",
            "Epoch 4510/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8896 - val_loss: 0.0965 - val_acc: 0.8983\n",
            "Epoch 4511/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8900 - val_loss: 0.0963 - val_acc: 0.8984\n",
            "Epoch 4512/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8970 - val_loss: 0.0958 - val_acc: 0.8984\n",
            "Epoch 4513/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8971 - val_loss: 0.0952 - val_acc: 0.8984\n",
            "Epoch 4514/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8940 - val_loss: 0.0945 - val_acc: 0.8982\n",
            "Epoch 4515/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8869 - val_loss: 0.0940 - val_acc: 0.8980\n",
            "Epoch 4516/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8879 - val_loss: 0.0936 - val_acc: 0.8979\n",
            "Epoch 4517/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1531 - acc: 0.8764 - val_loss: 0.0935 - val_acc: 0.8979\n",
            "Epoch 4518/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2649 - acc: 0.8507 - val_loss: 0.0949 - val_acc: 0.8976\n",
            "Epoch 4519/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1035 - acc: 0.8832 - val_loss: 0.0961 - val_acc: 0.8975\n",
            "Epoch 4520/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8916 - val_loss: 0.0962 - val_acc: 0.8979\n",
            "Epoch 4521/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8857 - val_loss: 0.0955 - val_acc: 0.8984\n",
            "Epoch 4522/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1080 - acc: 0.8791 - val_loss: 0.0948 - val_acc: 0.8987\n",
            "Epoch 4523/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1017 - acc: 0.8950 - val_loss: 0.0947 - val_acc: 0.8988\n",
            "Epoch 4524/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8888 - val_loss: 0.0947 - val_acc: 0.8987\n",
            "Epoch 4525/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8848 - val_loss: 0.0943 - val_acc: 0.8984\n",
            "Epoch 4526/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8858 - val_loss: 0.0938 - val_acc: 0.8981\n",
            "Epoch 4527/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8892 - val_loss: 0.0935 - val_acc: 0.8977\n",
            "Epoch 4528/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8887 - val_loss: 0.0932 - val_acc: 0.8975\n",
            "Epoch 4529/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8836 - val_loss: 0.0928 - val_acc: 0.8974\n",
            "Epoch 4530/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8837 - val_loss: 0.0923 - val_acc: 0.8975\n",
            "Epoch 4531/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8849 - val_loss: 0.0919 - val_acc: 0.8977\n",
            "Epoch 4532/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8854 - val_loss: 0.0917 - val_acc: 0.8979\n",
            "Epoch 4533/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1034 - acc: 0.8803 - val_loss: 0.0915 - val_acc: 0.8980\n",
            "Epoch 4534/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - acc: 0.8934 - val_loss: 0.0912 - val_acc: 0.8979\n",
            "Epoch 4535/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8745 - val_loss: 0.0907 - val_acc: 0.8976\n",
            "Epoch 4536/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2658 - acc: 0.8520 - val_loss: 0.0923 - val_acc: 0.8964\n",
            "Epoch 4537/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1057 - acc: 0.8770 - val_loss: 0.0936 - val_acc: 0.8957\n",
            "Epoch 4538/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8893 - val_loss: 0.0930 - val_acc: 0.8962\n",
            "Epoch 4539/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8854 - val_loss: 0.0920 - val_acc: 0.8972\n",
            "Epoch 4540/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8871 - val_loss: 0.0922 - val_acc: 0.8979\n",
            "Epoch 4541/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8917 - val_loss: 0.0928 - val_acc: 0.8982\n",
            "Epoch 4542/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8865 - val_loss: 0.0923 - val_acc: 0.8982\n",
            "Epoch 4543/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8796 - val_loss: 0.0914 - val_acc: 0.8978\n",
            "Epoch 4544/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8832 - val_loss: 0.0914 - val_acc: 0.8972\n",
            "Epoch 4545/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8826 - val_loss: 0.0919 - val_acc: 0.8966\n",
            "Epoch 4546/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8867 - val_loss: 0.0918 - val_acc: 0.8965\n",
            "Epoch 4547/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8868 - val_loss: 0.0913 - val_acc: 0.8969\n",
            "Epoch 4548/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8874 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4549/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0923 - acc: 0.8958 - val_loss: 0.0912 - val_acc: 0.8979\n",
            "Epoch 4550/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0923 - acc: 0.8921 - val_loss: 0.0912 - val_acc: 0.8980\n",
            "Epoch 4551/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8874 - val_loss: 0.0907 - val_acc: 0.8978\n",
            "Epoch 4552/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0901 - acc: 0.8948 - val_loss: 0.0904 - val_acc: 0.8973\n",
            "Epoch 4553/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0877 - acc: 0.8954 - val_loss: 0.0906 - val_acc: 0.8968\n",
            "Epoch 4554/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0947 - acc: 0.8895 - val_loss: 0.0907 - val_acc: 0.8966\n",
            "Epoch 4555/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2131 - acc: 0.8638 - val_loss: 0.0909 - val_acc: 0.8967\n",
            "Epoch 4556/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8856 - val_loss: 0.0907 - val_acc: 0.8973\n",
            "Epoch 4557/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3017 - acc: 0.8486 - val_loss: 0.0918 - val_acc: 0.8970\n",
            "Epoch 4558/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8858 - val_loss: 0.0932 - val_acc: 0.8969\n",
            "Epoch 4559/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1099 - acc: 0.8740 - val_loss: 0.0936 - val_acc: 0.8974\n",
            "Epoch 4560/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1097 - acc: 0.8747 - val_loss: 0.0936 - val_acc: 0.8979\n",
            "Epoch 4561/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1874 - acc: 0.8778 - val_loss: 0.0945 - val_acc: 0.8981\n",
            "Epoch 4562/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8886 - val_loss: 0.0950 - val_acc: 0.8982\n",
            "Epoch 4563/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8902 - val_loss: 0.0953 - val_acc: 0.8984\n",
            "Epoch 4564/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1142 - acc: 0.8868 - val_loss: 0.0958 - val_acc: 0.8983\n",
            "Epoch 4565/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1045 - acc: 0.8850 - val_loss: 0.0961 - val_acc: 0.8983\n",
            "Epoch 4566/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8828 - val_loss: 0.0961 - val_acc: 0.8983\n",
            "Epoch 4567/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8829 - val_loss: 0.0960 - val_acc: 0.8983\n",
            "Epoch 4568/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8910 - val_loss: 0.0957 - val_acc: 0.8984\n",
            "Epoch 4569/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8814 - val_loss: 0.0953 - val_acc: 0.8984\n",
            "Epoch 4570/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1076 - acc: 0.8838 - val_loss: 0.0948 - val_acc: 0.8985\n",
            "Epoch 4571/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8872 - val_loss: 0.0943 - val_acc: 0.8984\n",
            "Epoch 4572/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8921 - val_loss: 0.0939 - val_acc: 0.8984\n",
            "Epoch 4573/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0974 - acc: 0.8905 - val_loss: 0.0935 - val_acc: 0.8983\n",
            "Epoch 4574/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8890 - val_loss: 0.0930 - val_acc: 0.8981\n",
            "Epoch 4575/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8972 - val_loss: 0.0925 - val_acc: 0.8980\n",
            "Epoch 4576/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1007 - acc: 0.8858 - val_loss: 0.0920 - val_acc: 0.8979\n",
            "Epoch 4577/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8850 - val_loss: 0.0916 - val_acc: 0.8977\n",
            "Epoch 4578/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8769 - val_loss: 0.0913 - val_acc: 0.8975\n",
            "Epoch 4579/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2183 - acc: 0.8674 - val_loss: 0.0919 - val_acc: 0.8971\n",
            "Epoch 4580/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8856 - val_loss: 0.0923 - val_acc: 0.8969\n",
            "Epoch 4581/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8867 - val_loss: 0.0921 - val_acc: 0.8971\n",
            "Epoch 4582/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1075 - acc: 0.8740 - val_loss: 0.0917 - val_acc: 0.8975\n",
            "Epoch 4583/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8902 - val_loss: 0.0914 - val_acc: 0.8978\n",
            "Epoch 4584/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8871 - val_loss: 0.0913 - val_acc: 0.8980\n",
            "Epoch 4585/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8871 - val_loss: 0.0910 - val_acc: 0.8980\n",
            "Epoch 4586/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8831 - val_loss: 0.0907 - val_acc: 0.8977\n",
            "Epoch 4587/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8880 - val_loss: 0.0908 - val_acc: 0.8972\n",
            "Epoch 4588/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8882 - val_loss: 0.0909 - val_acc: 0.8970\n",
            "Epoch 4589/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8804 - val_loss: 0.0907 - val_acc: 0.8970\n",
            "Epoch 4590/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3170 - acc: 0.8453 - val_loss: 0.0922 - val_acc: 0.8965\n",
            "Epoch 4591/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8793 - val_loss: 0.0934 - val_acc: 0.8964\n",
            "Epoch 4592/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8821 - val_loss: 0.0934 - val_acc: 0.8970\n",
            "Epoch 4593/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8866 - val_loss: 0.0928 - val_acc: 0.8977\n",
            "Epoch 4594/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8875 - val_loss: 0.0928 - val_acc: 0.8983\n",
            "Epoch 4595/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8868 - val_loss: 0.0932 - val_acc: 0.8984\n",
            "Epoch 4596/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0950 - acc: 0.8926 - val_loss: 0.0930 - val_acc: 0.8982\n",
            "Epoch 4597/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8877 - val_loss: 0.0926 - val_acc: 0.8978\n",
            "Epoch 4598/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8908 - val_loss: 0.0925 - val_acc: 0.8974\n",
            "Epoch 4599/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8913 - val_loss: 0.0926 - val_acc: 0.8971\n",
            "Epoch 4600/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1060 - acc: 0.8790 - val_loss: 0.0925 - val_acc: 0.8970\n",
            "Epoch 4601/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1092 - acc: 0.8682 - val_loss: 0.0921 - val_acc: 0.8973\n",
            "Epoch 4602/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1960 - acc: 0.8626 - val_loss: 0.0925 - val_acc: 0.8973\n",
            "Epoch 4603/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8898 - val_loss: 0.0927 - val_acc: 0.8975\n",
            "Epoch 4604/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0998 - acc: 0.8857 - val_loss: 0.0924 - val_acc: 0.8979\n",
            "Epoch 4605/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1059 - acc: 0.8861 - val_loss: 0.0921 - val_acc: 0.8981\n",
            "Epoch 4606/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0918 - acc: 0.8948 - val_loss: 0.0919 - val_acc: 0.8983\n",
            "Epoch 4607/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0961 - acc: 0.8894 - val_loss: 0.0918 - val_acc: 0.8983\n",
            "Epoch 4608/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8892 - val_loss: 0.0916 - val_acc: 0.8981\n",
            "Epoch 4609/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8846 - val_loss: 0.0915 - val_acc: 0.8977\n",
            "Epoch 4610/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8830 - val_loss: 0.0914 - val_acc: 0.8974\n",
            "Epoch 4611/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8900 - val_loss: 0.0912 - val_acc: 0.8971\n",
            "Epoch 4612/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8751 - val_loss: 0.0909 - val_acc: 0.8971\n",
            "Epoch 4613/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0940 - acc: 0.8909 - val_loss: 0.0906 - val_acc: 0.8972\n",
            "Epoch 4614/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8870 - val_loss: 0.0905 - val_acc: 0.8975\n",
            "Epoch 4615/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8855 - val_loss: 0.0903 - val_acc: 0.8977\n",
            "Epoch 4616/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1408 - acc: 0.8781 - val_loss: 0.0902 - val_acc: 0.8975\n",
            "Epoch 4617/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8830 - val_loss: 0.0903 - val_acc: 0.8972\n",
            "Epoch 4618/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8843 - val_loss: 0.0904 - val_acc: 0.8971\n",
            "Epoch 4619/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8785 - val_loss: 0.0902 - val_acc: 0.8973\n",
            "Epoch 4620/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8838 - val_loss: 0.0901 - val_acc: 0.8975\n",
            "Epoch 4621/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8814 - val_loss: 0.0901 - val_acc: 0.8976\n",
            "Epoch 4622/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8827 - val_loss: 0.0901 - val_acc: 0.8976\n",
            "Epoch 4623/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8829 - val_loss: 0.0900 - val_acc: 0.8975\n",
            "Epoch 4624/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8852 - val_loss: 0.0899 - val_acc: 0.8972\n",
            "Epoch 4625/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0909 - acc: 0.8914 - val_loss: 0.0899 - val_acc: 0.8970\n",
            "Epoch 4626/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0935 - acc: 0.8842 - val_loss: 0.0899 - val_acc: 0.8968\n",
            "Epoch 4627/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8878 - val_loss: 0.0897 - val_acc: 0.8969\n",
            "Epoch 4628/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8805 - val_loss: 0.0896 - val_acc: 0.8971\n",
            "Epoch 4629/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8856 - val_loss: 0.0895 - val_acc: 0.8972\n",
            "Epoch 4630/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8857 - val_loss: 0.0895 - val_acc: 0.8973\n",
            "Epoch 4631/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0857 - acc: 0.8948 - val_loss: 0.0896 - val_acc: 0.8974\n",
            "Epoch 4632/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8861 - val_loss: 0.0895 - val_acc: 0.8973\n",
            "Epoch 4633/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1737 - acc: 0.8779 - val_loss: 0.0899 - val_acc: 0.8967\n",
            "Epoch 4634/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8874 - val_loss: 0.0902 - val_acc: 0.8965\n",
            "Epoch 4635/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8902 - val_loss: 0.0898 - val_acc: 0.8970\n",
            "Epoch 4636/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0855 - acc: 0.8992 - val_loss: 0.0898 - val_acc: 0.8976\n",
            "Epoch 4637/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8910 - val_loss: 0.0900 - val_acc: 0.8979\n",
            "Epoch 4638/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1190 - acc: 0.8892 - val_loss: 0.0898 - val_acc: 0.8977\n",
            "Epoch 4639/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8861 - val_loss: 0.0898 - val_acc: 0.8973\n",
            "Epoch 4640/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8857 - val_loss: 0.0900 - val_acc: 0.8969\n",
            "Epoch 4641/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8746 - val_loss: 0.0900 - val_acc: 0.8969\n",
            "Epoch 4642/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8808 - val_loss: 0.0898 - val_acc: 0.8973\n",
            "Epoch 4643/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8813 - val_loss: 0.0898 - val_acc: 0.8976\n",
            "Epoch 4644/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8835 - val_loss: 0.0899 - val_acc: 0.8980\n",
            "Epoch 4645/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8839 - val_loss: 0.0899 - val_acc: 0.8981\n",
            "Epoch 4646/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8866 - val_loss: 0.0897 - val_acc: 0.8980\n",
            "Epoch 4647/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0971 - acc: 0.8855 - val_loss: 0.0897 - val_acc: 0.8976\n",
            "Epoch 4648/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8744 - val_loss: 0.0899 - val_acc: 0.8970\n",
            "Epoch 4649/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8890 - val_loss: 0.0900 - val_acc: 0.8968\n",
            "Epoch 4650/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0889 - acc: 0.8943 - val_loss: 0.0897 - val_acc: 0.8971\n",
            "Epoch 4651/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8877 - val_loss: 0.0896 - val_acc: 0.8974\n",
            "Epoch 4652/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8881 - val_loss: 0.0897 - val_acc: 0.8977\n",
            "Epoch 4653/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8906 - val_loss: 0.0896 - val_acc: 0.8976\n",
            "Epoch 4654/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8901 - val_loss: 0.0893 - val_acc: 0.8973\n",
            "Epoch 4655/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1004 - acc: 0.8788 - val_loss: 0.0894 - val_acc: 0.8970\n",
            "Epoch 4656/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8753 - val_loss: 0.0896 - val_acc: 0.8967\n",
            "Epoch 4657/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0876 - acc: 0.8945 - val_loss: 0.0895 - val_acc: 0.8969\n",
            "Epoch 4658/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8840 - val_loss: 0.0894 - val_acc: 0.8971\n",
            "Epoch 4659/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8845 - val_loss: 0.0894 - val_acc: 0.8973\n",
            "Epoch 4660/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8859 - val_loss: 0.0892 - val_acc: 0.8974\n",
            "Epoch 4661/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8839 - val_loss: 0.0892 - val_acc: 0.8973\n",
            "Epoch 4662/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0959 - acc: 0.8840 - val_loss: 0.0893 - val_acc: 0.8970\n",
            "Epoch 4663/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8828 - val_loss: 0.0893 - val_acc: 0.8970\n",
            "Epoch 4664/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8820 - val_loss: 0.0891 - val_acc: 0.8969\n",
            "Epoch 4665/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0983 - acc: 0.8820 - val_loss: 0.0890 - val_acc: 0.8970\n",
            "Epoch 4666/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8851 - val_loss: 0.0890 - val_acc: 0.8971\n",
            "Epoch 4667/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0949 - acc: 0.8848 - val_loss: 0.0891 - val_acc: 0.8973\n",
            "Epoch 4668/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0943 - acc: 0.8851 - val_loss: 0.0892 - val_acc: 0.8974\n",
            "Epoch 4669/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0900 - acc: 0.8918 - val_loss: 0.0891 - val_acc: 0.8972\n",
            "Epoch 4670/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8796 - val_loss: 0.0891 - val_acc: 0.8969\n",
            "Epoch 4671/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8826 - val_loss: 0.0892 - val_acc: 0.8966\n",
            "Epoch 4672/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0909 - acc: 0.8908 - val_loss: 0.0892 - val_acc: 0.8966\n",
            "Epoch 4673/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8790 - val_loss: 0.0890 - val_acc: 0.8971\n",
            "Epoch 4674/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8891 - val_loss: 0.0890 - val_acc: 0.8974\n",
            "Epoch 4675/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0906 - acc: 0.8909 - val_loss: 0.0891 - val_acc: 0.8976\n",
            "Epoch 4676/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8905 - val_loss: 0.0891 - val_acc: 0.8976\n",
            "Epoch 4677/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8813 - val_loss: 0.0889 - val_acc: 0.8973\n",
            "Epoch 4678/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8922 - val_loss: 0.0890 - val_acc: 0.8970\n",
            "Epoch 4679/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1472 - acc: 0.8826 - val_loss: 0.0894 - val_acc: 0.8964\n",
            "Epoch 4680/5000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0903 - acc: 0.8903 - val_loss: 0.0894 - val_acc: 0.8965\n",
            "Epoch 4681/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8856 - val_loss: 0.0890 - val_acc: 0.8971\n",
            "Epoch 4682/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0970 - acc: 0.8847 - val_loss: 0.0890 - val_acc: 0.8977\n",
            "Epoch 4683/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8854 - val_loss: 0.0892 - val_acc: 0.8979\n",
            "Epoch 4684/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0907 - acc: 0.8915 - val_loss: 0.0889 - val_acc: 0.8978\n",
            "Epoch 4685/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0900 - acc: 0.8915 - val_loss: 0.0890 - val_acc: 0.8973\n",
            "Epoch 4686/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0942 - acc: 0.8885 - val_loss: 0.0893 - val_acc: 0.8969\n",
            "Epoch 4687/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8849 - val_loss: 0.0894 - val_acc: 0.8968\n",
            "Epoch 4688/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0915 - acc: 0.8919 - val_loss: 0.0891 - val_acc: 0.8971\n",
            "Epoch 4689/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3252 - acc: 0.8435 - val_loss: 0.0909 - val_acc: 0.8962\n",
            "Epoch 4690/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8807 - val_loss: 0.0924 - val_acc: 0.8959\n",
            "Epoch 4691/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8879 - val_loss: 0.0921 - val_acc: 0.8967\n",
            "Epoch 4692/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1381 - acc: 0.8737 - val_loss: 0.0919 - val_acc: 0.8976\n",
            "Epoch 4693/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8932 - val_loss: 0.0922 - val_acc: 0.8983\n",
            "Epoch 4694/5000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0976 - acc: 0.8870 - val_loss: 0.0927 - val_acc: 0.8987\n",
            "Epoch 4695/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8875 - val_loss: 0.0928 - val_acc: 0.8987\n",
            "Epoch 4696/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0966 - acc: 0.8898 - val_loss: 0.0925 - val_acc: 0.8986\n",
            "Epoch 4697/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8840 - val_loss: 0.0926 - val_acc: 0.8982\n",
            "Epoch 4698/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8837 - val_loss: 0.0930 - val_acc: 0.8978\n",
            "Epoch 4699/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8934 - val_loss: 0.0931 - val_acc: 0.8976\n",
            "Epoch 4700/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0925 - acc: 0.8933 - val_loss: 0.0928 - val_acc: 0.8977\n",
            "Epoch 4701/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8905 - val_loss: 0.0922 - val_acc: 0.8980\n",
            "Epoch 4702/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0924 - acc: 0.8939 - val_loss: 0.0921 - val_acc: 0.8983\n",
            "Epoch 4703/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8881 - val_loss: 0.0922 - val_acc: 0.8985\n",
            "Epoch 4704/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8888 - val_loss: 0.0919 - val_acc: 0.8985\n",
            "Epoch 4705/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8854 - val_loss: 0.0912 - val_acc: 0.8983\n",
            "Epoch 4706/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8854 - val_loss: 0.0907 - val_acc: 0.8980\n",
            "Epoch 4707/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8863 - val_loss: 0.0907 - val_acc: 0.8976\n",
            "Epoch 4708/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0945 - acc: 0.8880 - val_loss: 0.0908 - val_acc: 0.8973\n",
            "Epoch 4709/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8833 - val_loss: 0.0906 - val_acc: 0.8973\n",
            "Epoch 4710/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8725 - val_loss: 0.0901 - val_acc: 0.8975\n",
            "Epoch 4711/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1178 - acc: 0.8710 - val_loss: 0.0898 - val_acc: 0.8977\n",
            "Epoch 4712/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1443 - acc: 0.8845 - val_loss: 0.0896 - val_acc: 0.8979\n",
            "Epoch 4713/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2524 - acc: 0.8608 - val_loss: 0.0906 - val_acc: 0.8973\n",
            "Epoch 4714/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1087 - acc: 0.8786 - val_loss: 0.0922 - val_acc: 0.8967\n",
            "Epoch 4715/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8890 - val_loss: 0.0928 - val_acc: 0.8967\n",
            "Epoch 4716/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0920 - acc: 0.8949 - val_loss: 0.0920 - val_acc: 0.8973\n",
            "Epoch 4717/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0977 - acc: 0.8946 - val_loss: 0.0914 - val_acc: 0.8981\n",
            "Epoch 4718/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2509 - acc: 0.8663 - val_loss: 0.0931 - val_acc: 0.8985\n",
            "Epoch 4719/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8974 - val_loss: 0.0946 - val_acc: 0.8986\n",
            "Epoch 4720/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8925 - val_loss: 0.0948 - val_acc: 0.8985\n",
            "Epoch 4721/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8898 - val_loss: 0.0945 - val_acc: 0.8983\n",
            "Epoch 4722/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8969 - val_loss: 0.0946 - val_acc: 0.8980\n",
            "Epoch 4723/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1020 - acc: 0.8923 - val_loss: 0.0948 - val_acc: 0.8977\n",
            "Epoch 4724/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8836 - val_loss: 0.0947 - val_acc: 0.8977\n",
            "Epoch 4725/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8923 - val_loss: 0.0941 - val_acc: 0.8980\n",
            "Epoch 4726/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8957 - val_loss: 0.0935 - val_acc: 0.8983\n",
            "Epoch 4727/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1033 - acc: 0.8848 - val_loss: 0.0932 - val_acc: 0.8985\n",
            "Epoch 4728/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8851 - val_loss: 0.0929 - val_acc: 0.8985\n",
            "Epoch 4729/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1032 - acc: 0.8860 - val_loss: 0.0925 - val_acc: 0.8984\n",
            "Epoch 4730/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8901 - val_loss: 0.0921 - val_acc: 0.8982\n",
            "Epoch 4731/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8845 - val_loss: 0.0919 - val_acc: 0.8979\n",
            "Epoch 4732/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8882 - val_loss: 0.0916 - val_acc: 0.8977\n",
            "Epoch 4733/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2565 - acc: 0.8605 - val_loss: 0.0926 - val_acc: 0.8971\n",
            "Epoch 4734/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8894 - val_loss: 0.0932 - val_acc: 0.8970\n",
            "Epoch 4735/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8961 - val_loss: 0.0928 - val_acc: 0.8974\n",
            "Epoch 4736/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2183 - acc: 0.8610 - val_loss: 0.0927 - val_acc: 0.8981\n",
            "Epoch 4737/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8973 - val_loss: 0.0930 - val_acc: 0.8986\n",
            "Epoch 4738/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1116 - acc: 0.8759 - val_loss: 0.0934 - val_acc: 0.8988\n",
            "Epoch 4739/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8854 - val_loss: 0.0934 - val_acc: 0.8989\n",
            "Epoch 4740/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8826 - val_loss: 0.0931 - val_acc: 0.8987\n",
            "Epoch 4741/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1121 - acc: 0.8885 - val_loss: 0.0930 - val_acc: 0.8984\n",
            "Epoch 4742/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8930 - val_loss: 0.0931 - val_acc: 0.8980\n",
            "Epoch 4743/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8959 - val_loss: 0.0930 - val_acc: 0.8978\n",
            "Epoch 4744/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0928 - acc: 0.8993 - val_loss: 0.0927 - val_acc: 0.8978\n",
            "Epoch 4745/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1677 - acc: 0.8739 - val_loss: 0.0927 - val_acc: 0.8978\n",
            "Epoch 4746/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1112 - acc: 0.8842 - val_loss: 0.0927 - val_acc: 0.8980\n",
            "Epoch 4747/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1022 - acc: 0.8828 - val_loss: 0.0926 - val_acc: 0.8981\n",
            "Epoch 4748/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8790 - val_loss: 0.0925 - val_acc: 0.8983\n",
            "Epoch 4749/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8862 - val_loss: 0.0922 - val_acc: 0.8983\n",
            "Epoch 4750/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8862 - val_loss: 0.0918 - val_acc: 0.8984\n",
            "Epoch 4751/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8873 - val_loss: 0.0914 - val_acc: 0.8982\n",
            "Epoch 4752/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0871 - acc: 0.9001 - val_loss: 0.0912 - val_acc: 0.8981\n",
            "Epoch 4753/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8881 - val_loss: 0.0911 - val_acc: 0.8979\n",
            "Epoch 4754/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0918 - acc: 0.8949 - val_loss: 0.0909 - val_acc: 0.8979\n",
            "Epoch 4755/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0914 - acc: 0.8949 - val_loss: 0.0905 - val_acc: 0.8980\n",
            "Epoch 4756/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1052 - acc: 0.8761 - val_loss: 0.0901 - val_acc: 0.8980\n",
            "Epoch 4757/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0869 - acc: 0.9016 - val_loss: 0.0898 - val_acc: 0.8980\n",
            "Epoch 4758/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2312 - acc: 0.8634 - val_loss: 0.0907 - val_acc: 0.8971\n",
            "Epoch 4759/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8768 - val_loss: 0.0923 - val_acc: 0.8962\n",
            "Epoch 4760/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8856 - val_loss: 0.0923 - val_acc: 0.8963\n",
            "Epoch 4761/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8858 - val_loss: 0.0911 - val_acc: 0.8971\n",
            "Epoch 4762/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1015 - acc: 0.8841 - val_loss: 0.0908 - val_acc: 0.8979\n",
            "Epoch 4763/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0985 - acc: 0.8841 - val_loss: 0.0912 - val_acc: 0.8983\n",
            "Epoch 4764/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8845 - val_loss: 0.0909 - val_acc: 0.8984\n",
            "Epoch 4765/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0929 - acc: 0.8943 - val_loss: 0.0902 - val_acc: 0.8981\n",
            "Epoch 4766/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0934 - acc: 0.8886 - val_loss: 0.0901 - val_acc: 0.8976\n",
            "Epoch 4767/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0931 - acc: 0.8882 - val_loss: 0.0904 - val_acc: 0.8971\n",
            "Epoch 4768/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8790 - val_loss: 0.0905 - val_acc: 0.8968\n",
            "Epoch 4769/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3062 - acc: 0.8407 - val_loss: 0.0918 - val_acc: 0.8964\n",
            "Epoch 4770/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3042 - acc: 0.8397 - val_loss: 0.0958 - val_acc: 0.8957\n",
            "Epoch 4771/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8820 - val_loss: 0.0976 - val_acc: 0.8963\n",
            "Epoch 4772/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2498 - acc: 0.8427 - val_loss: 0.1017 - val_acc: 0.8965\n",
            "Epoch 4773/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1150 - acc: 0.8724 - val_loss: 0.1028 - val_acc: 0.8975\n",
            "Epoch 4774/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2285 - acc: 0.8585 - val_loss: 0.1061 - val_acc: 0.8982\n",
            "Epoch 4775/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1129 - acc: 0.8886 - val_loss: 0.1078 - val_acc: 0.8987\n",
            "Epoch 4776/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1133 - acc: 0.8872 - val_loss: 0.1084 - val_acc: 0.8990\n",
            "Epoch 4777/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1103 - acc: 0.8928 - val_loss: 0.1083 - val_acc: 0.8990\n",
            "Epoch 4778/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8928 - val_loss: 0.1075 - val_acc: 0.8990\n",
            "Epoch 4779/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1155 - acc: 0.8870 - val_loss: 0.1064 - val_acc: 0.8990\n",
            "Epoch 4780/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1250 - acc: 0.8811 - val_loss: 0.1054 - val_acc: 0.8989\n",
            "Epoch 4781/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1081 - acc: 0.8927 - val_loss: 0.1047 - val_acc: 0.8986\n",
            "Epoch 4782/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1123 - acc: 0.8875 - val_loss: 0.1043 - val_acc: 0.8982\n",
            "Epoch 4783/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8873 - val_loss: 0.1037 - val_acc: 0.8980\n",
            "Epoch 4784/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1786 - acc: 0.8732 - val_loss: 0.1036 - val_acc: 0.8978\n",
            "Epoch 4785/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1166 - acc: 0.8802 - val_loss: 0.1031 - val_acc: 0.8978\n",
            "Epoch 4786/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1271 - acc: 0.8896 - val_loss: 0.1023 - val_acc: 0.8980\n",
            "Epoch 4787/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1044 - acc: 0.8973 - val_loss: 0.1012 - val_acc: 0.8983\n",
            "Epoch 4788/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1252 - acc: 0.8838 - val_loss: 0.1001 - val_acc: 0.8986\n",
            "Epoch 4789/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1018 - acc: 0.8932 - val_loss: 0.0992 - val_acc: 0.8987\n",
            "Epoch 4790/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1117 - acc: 0.8810 - val_loss: 0.0982 - val_acc: 0.8988\n",
            "Epoch 4791/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8882 - val_loss: 0.0974 - val_acc: 0.8988\n",
            "Epoch 4792/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8881 - val_loss: 0.0966 - val_acc: 0.8987\n",
            "Epoch 4793/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8915 - val_loss: 0.0960 - val_acc: 0.8986\n",
            "Epoch 4794/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1012 - acc: 0.8912 - val_loss: 0.0954 - val_acc: 0.8985\n",
            "Epoch 4795/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8911 - val_loss: 0.0948 - val_acc: 0.8983\n",
            "Epoch 4796/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8901 - val_loss: 0.0941 - val_acc: 0.8982\n",
            "Epoch 4797/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8991 - val_loss: 0.0935 - val_acc: 0.8981\n",
            "Epoch 4798/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8894 - val_loss: 0.0929 - val_acc: 0.8981\n",
            "Epoch 4799/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8934 - val_loss: 0.0923 - val_acc: 0.8980\n",
            "Epoch 4800/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8919 - val_loss: 0.0918 - val_acc: 0.8979\n",
            "Epoch 4801/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - acc: 0.8853 - val_loss: 0.0913 - val_acc: 0.8978\n",
            "Epoch 4802/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8894 - val_loss: 0.0910 - val_acc: 0.8976\n",
            "Epoch 4803/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1148 - acc: 0.8861 - val_loss: 0.0909 - val_acc: 0.8974\n",
            "Epoch 4804/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1011 - acc: 0.8891 - val_loss: 0.0909 - val_acc: 0.8972\n",
            "Epoch 4805/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8870 - val_loss: 0.0906 - val_acc: 0.8972\n",
            "Epoch 4806/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2702 - acc: 0.8542 - val_loss: 0.0915 - val_acc: 0.8964\n",
            "Epoch 4807/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0991 - acc: 0.8810 - val_loss: 0.0922 - val_acc: 0.8960\n",
            "Epoch 4808/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1003 - acc: 0.8827 - val_loss: 0.0918 - val_acc: 0.8964\n",
            "Epoch 4809/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0995 - acc: 0.8833 - val_loss: 0.0910 - val_acc: 0.8971\n",
            "Epoch 4810/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1157 - acc: 0.8831 - val_loss: 0.0909 - val_acc: 0.8977\n",
            "Epoch 4811/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0927 - acc: 0.8919 - val_loss: 0.0913 - val_acc: 0.8980\n",
            "Epoch 4812/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8790 - val_loss: 0.0915 - val_acc: 0.8980\n",
            "Epoch 4813/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2841 - acc: 0.8511 - val_loss: 0.0914 - val_acc: 0.8977\n",
            "Epoch 4814/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8849 - val_loss: 0.0921 - val_acc: 0.8973\n",
            "Epoch 4815/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8845 - val_loss: 0.0928 - val_acc: 0.8972\n",
            "Epoch 4816/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8898 - val_loss: 0.0928 - val_acc: 0.8975\n",
            "Epoch 4817/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0956 - acc: 0.8860 - val_loss: 0.0926 - val_acc: 0.8978\n",
            "Epoch 4818/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1270 - acc: 0.8811 - val_loss: 0.0929 - val_acc: 0.8982\n",
            "Epoch 4819/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0953 - acc: 0.8906 - val_loss: 0.0931 - val_acc: 0.8983\n",
            "Epoch 4820/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8849 - val_loss: 0.0930 - val_acc: 0.8984\n",
            "Epoch 4821/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0967 - acc: 0.8945 - val_loss: 0.0929 - val_acc: 0.8984\n",
            "Epoch 4822/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1056 - acc: 0.8821 - val_loss: 0.0926 - val_acc: 0.8984\n",
            "Epoch 4823/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8904 - val_loss: 0.0925 - val_acc: 0.8982\n",
            "Epoch 4824/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8819 - val_loss: 0.0924 - val_acc: 0.8980\n",
            "Epoch 4825/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2216 - acc: 0.8658 - val_loss: 0.0932 - val_acc: 0.8977\n",
            "Epoch 4826/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - acc: 0.8983 - val_loss: 0.0935 - val_acc: 0.8977\n",
            "Epoch 4827/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8895 - val_loss: 0.0933 - val_acc: 0.8979\n",
            "Epoch 4828/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8898 - val_loss: 0.0929 - val_acc: 0.8982\n",
            "Epoch 4829/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0915 - acc: 0.8951 - val_loss: 0.0927 - val_acc: 0.8984\n",
            "Epoch 4830/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0969 - acc: 0.8905 - val_loss: 0.0926 - val_acc: 0.8985\n",
            "Epoch 4831/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1050 - acc: 0.8826 - val_loss: 0.0923 - val_acc: 0.8985\n",
            "Epoch 4832/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8847 - val_loss: 0.0919 - val_acc: 0.8984\n",
            "Epoch 4833/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8847 - val_loss: 0.0918 - val_acc: 0.8981\n",
            "Epoch 4834/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1031 - acc: 0.8783 - val_loss: 0.0919 - val_acc: 0.8978\n",
            "Epoch 4835/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1368 - acc: 0.8725 - val_loss: 0.0923 - val_acc: 0.8975\n",
            "Epoch 4836/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8849 - val_loss: 0.0922 - val_acc: 0.8975\n",
            "Epoch 4837/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8903 - val_loss: 0.0915 - val_acc: 0.8978\n",
            "Epoch 4838/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1013 - acc: 0.8912 - val_loss: 0.0909 - val_acc: 0.8982\n",
            "Epoch 4839/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1422 - acc: 0.8787 - val_loss: 0.0908 - val_acc: 0.8983\n",
            "Epoch 4840/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0988 - acc: 0.8858 - val_loss: 0.0909 - val_acc: 0.8983\n",
            "Epoch 4841/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1104 - acc: 0.8877 - val_loss: 0.0909 - val_acc: 0.8980\n",
            "Epoch 4842/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2221 - acc: 0.8691 - val_loss: 0.0913 - val_acc: 0.8974\n",
            "Epoch 4843/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0917 - acc: 0.8962 - val_loss: 0.0920 - val_acc: 0.8970\n",
            "Epoch 4844/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0973 - acc: 0.8872 - val_loss: 0.0924 - val_acc: 0.8969\n",
            "Epoch 4845/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2477 - acc: 0.8552 - val_loss: 0.0939 - val_acc: 0.8967\n",
            "Epoch 4846/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3058 - acc: 0.8396 - val_loss: 0.0996 - val_acc: 0.8958\n",
            "Epoch 4847/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2547 - acc: 0.8399 - val_loss: 0.1067 - val_acc: 0.8952\n",
            "Epoch 4848/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1079 - acc: 0.8891 - val_loss: 0.1091 - val_acc: 0.8963\n",
            "Epoch 4849/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8913 - val_loss: 0.1082 - val_acc: 0.8979\n",
            "Epoch 4850/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1163 - acc: 0.8828 - val_loss: 0.1071 - val_acc: 0.8987\n",
            "Epoch 4851/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1106 - acc: 0.8889 - val_loss: 0.1072 - val_acc: 0.8989\n",
            "Epoch 4852/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1141 - acc: 0.8858 - val_loss: 0.1074 - val_acc: 0.8989\n",
            "Epoch 4853/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1185 - acc: 0.8849 - val_loss: 0.1064 - val_acc: 0.8989\n",
            "Epoch 4854/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1176 - acc: 0.8849 - val_loss: 0.1044 - val_acc: 0.8988\n",
            "Epoch 4855/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8948 - val_loss: 0.1028 - val_acc: 0.8987\n",
            "Epoch 4856/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1036 - acc: 0.8950 - val_loss: 0.1021 - val_acc: 0.8982\n",
            "Epoch 4857/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1095 - acc: 0.8902 - val_loss: 0.1019 - val_acc: 0.8977\n",
            "Epoch 4858/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1105 - acc: 0.8862 - val_loss: 0.1017 - val_acc: 0.8974\n",
            "Epoch 4859/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2151 - acc: 0.8598 - val_loss: 0.1025 - val_acc: 0.8971\n",
            "Epoch 4860/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8825 - val_loss: 0.1025 - val_acc: 0.8971\n",
            "Epoch 4861/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8838 - val_loss: 0.1014 - val_acc: 0.8975\n",
            "Epoch 4862/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1069 - acc: 0.8871 - val_loss: 0.0998 - val_acc: 0.8980\n",
            "Epoch 4863/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1758 - acc: 0.8748 - val_loss: 0.0990 - val_acc: 0.8984\n",
            "Epoch 4864/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1041 - acc: 0.8921 - val_loss: 0.0984 - val_acc: 0.8987\n",
            "Epoch 4865/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8922 - val_loss: 0.0981 - val_acc: 0.8988\n",
            "Epoch 4866/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8889 - val_loss: 0.0977 - val_acc: 0.8989\n",
            "Epoch 4867/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8945 - val_loss: 0.0971 - val_acc: 0.8989\n",
            "Epoch 4868/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - acc: 0.8890 - val_loss: 0.0963 - val_acc: 0.8988\n",
            "Epoch 4869/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1042 - acc: 0.8896 - val_loss: 0.0957 - val_acc: 0.8986\n",
            "Epoch 4870/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8893 - val_loss: 0.0952 - val_acc: 0.8984\n",
            "Epoch 4871/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0996 - acc: 0.8924 - val_loss: 0.0949 - val_acc: 0.8981\n",
            "Epoch 4872/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8921 - val_loss: 0.0945 - val_acc: 0.8980\n",
            "Epoch 4873/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8861 - val_loss: 0.0938 - val_acc: 0.8980\n",
            "Epoch 4874/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8814 - val_loss: 0.0930 - val_acc: 0.8981\n",
            "Epoch 4875/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1424 - acc: 0.8670 - val_loss: 0.0925 - val_acc: 0.8981\n",
            "Epoch 4876/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0892 - acc: 0.8986 - val_loss: 0.0922 - val_acc: 0.8981\n",
            "Epoch 4877/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0887 - acc: 0.8987 - val_loss: 0.0919 - val_acc: 0.8981\n",
            "Epoch 4878/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0989 - acc: 0.8880 - val_loss: 0.0915 - val_acc: 0.8981\n",
            "Epoch 4879/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1812 - acc: 0.8745 - val_loss: 0.0915 - val_acc: 0.8977\n",
            "Epoch 4880/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0965 - acc: 0.8846 - val_loss: 0.0917 - val_acc: 0.8972\n",
            "Epoch 4881/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0952 - acc: 0.8911 - val_loss: 0.0919 - val_acc: 0.8969\n",
            "Epoch 4882/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0951 - acc: 0.8908 - val_loss: 0.0917 - val_acc: 0.8969\n",
            "Epoch 4883/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0975 - acc: 0.8874 - val_loss: 0.0912 - val_acc: 0.8971\n",
            "Epoch 4884/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8878 - val_loss: 0.0909 - val_acc: 0.8975\n",
            "Epoch 4885/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0915 - acc: 0.8928 - val_loss: 0.0910 - val_acc: 0.8978\n",
            "Epoch 4886/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0913 - acc: 0.8931 - val_loss: 0.0910 - val_acc: 0.8980\n",
            "Epoch 4887/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.8901 - val_loss: 0.0905 - val_acc: 0.8979\n",
            "Epoch 4888/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0921 - acc: 0.8902 - val_loss: 0.0902 - val_acc: 0.8975\n",
            "Epoch 4889/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0960 - acc: 0.8858 - val_loss: 0.0903 - val_acc: 0.8970\n",
            "Epoch 4890/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2536 - acc: 0.8475 - val_loss: 0.0913 - val_acc: 0.8963\n",
            "Epoch 4891/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8891 - val_loss: 0.0919 - val_acc: 0.8961\n",
            "Epoch 4892/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2481 - acc: 0.8558 - val_loss: 0.0928 - val_acc: 0.8961\n",
            "Epoch 4893/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0928 - acc: 0.8938 - val_loss: 0.0928 - val_acc: 0.8967\n",
            "Epoch 4894/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8719 - val_loss: 0.0923 - val_acc: 0.8977\n",
            "Epoch 4895/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8842 - val_loss: 0.0924 - val_acc: 0.8983\n",
            "Epoch 4896/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0933 - acc: 0.8933 - val_loss: 0.0929 - val_acc: 0.8985\n",
            "Epoch 4897/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1153 - acc: 0.8893 - val_loss: 0.0930 - val_acc: 0.8985\n",
            "Epoch 4898/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8906 - val_loss: 0.0928 - val_acc: 0.8984\n",
            "Epoch 4899/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2268 - acc: 0.8720 - val_loss: 0.0938 - val_acc: 0.8979\n",
            "Epoch 4900/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2095 - acc: 0.8618 - val_loss: 0.0970 - val_acc: 0.8972\n",
            "Epoch 4901/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1086 - acc: 0.8807 - val_loss: 0.0994 - val_acc: 0.8970\n",
            "Epoch 4902/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1043 - acc: 0.8886 - val_loss: 0.0998 - val_acc: 0.8975\n",
            "Epoch 4903/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0978 - acc: 0.8976 - val_loss: 0.0986 - val_acc: 0.8982\n",
            "Epoch 4904/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1021 - acc: 0.8938 - val_loss: 0.0976 - val_acc: 0.8987\n",
            "Epoch 4905/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1085 - acc: 0.8888 - val_loss: 0.0978 - val_acc: 0.8989\n",
            "Epoch 4906/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8877 - val_loss: 0.0985 - val_acc: 0.8990\n",
            "Epoch 4907/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0930 - acc: 0.9026 - val_loss: 0.0988 - val_acc: 0.8990\n",
            "Epoch 4908/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1101 - acc: 0.8911 - val_loss: 0.0978 - val_acc: 0.8989\n",
            "Epoch 4909/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8889 - val_loss: 0.0963 - val_acc: 0.8988\n",
            "Epoch 4910/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8888 - val_loss: 0.0956 - val_acc: 0.8985\n",
            "Epoch 4911/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1010 - acc: 0.8871 - val_loss: 0.0958 - val_acc: 0.8980\n",
            "Epoch 4912/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1111 - acc: 0.8894 - val_loss: 0.0961 - val_acc: 0.8975\n",
            "Epoch 4913/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8847 - val_loss: 0.0956 - val_acc: 0.8975\n",
            "Epoch 4914/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0999 - acc: 0.8886 - val_loss: 0.0945 - val_acc: 0.8976\n",
            "Epoch 4915/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8891 - val_loss: 0.0933 - val_acc: 0.8980\n",
            "Epoch 4916/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - acc: 0.8902 - val_loss: 0.0927 - val_acc: 0.8983\n",
            "Epoch 4917/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1066 - acc: 0.8965 - val_loss: 0.0927 - val_acc: 0.8984\n",
            "Epoch 4918/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0946 - acc: 0.8942 - val_loss: 0.0925 - val_acc: 0.8985\n",
            "Epoch 4919/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1025 - acc: 0.8889 - val_loss: 0.0919 - val_acc: 0.8984\n",
            "Epoch 4920/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8889 - val_loss: 0.0912 - val_acc: 0.8982\n",
            "Epoch 4921/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8859 - val_loss: 0.0910 - val_acc: 0.8978\n",
            "Epoch 4922/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1001 - acc: 0.8831 - val_loss: 0.0911 - val_acc: 0.8974\n",
            "Epoch 4923/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1002 - acc: 0.8833 - val_loss: 0.0911 - val_acc: 0.8972\n",
            "Epoch 4924/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2439 - acc: 0.8663 - val_loss: 0.0925 - val_acc: 0.8964\n",
            "Epoch 4925/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8765 - val_loss: 0.0929 - val_acc: 0.8964\n",
            "Epoch 4926/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0893 - acc: 0.8943 - val_loss: 0.0924 - val_acc: 0.8970\n",
            "Epoch 4927/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2778 - acc: 0.8558 - val_loss: 0.0939 - val_acc: 0.8968\n",
            "Epoch 4928/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0982 - acc: 0.8869 - val_loss: 0.0946 - val_acc: 0.8971\n",
            "Epoch 4929/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8878 - val_loss: 0.0943 - val_acc: 0.8977\n",
            "Epoch 4930/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8835 - val_loss: 0.0937 - val_acc: 0.8982\n",
            "Epoch 4931/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0984 - acc: 0.8898 - val_loss: 0.0936 - val_acc: 0.8985\n",
            "Epoch 4932/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0980 - acc: 0.8899 - val_loss: 0.0937 - val_acc: 0.8986\n",
            "Epoch 4933/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8917 - val_loss: 0.0936 - val_acc: 0.8985\n",
            "Epoch 4934/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1348 - acc: 0.8795 - val_loss: 0.0934 - val_acc: 0.8982\n",
            "Epoch 4935/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1005 - acc: 0.8857 - val_loss: 0.0933 - val_acc: 0.8979\n",
            "Epoch 4936/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1054 - acc: 0.8803 - val_loss: 0.0935 - val_acc: 0.8975\n",
            "Epoch 4937/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8925 - val_loss: 0.0936 - val_acc: 0.8973\n",
            "Epoch 4938/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1089 - acc: 0.8742 - val_loss: 0.0935 - val_acc: 0.8973\n",
            "Epoch 4939/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1037 - acc: 0.8849 - val_loss: 0.0930 - val_acc: 0.8975\n",
            "Epoch 4940/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1030 - acc: 0.8852 - val_loss: 0.0924 - val_acc: 0.8979\n",
            "Epoch 4941/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1055 - acc: 0.8789 - val_loss: 0.0920 - val_acc: 0.8982\n",
            "Epoch 4942/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8950 - val_loss: 0.0917 - val_acc: 0.8984\n",
            "Epoch 4943/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2775 - acc: 0.8626 - val_loss: 0.0922 - val_acc: 0.8983\n",
            "Epoch 4944/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0997 - acc: 0.8878 - val_loss: 0.0931 - val_acc: 0.8979\n",
            "Epoch 4945/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0957 - acc: 0.8915 - val_loss: 0.0939 - val_acc: 0.8977\n",
            "Epoch 4946/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1029 - acc: 0.8863 - val_loss: 0.0939 - val_acc: 0.8978\n",
            "Epoch 4947/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1026 - acc: 0.8864 - val_loss: 0.0934 - val_acc: 0.8981\n",
            "Epoch 4948/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1062 - acc: 0.8792 - val_loss: 0.0929 - val_acc: 0.8983\n",
            "Epoch 4949/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1023 - acc: 0.8839 - val_loss: 0.0927 - val_acc: 0.8983\n",
            "Epoch 4950/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8841 - val_loss: 0.0927 - val_acc: 0.8983\n",
            "Epoch 4951/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1016 - acc: 0.8867 - val_loss: 0.0925 - val_acc: 0.8981\n",
            "Epoch 4952/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0937 - acc: 0.8962 - val_loss: 0.0922 - val_acc: 0.8979\n",
            "Epoch 4953/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0932 - acc: 0.8961 - val_loss: 0.0919 - val_acc: 0.8977\n",
            "Epoch 4954/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0990 - acc: 0.8872 - val_loss: 0.0916 - val_acc: 0.8976\n",
            "Epoch 4955/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0912 - acc: 0.8948 - val_loss: 0.0912 - val_acc: 0.8976\n",
            "Epoch 4956/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0905 - acc: 0.8949 - val_loss: 0.0908 - val_acc: 0.8977\n",
            "Epoch 4957/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0884 - acc: 0.8959 - val_loss: 0.0906 - val_acc: 0.8977\n",
            "Epoch 4958/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8903 - val_loss: 0.0905 - val_acc: 0.8977\n",
            "Epoch 4959/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1053 - acc: 0.8784 - val_loss: 0.0904 - val_acc: 0.8978\n",
            "Epoch 4960/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0964 - acc: 0.8887 - val_loss: 0.0902 - val_acc: 0.8978\n",
            "Epoch 4961/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8873 - val_loss: 0.0900 - val_acc: 0.8977\n",
            "Epoch 4962/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8869 - val_loss: 0.0899 - val_acc: 0.8975\n",
            "Epoch 4963/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0958 - acc: 0.8867 - val_loss: 0.0898 - val_acc: 0.8974\n",
            "Epoch 4964/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0866 - acc: 0.8991 - val_loss: 0.0897 - val_acc: 0.8973\n",
            "Epoch 4965/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0862 - acc: 0.8991 - val_loss: 0.0895 - val_acc: 0.8974\n",
            "Epoch 4966/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0919 - acc: 0.8877 - val_loss: 0.0895 - val_acc: 0.8975\n",
            "Epoch 4967/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0926 - acc: 0.8894 - val_loss: 0.0895 - val_acc: 0.8975\n",
            "Epoch 4968/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0976 - acc: 0.8840 - val_loss: 0.0895 - val_acc: 0.8974\n",
            "Epoch 4969/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0972 - acc: 0.8840 - val_loss: 0.0894 - val_acc: 0.8973\n",
            "Epoch 4970/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2924 - acc: 0.8572 - val_loss: 0.0906 - val_acc: 0.8959\n",
            "Epoch 4971/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0994 - acc: 0.8803 - val_loss: 0.0926 - val_acc: 0.8951\n",
            "Epoch 4972/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0954 - acc: 0.8879 - val_loss: 0.0924 - val_acc: 0.8956\n",
            "Epoch 4973/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1047 - acc: 0.8784 - val_loss: 0.0908 - val_acc: 0.8970\n",
            "Epoch 4974/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1014 - acc: 0.8826 - val_loss: 0.0904 - val_acc: 0.8980\n",
            "Epoch 4975/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0948 - acc: 0.8921 - val_loss: 0.0912 - val_acc: 0.8985\n",
            "Epoch 4976/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0939 - acc: 0.8911 - val_loss: 0.0913 - val_acc: 0.8985\n",
            "Epoch 4977/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0938 - acc: 0.8911 - val_loss: 0.0906 - val_acc: 0.8982\n",
            "Epoch 4978/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0916 - acc: 0.8975 - val_loss: 0.0903 - val_acc: 0.8977\n",
            "Epoch 4979/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0909 - acc: 0.8968 - val_loss: 0.0907 - val_acc: 0.8970\n",
            "Epoch 4980/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0968 - acc: 0.8841 - val_loss: 0.0912 - val_acc: 0.8965\n",
            "Epoch 4981/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1048 - acc: 0.8761 - val_loss: 0.0910 - val_acc: 0.8965\n",
            "Epoch 4982/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1040 - acc: 0.8779 - val_loss: 0.0903 - val_acc: 0.8970\n",
            "Epoch 4983/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0979 - acc: 0.8857 - val_loss: 0.0900 - val_acc: 0.8976\n",
            "Epoch 4984/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0941 - acc: 0.8874 - val_loss: 0.0901 - val_acc: 0.8980\n",
            "Epoch 4985/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1058 - acc: 0.8751 - val_loss: 0.0901 - val_acc: 0.8981\n",
            "Epoch 4986/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0922 - acc: 0.8906 - val_loss: 0.0897 - val_acc: 0.8981\n",
            "Epoch 4987/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0914 - acc: 0.8907 - val_loss: 0.0895 - val_acc: 0.8978\n",
            "Epoch 4988/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0986 - acc: 0.8922 - val_loss: 0.0899 - val_acc: 0.8973\n",
            "Epoch 4989/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0962 - acc: 0.8825 - val_loss: 0.0901 - val_acc: 0.8970\n",
            "Epoch 4990/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0924 - acc: 0.8861 - val_loss: 0.0898 - val_acc: 0.8971\n",
            "Epoch 4991/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1051 - acc: 0.8840 - val_loss: 0.0894 - val_acc: 0.8973\n",
            "Epoch 4992/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0944 - acc: 0.8886 - val_loss: 0.0892 - val_acc: 0.8977\n",
            "Epoch 4993/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0923 - acc: 0.8871 - val_loss: 0.0896 - val_acc: 0.8978\n",
            "Epoch 4994/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.3291 - acc: 0.8495 - val_loss: 0.0904 - val_acc: 0.8971\n",
            "Epoch 4995/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0992 - acc: 0.8800 - val_loss: 0.0924 - val_acc: 0.8964\n",
            "Epoch 4996/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1019 - acc: 0.8849 - val_loss: 0.0933 - val_acc: 0.8964\n",
            "Epoch 4997/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1082 - acc: 0.8800 - val_loss: 0.0926 - val_acc: 0.8972\n",
            "Epoch 4998/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1187 - acc: 0.8805 - val_loss: 0.0919 - val_acc: 0.8979\n",
            "Epoch 4999/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0987 - acc: 0.8867 - val_loss: 0.0920 - val_acc: 0.8984\n",
            "Epoch 5000/5000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0963 - acc: 0.8878 - val_loss: 0.0925 - val_acc: 0.8985\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 32, 32, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "latent (Dense)               (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2 (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_8 (UpSampling2 (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "output (Conv2D)              (None, 64, 64, 1)         145       \n",
            "=================================================================\n",
            "Total params: 1,053,473\n",
            "Trainable params: 1,053,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAMHCAYAAACaGDu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABUkAAANHCAYAAAALxtxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAKBQCAQCAQCgcCGxv8DlmH8Z/W8DsYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1728x1728 with 19 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-8d85a6d07339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0munseen_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unseen_encoder.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munseen_autoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unseen_autoencoder.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unseen_encoder.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unseen_autoencoder.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "lIeooSyjXpBR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "unseen_encoder.save('unseen_encoder.h5')\n",
        "unseen_autoencoder.save('unseen_autoencoder.h5')\n",
        "files.download('unseen_encoder.h5')\n",
        "files.download('unseen_autoencoder.h5')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4vOKHVKs8t3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70365
        },
        "outputId": "fec7b93f-3e7a-4974-ca28-1eb57fe67890"
      },
      "cell_type": "code",
      "source": [
        "shuffled_encoder,shuffled_autoencoder = train_encoder(shuffled_dataset,epochs = 2000)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.6930 - acc: 0.4502 - val_loss: 0.6905 - val_acc: 0.7473\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6906 - acc: 0.7715 - val_loss: 0.6845 - val_acc: 0.8418\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6850 - acc: 0.8631 - val_loss: 0.6759 - val_acc: 0.8607\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6771 - acc: 0.8760 - val_loss: 0.6626 - val_acc: 0.8675\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6657 - acc: 0.8998 - val_loss: 0.6429 - val_acc: 0.8697\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6449 - acc: 0.8817 - val_loss: 0.6151 - val_acc: 0.8707\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6181 - acc: 0.8825 - val_loss: 0.5759 - val_acc: 0.8713\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5819 - acc: 0.8902 - val_loss: 0.5259 - val_acc: 0.8716\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.5357 - acc: 0.8965 - val_loss: 0.4656 - val_acc: 0.8717\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4755 - acc: 0.8900 - val_loss: 0.3996 - val_acc: 0.8717\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.4090 - acc: 0.8900 - val_loss: 0.3375 - val_acc: 0.8717\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3530 - acc: 0.8921 - val_loss: 0.2932 - val_acc: 0.8717\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2826 - acc: 0.8966 - val_loss: 0.2789 - val_acc: 0.8717\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2480 - acc: 0.8966 - val_loss: 0.2963 - val_acc: 0.8717\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3105 - acc: 0.8767 - val_loss: 0.3208 - val_acc: 0.8717\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2600 - acc: 0.8954 - val_loss: 0.3394 - val_acc: 0.8717\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2780 - acc: 0.8930 - val_loss: 0.3431 - val_acc: 0.8717\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2801 - acc: 0.8923 - val_loss: 0.3326 - val_acc: 0.8717\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2448 - acc: 0.8944 - val_loss: 0.3136 - val_acc: 0.8717\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2474 - acc: 0.8920 - val_loss: 0.2902 - val_acc: 0.8717\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2082 - acc: 0.8974 - val_loss: 0.2691 - val_acc: 0.8717\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2552 - acc: 0.8844 - val_loss: 0.2504 - val_acc: 0.8717\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2167 - acc: 0.8906 - val_loss: 0.2371 - val_acc: 0.8717\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2101 - acc: 0.8875 - val_loss: 0.2284 - val_acc: 0.8717\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1931 - acc: 0.8942 - val_loss: 0.2233 - val_acc: 0.8717\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1827 - acc: 0.8993 - val_loss: 0.2205 - val_acc: 0.8717\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2070 - acc: 0.8867 - val_loss: 0.2189 - val_acc: 0.8717\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2188 - acc: 0.8881 - val_loss: 0.2177 - val_acc: 0.8717\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1991 - acc: 0.8949 - val_loss: 0.2165 - val_acc: 0.8717\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1937 - acc: 0.9013 - val_loss: 0.2151 - val_acc: 0.8717\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1994 - acc: 0.8974 - val_loss: 0.2137 - val_acc: 0.8717\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2033 - acc: 0.8880 - val_loss: 0.2124 - val_acc: 0.8717\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2078 - acc: 0.8917 - val_loss: 0.2116 - val_acc: 0.8717\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1865 - acc: 0.8922 - val_loss: 0.2116 - val_acc: 0.8717\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1842 - acc: 0.8922 - val_loss: 0.2124 - val_acc: 0.8717\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1891 - acc: 0.8884 - val_loss: 0.2138 - val_acc: 0.8717\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1991 - acc: 0.8883 - val_loss: 0.2151 - val_acc: 0.8717\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1991 - acc: 0.8883 - val_loss: 0.2159 - val_acc: 0.8717\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1764 - acc: 0.8940 - val_loss: 0.2162 - val_acc: 0.8717\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1752 - acc: 0.8972 - val_loss: 0.2163 - val_acc: 0.8717\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1944 - acc: 0.8870 - val_loss: 0.2153 - val_acc: 0.8717\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1894 - acc: 0.8939 - val_loss: 0.2138 - val_acc: 0.8717\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1975 - acc: 0.8838 - val_loss: 0.2116 - val_acc: 0.8717\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2068 - acc: 0.8857 - val_loss: 0.2089 - val_acc: 0.8717\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1769 - acc: 0.8928 - val_loss: 0.2067 - val_acc: 0.8717\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1749 - acc: 0.8998 - val_loss: 0.2051 - val_acc: 0.8717\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1760 - acc: 0.8944 - val_loss: 0.2039 - val_acc: 0.8717\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2034 - acc: 0.8801 - val_loss: 0.2024 - val_acc: 0.8717\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1762 - acc: 0.8941 - val_loss: 0.2013 - val_acc: 0.8717\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1680 - acc: 0.8963 - val_loss: 0.2006 - val_acc: 0.8717\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1923 - acc: 0.8806 - val_loss: 0.1998 - val_acc: 0.8717\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1849 - acc: 0.8854 - val_loss: 0.1991 - val_acc: 0.8717\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1820 - acc: 0.8896 - val_loss: 0.1985 - val_acc: 0.8717\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1795 - acc: 0.8949 - val_loss: 0.1981 - val_acc: 0.8717\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1798 - acc: 0.8911 - val_loss: 0.1979 - val_acc: 0.8717\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1768 - acc: 0.8923 - val_loss: 0.1977 - val_acc: 0.8717\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1814 - acc: 0.8912 - val_loss: 0.1976 - val_acc: 0.8717\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1609 - acc: 0.8982 - val_loss: 0.1979 - val_acc: 0.8717\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1931 - acc: 0.8883 - val_loss: 0.1981 - val_acc: 0.8717\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1923 - acc: 0.8883 - val_loss: 0.1982 - val_acc: 0.8717\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1770 - acc: 0.8883 - val_loss: 0.1981 - val_acc: 0.8717\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1740 - acc: 0.8894 - val_loss: 0.1978 - val_acc: 0.8717\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1664 - acc: 0.8948 - val_loss: 0.1977 - val_acc: 0.8717\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1805 - acc: 0.8927 - val_loss: 0.1974 - val_acc: 0.8717\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1682 - acc: 0.8945 - val_loss: 0.1971 - val_acc: 0.8717\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1639 - acc: 0.8963 - val_loss: 0.1968 - val_acc: 0.8717\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1738 - acc: 0.9001 - val_loss: 0.1966 - val_acc: 0.8717\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1902 - acc: 0.8952 - val_loss: 0.1960 - val_acc: 0.8717\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1894 - acc: 0.8952 - val_loss: 0.1953 - val_acc: 0.8717\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1620 - acc: 0.8967 - val_loss: 0.1947 - val_acc: 0.8717\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1616 - acc: 0.8944 - val_loss: 0.1941 - val_acc: 0.8717\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1789 - acc: 0.8895 - val_loss: 0.1932 - val_acc: 0.8717\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1726 - acc: 0.8905 - val_loss: 0.1923 - val_acc: 0.8717\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1913 - acc: 0.8850 - val_loss: 0.1913 - val_acc: 0.8717\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1718 - acc: 0.8922 - val_loss: 0.1906 - val_acc: 0.8717\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1532 - acc: 0.8972 - val_loss: 0.1903 - val_acc: 0.8717\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1637 - acc: 0.8955 - val_loss: 0.1901 - val_acc: 0.8717\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1574 - acc: 0.8995 - val_loss: 0.1902 - val_acc: 0.8717\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2026 - acc: 0.8804 - val_loss: 0.1900 - val_acc: 0.8717\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1724 - acc: 0.8903 - val_loss: 0.1898 - val_acc: 0.8717\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1744 - acc: 0.8900 - val_loss: 0.1897 - val_acc: 0.8717\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1625 - acc: 0.8951 - val_loss: 0.1897 - val_acc: 0.8717\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1543 - acc: 0.8972 - val_loss: 0.1899 - val_acc: 0.8717\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1675 - acc: 0.8933 - val_loss: 0.1902 - val_acc: 0.8717\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1663 - acc: 0.8922 - val_loss: 0.1905 - val_acc: 0.8717\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1494 - acc: 0.9035 - val_loss: 0.1911 - val_acc: 0.8717\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1711 - acc: 0.8904 - val_loss: 0.1912 - val_acc: 0.8717\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1706 - acc: 0.8904 - val_loss: 0.1908 - val_acc: 0.8717\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1721 - acc: 0.8880 - val_loss: 0.1900 - val_acc: 0.8717\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1716 - acc: 0.8880 - val_loss: 0.1890 - val_acc: 0.8717\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1637 - acc: 0.8914 - val_loss: 0.1881 - val_acc: 0.8717\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1558 - acc: 0.8983 - val_loss: 0.1877 - val_acc: 0.8717\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1772 - acc: 0.8857 - val_loss: 0.1870 - val_acc: 0.8717\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1763 - acc: 0.8857 - val_loss: 0.1863 - val_acc: 0.8717\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1607 - acc: 0.8925 - val_loss: 0.1859 - val_acc: 0.8717\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1675 - acc: 0.8881 - val_loss: 0.1856 - val_acc: 0.8717\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1661 - acc: 0.8886 - val_loss: 0.1854 - val_acc: 0.8717\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1691 - acc: 0.8864 - val_loss: 0.1851 - val_acc: 0.8717\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1686 - acc: 0.8864 - val_loss: 0.1849 - val_acc: 0.8717\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1657 - acc: 0.8885 - val_loss: 0.1848 - val_acc: 0.8717\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1650 - acc: 0.8885 - val_loss: 0.1849 - val_acc: 0.8717\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1791 - acc: 0.8859 - val_loss: 0.1848 - val_acc: 0.8717\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1568 - acc: 0.8915 - val_loss: 0.1847 - val_acc: 0.8717\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1585 - acc: 0.8932 - val_loss: 0.1845 - val_acc: 0.8717\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1582 - acc: 0.8951 - val_loss: 0.1845 - val_acc: 0.8717\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1487 - acc: 0.8972 - val_loss: 0.1847 - val_acc: 0.8717\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1525 - acc: 0.8990 - val_loss: 0.1851 - val_acc: 0.8717\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1555 - acc: 0.8970 - val_loss: 0.1854 - val_acc: 0.8717\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1581 - acc: 0.8894 - val_loss: 0.1853 - val_acc: 0.8717\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1498 - acc: 0.8949 - val_loss: 0.1849 - val_acc: 0.8717\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1523 - acc: 0.8948 - val_loss: 0.1841 - val_acc: 0.8717\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1519 - acc: 0.8948 - val_loss: 0.1832 - val_acc: 0.8717\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1560 - acc: 0.8930 - val_loss: 0.1823 - val_acc: 0.8717\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1608 - acc: 0.8873 - val_loss: 0.1814 - val_acc: 0.8717\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1540 - acc: 0.8933 - val_loss: 0.1808 - val_acc: 0.8717\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1544 - acc: 0.8944 - val_loss: 0.1806 - val_acc: 0.8717\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1639 - acc: 0.8830 - val_loss: 0.1804 - val_acc: 0.8717\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1665 - acc: 0.8848 - val_loss: 0.1802 - val_acc: 0.8717\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1588 - acc: 0.8912 - val_loss: 0.1800 - val_acc: 0.8717\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1604 - acc: 0.8909 - val_loss: 0.1799 - val_acc: 0.8717\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1503 - acc: 0.8968 - val_loss: 0.1799 - val_acc: 0.8717\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1594 - acc: 0.8866 - val_loss: 0.1800 - val_acc: 0.8717\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1528 - acc: 0.8940 - val_loss: 0.1803 - val_acc: 0.8717\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1531 - acc: 0.8906 - val_loss: 0.1803 - val_acc: 0.8717\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1528 - acc: 0.8906 - val_loss: 0.1799 - val_acc: 0.8717\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1447 - acc: 0.8997 - val_loss: 0.1795 - val_acc: 0.8717\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1439 - acc: 0.8946 - val_loss: 0.1791 - val_acc: 0.8717\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1401 - acc: 0.9016 - val_loss: 0.1790 - val_acc: 0.8717\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1672 - acc: 0.8853 - val_loss: 0.1786 - val_acc: 0.8717\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1602 - acc: 0.8853 - val_loss: 0.1782 - val_acc: 0.8717\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1453 - acc: 0.8960 - val_loss: 0.1780 - val_acc: 0.8717\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1451 - acc: 0.8960 - val_loss: 0.1779 - val_acc: 0.8717\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1438 - acc: 0.8966 - val_loss: 0.1777 - val_acc: 0.8717\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1433 - acc: 0.8966 - val_loss: 0.1775 - val_acc: 0.8717\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1543 - acc: 0.8901 - val_loss: 0.1774 - val_acc: 0.8717\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1632 - acc: 0.8820 - val_loss: 0.1773 - val_acc: 0.8717\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1550 - acc: 0.8900 - val_loss: 0.1768 - val_acc: 0.8717\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1635 - acc: 0.8855 - val_loss: 0.1765 - val_acc: 0.8717\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1422 - acc: 0.8983 - val_loss: 0.1765 - val_acc: 0.8717\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1436 - acc: 0.8987 - val_loss: 0.1765 - val_acc: 0.8717\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1539 - acc: 0.8891 - val_loss: 0.1766 - val_acc: 0.8717\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1535 - acc: 0.8891 - val_loss: 0.1768 - val_acc: 0.8717\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1468 - acc: 0.8929 - val_loss: 0.1768 - val_acc: 0.8717\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1449 - acc: 0.8946 - val_loss: 0.1767 - val_acc: 0.8717\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1445 - acc: 0.8933 - val_loss: 0.1763 - val_acc: 0.8717\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1442 - acc: 0.8933 - val_loss: 0.1759 - val_acc: 0.8717\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1390 - acc: 0.8954 - val_loss: 0.1755 - val_acc: 0.8717\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1403 - acc: 0.8946 - val_loss: 0.1751 - val_acc: 0.8717\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1484 - acc: 0.8880 - val_loss: 0.1748 - val_acc: 0.8717\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1439 - acc: 0.8933 - val_loss: 0.1746 - val_acc: 0.8717\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1507 - acc: 0.8898 - val_loss: 0.1745 - val_acc: 0.8717\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1415 - acc: 0.8942 - val_loss: 0.1743 - val_acc: 0.8717\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1896 - acc: 0.8846 - val_loss: 0.1741 - val_acc: 0.8717\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1550 - acc: 0.8845 - val_loss: 0.1744 - val_acc: 0.8717\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1431 - acc: 0.8955 - val_loss: 0.1743 - val_acc: 0.8717\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1495 - acc: 0.8897 - val_loss: 0.1737 - val_acc: 0.8717\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1538 - acc: 0.8944 - val_loss: 0.1737 - val_acc: 0.8717\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1480 - acc: 0.8902 - val_loss: 0.1741 - val_acc: 0.8717\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1479 - acc: 0.8902 - val_loss: 0.1744 - val_acc: 0.8717\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1415 - acc: 0.8942 - val_loss: 0.1741 - val_acc: 0.8717\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1528 - acc: 0.8876 - val_loss: 0.1736 - val_acc: 0.8717\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1524 - acc: 0.8885 - val_loss: 0.1733 - val_acc: 0.8717\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1565 - acc: 0.8907 - val_loss: 0.1731 - val_acc: 0.8717\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1564 - acc: 0.8868 - val_loss: 0.1730 - val_acc: 0.8717\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1507 - acc: 0.8913 - val_loss: 0.1729 - val_acc: 0.8717\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1392 - acc: 0.8961 - val_loss: 0.1730 - val_acc: 0.8717\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1500 - acc: 0.8922 - val_loss: 0.1731 - val_acc: 0.8717\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1497 - acc: 0.8922 - val_loss: 0.1730 - val_acc: 0.8717\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1785 - acc: 0.8776 - val_loss: 0.1728 - val_acc: 0.8717\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1349 - acc: 0.8982 - val_loss: 0.1726 - val_acc: 0.8717\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1441 - acc: 0.8935 - val_loss: 0.1724 - val_acc: 0.8717\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1436 - acc: 0.8935 - val_loss: 0.1722 - val_acc: 0.8717\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1561 - acc: 0.8837 - val_loss: 0.1722 - val_acc: 0.8717\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1433 - acc: 0.8910 - val_loss: 0.1719 - val_acc: 0.8717\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1476 - acc: 0.8908 - val_loss: 0.1714 - val_acc: 0.8717\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1455 - acc: 0.8916 - val_loss: 0.1712 - val_acc: 0.8717\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1403 - acc: 0.8955 - val_loss: 0.1711 - val_acc: 0.8717\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1421 - acc: 0.8924 - val_loss: 0.1709 - val_acc: 0.8717\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1565 - acc: 0.8814 - val_loss: 0.1705 - val_acc: 0.8717\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1502 - acc: 0.8901 - val_loss: 0.1705 - val_acc: 0.8717\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1495 - acc: 0.8901 - val_loss: 0.1711 - val_acc: 0.8717\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1401 - acc: 0.8942 - val_loss: 0.1717 - val_acc: 0.8717\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1370 - acc: 0.8959 - val_loss: 0.1707 - val_acc: 0.8717\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2311 - acc: 0.8783 - val_loss: 0.1701 - val_acc: 0.8717\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1627 - acc: 0.8783 - val_loss: 0.1727 - val_acc: 0.8717\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1432 - acc: 0.8928 - val_loss: 0.1740 - val_acc: 0.8717\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1527 - acc: 0.8914 - val_loss: 0.1725 - val_acc: 0.8717\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1768 - acc: 0.8874 - val_loss: 0.1707 - val_acc: 0.8717\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1587 - acc: 0.8858 - val_loss: 0.1704 - val_acc: 0.8717\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1422 - acc: 0.8912 - val_loss: 0.1715 - val_acc: 0.8717\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1476 - acc: 0.8932 - val_loss: 0.1726 - val_acc: 0.8717\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1530 - acc: 0.8883 - val_loss: 0.1717 - val_acc: 0.8717\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1494 - acc: 0.8874 - val_loss: 0.1706 - val_acc: 0.8717\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1437 - acc: 0.8938 - val_loss: 0.1700 - val_acc: 0.8717\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1893 - acc: 0.8826 - val_loss: 0.1707 - val_acc: 0.8717\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1582 - acc: 0.8808 - val_loss: 0.1721 - val_acc: 0.8717\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1483 - acc: 0.8900 - val_loss: 0.1722 - val_acc: 0.8717\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1485 - acc: 0.8900 - val_loss: 0.1708 - val_acc: 0.8717\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1345 - acc: 0.8982 - val_loss: 0.1691 - val_acc: 0.8717\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1369 - acc: 0.8968 - val_loss: 0.1693 - val_acc: 0.8717\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2355 - acc: 0.8919 - val_loss: 0.1698 - val_acc: 0.8717\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1579 - acc: 0.8919 - val_loss: 0.1699 - val_acc: 0.8717\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1415 - acc: 0.8940 - val_loss: 0.1698 - val_acc: 0.8717\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1501 - acc: 0.8876 - val_loss: 0.1696 - val_acc: 0.8717\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1430 - acc: 0.8927 - val_loss: 0.1694 - val_acc: 0.8717\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1429 - acc: 0.8927 - val_loss: 0.1694 - val_acc: 0.8717\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1425 - acc: 0.8936 - val_loss: 0.1693 - val_acc: 0.8717\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1381 - acc: 0.8961 - val_loss: 0.1692 - val_acc: 0.8717\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1419 - acc: 0.8909 - val_loss: 0.1690 - val_acc: 0.8717\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1384 - acc: 0.8948 - val_loss: 0.1689 - val_acc: 0.8717\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1935 - acc: 0.8938 - val_loss: 0.1684 - val_acc: 0.8717\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1566 - acc: 0.8817 - val_loss: 0.1685 - val_acc: 0.8717\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1570 - acc: 0.8817 - val_loss: 0.1685 - val_acc: 0.8717\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1405 - acc: 0.8942 - val_loss: 0.1684 - val_acc: 0.8717\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1523 - acc: 0.8898 - val_loss: 0.1682 - val_acc: 0.8717\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1770 - acc: 0.8993 - val_loss: 0.1683 - val_acc: 0.8717\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1977 - acc: 0.8885 - val_loss: 0.1689 - val_acc: 0.8717\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1472 - acc: 0.8885 - val_loss: 0.1695 - val_acc: 0.8717\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1326 - acc: 0.9006 - val_loss: 0.1694 - val_acc: 0.8717\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1400 - acc: 0.8955 - val_loss: 0.1690 - val_acc: 0.8717\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1481 - acc: 0.8903 - val_loss: 0.1690 - val_acc: 0.8717\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1454 - acc: 0.8888 - val_loss: 0.1698 - val_acc: 0.8717\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1454 - acc: 0.8896 - val_loss: 0.1705 - val_acc: 0.8717\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1588 - acc: 0.8848 - val_loss: 0.1698 - val_acc: 0.8717\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1500 - acc: 0.8862 - val_loss: 0.1685 - val_acc: 0.8717\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1286 - acc: 0.9025 - val_loss: 0.1679 - val_acc: 0.8717\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8969 - val_loss: 0.1678 - val_acc: 0.8717\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1357 - acc: 0.8995 - val_loss: 0.1677 - val_acc: 0.8717\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1418 - acc: 0.8962 - val_loss: 0.1676 - val_acc: 0.8717\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1252 - acc: 0.9037 - val_loss: 0.1677 - val_acc: 0.8717\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1392 - acc: 0.8910 - val_loss: 0.1680 - val_acc: 0.8717\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1297 - acc: 0.8981 - val_loss: 0.1679 - val_acc: 0.8717\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1553 - acc: 0.8888 - val_loss: 0.1673 - val_acc: 0.8717\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1452 - acc: 0.8902 - val_loss: 0.1668 - val_acc: 0.8717\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1539 - acc: 0.8823 - val_loss: 0.1666 - val_acc: 0.8717\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1357 - acc: 0.8954 - val_loss: 0.1664 - val_acc: 0.8717\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1354 - acc: 0.8954 - val_loss: 0.1661 - val_acc: 0.8717\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1506 - acc: 0.8848 - val_loss: 0.1659 - val_acc: 0.8717\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1539 - acc: 0.8838 - val_loss: 0.1658 - val_acc: 0.8717\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1494 - acc: 0.8846 - val_loss: 0.1657 - val_acc: 0.8717\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1449 - acc: 0.8878 - val_loss: 0.1653 - val_acc: 0.8717\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1369 - acc: 0.8921 - val_loss: 0.1650 - val_acc: 0.8717\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1537 - acc: 0.8800 - val_loss: 0.1648 - val_acc: 0.8717\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1453 - acc: 0.8871 - val_loss: 0.1647 - val_acc: 0.8717\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1451 - acc: 0.8871 - val_loss: 0.1646 - val_acc: 0.8717\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8969 - val_loss: 0.1646 - val_acc: 0.8717\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1305 - acc: 0.8969 - val_loss: 0.1646 - val_acc: 0.8717\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1373 - acc: 0.8952 - val_loss: 0.1645 - val_acc: 0.8717\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1369 - acc: 0.8952 - val_loss: 0.1644 - val_acc: 0.8717\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8966 - val_loss: 0.1642 - val_acc: 0.8717\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1374 - acc: 0.8921 - val_loss: 0.1641 - val_acc: 0.8717\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1476 - acc: 0.8867 - val_loss: 0.1637 - val_acc: 0.8717\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1890 - acc: 0.8849 - val_loss: 0.1641 - val_acc: 0.8716\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1481 - acc: 0.8925 - val_loss: 0.1653 - val_acc: 0.8716\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1363 - acc: 0.8912 - val_loss: 0.1651 - val_acc: 0.8716\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1381 - acc: 0.8913 - val_loss: 0.1639 - val_acc: 0.8717\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1368 - acc: 0.8946 - val_loss: 0.1637 - val_acc: 0.8717\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1360 - acc: 0.8946 - val_loss: 0.1649 - val_acc: 0.8717\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1474 - acc: 0.8875 - val_loss: 0.1642 - val_acc: 0.8717\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1302 - acc: 0.8973 - val_loss: 0.1632 - val_acc: 0.8717\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1423 - acc: 0.8999 - val_loss: 0.1632 - val_acc: 0.8717\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1291 - acc: 0.8980 - val_loss: 0.1635 - val_acc: 0.8717\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1506 - acc: 0.8848 - val_loss: 0.1635 - val_acc: 0.8717\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1389 - acc: 0.8903 - val_loss: 0.1628 - val_acc: 0.8717\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1395 - acc: 0.8961 - val_loss: 0.1625 - val_acc: 0.8717\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1384 - acc: 0.8961 - val_loss: 0.1632 - val_acc: 0.8717\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8976 - val_loss: 0.1639 - val_acc: 0.8717\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1459 - acc: 0.8862 - val_loss: 0.1631 - val_acc: 0.8717\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1442 - acc: 0.8903 - val_loss: 0.1623 - val_acc: 0.8717\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1431 - acc: 0.8863 - val_loss: 0.1621 - val_acc: 0.8717\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1498 - acc: 0.8834 - val_loss: 0.1623 - val_acc: 0.8717\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1498 - acc: 0.8834 - val_loss: 0.1622 - val_acc: 0.8717\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1370 - acc: 0.8939 - val_loss: 0.1619 - val_acc: 0.8717\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1364 - acc: 0.8939 - val_loss: 0.1617 - val_acc: 0.8717\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1429 - acc: 0.8895 - val_loss: 0.1618 - val_acc: 0.8717\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1306 - acc: 0.8970 - val_loss: 0.1618 - val_acc: 0.8717\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1718 - acc: 0.8969 - val_loss: 0.1619 - val_acc: 0.8717\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1550 - acc: 0.8813 - val_loss: 0.1630 - val_acc: 0.8716\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1611 - acc: 0.8834 - val_loss: 0.1632 - val_acc: 0.8716\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1428 - acc: 0.8936 - val_loss: 0.1623 - val_acc: 0.8717\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1533 - acc: 0.8816 - val_loss: 0.1620 - val_acc: 0.8717\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1523 - acc: 0.8816 - val_loss: 0.1630 - val_acc: 0.8717\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1313 - acc: 0.8985 - val_loss: 0.1640 - val_acc: 0.8717\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2030 - acc: 0.8952 - val_loss: 0.1614 - val_acc: 0.8717\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1964 - acc: 0.8853 - val_loss: 0.1649 - val_acc: 0.8716\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1449 - acc: 0.8894 - val_loss: 0.1694 - val_acc: 0.8716\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1918 - acc: 0.8887 - val_loss: 0.1741 - val_acc: 0.8716\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1710 - acc: 0.8999 - val_loss: 0.1746 - val_acc: 0.8716\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1414 - acc: 0.8997 - val_loss: 0.1706 - val_acc: 0.8716\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1500 - acc: 0.8912 - val_loss: 0.1676 - val_acc: 0.8717\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1462 - acc: 0.8912 - val_loss: 0.1685 - val_acc: 0.8717\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1408 - acc: 0.8921 - val_loss: 0.1705 - val_acc: 0.8717\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1569 - acc: 0.8831 - val_loss: 0.1701 - val_acc: 0.8717\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1424 - acc: 0.8948 - val_loss: 0.1677 - val_acc: 0.8717\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1420 - acc: 0.8887 - val_loss: 0.1657 - val_acc: 0.8717\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1402 - acc: 0.8887 - val_loss: 0.1657 - val_acc: 0.8717\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1548 - acc: 0.8816 - val_loss: 0.1664 - val_acc: 0.8717\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2038 - acc: 0.8870 - val_loss: 0.1693 - val_acc: 0.8717\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1484 - acc: 0.8870 - val_loss: 0.1711 - val_acc: 0.8717\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1598 - acc: 0.8867 - val_loss: 0.1703 - val_acc: 0.8717\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1440 - acc: 0.8936 - val_loss: 0.1677 - val_acc: 0.8717\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1380 - acc: 0.8956 - val_loss: 0.1653 - val_acc: 0.8717\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1340 - acc: 0.8973 - val_loss: 0.1650 - val_acc: 0.8717\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8973 - val_loss: 0.1679 - val_acc: 0.8717\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1340 - acc: 0.8972 - val_loss: 0.1706 - val_acc: 0.8717\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1319 - acc: 0.8991 - val_loss: 0.1704 - val_acc: 0.8717\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1313 - acc: 0.8991 - val_loss: 0.1676 - val_acc: 0.8717\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1372 - acc: 0.8957 - val_loss: 0.1647 - val_acc: 0.8717\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1608 - acc: 0.8885 - val_loss: 0.1634 - val_acc: 0.8717\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1876 - acc: 0.8909 - val_loss: 0.1650 - val_acc: 0.8717\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1761 - acc: 0.8951 - val_loss: 0.1695 - val_acc: 0.8717\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1501 - acc: 0.8903 - val_loss: 0.1724 - val_acc: 0.8717\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1578 - acc: 0.8857 - val_loss: 0.1718 - val_acc: 0.8717\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1533 - acc: 0.8881 - val_loss: 0.1684 - val_acc: 0.8717\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1501 - acc: 0.8857 - val_loss: 0.1649 - val_acc: 0.8717\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1440 - acc: 0.8887 - val_loss: 0.1642 - val_acc: 0.8717\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1370 - acc: 0.8949 - val_loss: 0.1671 - val_acc: 0.8717\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1304 - acc: 0.8985 - val_loss: 0.1706 - val_acc: 0.8717\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2474 - acc: 0.8870 - val_loss: 0.1668 - val_acc: 0.8717\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1473 - acc: 0.8870 - val_loss: 0.1637 - val_acc: 0.8717\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1370 - acc: 0.8925 - val_loss: 0.1630 - val_acc: 0.8717\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1473 - acc: 0.8853 - val_loss: 0.1639 - val_acc: 0.8717\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1455 - acc: 0.8845 - val_loss: 0.1649 - val_acc: 0.8717\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1459 - acc: 0.8893 - val_loss: 0.1651 - val_acc: 0.8717\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1647 - acc: 0.8870 - val_loss: 0.1651 - val_acc: 0.8717\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1482 - acc: 0.8879 - val_loss: 0.1644 - val_acc: 0.8717\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1494 - acc: 0.8810 - val_loss: 0.1636 - val_acc: 0.8717\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1390 - acc: 0.8943 - val_loss: 0.1634 - val_acc: 0.8717\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1441 - acc: 0.8885 - val_loss: 0.1637 - val_acc: 0.8717\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1417 - acc: 0.8912 - val_loss: 0.1641 - val_acc: 0.8717\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1387 - acc: 0.8923 - val_loss: 0.1641 - val_acc: 0.8717\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1385 - acc: 0.8923 - val_loss: 0.1635 - val_acc: 0.8717\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1478 - acc: 0.8901 - val_loss: 0.1623 - val_acc: 0.8717\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1465 - acc: 0.8901 - val_loss: 0.1614 - val_acc: 0.8717\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1346 - acc: 0.8941 - val_loss: 0.1612 - val_acc: 0.8717\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1620 - acc: 0.8855 - val_loss: 0.1616 - val_acc: 0.8717\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1391 - acc: 0.8898 - val_loss: 0.1621 - val_acc: 0.8717\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1373 - acc: 0.8893 - val_loss: 0.1620 - val_acc: 0.8717\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1314 - acc: 0.8956 - val_loss: 0.1613 - val_acc: 0.8717\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8962 - val_loss: 0.1606 - val_acc: 0.8717\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1271 - acc: 0.8962 - val_loss: 0.1604 - val_acc: 0.8717\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2337 - acc: 0.8834 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1322 - acc: 0.8914 - val_loss: 0.1604 - val_acc: 0.8717\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1325 - acc: 0.8914 - val_loss: 0.1605 - val_acc: 0.8717\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1458 - acc: 0.8842 - val_loss: 0.1604 - val_acc: 0.8717\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1353 - acc: 0.8926 - val_loss: 0.1601 - val_acc: 0.8717\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1348 - acc: 0.8926 - val_loss: 0.1599 - val_acc: 0.8717\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1272 - acc: 0.8979 - val_loss: 0.1601 - val_acc: 0.8717\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1441 - acc: 0.8876 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1440 - acc: 0.8878 - val_loss: 0.1601 - val_acc: 0.8717\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1252 - acc: 0.8996 - val_loss: 0.1596 - val_acc: 0.8717\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1246 - acc: 0.8996 - val_loss: 0.1592 - val_acc: 0.8717\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1365 - acc: 0.8904 - val_loss: 0.1590 - val_acc: 0.8717\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1805 - acc: 0.8995 - val_loss: 0.1593 - val_acc: 0.8717\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1356 - acc: 0.9008 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1513 - acc: 0.8896 - val_loss: 0.1610 - val_acc: 0.8717\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1898 - acc: 0.8822 - val_loss: 0.1624 - val_acc: 0.8717\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1327 - acc: 0.8957 - val_loss: 0.1623 - val_acc: 0.8717\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1442 - acc: 0.8857 - val_loss: 0.1609 - val_acc: 0.8717\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1587 - acc: 0.8874 - val_loss: 0.1599 - val_acc: 0.8717\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1286 - acc: 0.8956 - val_loss: 0.1597 - val_acc: 0.8717\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1494 - acc: 0.8851 - val_loss: 0.1607 - val_acc: 0.8717\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1653 - acc: 0.8905 - val_loss: 0.1616 - val_acc: 0.8717\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1368 - acc: 0.8955 - val_loss: 0.1614 - val_acc: 0.8717\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8959 - val_loss: 0.1604 - val_acc: 0.8717\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1245 - acc: 0.8994 - val_loss: 0.1595 - val_acc: 0.8717\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1241 - acc: 0.8994 - val_loss: 0.1591 - val_acc: 0.8717\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8966 - val_loss: 0.1589 - val_acc: 0.8717\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1267 - acc: 0.8966 - val_loss: 0.1589 - val_acc: 0.8717\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1712 - acc: 0.9100 - val_loss: 0.1592 - val_acc: 0.8717\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1708 - acc: 0.8941 - val_loss: 0.1600 - val_acc: 0.8717\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1305 - acc: 0.8941 - val_loss: 0.1605 - val_acc: 0.8717\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1338 - acc: 0.8944 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1567 - acc: 0.8900 - val_loss: 0.1599 - val_acc: 0.8717\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1439 - acc: 0.8855 - val_loss: 0.1593 - val_acc: 0.8717\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1918 - acc: 0.8910 - val_loss: 0.1594 - val_acc: 0.8717\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2084 - acc: 0.8904 - val_loss: 0.1607 - val_acc: 0.8717\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1758 - acc: 0.8825 - val_loss: 0.1628 - val_acc: 0.8717\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1482 - acc: 0.8840 - val_loss: 0.1637 - val_acc: 0.8717\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1506 - acc: 0.8958 - val_loss: 0.1634 - val_acc: 0.8717\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1435 - acc: 0.8900 - val_loss: 0.1621 - val_acc: 0.8717\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8985 - val_loss: 0.1615 - val_acc: 0.8717\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1389 - acc: 0.8921 - val_loss: 0.1626 - val_acc: 0.8717\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1325 - acc: 0.8965 - val_loss: 0.1644 - val_acc: 0.8717\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1614 - acc: 0.8767 - val_loss: 0.1640 - val_acc: 0.8717\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1336 - acc: 0.8954 - val_loss: 0.1624 - val_acc: 0.8717\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1349 - acc: 0.8930 - val_loss: 0.1610 - val_acc: 0.8717\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1340 - acc: 0.8930 - val_loss: 0.1604 - val_acc: 0.8717\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8921 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8921 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1404 - acc: 0.8947 - val_loss: 0.1601 - val_acc: 0.8717\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2304 - acc: 0.8842 - val_loss: 0.1615 - val_acc: 0.8717\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1483 - acc: 0.8854 - val_loss: 0.1628 - val_acc: 0.8717\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1401 - acc: 0.8906 - val_loss: 0.1627 - val_acc: 0.8717\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1422 - acc: 0.8875 - val_loss: 0.1615 - val_acc: 0.8717\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1452 - acc: 0.8880 - val_loss: 0.1600 - val_acc: 0.8717\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1415 - acc: 0.8867 - val_loss: 0.1595 - val_acc: 0.8717\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1404 - acc: 0.8867 - val_loss: 0.1605 - val_acc: 0.8717\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1201 - acc: 0.9013 - val_loss: 0.1622 - val_acc: 0.8717\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8974 - val_loss: 0.1627 - val_acc: 0.8717\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1291 - acc: 0.8974 - val_loss: 0.1614 - val_acc: 0.8717\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1709 - acc: 0.8899 - val_loss: 0.1590 - val_acc: 0.8717\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1383 - acc: 0.8887 - val_loss: 0.1587 - val_acc: 0.8717\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1354 - acc: 0.8917 - val_loss: 0.1595 - val_acc: 0.8717\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1338 - acc: 0.8922 - val_loss: 0.1601 - val_acc: 0.8717\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1356 - acc: 0.8905 - val_loss: 0.1598 - val_acc: 0.8717\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1389 - acc: 0.8884 - val_loss: 0.1588 - val_acc: 0.8717\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1287 - acc: 0.8940 - val_loss: 0.1578 - val_acc: 0.8717\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1269 - acc: 0.8972 - val_loss: 0.1580 - val_acc: 0.8717\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1260 - acc: 0.8972 - val_loss: 0.1595 - val_acc: 0.8717\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1370 - acc: 0.8876 - val_loss: 0.1603 - val_acc: 0.8717\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1330 - acc: 0.8947 - val_loss: 0.1595 - val_acc: 0.8717\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2309 - acc: 0.8741 - val_loss: 0.1567 - val_acc: 0.8717\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1566 - acc: 0.8750 - val_loss: 0.1578 - val_acc: 0.8717\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1265 - acc: 0.8998 - val_loss: 0.1602 - val_acc: 0.8717\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1316 - acc: 0.8944 - val_loss: 0.1613 - val_acc: 0.8717\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1325 - acc: 0.8944 - val_loss: 0.1605 - val_acc: 0.8717\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1941 - acc: 0.8939 - val_loss: 0.1603 - val_acc: 0.8717\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1292 - acc: 0.8964 - val_loss: 0.1587 - val_acc: 0.8717\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1581 - acc: 0.8796 - val_loss: 0.1576 - val_acc: 0.8717\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1453 - acc: 0.8806 - val_loss: 0.1573 - val_acc: 0.8717\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1350 - acc: 0.8896 - val_loss: 0.1580 - val_acc: 0.8717\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1354 - acc: 0.8896 - val_loss: 0.1586 - val_acc: 0.8717\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1355 - acc: 0.8911 - val_loss: 0.1586 - val_acc: 0.8717\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1353 - acc: 0.8911 - val_loss: 0.1579 - val_acc: 0.8717\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1440 - acc: 0.8899 - val_loss: 0.1570 - val_acc: 0.8717\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1433 - acc: 0.8899 - val_loss: 0.1565 - val_acc: 0.8717\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1364 - acc: 0.8912 - val_loss: 0.1565 - val_acc: 0.8717\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8939 - val_loss: 0.1567 - val_acc: 0.8717\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1397 - acc: 0.8884 - val_loss: 0.1568 - val_acc: 0.8717\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1365 - acc: 0.8883 - val_loss: 0.1565 - val_acc: 0.8717\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1932 - acc: 0.8967 - val_loss: 0.1566 - val_acc: 0.8717\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1278 - acc: 0.8959 - val_loss: 0.1564 - val_acc: 0.8717\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1356 - acc: 0.8928 - val_loss: 0.1563 - val_acc: 0.8717\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1332 - acc: 0.8901 - val_loss: 0.1564 - val_acc: 0.8717\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1259 - acc: 0.8963 - val_loss: 0.1566 - val_acc: 0.8717\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1258 - acc: 0.8963 - val_loss: 0.1566 - val_acc: 0.8717\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1269 - acc: 0.9001 - val_loss: 0.1563 - val_acc: 0.8717\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1261 - acc: 0.8968 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1255 - acc: 0.8967 - val_loss: 0.1553 - val_acc: 0.8717\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1385 - acc: 0.8945 - val_loss: 0.1553 - val_acc: 0.8717\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1330 - acc: 0.8940 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1332 - acc: 0.8905 - val_loss: 0.1559 - val_acc: 0.8717\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1455 - acc: 0.8848 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1335 - acc: 0.8923 - val_loss: 0.1552 - val_acc: 0.8717\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1229 - acc: 0.8973 - val_loss: 0.1548 - val_acc: 0.8717\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1228 - acc: 0.8994 - val_loss: 0.1551 - val_acc: 0.8717\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1438 - acc: 0.8791 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1514 - acc: 0.8804 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1344 - acc: 0.8903 - val_loss: 0.1550 - val_acc: 0.8717\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1275 - acc: 0.8952 - val_loss: 0.1544 - val_acc: 0.8717\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1271 - acc: 0.8951 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1288 - acc: 0.8930 - val_loss: 0.1542 - val_acc: 0.8717\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1277 - acc: 0.8972 - val_loss: 0.1542 - val_acc: 0.8717\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1323 - acc: 0.8921 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1199 - acc: 0.9035 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1331 - acc: 0.8904 - val_loss: 0.1538 - val_acc: 0.8717\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1340 - acc: 0.8881 - val_loss: 0.1538 - val_acc: 0.8717\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1338 - acc: 0.8881 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2202 - acc: 0.8910 - val_loss: 0.1536 - val_acc: 0.8717\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1730 - acc: 0.8946 - val_loss: 0.1557 - val_acc: 0.8717\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1240 - acc: 0.8993 - val_loss: 0.1577 - val_acc: 0.8716\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1442 - acc: 0.8856 - val_loss: 0.1575 - val_acc: 0.8716\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1437 - acc: 0.8856 - val_loss: 0.1557 - val_acc: 0.8716\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1319 - acc: 0.8925 - val_loss: 0.1545 - val_acc: 0.8716\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1372 - acc: 0.8880 - val_loss: 0.1555 - val_acc: 0.8717\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1366 - acc: 0.8886 - val_loss: 0.1574 - val_acc: 0.8717\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2475 - acc: 0.8862 - val_loss: 0.1550 - val_acc: 0.8717\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1367 - acc: 0.8864 - val_loss: 0.1549 - val_acc: 0.8717\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1241 - acc: 0.8988 - val_loss: 0.1559 - val_acc: 0.8717\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1384 - acc: 0.8863 - val_loss: 0.1565 - val_acc: 0.8717\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8916 - val_loss: 0.1562 - val_acc: 0.8717\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1331 - acc: 0.8932 - val_loss: 0.1555 - val_acc: 0.8717\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1321 - acc: 0.8932 - val_loss: 0.1554 - val_acc: 0.8717\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8951 - val_loss: 0.1561 - val_acc: 0.8717\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1229 - acc: 0.8972 - val_loss: 0.1570 - val_acc: 0.8717\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1390 - acc: 0.8949 - val_loss: 0.1570 - val_acc: 0.8717\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1260 - acc: 0.8990 - val_loss: 0.1563 - val_acc: 0.8717\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8894 - val_loss: 0.1552 - val_acc: 0.8717\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1273 - acc: 0.8949 - val_loss: 0.1547 - val_acc: 0.8717\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1288 - acc: 0.8948 - val_loss: 0.1544 - val_acc: 0.8717\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1287 - acc: 0.8948 - val_loss: 0.1543 - val_acc: 0.8717\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1353 - acc: 0.8873 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1351 - acc: 0.8873 - val_loss: 0.1540 - val_acc: 0.8717\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1288 - acc: 0.8933 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8945 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1917 - acc: 0.8828 - val_loss: 0.1538 - val_acc: 0.8716\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1375 - acc: 0.8848 - val_loss: 0.1540 - val_acc: 0.8716\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1328 - acc: 0.8910 - val_loss: 0.1540 - val_acc: 0.8716\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1582 - acc: 0.8924 - val_loss: 0.1540 - val_acc: 0.8716\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1244 - acc: 0.8967 - val_loss: 0.1537 - val_acc: 0.8716\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1350 - acc: 0.8866 - val_loss: 0.1534 - val_acc: 0.8716\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1554 - acc: 0.8981 - val_loss: 0.1536 - val_acc: 0.8716\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1315 - acc: 0.8932 - val_loss: 0.1539 - val_acc: 0.8716\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1308 - acc: 0.8906 - val_loss: 0.1539 - val_acc: 0.8716\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1224 - acc: 0.8996 - val_loss: 0.1537 - val_acc: 0.8716\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1220 - acc: 0.8996 - val_loss: 0.1534 - val_acc: 0.8716\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1607 - acc: 0.9012 - val_loss: 0.1533 - val_acc: 0.8716\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1592 - acc: 0.8850 - val_loss: 0.1538 - val_acc: 0.8716\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1367 - acc: 0.8851 - val_loss: 0.1542 - val_acc: 0.8716\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1294 - acc: 0.8931 - val_loss: 0.1541 - val_acc: 0.8716\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1328 - acc: 0.8896 - val_loss: 0.1538 - val_acc: 0.8716\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8899 - val_loss: 0.1536 - val_acc: 0.8717\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1337 - acc: 0.8900 - val_loss: 0.1537 - val_acc: 0.8717\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1408 - acc: 0.8820 - val_loss: 0.1537 - val_acc: 0.8717\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1404 - acc: 0.8820 - val_loss: 0.1535 - val_acc: 0.8717\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2502 - acc: 0.8858 - val_loss: 0.1536 - val_acc: 0.8717\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1230 - acc: 0.8983 - val_loss: 0.1565 - val_acc: 0.8716\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1319 - acc: 0.8975 - val_loss: 0.1586 - val_acc: 0.8716\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1345 - acc: 0.8910 - val_loss: 0.1580 - val_acc: 0.8716\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1338 - acc: 0.8910 - val_loss: 0.1557 - val_acc: 0.8716\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1355 - acc: 0.8891 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1295 - acc: 0.8928 - val_loss: 0.1547 - val_acc: 0.8717\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8964 - val_loss: 0.1563 - val_acc: 0.8717\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1285 - acc: 0.8947 - val_loss: 0.1566 - val_acc: 0.8717\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8933 - val_loss: 0.1556 - val_acc: 0.8717\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1706 - acc: 0.8883 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1217 - acc: 0.8954 - val_loss: 0.1540 - val_acc: 0.8716\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1263 - acc: 0.8933 - val_loss: 0.1543 - val_acc: 0.8716\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1268 - acc: 0.8933 - val_loss: 0.1541 - val_acc: 0.8716\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1257 - acc: 0.8940 - val_loss: 0.1535 - val_acc: 0.8716\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1270 - acc: 0.8939 - val_loss: 0.1528 - val_acc: 0.8716\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1300 - acc: 0.8921 - val_loss: 0.1526 - val_acc: 0.8716\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1884 - acc: 0.8951 - val_loss: 0.1526 - val_acc: 0.8716\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1246 - acc: 0.8976 - val_loss: 0.1527 - val_acc: 0.8716\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1316 - acc: 0.8894 - val_loss: 0.1527 - val_acc: 0.8716\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1262 - acc: 0.8915 - val_loss: 0.1527 - val_acc: 0.8716\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1328 - acc: 0.8897 - val_loss: 0.1526 - val_acc: 0.8716\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1344 - acc: 0.8918 - val_loss: 0.1525 - val_acc: 0.8716\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1318 - acc: 0.8894 - val_loss: 0.1523 - val_acc: 0.8716\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1341 - acc: 0.8875 - val_loss: 0.1521 - val_acc: 0.8716\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1395 - acc: 0.8888 - val_loss: 0.1519 - val_acc: 0.8716\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1355 - acc: 0.8867 - val_loss: 0.1518 - val_acc: 0.8716\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1350 - acc: 0.8867 - val_loss: 0.1517 - val_acc: 0.8716\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8960 - val_loss: 0.1516 - val_acc: 0.8716\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1291 - acc: 0.8894 - val_loss: 0.1515 - val_acc: 0.8716\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1305 - acc: 0.8922 - val_loss: 0.1513 - val_acc: 0.8716\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1585 - acc: 0.8829 - val_loss: 0.1512 - val_acc: 0.8716\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1378 - acc: 0.8832 - val_loss: 0.1512 - val_acc: 0.8716\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1558 - acc: 0.8775 - val_loss: 0.1512 - val_acc: 0.8716\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1203 - acc: 0.8981 - val_loss: 0.1510 - val_acc: 0.8715\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1264 - acc: 0.8933 - val_loss: 0.1509 - val_acc: 0.8715\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1370 - acc: 0.8846 - val_loss: 0.1509 - val_acc: 0.8715\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1273 - acc: 0.8907 - val_loss: 0.1509 - val_acc: 0.8715\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1266 - acc: 0.8914 - val_loss: 0.1506 - val_acc: 0.8715\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1261 - acc: 0.8914 - val_loss: 0.1503 - val_acc: 0.8715\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8949 - val_loss: 0.1502 - val_acc: 0.8715\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8923 - val_loss: 0.1503 - val_acc: 0.8715\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1226 - acc: 0.8927 - val_loss: 0.1503 - val_acc: 0.8714\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1385 - acc: 0.8811 - val_loss: 0.1501 - val_acc: 0.8714\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1998 - acc: 0.8947 - val_loss: 0.1506 - val_acc: 0.8714\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8956 - val_loss: 0.1510 - val_acc: 0.8714\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1334 - acc: 0.8896 - val_loss: 0.1508 - val_acc: 0.8714\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2280 - acc: 0.8890 - val_loss: 0.1538 - val_acc: 0.8714\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1457 - acc: 0.8779 - val_loss: 0.1548 - val_acc: 0.8714\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1343 - acc: 0.8910 - val_loss: 0.1532 - val_acc: 0.8714\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1505 - acc: 0.8823 - val_loss: 0.1516 - val_acc: 0.8715\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1862 - acc: 0.8897 - val_loss: 0.1524 - val_acc: 0.8716\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1323 - acc: 0.8873 - val_loss: 0.1530 - val_acc: 0.8716\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1282 - acc: 0.8911 - val_loss: 0.1527 - val_acc: 0.8716\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1305 - acc: 0.8931 - val_loss: 0.1523 - val_acc: 0.8716\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1335 - acc: 0.8883 - val_loss: 0.1522 - val_acc: 0.8716\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1224 - acc: 0.8968 - val_loss: 0.1523 - val_acc: 0.8716\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1224 - acc: 0.8968 - val_loss: 0.1524 - val_acc: 0.8716\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1353 - acc: 0.8826 - val_loss: 0.1523 - val_acc: 0.8716\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1465 - acc: 0.8966 - val_loss: 0.1522 - val_acc: 0.8716\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1289 - acc: 0.8899 - val_loss: 0.1518 - val_acc: 0.8716\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1284 - acc: 0.8899 - val_loss: 0.1515 - val_acc: 0.8716\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1326 - acc: 0.8857 - val_loss: 0.1512 - val_acc: 0.8716\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8968 - val_loss: 0.1509 - val_acc: 0.8715\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1375 - acc: 0.8917 - val_loss: 0.1506 - val_acc: 0.8715\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1359 - acc: 0.8939 - val_loss: 0.1505 - val_acc: 0.8715\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2274 - acc: 0.8869 - val_loss: 0.1524 - val_acc: 0.8715\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1350 - acc: 0.8873 - val_loss: 0.1552 - val_acc: 0.8714\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8964 - val_loss: 0.1556 - val_acc: 0.8714\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1437 - acc: 0.8925 - val_loss: 0.1539 - val_acc: 0.8715\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1360 - acc: 0.8934 - val_loss: 0.1521 - val_acc: 0.8715\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1245 - acc: 0.8959 - val_loss: 0.1516 - val_acc: 0.8716\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1261 - acc: 0.8908 - val_loss: 0.1528 - val_acc: 0.8716\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1291 - acc: 0.8901 - val_loss: 0.1533 - val_acc: 0.8716\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1874 - acc: 0.8964 - val_loss: 0.1514 - val_acc: 0.8716\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8937 - val_loss: 0.1513 - val_acc: 0.8715\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1573 - acc: 0.8956 - val_loss: 0.1529 - val_acc: 0.8715\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1320 - acc: 0.8969 - val_loss: 0.1545 - val_acc: 0.8715\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1347 - acc: 0.8925 - val_loss: 0.1546 - val_acc: 0.8716\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8995 - val_loss: 0.1534 - val_acc: 0.8716\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1335 - acc: 0.8883 - val_loss: 0.1523 - val_acc: 0.8716\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.9004 - val_loss: 0.1525 - val_acc: 0.8716\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1165 - acc: 0.9004 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8954 - val_loss: 0.1550 - val_acc: 0.8717\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1318 - acc: 0.8887 - val_loss: 0.1541 - val_acc: 0.8717\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1309 - acc: 0.8888 - val_loss: 0.1519 - val_acc: 0.8717\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1295 - acc: 0.8896 - val_loss: 0.1507 - val_acc: 0.8717\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1373 - acc: 0.8848 - val_loss: 0.1510 - val_acc: 0.8716\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8861 - val_loss: 0.1519 - val_acc: 0.8716\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1265 - acc: 0.9004 - val_loss: 0.1523 - val_acc: 0.8715\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1208 - acc: 0.8968 - val_loss: 0.1514 - val_acc: 0.8715\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1219 - acc: 0.8992 - val_loss: 0.1503 - val_acc: 0.8715\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1239 - acc: 0.8959 - val_loss: 0.1504 - val_acc: 0.8715\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8910 - val_loss: 0.1515 - val_acc: 0.8715\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8979 - val_loss: 0.1517 - val_acc: 0.8715\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8978 - val_loss: 0.1505 - val_acc: 0.8715\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1327 - acc: 0.8897 - val_loss: 0.1494 - val_acc: 0.8714\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8899 - val_loss: 0.1493 - val_acc: 0.8714\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8907 - val_loss: 0.1496 - val_acc: 0.8713\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1226 - acc: 0.8948 - val_loss: 0.1497 - val_acc: 0.8713\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1365 - acc: 0.8845 - val_loss: 0.1493 - val_acc: 0.8713\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1359 - acc: 0.8844 - val_loss: 0.1487 - val_acc: 0.8713\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1446 - acc: 0.8857 - val_loss: 0.1486 - val_acc: 0.8713\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1341 - acc: 0.8843 - val_loss: 0.1487 - val_acc: 0.8713\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1301 - acc: 0.8875 - val_loss: 0.1487 - val_acc: 0.8714\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1231 - acc: 0.8917 - val_loss: 0.1485 - val_acc: 0.8714\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1375 - acc: 0.8797 - val_loss: 0.1481 - val_acc: 0.8713\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1309 - acc: 0.8869 - val_loss: 0.1478 - val_acc: 0.8713\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1306 - acc: 0.8869 - val_loss: 0.1477 - val_acc: 0.8712\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1874 - acc: 0.8923 - val_loss: 0.1487 - val_acc: 0.8711\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1182 - acc: 0.9021 - val_loss: 0.1502 - val_acc: 0.8710\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1154 - acc: 0.9022 - val_loss: 0.1501 - val_acc: 0.8710\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1314 - acc: 0.8975 - val_loss: 0.1489 - val_acc: 0.8712\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8960 - val_loss: 0.1482 - val_acc: 0.8714\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8910 - val_loss: 0.1489 - val_acc: 0.8715\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1241 - acc: 0.8919 - val_loss: 0.1498 - val_acc: 0.8715\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1332 - acc: 0.8865 - val_loss: 0.1492 - val_acc: 0.8715\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8897 - val_loss: 0.1482 - val_acc: 0.8714\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1217 - acc: 0.8909 - val_loss: 0.1479 - val_acc: 0.8713\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8908 - val_loss: 0.1480 - val_acc: 0.8713\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1299 - acc: 0.8884 - val_loss: 0.1479 - val_acc: 0.8712\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8869 - val_loss: 0.1478 - val_acc: 0.8712\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1274 - acc: 0.8869 - val_loss: 0.1476 - val_acc: 0.8712\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1288 - acc: 0.8888 - val_loss: 0.1476 - val_acc: 0.8713\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1181 - acc: 0.8974 - val_loss: 0.1481 - val_acc: 0.8713\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1180 - acc: 0.8975 - val_loss: 0.1483 - val_acc: 0.8714\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1351 - acc: 0.8846 - val_loss: 0.1475 - val_acc: 0.8714\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8995 - val_loss: 0.1470 - val_acc: 0.8713\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8994 - val_loss: 0.1470 - val_acc: 0.8713\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8955 - val_loss: 0.1471 - val_acc: 0.8713\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8971 - val_loss: 0.1470 - val_acc: 0.8713\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1416 - acc: 0.8850 - val_loss: 0.1469 - val_acc: 0.8713\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1297 - acc: 0.8860 - val_loss: 0.1467 - val_acc: 0.8713\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1600 - acc: 0.8920 - val_loss: 0.1468 - val_acc: 0.8713\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1712 - acc: 0.8827 - val_loss: 0.1476 - val_acc: 0.8712\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1372 - acc: 0.8828 - val_loss: 0.1483 - val_acc: 0.8712\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1274 - acc: 0.8914 - val_loss: 0.1480 - val_acc: 0.8713\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1249 - acc: 0.8935 - val_loss: 0.1476 - val_acc: 0.8713\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1208 - acc: 0.8984 - val_loss: 0.1474 - val_acc: 0.8714\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1272 - acc: 0.8891 - val_loss: 0.1475 - val_acc: 0.8714\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1198 - acc: 0.8967 - val_loss: 0.1475 - val_acc: 0.8714\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1187 - acc: 0.8967 - val_loss: 0.1473 - val_acc: 0.8714\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1446 - acc: 0.8814 - val_loss: 0.1471 - val_acc: 0.8713\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1933 - acc: 0.8881 - val_loss: 0.1488 - val_acc: 0.8711\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1303 - acc: 0.8931 - val_loss: 0.1503 - val_acc: 0.8711\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1248 - acc: 0.8978 - val_loss: 0.1495 - val_acc: 0.8712\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8979 - val_loss: 0.1478 - val_acc: 0.8714\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.9011 - val_loss: 0.1481 - val_acc: 0.8715\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1296 - acc: 0.8891 - val_loss: 0.1501 - val_acc: 0.8716\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1309 - acc: 0.8892 - val_loss: 0.1500 - val_acc: 0.8716\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1441 - acc: 0.8870 - val_loss: 0.1475 - val_acc: 0.8716\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1345 - acc: 0.8843 - val_loss: 0.1473 - val_acc: 0.8715\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - acc: 0.8880 - val_loss: 0.1486 - val_acc: 0.8715\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1393 - acc: 0.8876 - val_loss: 0.1498 - val_acc: 0.8715\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1372 - acc: 0.8892 - val_loss: 0.1497 - val_acc: 0.8715\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8919 - val_loss: 0.1483 - val_acc: 0.8715\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1341 - acc: 0.8871 - val_loss: 0.1473 - val_acc: 0.8715\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1240 - acc: 0.8946 - val_loss: 0.1477 - val_acc: 0.8716\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8887 - val_loss: 0.1481 - val_acc: 0.8716\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - acc: 0.8887 - val_loss: 0.1474 - val_acc: 0.8715\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1379 - acc: 0.8814 - val_loss: 0.1466 - val_acc: 0.8715\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1274 - acc: 0.8866 - val_loss: 0.1465 - val_acc: 0.8714\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1273 - acc: 0.8866 - val_loss: 0.1465 - val_acc: 0.8713\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1214 - acc: 0.8932 - val_loss: 0.1464 - val_acc: 0.8713\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1211 - acc: 0.8932 - val_loss: 0.1461 - val_acc: 0.8713\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1187 - acc: 0.8952 - val_loss: 0.1459 - val_acc: 0.8713\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1359 - acc: 0.8898 - val_loss: 0.1459 - val_acc: 0.8714\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1158 - acc: 0.8970 - val_loss: 0.1461 - val_acc: 0.8714\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1178 - acc: 0.8961 - val_loss: 0.1459 - val_acc: 0.8713\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8984 - val_loss: 0.1454 - val_acc: 0.8713\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8986 - val_loss: 0.1452 - val_acc: 0.8712\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8972 - val_loss: 0.1451 - val_acc: 0.8712\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2946 - acc: 0.8837 - val_loss: 0.1494 - val_acc: 0.8710\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1180 - acc: 0.8991 - val_loss: 0.1548 - val_acc: 0.8709\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1224 - acc: 0.8991 - val_loss: 0.1558 - val_acc: 0.8711\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1418 - acc: 0.8850 - val_loss: 0.1527 - val_acc: 0.8713\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1573 - acc: 0.8765 - val_loss: 0.1500 - val_acc: 0.8715\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1317 - acc: 0.8879 - val_loss: 0.1504 - val_acc: 0.8716\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1300 - acc: 0.8886 - val_loss: 0.1520 - val_acc: 0.8716\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1304 - acc: 0.8886 - val_loss: 0.1513 - val_acc: 0.8716\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1273 - acc: 0.8952 - val_loss: 0.1489 - val_acc: 0.8716\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1696 - acc: 0.8931 - val_loss: 0.1489 - val_acc: 0.8715\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2514 - acc: 0.8859 - val_loss: 0.1548 - val_acc: 0.8713\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1377 - acc: 0.8865 - val_loss: 0.1614 - val_acc: 0.8712\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1532 - acc: 0.8902 - val_loss: 0.1650 - val_acc: 0.8712\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1508 - acc: 0.8847 - val_loss: 0.1639 - val_acc: 0.8713\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1493 - acc: 0.8848 - val_loss: 0.1597 - val_acc: 0.8714\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1401 - acc: 0.8888 - val_loss: 0.1554 - val_acc: 0.8715\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1605 - acc: 0.8832 - val_loss: 0.1539 - val_acc: 0.8716\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1340 - acc: 0.8869 - val_loss: 0.1546 - val_acc: 0.8717\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1299 - acc: 0.8942 - val_loss: 0.1565 - val_acc: 0.8717\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1306 - acc: 0.8943 - val_loss: 0.1575 - val_acc: 0.8717\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1353 - acc: 0.8913 - val_loss: 0.1561 - val_acc: 0.8717\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1386 - acc: 0.8894 - val_loss: 0.1532 - val_acc: 0.8717\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1360 - acc: 0.8894 - val_loss: 0.1509 - val_acc: 0.8717\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1226 - acc: 0.8958 - val_loss: 0.1504 - val_acc: 0.8717\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1322 - acc: 0.8900 - val_loss: 0.1514 - val_acc: 0.8716\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1325 - acc: 0.8900 - val_loss: 0.1526 - val_acc: 0.8716\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1262 - acc: 0.8940 - val_loss: 0.1530 - val_acc: 0.8716\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1312 - acc: 0.8893 - val_loss: 0.1522 - val_acc: 0.8716\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2006 - acc: 0.8885 - val_loss: 0.1528 - val_acc: 0.8716\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1294 - acc: 0.8892 - val_loss: 0.1522 - val_acc: 0.8716\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8933 - val_loss: 0.1509 - val_acc: 0.8716\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8960 - val_loss: 0.1498 - val_acc: 0.8716\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2101 - acc: 0.8894 - val_loss: 0.1497 - val_acc: 0.8716\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1266 - acc: 0.8948 - val_loss: 0.1495 - val_acc: 0.8716\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1243 - acc: 0.8912 - val_loss: 0.1494 - val_acc: 0.8716\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1241 - acc: 0.8912 - val_loss: 0.1493 - val_acc: 0.8716\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2456 - acc: 0.8831 - val_loss: 0.1503 - val_acc: 0.8715\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1357 - acc: 0.8840 - val_loss: 0.1518 - val_acc: 0.8715\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1314 - acc: 0.8921 - val_loss: 0.1526 - val_acc: 0.8715\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1372 - acc: 0.8874 - val_loss: 0.1523 - val_acc: 0.8715\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1366 - acc: 0.8873 - val_loss: 0.1512 - val_acc: 0.8715\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1260 - acc: 0.8944 - val_loss: 0.1502 - val_acc: 0.8715\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1245 - acc: 0.8944 - val_loss: 0.1501 - val_acc: 0.8716\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1377 - acc: 0.8965 - val_loss: 0.1504 - val_acc: 0.8716\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8966 - val_loss: 0.1506 - val_acc: 0.8716\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1158 - acc: 0.9005 - val_loss: 0.1504 - val_acc: 0.8716\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1153 - acc: 0.9005 - val_loss: 0.1500 - val_acc: 0.8716\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1326 - acc: 0.8875 - val_loss: 0.1493 - val_acc: 0.8716\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1274 - acc: 0.8904 - val_loss: 0.1488 - val_acc: 0.8716\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2081 - acc: 0.8947 - val_loss: 0.1491 - val_acc: 0.8715\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1592 - acc: 0.8854 - val_loss: 0.1508 - val_acc: 0.8715\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1332 - acc: 0.8855 - val_loss: 0.1521 - val_acc: 0.8715\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1232 - acc: 0.8955 - val_loss: 0.1521 - val_acc: 0.8715\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2096 - acc: 0.8840 - val_loss: 0.1532 - val_acc: 0.8715\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1433 - acc: 0.8850 - val_loss: 0.1526 - val_acc: 0.8715\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2409 - acc: 0.8822 - val_loss: 0.1544 - val_acc: 0.8715\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1447 - acc: 0.8832 - val_loss: 0.1544 - val_acc: 0.8716\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1804 - acc: 0.8985 - val_loss: 0.1549 - val_acc: 0.8716\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1415 - acc: 0.8838 - val_loss: 0.1539 - val_acc: 0.8717\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1252 - acc: 0.8965 - val_loss: 0.1522 - val_acc: 0.8717\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8965 - val_loss: 0.1515 - val_acc: 0.8717\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1367 - acc: 0.8846 - val_loss: 0.1523 - val_acc: 0.8717\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8993 - val_loss: 0.1543 - val_acc: 0.8717\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1256 - acc: 0.8941 - val_loss: 0.1553 - val_acc: 0.8717\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1372 - acc: 0.8884 - val_loss: 0.1545 - val_acc: 0.8717\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1265 - acc: 0.8944 - val_loss: 0.1530 - val_acc: 0.8717\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1376 - acc: 0.8855 - val_loss: 0.1515 - val_acc: 0.8717\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1157 - acc: 0.9029 - val_loss: 0.1509 - val_acc: 0.8717\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1397 - acc: 0.8835 - val_loss: 0.1504 - val_acc: 0.8717\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1320 - acc: 0.8906 - val_loss: 0.1502 - val_acc: 0.8716\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1393 - acc: 0.8859 - val_loss: 0.1499 - val_acc: 0.8716\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1305 - acc: 0.8899 - val_loss: 0.1494 - val_acc: 0.8716\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1298 - acc: 0.8898 - val_loss: 0.1487 - val_acc: 0.8715\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1277 - acc: 0.8919 - val_loss: 0.1481 - val_acc: 0.8715\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1227 - acc: 0.8962 - val_loss: 0.1481 - val_acc: 0.8716\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8962 - val_loss: 0.1484 - val_acc: 0.8716\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8951 - val_loss: 0.1487 - val_acc: 0.8716\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1907 - acc: 0.8941 - val_loss: 0.1477 - val_acc: 0.8716\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1248 - acc: 0.8913 - val_loss: 0.1473 - val_acc: 0.8716\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1241 - acc: 0.8926 - val_loss: 0.1474 - val_acc: 0.8715\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1255 - acc: 0.8931 - val_loss: 0.1476 - val_acc: 0.8715\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1284 - acc: 0.8949 - val_loss: 0.1476 - val_acc: 0.8715\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8998 - val_loss: 0.1473 - val_acc: 0.8714\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1259 - acc: 0.8934 - val_loss: 0.1467 - val_acc: 0.8714\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1246 - acc: 0.8904 - val_loss: 0.1464 - val_acc: 0.8714\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1277 - acc: 0.8872 - val_loss: 0.1463 - val_acc: 0.8714\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1316 - acc: 0.8863 - val_loss: 0.1463 - val_acc: 0.8714\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8877 - val_loss: 0.1462 - val_acc: 0.8714\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1303 - acc: 0.8878 - val_loss: 0.1460 - val_acc: 0.8713\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1326 - acc: 0.8878 - val_loss: 0.1456 - val_acc: 0.8713\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1171 - acc: 0.9009 - val_loss: 0.1455 - val_acc: 0.8712\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1173 - acc: 0.8969 - val_loss: 0.1454 - val_acc: 0.8712\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8870 - val_loss: 0.1452 - val_acc: 0.8711\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8893 - val_loss: 0.1450 - val_acc: 0.8711\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1234 - acc: 0.8893 - val_loss: 0.1448 - val_acc: 0.8710\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1219 - acc: 0.8913 - val_loss: 0.1445 - val_acc: 0.8710\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8900 - val_loss: 0.1443 - val_acc: 0.8710\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1393 - acc: 0.8886 - val_loss: 0.1442 - val_acc: 0.8710\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1246 - acc: 0.8877 - val_loss: 0.1442 - val_acc: 0.8710\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1264 - acc: 0.8876 - val_loss: 0.1442 - val_acc: 0.8710\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1354 - acc: 0.8975 - val_loss: 0.1442 - val_acc: 0.8710\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8871 - val_loss: 0.1442 - val_acc: 0.8710\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2322 - acc: 0.8908 - val_loss: 0.1460 - val_acc: 0.8708\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2486 - acc: 0.8808 - val_loss: 0.1548 - val_acc: 0.8706\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1407 - acc: 0.8828 - val_loss: 0.1616 - val_acc: 0.8706\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1591 - acc: 0.8737 - val_loss: 0.1620 - val_acc: 0.8709\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1310 - acc: 0.8992 - val_loss: 0.1576 - val_acc: 0.8712\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1308 - acc: 0.8937 - val_loss: 0.1519 - val_acc: 0.8715\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1528 - acc: 0.8883 - val_loss: 0.1493 - val_acc: 0.8716\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1405 - acc: 0.8799 - val_loss: 0.1497 - val_acc: 0.8717\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1306 - acc: 0.8935 - val_loss: 0.1521 - val_acc: 0.8717\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1414 - acc: 0.8806 - val_loss: 0.1523 - val_acc: 0.8717\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8854 - val_loss: 0.1504 - val_acc: 0.8717\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2290 - acc: 0.8891 - val_loss: 0.1483 - val_acc: 0.8717\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1950 - acc: 0.8981 - val_loss: 0.1507 - val_acc: 0.8716\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1301 - acc: 0.8910 - val_loss: 0.1546 - val_acc: 0.8716\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1339 - acc: 0.8897 - val_loss: 0.1571 - val_acc: 0.8716\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2230 - acc: 0.8889 - val_loss: 0.1608 - val_acc: 0.8716\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1504 - acc: 0.8895 - val_loss: 0.1615 - val_acc: 0.8716\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1485 - acc: 0.8895 - val_loss: 0.1597 - val_acc: 0.8717\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1321 - acc: 0.8938 - val_loss: 0.1567 - val_acc: 0.8717\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1394 - acc: 0.8883 - val_loss: 0.1544 - val_acc: 0.8717\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1368 - acc: 0.8895 - val_loss: 0.1542 - val_acc: 0.8717\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8960 - val_loss: 0.1563 - val_acc: 0.8717\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1255 - acc: 0.8961 - val_loss: 0.1591 - val_acc: 0.8718\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1297 - acc: 0.8949 - val_loss: 0.1601 - val_acc: 0.8718\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1348 - acc: 0.8902 - val_loss: 0.1582 - val_acc: 0.8718\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1331 - acc: 0.8902 - val_loss: 0.1548 - val_acc: 0.8718\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.9002 - val_loss: 0.1520 - val_acc: 0.8717\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1306 - acc: 0.8953 - val_loss: 0.1506 - val_acc: 0.8717\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8953 - val_loss: 0.1505 - val_acc: 0.8717\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8967 - val_loss: 0.1509 - val_acc: 0.8717\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1320 - acc: 0.8914 - val_loss: 0.1509 - val_acc: 0.8717\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8944 - val_loss: 0.1505 - val_acc: 0.8717\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1379 - acc: 0.8912 - val_loss: 0.1497 - val_acc: 0.8717\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1376 - acc: 0.8849 - val_loss: 0.1488 - val_acc: 0.8717\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1444 - acc: 0.8957 - val_loss: 0.1481 - val_acc: 0.8717\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1212 - acc: 0.8954 - val_loss: 0.1476 - val_acc: 0.8717\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8954 - val_loss: 0.1475 - val_acc: 0.8717\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8993 - val_loss: 0.1477 - val_acc: 0.8717\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1360 - acc: 0.8804 - val_loss: 0.1480 - val_acc: 0.8716\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1284 - acc: 0.8902 - val_loss: 0.1478 - val_acc: 0.8716\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1278 - acc: 0.8902 - val_loss: 0.1473 - val_acc: 0.8716\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2231 - acc: 0.8922 - val_loss: 0.1463 - val_acc: 0.8716\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1255 - acc: 0.8925 - val_loss: 0.1469 - val_acc: 0.8715\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8969 - val_loss: 0.1479 - val_acc: 0.8715\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8918 - val_loss: 0.1483 - val_acc: 0.8715\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1307 - acc: 0.8876 - val_loss: 0.1480 - val_acc: 0.8715\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1289 - acc: 0.8901 - val_loss: 0.1472 - val_acc: 0.8715\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8878 - val_loss: 0.1463 - val_acc: 0.8715\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1282 - acc: 0.8879 - val_loss: 0.1461 - val_acc: 0.8715\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8912 - val_loss: 0.1465 - val_acc: 0.8715\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8998 - val_loss: 0.1471 - val_acc: 0.8715\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1182 - acc: 0.8980 - val_loss: 0.1477 - val_acc: 0.8716\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1337 - acc: 0.8855 - val_loss: 0.1472 - val_acc: 0.8715\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8923 - val_loss: 0.1462 - val_acc: 0.8715\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1227 - acc: 0.8923 - val_loss: 0.1452 - val_acc: 0.8715\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8939 - val_loss: 0.1447 - val_acc: 0.8714\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1291 - acc: 0.8875 - val_loss: 0.1446 - val_acc: 0.8714\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1292 - acc: 0.8880 - val_loss: 0.1447 - val_acc: 0.8713\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1304 - acc: 0.8885 - val_loss: 0.1446 - val_acc: 0.8713\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1168 - acc: 0.8978 - val_loss: 0.1443 - val_acc: 0.8713\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1294 - acc: 0.8879 - val_loss: 0.1440 - val_acc: 0.8713\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1279 - acc: 0.8859 - val_loss: 0.1438 - val_acc: 0.8714\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1216 - acc: 0.8926 - val_loss: 0.1438 - val_acc: 0.8714\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1214 - acc: 0.8926 - val_loss: 0.1439 - val_acc: 0.8714\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8969 - val_loss: 0.1439 - val_acc: 0.8714\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1245 - acc: 0.8910 - val_loss: 0.1437 - val_acc: 0.8713\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1158 - acc: 0.8986 - val_loss: 0.1433 - val_acc: 0.8713\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1154 - acc: 0.8984 - val_loss: 0.1430 - val_acc: 0.8712\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8891 - val_loss: 0.1428 - val_acc: 0.8711\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8986 - val_loss: 0.1427 - val_acc: 0.8710\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1189 - acc: 0.8940 - val_loss: 0.1426 - val_acc: 0.8709\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1207 - acc: 0.8922 - val_loss: 0.1425 - val_acc: 0.8708\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2330 - acc: 0.8812 - val_loss: 0.1437 - val_acc: 0.8706\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1264 - acc: 0.8866 - val_loss: 0.1452 - val_acc: 0.8705\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1223 - acc: 0.8929 - val_loss: 0.1455 - val_acc: 0.8706\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2458 - acc: 0.8903 - val_loss: 0.1486 - val_acc: 0.8707\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1346 - acc: 0.8823 - val_loss: 0.1496 - val_acc: 0.8709\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1451 - acc: 0.8807 - val_loss: 0.1486 - val_acc: 0.8711\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1288 - acc: 0.8904 - val_loss: 0.1465 - val_acc: 0.8713\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8963 - val_loss: 0.1453 - val_acc: 0.8714\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1176 - acc: 0.8963 - val_loss: 0.1468 - val_acc: 0.8716\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1292 - acc: 0.8865 - val_loss: 0.1491 - val_acc: 0.8716\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1346 - acc: 0.8910 - val_loss: 0.1490 - val_acc: 0.8716\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - acc: 0.8932 - val_loss: 0.1474 - val_acc: 0.8716\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1253 - acc: 0.8904 - val_loss: 0.1456 - val_acc: 0.8715\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1202 - acc: 0.8966 - val_loss: 0.1451 - val_acc: 0.8713\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8995 - val_loss: 0.1456 - val_acc: 0.8712\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1151 - acc: 0.9010 - val_loss: 0.1461 - val_acc: 0.8711\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1313 - acc: 0.8848 - val_loss: 0.1461 - val_acc: 0.8710\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1548 - acc: 0.8921 - val_loss: 0.1460 - val_acc: 0.8710\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8955 - val_loss: 0.1454 - val_acc: 0.8711\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8955 - val_loss: 0.1446 - val_acc: 0.8712\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8891 - val_loss: 0.1441 - val_acc: 0.8713\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1263 - acc: 0.8896 - val_loss: 0.1441 - val_acc: 0.8713\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1435 - acc: 0.8817 - val_loss: 0.1443 - val_acc: 0.8714\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1317 - acc: 0.8818 - val_loss: 0.1446 - val_acc: 0.8714\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1299 - acc: 0.8859 - val_loss: 0.1444 - val_acc: 0.8714\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8981 - val_loss: 0.1441 - val_acc: 0.8713\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1142 - acc: 0.8981 - val_loss: 0.1438 - val_acc: 0.8713\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8970 - val_loss: 0.1434 - val_acc: 0.8712\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1888 - acc: 0.8878 - val_loss: 0.1443 - val_acc: 0.8710\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8886 - val_loss: 0.1456 - val_acc: 0.8709\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1993 - acc: 0.8936 - val_loss: 0.1489 - val_acc: 0.8708\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1693 - acc: 0.8934 - val_loss: 0.1527 - val_acc: 0.8708\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1295 - acc: 0.8924 - val_loss: 0.1530 - val_acc: 0.8709\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1296 - acc: 0.8925 - val_loss: 0.1502 - val_acc: 0.8711\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8947 - val_loss: 0.1467 - val_acc: 0.8713\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1191 - acc: 0.8949 - val_loss: 0.1454 - val_acc: 0.8715\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1198 - acc: 0.8932 - val_loss: 0.1470 - val_acc: 0.8716\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8932 - val_loss: 0.1497 - val_acc: 0.8716\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1323 - acc: 0.8898 - val_loss: 0.1505 - val_acc: 0.8716\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1208 - acc: 0.8941 - val_loss: 0.1491 - val_acc: 0.8716\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8920 - val_loss: 0.1472 - val_acc: 0.8715\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2173 - acc: 0.8945 - val_loss: 0.1456 - val_acc: 0.8714\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1214 - acc: 0.8974 - val_loss: 0.1466 - val_acc: 0.8714\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1231 - acc: 0.8912 - val_loss: 0.1482 - val_acc: 0.8713\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1314 - acc: 0.8892 - val_loss: 0.1490 - val_acc: 0.8713\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1278 - acc: 0.8900 - val_loss: 0.1486 - val_acc: 0.8713\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1345 - acc: 0.8865 - val_loss: 0.1471 - val_acc: 0.8714\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1202 - acc: 0.8941 - val_loss: 0.1457 - val_acc: 0.8715\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8942 - val_loss: 0.1455 - val_acc: 0.8715\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2375 - acc: 0.8908 - val_loss: 0.1461 - val_acc: 0.8716\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1306 - acc: 0.8867 - val_loss: 0.1462 - val_acc: 0.8716\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8912 - val_loss: 0.1459 - val_acc: 0.8716\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8961 - val_loss: 0.1456 - val_acc: 0.8716\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1184 - acc: 0.8960 - val_loss: 0.1454 - val_acc: 0.8716\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1234 - acc: 0.8922 - val_loss: 0.1453 - val_acc: 0.8716\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1321 - acc: 0.8832 - val_loss: 0.1452 - val_acc: 0.8716\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1449 - acc: 0.8775 - val_loss: 0.1451 - val_acc: 0.8715\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1794 - acc: 0.8880 - val_loss: 0.1452 - val_acc: 0.8715\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8979 - val_loss: 0.1452 - val_acc: 0.8714\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1223 - acc: 0.8932 - val_loss: 0.1451 - val_acc: 0.8714\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1319 - acc: 0.8834 - val_loss: 0.1449 - val_acc: 0.8714\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1383 - acc: 0.8897 - val_loss: 0.1448 - val_acc: 0.8714\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8907 - val_loss: 0.1447 - val_acc: 0.8713\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8912 - val_loss: 0.1445 - val_acc: 0.8713\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1192 - acc: 0.8945 - val_loss: 0.1443 - val_acc: 0.8713\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1186 - acc: 0.8920 - val_loss: 0.1440 - val_acc: 0.8713\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2510 - acc: 0.8796 - val_loss: 0.1441 - val_acc: 0.8712\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1266 - acc: 0.8896 - val_loss: 0.1455 - val_acc: 0.8711\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8934 - val_loss: 0.1464 - val_acc: 0.8711\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8952 - val_loss: 0.1462 - val_acc: 0.8711\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1300 - acc: 0.8894 - val_loss: 0.1453 - val_acc: 0.8712\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1287 - acc: 0.8894 - val_loss: 0.1446 - val_acc: 0.8713\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1372 - acc: 0.8779 - val_loss: 0.1445 - val_acc: 0.8714\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1482 - acc: 0.8930 - val_loss: 0.1448 - val_acc: 0.8714\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1382 - acc: 0.8824 - val_loss: 0.1451 - val_acc: 0.8714\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1378 - acc: 0.8849 - val_loss: 0.1450 - val_acc: 0.8714\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1956 - acc: 0.8890 - val_loss: 0.1438 - val_acc: 0.8714\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8929 - val_loss: 0.1438 - val_acc: 0.8713\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2443 - acc: 0.8863 - val_loss: 0.1464 - val_acc: 0.8712\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1294 - acc: 0.8878 - val_loss: 0.1495 - val_acc: 0.8711\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1306 - acc: 0.8870 - val_loss: 0.1510 - val_acc: 0.8711\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1244 - acc: 0.8965 - val_loss: 0.1503 - val_acc: 0.8712\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8933 - val_loss: 0.1483 - val_acc: 0.8713\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2032 - acc: 0.8940 - val_loss: 0.1477 - val_acc: 0.8714\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8974 - val_loss: 0.1470 - val_acc: 0.8715\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1256 - acc: 0.8899 - val_loss: 0.1469 - val_acc: 0.8716\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1152 - acc: 0.8983 - val_loss: 0.1474 - val_acc: 0.8717\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1150 - acc: 0.8982 - val_loss: 0.1482 - val_acc: 0.8717\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1189 - acc: 0.8969 - val_loss: 0.1485 - val_acc: 0.8717\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1248 - acc: 0.8941 - val_loss: 0.1481 - val_acc: 0.8717\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1243 - acc: 0.8941 - val_loss: 0.1472 - val_acc: 0.8717\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1296 - acc: 0.8877 - val_loss: 0.1461 - val_acc: 0.8716\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1191 - acc: 0.8965 - val_loss: 0.1454 - val_acc: 0.8715\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1239 - acc: 0.8925 - val_loss: 0.1451 - val_acc: 0.8715\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8933 - val_loss: 0.1449 - val_acc: 0.8714\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1207 - acc: 0.8906 - val_loss: 0.1446 - val_acc: 0.8713\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1204 - acc: 0.8906 - val_loss: 0.1442 - val_acc: 0.8713\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1224 - acc: 0.8900 - val_loss: 0.1436 - val_acc: 0.8713\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1183 - acc: 0.8936 - val_loss: 0.1432 - val_acc: 0.8712\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1176 - acc: 0.8936 - val_loss: 0.1431 - val_acc: 0.8712\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1334 - acc: 0.8813 - val_loss: 0.1431 - val_acc: 0.8712\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2239 - acc: 0.8917 - val_loss: 0.1429 - val_acc: 0.8711\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8936 - val_loss: 0.1434 - val_acc: 0.8710\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2075 - acc: 0.8966 - val_loss: 0.1458 - val_acc: 0.8708\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8989 - val_loss: 0.1478 - val_acc: 0.8708\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1294 - acc: 0.8878 - val_loss: 0.1483 - val_acc: 0.8708\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1154 - acc: 0.8999 - val_loss: 0.1471 - val_acc: 0.8709\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - acc: 0.8941 - val_loss: 0.1452 - val_acc: 0.8711\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8881 - val_loss: 0.1441 - val_acc: 0.8713\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8882 - val_loss: 0.1444 - val_acc: 0.8714\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1308 - acc: 0.8845 - val_loss: 0.1455 - val_acc: 0.8714\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8923 - val_loss: 0.1461 - val_acc: 0.8714\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1117 - acc: 0.9022 - val_loss: 0.1458 - val_acc: 0.8714\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1112 - acc: 0.9022 - val_loss: 0.1447 - val_acc: 0.8713\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1138 - acc: 0.8965 - val_loss: 0.1437 - val_acc: 0.8712\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1191 - acc: 0.8997 - val_loss: 0.1431 - val_acc: 0.8710\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1082 - acc: 0.9032 - val_loss: 0.1429 - val_acc: 0.8709\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1643 - acc: 0.8895 - val_loss: 0.1434 - val_acc: 0.8708\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1936 - acc: 0.8942 - val_loss: 0.1455 - val_acc: 0.8706\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1143 - acc: 0.8969 - val_loss: 0.1473 - val_acc: 0.8705\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1298 - acc: 0.8889 - val_loss: 0.1477 - val_acc: 0.8705\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1269 - acc: 0.8876 - val_loss: 0.1468 - val_acc: 0.8707\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1281 - acc: 0.8893 - val_loss: 0.1453 - val_acc: 0.8710\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8947 - val_loss: 0.1441 - val_acc: 0.8712\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1480 - acc: 0.8814 - val_loss: 0.1442 - val_acc: 0.8713\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1304 - acc: 0.8844 - val_loss: 0.1451 - val_acc: 0.8714\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1322 - acc: 0.8836 - val_loss: 0.1457 - val_acc: 0.8715\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1315 - acc: 0.8845 - val_loss: 0.1454 - val_acc: 0.8714\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1272 - acc: 0.8874 - val_loss: 0.1443 - val_acc: 0.8714\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8934 - val_loss: 0.1432 - val_acc: 0.8713\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8915 - val_loss: 0.1427 - val_acc: 0.8711\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2423 - acc: 0.8846 - val_loss: 0.1448 - val_acc: 0.8709\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8863 - val_loss: 0.1477 - val_acc: 0.8707\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8958 - val_loss: 0.1492 - val_acc: 0.8707\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.9018 - val_loss: 0.1486 - val_acc: 0.8708\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.9019 - val_loss: 0.1465 - val_acc: 0.8710\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1243 - acc: 0.8945 - val_loss: 0.1445 - val_acc: 0.8712\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1155 - acc: 0.8961 - val_loss: 0.1439 - val_acc: 0.8713\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1624 - acc: 0.8920 - val_loss: 0.1445 - val_acc: 0.8714\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1212 - acc: 0.8918 - val_loss: 0.1451 - val_acc: 0.8714\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1294 - acc: 0.8865 - val_loss: 0.1451 - val_acc: 0.8714\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1196 - acc: 0.8910 - val_loss: 0.1445 - val_acc: 0.8714\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1499 - acc: 0.8872 - val_loss: 0.1433 - val_acc: 0.8713\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1208 - acc: 0.8907 - val_loss: 0.1427 - val_acc: 0.8711\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1256 - acc: 0.8883 - val_loss: 0.1425 - val_acc: 0.8709\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1239 - acc: 0.8867 - val_loss: 0.1426 - val_acc: 0.8708\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1154 - acc: 0.8965 - val_loss: 0.1426 - val_acc: 0.8707\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.8963 - val_loss: 0.1426 - val_acc: 0.8706\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1151 - acc: 0.8967 - val_loss: 0.1423 - val_acc: 0.8706\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1293 - acc: 0.8839 - val_loss: 0.1421 - val_acc: 0.8707\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1287 - acc: 0.8839 - val_loss: 0.1419 - val_acc: 0.8708\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1197 - acc: 0.8896 - val_loss: 0.1418 - val_acc: 0.8708\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1142 - acc: 0.8991 - val_loss: 0.1417 - val_acc: 0.8708\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1191 - acc: 0.8949 - val_loss: 0.1415 - val_acc: 0.8708\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1254 - acc: 0.8855 - val_loss: 0.1412 - val_acc: 0.8707\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8854 - val_loss: 0.1408 - val_acc: 0.8705\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8854 - val_loss: 0.1405 - val_acc: 0.8702\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1209 - acc: 0.8891 - val_loss: 0.1402 - val_acc: 0.8700\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1401 - acc: 0.8808 - val_loss: 0.1400 - val_acc: 0.8698\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1332 - acc: 0.8819 - val_loss: 0.1399 - val_acc: 0.8696\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1201 - acc: 0.8900 - val_loss: 0.1399 - val_acc: 0.8695\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8978 - val_loss: 0.1399 - val_acc: 0.8696\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1612 - acc: 0.8912 - val_loss: 0.1399 - val_acc: 0.8696\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1146 - acc: 0.8951 - val_loss: 0.1399 - val_acc: 0.8697\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1144 - acc: 0.8952 - val_loss: 0.1398 - val_acc: 0.8697\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1125 - acc: 0.8952 - val_loss: 0.1398 - val_acc: 0.8698\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1418 - acc: 0.8796 - val_loss: 0.1396 - val_acc: 0.8696\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1284 - acc: 0.8818 - val_loss: 0.1395 - val_acc: 0.8694\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8920 - val_loss: 0.1395 - val_acc: 0.8692\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1325 - acc: 0.8792 - val_loss: 0.1394 - val_acc: 0.8690\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1146 - acc: 0.8957 - val_loss: 0.1393 - val_acc: 0.8690\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.8936 - val_loss: 0.1392 - val_acc: 0.8689\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1224 - acc: 0.8865 - val_loss: 0.1392 - val_acc: 0.8689\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8865 - val_loss: 0.1393 - val_acc: 0.8689\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8867 - val_loss: 0.1392 - val_acc: 0.8688\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1732 - acc: 0.8862 - val_loss: 0.1390 - val_acc: 0.8685\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2504 - acc: 0.8794 - val_loss: 0.1420 - val_acc: 0.8673\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1466 - acc: 0.8824 - val_loss: 0.1473 - val_acc: 0.8666\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1364 - acc: 0.8870 - val_loss: 0.1502 - val_acc: 0.8670\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1744 - acc: 0.8816 - val_loss: 0.1521 - val_acc: 0.8679\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1440 - acc: 0.8797 - val_loss: 0.1502 - val_acc: 0.8692\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1284 - acc: 0.8923 - val_loss: 0.1466 - val_acc: 0.8703\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1244 - acc: 0.8935 - val_loss: 0.1441 - val_acc: 0.8710\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1365 - acc: 0.8804 - val_loss: 0.1445 - val_acc: 0.8713\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8930 - val_loss: 0.1476 - val_acc: 0.8715\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1285 - acc: 0.8868 - val_loss: 0.1496 - val_acc: 0.8716\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1299 - acc: 0.8869 - val_loss: 0.1484 - val_acc: 0.8716\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1352 - acc: 0.8866 - val_loss: 0.1455 - val_acc: 0.8715\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8956 - val_loss: 0.1434 - val_acc: 0.8714\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1271 - acc: 0.8887 - val_loss: 0.1426 - val_acc: 0.8712\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1146 - acc: 0.8970 - val_loss: 0.1428 - val_acc: 0.8710\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1152 - acc: 0.8967 - val_loss: 0.1431 - val_acc: 0.8709\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1169 - acc: 0.8961 - val_loss: 0.1430 - val_acc: 0.8708\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1165 - acc: 0.8965 - val_loss: 0.1426 - val_acc: 0.8709\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1143 - acc: 0.8967 - val_loss: 0.1419 - val_acc: 0.8709\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8968 - val_loss: 0.1414 - val_acc: 0.8710\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1243 - acc: 0.8871 - val_loss: 0.1412 - val_acc: 0.8710\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1338 - acc: 0.8851 - val_loss: 0.1413 - val_acc: 0.8711\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8991 - val_loss: 0.1414 - val_acc: 0.8711\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - acc: 0.8889 - val_loss: 0.1413 - val_acc: 0.8710\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1284 - acc: 0.8847 - val_loss: 0.1407 - val_acc: 0.8709\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1840 - acc: 0.8832 - val_loss: 0.1401 - val_acc: 0.8707\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1241 - acc: 0.8849 - val_loss: 0.1405 - val_acc: 0.8704\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1240 - acc: 0.8871 - val_loss: 0.1410 - val_acc: 0.8701\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8969 - val_loss: 0.1410 - val_acc: 0.8700\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1135 - acc: 0.8968 - val_loss: 0.1405 - val_acc: 0.8701\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2223 - acc: 0.8816 - val_loss: 0.1416 - val_acc: 0.8700\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1258 - acc: 0.8853 - val_loss: 0.1425 - val_acc: 0.8700\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1229 - acc: 0.8881 - val_loss: 0.1426 - val_acc: 0.8701\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2474 - acc: 0.8797 - val_loss: 0.1462 - val_acc: 0.8700\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1322 - acc: 0.8838 - val_loss: 0.1483 - val_acc: 0.8700\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1336 - acc: 0.8831 - val_loss: 0.1479 - val_acc: 0.8702\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1305 - acc: 0.8858 - val_loss: 0.1457 - val_acc: 0.8705\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1338 - acc: 0.8802 - val_loss: 0.1432 - val_acc: 0.8708\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1202 - acc: 0.8934 - val_loss: 0.1423 - val_acc: 0.8711\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1216 - acc: 0.8926 - val_loss: 0.1434 - val_acc: 0.8713\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8880 - val_loss: 0.1453 - val_acc: 0.8714\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8911 - val_loss: 0.1460 - val_acc: 0.8714\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1296 - acc: 0.8892 - val_loss: 0.1449 - val_acc: 0.8713\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1219 - acc: 0.8922 - val_loss: 0.1432 - val_acc: 0.8711\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1163 - acc: 0.8956 - val_loss: 0.1419 - val_acc: 0.8709\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1302 - acc: 0.8908 - val_loss: 0.1414 - val_acc: 0.8707\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1871 - acc: 0.8912 - val_loss: 0.1426 - val_acc: 0.8704\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - acc: 0.8888 - val_loss: 0.1443 - val_acc: 0.8701\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8887 - val_loss: 0.1451 - val_acc: 0.8701\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1581 - acc: 0.8900 - val_loss: 0.1457 - val_acc: 0.8701\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1206 - acc: 0.8923 - val_loss: 0.1450 - val_acc: 0.8703\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8947 - val_loss: 0.1433 - val_acc: 0.8705\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8939 - val_loss: 0.1419 - val_acc: 0.8708\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8941 - val_loss: 0.1415 - val_acc: 0.8710\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1313 - acc: 0.8794 - val_loss: 0.1420 - val_acc: 0.8712\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1546 - acc: 0.8954 - val_loss: 0.1424 - val_acc: 0.8712\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1283 - acc: 0.8838 - val_loss: 0.1423 - val_acc: 0.8711\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1296 - acc: 0.8841 - val_loss: 0.1418 - val_acc: 0.8711\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1126 - acc: 0.8973 - val_loss: 0.1412 - val_acc: 0.8709\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1121 - acc: 0.8973 - val_loss: 0.1408 - val_acc: 0.8708\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1260 - acc: 0.8867 - val_loss: 0.1405 - val_acc: 0.8706\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8875 - val_loss: 0.1403 - val_acc: 0.8705\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2125 - acc: 0.8944 - val_loss: 0.1413 - val_acc: 0.8703\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1128 - acc: 0.8985 - val_loss: 0.1424 - val_acc: 0.8702\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8961 - val_loss: 0.1427 - val_acc: 0.8703\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1997 - acc: 0.8948 - val_loss: 0.1443 - val_acc: 0.8703\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1128 - acc: 0.8995 - val_loss: 0.1445 - val_acc: 0.8704\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8892 - val_loss: 0.1435 - val_acc: 0.8706\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1403 - acc: 0.8862 - val_loss: 0.1422 - val_acc: 0.8708\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1329 - acc: 0.8801 - val_loss: 0.1414 - val_acc: 0.8710\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1156 - acc: 0.8951 - val_loss: 0.1413 - val_acc: 0.8711\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1128 - acc: 0.8955 - val_loss: 0.1418 - val_acc: 0.8712\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1459 - acc: 0.8954 - val_loss: 0.1419 - val_acc: 0.8712\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1319 - acc: 0.8820 - val_loss: 0.1416 - val_acc: 0.8712\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1286 - acc: 0.8849 - val_loss: 0.1412 - val_acc: 0.8711\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2453 - acc: 0.8848 - val_loss: 0.1410 - val_acc: 0.8708\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8949 - val_loss: 0.1427 - val_acc: 0.8705\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8947 - val_loss: 0.1444 - val_acc: 0.8703\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1527 - acc: 0.8912 - val_loss: 0.1463 - val_acc: 0.8701\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8955 - val_loss: 0.1465 - val_acc: 0.8702\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1336 - acc: 0.8837 - val_loss: 0.1451 - val_acc: 0.8704\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1314 - acc: 0.8831 - val_loss: 0.1431 - val_acc: 0.8708\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8981 - val_loss: 0.1419 - val_acc: 0.8711\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1159 - acc: 0.8937 - val_loss: 0.1423 - val_acc: 0.8713\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1211 - acc: 0.8892 - val_loss: 0.1435 - val_acc: 0.8713\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8941 - val_loss: 0.1445 - val_acc: 0.8714\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1096 - acc: 0.9026 - val_loss: 0.1442 - val_acc: 0.8713\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1321 - acc: 0.8830 - val_loss: 0.1427 - val_acc: 0.8711\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8901 - val_loss: 0.1410 - val_acc: 0.8708\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8900 - val_loss: 0.1403 - val_acc: 0.8704\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1282 - acc: 0.8833 - val_loss: 0.1404 - val_acc: 0.8700\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1217 - acc: 0.8880 - val_loss: 0.1407 - val_acc: 0.8697\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8876 - val_loss: 0.1409 - val_acc: 0.8694\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1157 - acc: 0.8953 - val_loss: 0.1405 - val_acc: 0.8694\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1228 - acc: 0.8905 - val_loss: 0.1398 - val_acc: 0.8694\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1483 - acc: 0.8742 - val_loss: 0.1390 - val_acc: 0.8696\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1357 - acc: 0.8749 - val_loss: 0.1385 - val_acc: 0.8697\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1139 - acc: 0.8935 - val_loss: 0.1386 - val_acc: 0.8699\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1163 - acc: 0.8914 - val_loss: 0.1392 - val_acc: 0.8700\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8915 - val_loss: 0.1395 - val_acc: 0.8699\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1135 - acc: 0.8925 - val_loss: 0.1391 - val_acc: 0.8697\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1081 - acc: 0.8987 - val_loss: 0.1383 - val_acc: 0.8694\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1145 - acc: 0.8908 - val_loss: 0.1376 - val_acc: 0.8688\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1139 - acc: 0.8906 - val_loss: 0.1373 - val_acc: 0.8683\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2118 - acc: 0.8823 - val_loss: 0.1385 - val_acc: 0.8673\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1175 - acc: 0.8874 - val_loss: 0.1406 - val_acc: 0.8666\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1225 - acc: 0.8840 - val_loss: 0.1414 - val_acc: 0.8664\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1271 - acc: 0.8835 - val_loss: 0.1404 - val_acc: 0.8670\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1885 - acc: 0.8731 - val_loss: 0.1402 - val_acc: 0.8676\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1245 - acc: 0.8827 - val_loss: 0.1391 - val_acc: 0.8684\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1267 - acc: 0.8849 - val_loss: 0.1382 - val_acc: 0.8692\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8989 - val_loss: 0.1384 - val_acc: 0.8697\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1219 - acc: 0.8857 - val_loss: 0.1391 - val_acc: 0.8700\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8860 - val_loss: 0.1398 - val_acc: 0.8701\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1195 - acc: 0.8904 - val_loss: 0.1397 - val_acc: 0.8700\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1189 - acc: 0.8904 - val_loss: 0.1391 - val_acc: 0.8697\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1534 - acc: 0.8879 - val_loss: 0.1385 - val_acc: 0.8692\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2392 - acc: 0.8815 - val_loss: 0.1412 - val_acc: 0.8682\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1242 - acc: 0.8855 - val_loss: 0.1448 - val_acc: 0.8675\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1277 - acc: 0.8852 - val_loss: 0.1467 - val_acc: 0.8674\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8907 - val_loss: 0.1463 - val_acc: 0.8680\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1271 - acc: 0.8848 - val_loss: 0.1441 - val_acc: 0.8688\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1936 - acc: 0.8781 - val_loss: 0.1433 - val_acc: 0.8694\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1234 - acc: 0.8909 - val_loss: 0.1420 - val_acc: 0.8701\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1408 - acc: 0.8735 - val_loss: 0.1411 - val_acc: 0.8706\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1193 - acc: 0.8918 - val_loss: 0.1414 - val_acc: 0.8709\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1126 - acc: 0.8991 - val_loss: 0.1426 - val_acc: 0.8712\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1132 - acc: 0.8992 - val_loss: 0.1434 - val_acc: 0.8713\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8940 - val_loss: 0.1432 - val_acc: 0.8713\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1340 - acc: 0.8794 - val_loss: 0.1420 - val_acc: 0.8712\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1180 - acc: 0.8937 - val_loss: 0.1409 - val_acc: 0.8710\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1308 - acc: 0.8800 - val_loss: 0.1400 - val_acc: 0.8708\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1220 - acc: 0.8848 - val_loss: 0.1397 - val_acc: 0.8706\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1492 - acc: 0.8866 - val_loss: 0.1400 - val_acc: 0.8703\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8973 - val_loss: 0.1403 - val_acc: 0.8701\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8897 - val_loss: 0.1402 - val_acc: 0.8700\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1212 - acc: 0.8897 - val_loss: 0.1397 - val_acc: 0.8700\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1212 - acc: 0.8883 - val_loss: 0.1392 - val_acc: 0.8700\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1253 - acc: 0.8881 - val_loss: 0.1387 - val_acc: 0.8701\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1195 - acc: 0.8897 - val_loss: 0.1386 - val_acc: 0.8703\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1213 - acc: 0.8869 - val_loss: 0.1388 - val_acc: 0.8703\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2281 - acc: 0.8800 - val_loss: 0.1382 - val_acc: 0.8701\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1213 - acc: 0.8879 - val_loss: 0.1382 - val_acc: 0.8699\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1131 - acc: 0.8946 - val_loss: 0.1385 - val_acc: 0.8697\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1192 - acc: 0.8912 - val_loss: 0.1387 - val_acc: 0.8696\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8918 - val_loss: 0.1387 - val_acc: 0.8695\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8880 - val_loss: 0.1384 - val_acc: 0.8695\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1183 - acc: 0.8880 - val_loss: 0.1380 - val_acc: 0.8696\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1783 - acc: 0.8950 - val_loss: 0.1382 - val_acc: 0.8696\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1118 - acc: 0.8991 - val_loss: 0.1384 - val_acc: 0.8697\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1124 - acc: 0.8949 - val_loss: 0.1386 - val_acc: 0.8698\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1123 - acc: 0.8950 - val_loss: 0.1387 - val_acc: 0.8699\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1943 - acc: 0.8815 - val_loss: 0.1390 - val_acc: 0.8697\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8891 - val_loss: 0.1393 - val_acc: 0.8696\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1300 - acc: 0.8888 - val_loss: 0.1397 - val_acc: 0.8695\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1276 - acc: 0.8826 - val_loss: 0.1397 - val_acc: 0.8694\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1208 - acc: 0.8943 - val_loss: 0.1393 - val_acc: 0.8695\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1120 - acc: 0.8953 - val_loss: 0.1388 - val_acc: 0.8697\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1118 - acc: 0.8977 - val_loss: 0.1385 - val_acc: 0.8699\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1294 - acc: 0.8776 - val_loss: 0.1385 - val_acc: 0.8701\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1546 - acc: 0.8860 - val_loss: 0.1385 - val_acc: 0.8702\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8892 - val_loss: 0.1384 - val_acc: 0.8702\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8940 - val_loss: 0.1383 - val_acc: 0.8702\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8938 - val_loss: 0.1381 - val_acc: 0.8701\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1285 - acc: 0.8916 - val_loss: 0.1380 - val_acc: 0.8698\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1191 - acc: 0.8904 - val_loss: 0.1379 - val_acc: 0.8696\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1082 - acc: 0.9013 - val_loss: 0.1377 - val_acc: 0.8694\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1211 - acc: 0.8854 - val_loss: 0.1374 - val_acc: 0.8693\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1191 - acc: 0.8882 - val_loss: 0.1371 - val_acc: 0.8692\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8880 - val_loss: 0.1369 - val_acc: 0.8692\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1202 - acc: 0.8854 - val_loss: 0.1368 - val_acc: 0.8691\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1172 - acc: 0.8892 - val_loss: 0.1367 - val_acc: 0.8690\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1085 - acc: 0.8972 - val_loss: 0.1366 - val_acc: 0.8688\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1082 - acc: 0.8972 - val_loss: 0.1365 - val_acc: 0.8687\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1247 - acc: 0.8825 - val_loss: 0.1362 - val_acc: 0.8684\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1150 - acc: 0.8897 - val_loss: 0.1359 - val_acc: 0.8680\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1236 - acc: 0.8909 - val_loss: 0.1356 - val_acc: 0.8676\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1139 - acc: 0.8909 - val_loss: 0.1354 - val_acc: 0.8673\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1520 - acc: 0.8828 - val_loss: 0.1354 - val_acc: 0.8670\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1225 - acc: 0.8838 - val_loss: 0.1356 - val_acc: 0.8669\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1635 - acc: 0.8789 - val_loss: 0.1363 - val_acc: 0.8669\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1104 - acc: 0.8942 - val_loss: 0.1366 - val_acc: 0.8672\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8843 - val_loss: 0.1365 - val_acc: 0.8678\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1218 - acc: 0.8827 - val_loss: 0.1361 - val_acc: 0.8684\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8896 - val_loss: 0.1360 - val_acc: 0.8688\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1155 - acc: 0.8926 - val_loss: 0.1361 - val_acc: 0.8690\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1151 - acc: 0.8929 - val_loss: 0.1364 - val_acc: 0.8691\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1180 - acc: 0.8896 - val_loss: 0.1364 - val_acc: 0.8689\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1177 - acc: 0.8896 - val_loss: 0.1362 - val_acc: 0.8686\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1097 - acc: 0.8965 - val_loss: 0.1357 - val_acc: 0.8682\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1168 - acc: 0.8862 - val_loss: 0.1354 - val_acc: 0.8678\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1086 - acc: 0.8956 - val_loss: 0.1353 - val_acc: 0.8675\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8910 - val_loss: 0.1352 - val_acc: 0.8673\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1147 - acc: 0.8889 - val_loss: 0.1351 - val_acc: 0.8674\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1143 - acc: 0.8889 - val_loss: 0.1350 - val_acc: 0.8676\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8840 - val_loss: 0.1349 - val_acc: 0.8677\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8895 - val_loss: 0.1348 - val_acc: 0.8677\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1296 - acc: 0.8886 - val_loss: 0.1346 - val_acc: 0.8675\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1143 - acc: 0.8898 - val_loss: 0.1346 - val_acc: 0.8673\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1214 - acc: 0.8788 - val_loss: 0.1345 - val_acc: 0.8671\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8876 - val_loss: 0.1344 - val_acc: 0.8668\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2351 - acc: 0.8808 - val_loss: 0.1356 - val_acc: 0.8658\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1103 - acc: 0.8913 - val_loss: 0.1371 - val_acc: 0.8655\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1165 - acc: 0.8834 - val_loss: 0.1374 - val_acc: 0.8660\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1169 - acc: 0.8881 - val_loss: 0.1366 - val_acc: 0.8670\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1157 - acc: 0.8869 - val_loss: 0.1358 - val_acc: 0.8682\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8877 - val_loss: 0.1359 - val_acc: 0.8690\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1138 - acc: 0.8939 - val_loss: 0.1368 - val_acc: 0.8695\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1092 - acc: 0.8980 - val_loss: 0.1372 - val_acc: 0.8696\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1080 - acc: 0.9000 - val_loss: 0.1367 - val_acc: 0.8695\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1213 - acc: 0.8830 - val_loss: 0.1360 - val_acc: 0.8691\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8905 - val_loss: 0.1356 - val_acc: 0.8686\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1392 - acc: 0.8913 - val_loss: 0.1355 - val_acc: 0.8680\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2597 - acc: 0.8767 - val_loss: 0.1386 - val_acc: 0.8668\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8920 - val_loss: 0.1425 - val_acc: 0.8662\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8914 - val_loss: 0.1439 - val_acc: 0.8665\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1278 - acc: 0.8839 - val_loss: 0.1425 - val_acc: 0.8676\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1265 - acc: 0.8862 - val_loss: 0.1397 - val_acc: 0.8688\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1249 - acc: 0.8837 - val_loss: 0.1376 - val_acc: 0.8698\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1224 - acc: 0.8846 - val_loss: 0.1382 - val_acc: 0.8704\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1103 - acc: 0.8974 - val_loss: 0.1410 - val_acc: 0.8708\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1130 - acc: 0.8981 - val_loss: 0.1432 - val_acc: 0.8710\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2716 - acc: 0.8851 - val_loss: 0.1404 - val_acc: 0.8709\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - acc: 0.8885 - val_loss: 0.1389 - val_acc: 0.8706\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1121 - acc: 0.8956 - val_loss: 0.1396 - val_acc: 0.8703\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1131 - acc: 0.8954 - val_loss: 0.1410 - val_acc: 0.8700\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1174 - acc: 0.8927 - val_loss: 0.1417 - val_acc: 0.8699\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1195 - acc: 0.8919 - val_loss: 0.1412 - val_acc: 0.8700\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1312 - acc: 0.8833 - val_loss: 0.1401 - val_acc: 0.8702\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8939 - val_loss: 0.1390 - val_acc: 0.8705\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1214 - acc: 0.8868 - val_loss: 0.1388 - val_acc: 0.8707\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1142 - acc: 0.8924 - val_loss: 0.1396 - val_acc: 0.8709\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8906 - val_loss: 0.1405 - val_acc: 0.8710\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1183 - acc: 0.8912 - val_loss: 0.1408 - val_acc: 0.8709\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8912 - val_loss: 0.1402 - val_acc: 0.8708\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1261 - acc: 0.8839 - val_loss: 0.1385 - val_acc: 0.8705\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1132 - acc: 0.8942 - val_loss: 0.1372 - val_acc: 0.8702\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8878 - val_loss: 0.1364 - val_acc: 0.8698\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1144 - acc: 0.8901 - val_loss: 0.1361 - val_acc: 0.8695\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1211 - acc: 0.8876 - val_loss: 0.1361 - val_acc: 0.8691\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1276 - acc: 0.8874 - val_loss: 0.1362 - val_acc: 0.8687\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1124 - acc: 0.8914 - val_loss: 0.1359 - val_acc: 0.8685\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1120 - acc: 0.8912 - val_loss: 0.1355 - val_acc: 0.8684\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1187 - acc: 0.8884 - val_loss: 0.1351 - val_acc: 0.8685\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1225 - acc: 0.8843 - val_loss: 0.1350 - val_acc: 0.8685\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1220 - acc: 0.8844 - val_loss: 0.1351 - val_acc: 0.8683\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1092 - acc: 0.8937 - val_loss: 0.1351 - val_acc: 0.8682\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1088 - acc: 0.8935 - val_loss: 0.1349 - val_acc: 0.8680\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8863 - val_loss: 0.1345 - val_acc: 0.8677\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1210 - acc: 0.8798 - val_loss: 0.1341 - val_acc: 0.8673\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1347 - acc: 0.8735 - val_loss: 0.1339 - val_acc: 0.8666\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1334 - acc: 0.8729 - val_loss: 0.1342 - val_acc: 0.8658\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8934 - val_loss: 0.1342 - val_acc: 0.8653\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1174 - acc: 0.8884 - val_loss: 0.1340 - val_acc: 0.8654\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2441 - acc: 0.8655 - val_loss: 0.1362 - val_acc: 0.8640\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1158 - acc: 0.8841 - val_loss: 0.1381 - val_acc: 0.8634\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8850 - val_loss: 0.1383 - val_acc: 0.8639\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1146 - acc: 0.8883 - val_loss: 0.1374 - val_acc: 0.8651\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1135 - acc: 0.8894 - val_loss: 0.1366 - val_acc: 0.8664\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8877 - val_loss: 0.1363 - val_acc: 0.8677\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1127 - acc: 0.8888 - val_loss: 0.1367 - val_acc: 0.8687\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8877 - val_loss: 0.1372 - val_acc: 0.8692\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8919 - val_loss: 0.1372 - val_acc: 0.8695\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1143 - acc: 0.8920 - val_loss: 0.1366 - val_acc: 0.8696\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1210 - acc: 0.8883 - val_loss: 0.1356 - val_acc: 0.8693\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1197 - acc: 0.8880 - val_loss: 0.1349 - val_acc: 0.8690\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8897 - val_loss: 0.1348 - val_acc: 0.8685\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8892 - val_loss: 0.1350 - val_acc: 0.8680\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1277 - acc: 0.8851 - val_loss: 0.1353 - val_acc: 0.8677\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1162 - acc: 0.8845 - val_loss: 0.1352 - val_acc: 0.8676\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1775 - acc: 0.8801 - val_loss: 0.1359 - val_acc: 0.8674\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1172 - acc: 0.8893 - val_loss: 0.1360 - val_acc: 0.8675\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1203 - acc: 0.8847 - val_loss: 0.1354 - val_acc: 0.8680\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1169 - acc: 0.8846 - val_loss: 0.1348 - val_acc: 0.8685\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8850 - val_loss: 0.1347 - val_acc: 0.8689\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1122 - acc: 0.8919 - val_loss: 0.1351 - val_acc: 0.8691\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2613 - acc: 0.8727 - val_loss: 0.1349 - val_acc: 0.8686\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1524 - acc: 0.8779 - val_loss: 0.1365 - val_acc: 0.8679\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8865 - val_loss: 0.1383 - val_acc: 0.8674\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1220 - acc: 0.8821 - val_loss: 0.1390 - val_acc: 0.8674\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1223 - acc: 0.8821 - val_loss: 0.1383 - val_acc: 0.8677\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1130 - acc: 0.8932 - val_loss: 0.1369 - val_acc: 0.8683\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1244 - acc: 0.8880 - val_loss: 0.1364 - val_acc: 0.8689\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8916 - val_loss: 0.1373 - val_acc: 0.8696\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2257 - acc: 0.8808 - val_loss: 0.1375 - val_acc: 0.8697\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1203 - acc: 0.8866 - val_loss: 0.1374 - val_acc: 0.8698\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1172 - acc: 0.8907 - val_loss: 0.1374 - val_acc: 0.8698\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1151 - acc: 0.8916 - val_loss: 0.1374 - val_acc: 0.8698\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1137 - acc: 0.8944 - val_loss: 0.1375 - val_acc: 0.8699\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8894 - val_loss: 0.1374 - val_acc: 0.8699\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1145 - acc: 0.8895 - val_loss: 0.1373 - val_acc: 0.8699\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2153 - acc: 0.8867 - val_loss: 0.1377 - val_acc: 0.8697\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1109 - acc: 0.8961 - val_loss: 0.1381 - val_acc: 0.8697\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1294 - acc: 0.8792 - val_loss: 0.1382 - val_acc: 0.8697\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8793 - val_loss: 0.1379 - val_acc: 0.8698\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1125 - acc: 0.8945 - val_loss: 0.1375 - val_acc: 0.8700\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1203 - acc: 0.8878 - val_loss: 0.1372 - val_acc: 0.8701\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8984 - val_loss: 0.1372 - val_acc: 0.8703\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1090 - acc: 0.8987 - val_loss: 0.1374 - val_acc: 0.8703\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1063 - acc: 0.8995 - val_loss: 0.1375 - val_acc: 0.8703\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1121 - acc: 0.8988 - val_loss: 0.1373 - val_acc: 0.8702\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1128 - acc: 0.8940 - val_loss: 0.1369 - val_acc: 0.8701\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1414 - acc: 0.8914 - val_loss: 0.1363 - val_acc: 0.8698\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8862 - val_loss: 0.1359 - val_acc: 0.8694\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1230 - acc: 0.8819 - val_loss: 0.1355 - val_acc: 0.8690\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8842 - val_loss: 0.1352 - val_acc: 0.8686\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1046 - acc: 0.9000 - val_loss: 0.1349 - val_acc: 0.8684\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1828 - acc: 0.8905 - val_loss: 0.1354 - val_acc: 0.8679\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1083 - acc: 0.8938 - val_loss: 0.1357 - val_acc: 0.8678\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1097 - acc: 0.8961 - val_loss: 0.1354 - val_acc: 0.8680\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1131 - acc: 0.8929 - val_loss: 0.1349 - val_acc: 0.8684\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1065 - acc: 0.9014 - val_loss: 0.1348 - val_acc: 0.8689\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1339 - acc: 0.8870 - val_loss: 0.1351 - val_acc: 0.8692\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1186 - acc: 0.8878 - val_loss: 0.1353 - val_acc: 0.8694\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8879 - val_loss: 0.1351 - val_acc: 0.8693\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8873 - val_loss: 0.1348 - val_acc: 0.8690\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1257 - acc: 0.8786 - val_loss: 0.1344 - val_acc: 0.8686\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - acc: 0.8783 - val_loss: 0.1342 - val_acc: 0.8682\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1100 - acc: 0.8923 - val_loss: 0.1341 - val_acc: 0.8679\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1408 - acc: 0.8800 - val_loss: 0.1340 - val_acc: 0.8675\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8804 - val_loss: 0.1339 - val_acc: 0.8674\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1596 - acc: 0.8751 - val_loss: 0.1341 - val_acc: 0.8671\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8831 - val_loss: 0.1341 - val_acc: 0.8671\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8891 - val_loss: 0.1338 - val_acc: 0.8674\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1248 - acc: 0.8774 - val_loss: 0.1334 - val_acc: 0.8677\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1122 - acc: 0.8891 - val_loss: 0.1334 - val_acc: 0.8679\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1969 - acc: 0.8846 - val_loss: 0.1335 - val_acc: 0.8679\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1106 - acc: 0.8933 - val_loss: 0.1336 - val_acc: 0.8678\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1085 - acc: 0.8943 - val_loss: 0.1337 - val_acc: 0.8677\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1029 - acc: 0.8998 - val_loss: 0.1338 - val_acc: 0.8676\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1066 - acc: 0.8934 - val_loss: 0.1338 - val_acc: 0.8675\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1694 - acc: 0.8832 - val_loss: 0.1342 - val_acc: 0.8671\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8876 - val_loss: 0.1347 - val_acc: 0.8671\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1217 - acc: 0.8863 - val_loss: 0.1347 - val_acc: 0.8673\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1216 - acc: 0.8829 - val_loss: 0.1343 - val_acc: 0.8679\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8851 - val_loss: 0.1340 - val_acc: 0.8686\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8885 - val_loss: 0.1343 - val_acc: 0.8691\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1130 - acc: 0.8890 - val_loss: 0.1347 - val_acc: 0.8692\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1131 - acc: 0.8921 - val_loss: 0.1348 - val_acc: 0.8691\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1169 - acc: 0.8849 - val_loss: 0.1343 - val_acc: 0.8687\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8844 - val_loss: 0.1335 - val_acc: 0.8680\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1081 - acc: 0.8942 - val_loss: 0.1329 - val_acc: 0.8672\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1156 - acc: 0.8854 - val_loss: 0.1327 - val_acc: 0.8666\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1083 - acc: 0.8935 - val_loss: 0.1325 - val_acc: 0.8663\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1281 - acc: 0.8797 - val_loss: 0.1324 - val_acc: 0.8663\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1081 - acc: 0.8957 - val_loss: 0.1323 - val_acc: 0.8667\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1118 - acc: 0.8911 - val_loss: 0.1323 - val_acc: 0.8672\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1075 - acc: 0.8935 - val_loss: 0.1323 - val_acc: 0.8675\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1169 - acc: 0.8830 - val_loss: 0.1321 - val_acc: 0.8674\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8831 - val_loss: 0.1319 - val_acc: 0.8668\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8860 - val_loss: 0.1318 - val_acc: 0.8662\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8811 - val_loss: 0.1316 - val_acc: 0.8653\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2225 - acc: 0.8635 - val_loss: 0.1326 - val_acc: 0.8637\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2043 - acc: 0.8662 - val_loss: 0.1365 - val_acc: 0.8620\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1176 - acc: 0.8843 - val_loss: 0.1387 - val_acc: 0.8622\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8849 - val_loss: 0.1379 - val_acc: 0.8642\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1125 - acc: 0.8937 - val_loss: 0.1357 - val_acc: 0.8668\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1290 - acc: 0.8875 - val_loss: 0.1347 - val_acc: 0.8686\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1084 - acc: 0.8951 - val_loss: 0.1353 - val_acc: 0.8696\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1295 - acc: 0.8793 - val_loss: 0.1357 - val_acc: 0.8700\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1259 - acc: 0.8824 - val_loss: 0.1352 - val_acc: 0.8701\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1173 - acc: 0.8926 - val_loss: 0.1346 - val_acc: 0.8698\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2264 - acc: 0.8763 - val_loss: 0.1347 - val_acc: 0.8692\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1271 - acc: 0.8799 - val_loss: 0.1363 - val_acc: 0.8687\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1125 - acc: 0.8959 - val_loss: 0.1376 - val_acc: 0.8685\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1147 - acc: 0.8938 - val_loss: 0.1379 - val_acc: 0.8686\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1338 - acc: 0.8949 - val_loss: 0.1376 - val_acc: 0.8689\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1213 - acc: 0.8868 - val_loss: 0.1367 - val_acc: 0.8694\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1279 - acc: 0.8846 - val_loss: 0.1360 - val_acc: 0.8699\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1239 - acc: 0.8831 - val_loss: 0.1358 - val_acc: 0.8702\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1345 - acc: 0.8950 - val_loss: 0.1360 - val_acc: 0.8704\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8905 - val_loss: 0.1361 - val_acc: 0.8705\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1181 - acc: 0.8905 - val_loss: 0.1359 - val_acc: 0.8704\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8909 - val_loss: 0.1354 - val_acc: 0.8703\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2552 - acc: 0.8747 - val_loss: 0.1358 - val_acc: 0.8699\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1327 - acc: 0.8846 - val_loss: 0.1374 - val_acc: 0.8696\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8929 - val_loss: 0.1390 - val_acc: 0.8694\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8872 - val_loss: 0.1393 - val_acc: 0.8693\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1328 - acc: 0.8784 - val_loss: 0.1384 - val_acc: 0.8695\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1140 - acc: 0.8910 - val_loss: 0.1370 - val_acc: 0.8698\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1198 - acc: 0.8856 - val_loss: 0.1362 - val_acc: 0.8700\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1269 - acc: 0.8851 - val_loss: 0.1364 - val_acc: 0.8703\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1114 - acc: 0.8945 - val_loss: 0.1370 - val_acc: 0.8704\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1116 - acc: 0.8947 - val_loss: 0.1371 - val_acc: 0.8704\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8877 - val_loss: 0.1364 - val_acc: 0.8703\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1094 - acc: 0.8959 - val_loss: 0.1354 - val_acc: 0.8700\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1106 - acc: 0.8950 - val_loss: 0.1345 - val_acc: 0.8695\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1080 - acc: 0.8966 - val_loss: 0.1341 - val_acc: 0.8691\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1070 - acc: 0.8957 - val_loss: 0.1338 - val_acc: 0.8688\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1067 - acc: 0.8954 - val_loss: 0.1335 - val_acc: 0.8685\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1179 - acc: 0.8849 - val_loss: 0.1331 - val_acc: 0.8683\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1290 - acc: 0.8845 - val_loss: 0.1326 - val_acc: 0.8682\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1056 - acc: 0.8965 - val_loss: 0.1322 - val_acc: 0.8683\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8867 - val_loss: 0.1321 - val_acc: 0.8684\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1200 - acc: 0.8824 - val_loss: 0.1320 - val_acc: 0.8683\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1166 - acc: 0.8861 - val_loss: 0.1319 - val_acc: 0.8682\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8851 - val_loss: 0.1317 - val_acc: 0.8679\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8850 - val_loss: 0.1315 - val_acc: 0.8676\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1054 - acc: 0.8950 - val_loss: 0.1313 - val_acc: 0.8672\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8946 - val_loss: 0.1311 - val_acc: 0.8667\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1121 - acc: 0.8873 - val_loss: 0.1310 - val_acc: 0.8662\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1165 - acc: 0.8821 - val_loss: 0.1311 - val_acc: 0.8656\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1123 - acc: 0.8931 - val_loss: 0.1311 - val_acc: 0.8650\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8803 - val_loss: 0.1310 - val_acc: 0.8646\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.8788 - val_loss: 0.1308 - val_acc: 0.8646\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8830 - val_loss: 0.1306 - val_acc: 0.8646\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1131 - acc: 0.8820 - val_loss: 0.1304 - val_acc: 0.8647\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1125 - acc: 0.8822 - val_loss: 0.1302 - val_acc: 0.8646\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1212 - acc: 0.8750 - val_loss: 0.1302 - val_acc: 0.8646\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1086 - acc: 0.8893 - val_loss: 0.1303 - val_acc: 0.8648\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2306 - acc: 0.8716 - val_loss: 0.1304 - val_acc: 0.8640\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8840 - val_loss: 0.1310 - val_acc: 0.8638\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1196 - acc: 0.8804 - val_loss: 0.1311 - val_acc: 0.8644\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1114 - acc: 0.8871 - val_loss: 0.1308 - val_acc: 0.8655\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8910 - val_loss: 0.1307 - val_acc: 0.8666\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1228 - acc: 0.8858 - val_loss: 0.1310 - val_acc: 0.8674\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1092 - acc: 0.8909 - val_loss: 0.1311 - val_acc: 0.8676\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1111 - acc: 0.8871 - val_loss: 0.1309 - val_acc: 0.8675\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1106 - acc: 0.8869 - val_loss: 0.1307 - val_acc: 0.8671\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8864 - val_loss: 0.1307 - val_acc: 0.8666\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1064 - acc: 0.8922 - val_loss: 0.1307 - val_acc: 0.8663\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1062 - acc: 0.8915 - val_loss: 0.1306 - val_acc: 0.8661\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1060 - acc: 0.8915 - val_loss: 0.1306 - val_acc: 0.8661\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8753 - val_loss: 0.1304 - val_acc: 0.8662\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1098 - acc: 0.8867 - val_loss: 0.1303 - val_acc: 0.8664\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1095 - acc: 0.8869 - val_loss: 0.1301 - val_acc: 0.8665\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8791 - val_loss: 0.1300 - val_acc: 0.8666\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1174 - acc: 0.8792 - val_loss: 0.1301 - val_acc: 0.8665\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1039 - acc: 0.8933 - val_loss: 0.1302 - val_acc: 0.8665\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8828 - val_loss: 0.1300 - val_acc: 0.8662\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8826 - val_loss: 0.1298 - val_acc: 0.8657\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1069 - acc: 0.8911 - val_loss: 0.1297 - val_acc: 0.8654\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1034 - acc: 0.8945 - val_loss: 0.1297 - val_acc: 0.8652\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1031 - acc: 0.8946 - val_loss: 0.1298 - val_acc: 0.8651\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1144 - acc: 0.8845 - val_loss: 0.1298 - val_acc: 0.8652\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1060 - acc: 0.8925 - val_loss: 0.1297 - val_acc: 0.8653\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1159 - acc: 0.8818 - val_loss: 0.1296 - val_acc: 0.8651\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.8817 - val_loss: 0.1296 - val_acc: 0.8647\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1217 - acc: 0.8751 - val_loss: 0.1296 - val_acc: 0.8641\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2718 - acc: 0.8610 - val_loss: 0.1324 - val_acc: 0.8623\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1075 - acc: 0.8876 - val_loss: 0.1352 - val_acc: 0.8617\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8788 - val_loss: 0.1353 - val_acc: 0.8628\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1265 - acc: 0.8743 - val_loss: 0.1333 - val_acc: 0.8651\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1219 - acc: 0.8791 - val_loss: 0.1314 - val_acc: 0.8673\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1195 - acc: 0.8812 - val_loss: 0.1319 - val_acc: 0.8688\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1150 - acc: 0.8921 - val_loss: 0.1343 - val_acc: 0.8696\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1106 - acc: 0.8937 - val_loss: 0.1353 - val_acc: 0.8698\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1108 - acc: 0.8938 - val_loss: 0.1340 - val_acc: 0.8695\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1534 - acc: 0.8800 - val_loss: 0.1321 - val_acc: 0.8688\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1179 - acc: 0.8812 - val_loss: 0.1325 - val_acc: 0.8679\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2719 - acc: 0.8684 - val_loss: 0.1390 - val_acc: 0.8660\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1259 - acc: 0.8795 - val_loss: 0.1458 - val_acc: 0.8647\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1312 - acc: 0.8891 - val_loss: 0.1486 - val_acc: 0.8649\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1293 - acc: 0.8841 - val_loss: 0.1460 - val_acc: 0.8665\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1266 - acc: 0.8854 - val_loss: 0.1407 - val_acc: 0.8683\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1286 - acc: 0.8814 - val_loss: 0.1370 - val_acc: 0.8695\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1245 - acc: 0.8828 - val_loss: 0.1371 - val_acc: 0.8703\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1263 - acc: 0.8822 - val_loss: 0.1401 - val_acc: 0.8707\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2485 - acc: 0.8838 - val_loss: 0.1407 - val_acc: 0.8709\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1280 - acc: 0.8831 - val_loss: 0.1395 - val_acc: 0.8708\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1477 - acc: 0.8841 - val_loss: 0.1382 - val_acc: 0.8707\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8887 - val_loss: 0.1380 - val_acc: 0.8705\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1094 - acc: 0.8975 - val_loss: 0.1387 - val_acc: 0.8703\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8974 - val_loss: 0.1393 - val_acc: 0.8701\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2013 - acc: 0.8881 - val_loss: 0.1413 - val_acc: 0.8699\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1383 - acc: 0.8745 - val_loss: 0.1420 - val_acc: 0.8699\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1389 - acc: 0.8746 - val_loss: 0.1412 - val_acc: 0.8701\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8941 - val_loss: 0.1397 - val_acc: 0.8704\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8919 - val_loss: 0.1383 - val_acc: 0.8707\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8921 - val_loss: 0.1378 - val_acc: 0.8709\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8938 - val_loss: 0.1382 - val_acc: 0.8711\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1890 - acc: 0.8928 - val_loss: 0.1384 - val_acc: 0.8712\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1079 - acc: 0.8999 - val_loss: 0.1383 - val_acc: 0.8712\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8921 - val_loss: 0.1376 - val_acc: 0.8711\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8900 - val_loss: 0.1368 - val_acc: 0.8710\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1201 - acc: 0.8870 - val_loss: 0.1360 - val_acc: 0.8708\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1073 - acc: 0.8982 - val_loss: 0.1356 - val_acc: 0.8705\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1070 - acc: 0.8979 - val_loss: 0.1354 - val_acc: 0.8704\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8851 - val_loss: 0.1351 - val_acc: 0.8702\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1227 - acc: 0.8866 - val_loss: 0.1347 - val_acc: 0.8701\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1033 - acc: 0.8998 - val_loss: 0.1342 - val_acc: 0.8700\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1864 - acc: 0.8929 - val_loss: 0.1344 - val_acc: 0.8698\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8956 - val_loss: 0.1343 - val_acc: 0.8698\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8855 - val_loss: 0.1340 - val_acc: 0.8698\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1143 - acc: 0.8900 - val_loss: 0.1335 - val_acc: 0.8698\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1136 - acc: 0.8900 - val_loss: 0.1331 - val_acc: 0.8698\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1140 - acc: 0.8897 - val_loss: 0.1329 - val_acc: 0.8698\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1118 - acc: 0.8888 - val_loss: 0.1327 - val_acc: 0.8697\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8865 - val_loss: 0.1324 - val_acc: 0.8696\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8864 - val_loss: 0.1320 - val_acc: 0.8693\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1074 - acc: 0.8920 - val_loss: 0.1315 - val_acc: 0.8690\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2087 - acc: 0.8776 - val_loss: 0.1316 - val_acc: 0.8682\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1136 - acc: 0.8849 - val_loss: 0.1327 - val_acc: 0.8673\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1145 - acc: 0.8888 - val_loss: 0.1336 - val_acc: 0.8668\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1222 - acc: 0.8790 - val_loss: 0.1334 - val_acc: 0.8667\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1554 - acc: 0.8664 - val_loss: 0.1327 - val_acc: 0.8671\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8891 - val_loss: 0.1319 - val_acc: 0.8677\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1234 - acc: 0.8957 - val_loss: 0.1315 - val_acc: 0.8683\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1089 - acc: 0.8914 - val_loss: 0.1316 - val_acc: 0.8688\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1236 - acc: 0.8767 - val_loss: 0.1318 - val_acc: 0.8691\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1098 - acc: 0.8919 - val_loss: 0.1321 - val_acc: 0.8693\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1076 - acc: 0.8940 - val_loss: 0.1323 - val_acc: 0.8693\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1231 - acc: 0.8797 - val_loss: 0.1318 - val_acc: 0.8692\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1579 - acc: 0.8825 - val_loss: 0.1310 - val_acc: 0.8687\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1137 - acc: 0.8872 - val_loss: 0.1309 - val_acc: 0.8681\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1042 - acc: 0.8955 - val_loss: 0.1313 - val_acc: 0.8677\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1140 - acc: 0.8869 - val_loss: 0.1315 - val_acc: 0.8674\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1197 - acc: 0.8842 - val_loss: 0.1312 - val_acc: 0.8675\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8848 - val_loss: 0.1306 - val_acc: 0.8679\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1124 - acc: 0.8887 - val_loss: 0.1303 - val_acc: 0.8684\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1060 - acc: 0.8909 - val_loss: 0.1304 - val_acc: 0.8687\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2360 - acc: 0.8713 - val_loss: 0.1305 - val_acc: 0.8684\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1164 - acc: 0.8842 - val_loss: 0.1310 - val_acc: 0.8680\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1079 - acc: 0.8933 - val_loss: 0.1314 - val_acc: 0.8679\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1127 - acc: 0.8892 - val_loss: 0.1313 - val_acc: 0.8679\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8911 - val_loss: 0.1310 - val_acc: 0.8681\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1097 - acc: 0.8913 - val_loss: 0.1307 - val_acc: 0.8683\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1122 - acc: 0.8874 - val_loss: 0.1307 - val_acc: 0.8686\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1063 - acc: 0.8971 - val_loss: 0.1310 - val_acc: 0.8688\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1133 - acc: 0.8919 - val_loss: 0.1314 - val_acc: 0.8688\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1161 - acc: 0.8912 - val_loss: 0.1315 - val_acc: 0.8687\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1152 - acc: 0.8881 - val_loss: 0.1311 - val_acc: 0.8685\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1072 - acc: 0.8924 - val_loss: 0.1305 - val_acc: 0.8681\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1108 - acc: 0.8877 - val_loss: 0.1301 - val_acc: 0.8677\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1101 - acc: 0.8874 - val_loss: 0.1300 - val_acc: 0.8672\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8804 - val_loss: 0.1300 - val_acc: 0.8668\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1055 - acc: 0.8928 - val_loss: 0.1299 - val_acc: 0.8668\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1077 - acc: 0.8915 - val_loss: 0.1297 - val_acc: 0.8671\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1047 - acc: 0.8950 - val_loss: 0.1297 - val_acc: 0.8675\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1041 - acc: 0.8957 - val_loss: 0.1301 - val_acc: 0.8679\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8765 - val_loss: 0.1300 - val_acc: 0.8678\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8766 - val_loss: 0.1295 - val_acc: 0.8674\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1073 - acc: 0.8909 - val_loss: 0.1292 - val_acc: 0.8668\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1069 - acc: 0.8905 - val_loss: 0.1291 - val_acc: 0.8662\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1356 - acc: 0.8840 - val_loss: 0.1293 - val_acc: 0.8651\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1348 - acc: 0.8888 - val_loss: 0.1300 - val_acc: 0.8642\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1130 - acc: 0.8849 - val_loss: 0.1304 - val_acc: 0.8641\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1041 - acc: 0.8955 - val_loss: 0.1299 - val_acc: 0.8649\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2867 - acc: 0.8571 - val_loss: 0.1329 - val_acc: 0.8645\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1171 - acc: 0.8819 - val_loss: 0.1350 - val_acc: 0.8648\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1231 - acc: 0.8804 - val_loss: 0.1347 - val_acc: 0.8661\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8876 - val_loss: 0.1329 - val_acc: 0.8676\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1058 - acc: 0.8959 - val_loss: 0.1319 - val_acc: 0.8688\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1046 - acc: 0.8969 - val_loss: 0.1325 - val_acc: 0.8696\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1206 - acc: 0.8832 - val_loss: 0.1339 - val_acc: 0.8699\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1212 - acc: 0.8835 - val_loss: 0.1345 - val_acc: 0.8700\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2186 - acc: 0.8865 - val_loss: 0.1335 - val_acc: 0.8697\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2037 - acc: 0.8813 - val_loss: 0.1340 - val_acc: 0.8691\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8859 - val_loss: 0.1366 - val_acc: 0.8687\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1356 - acc: 0.8826 - val_loss: 0.1391 - val_acc: 0.8686\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1250 - acc: 0.8828 - val_loss: 0.1399 - val_acc: 0.8688\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1258 - acc: 0.8854 - val_loss: 0.1387 - val_acc: 0.8693\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1260 - acc: 0.8840 - val_loss: 0.1369 - val_acc: 0.8699\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8904 - val_loss: 0.1357 - val_acc: 0.8704\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8913 - val_loss: 0.1361 - val_acc: 0.8708\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8919 - val_loss: 0.1376 - val_acc: 0.8710\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1159 - acc: 0.8942 - val_loss: 0.1389 - val_acc: 0.8710\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1198 - acc: 0.8909 - val_loss: 0.1384 - val_acc: 0.8709\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8909 - val_loss: 0.1365 - val_acc: 0.8706\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1091 - acc: 0.8981 - val_loss: 0.1347 - val_acc: 0.8702\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1240 - acc: 0.8896 - val_loss: 0.1336 - val_acc: 0.8698\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1107 - acc: 0.8928 - val_loss: 0.1332 - val_acc: 0.8693\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1107 - acc: 0.8925 - val_loss: 0.1329 - val_acc: 0.8691\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1354 - acc: 0.8878 - val_loss: 0.1328 - val_acc: 0.8689\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1136 - acc: 0.8899 - val_loss: 0.1325 - val_acc: 0.8690\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2234 - acc: 0.8784 - val_loss: 0.1337 - val_acc: 0.8688\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1136 - acc: 0.8902 - val_loss: 0.1341 - val_acc: 0.8689\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8901 - val_loss: 0.1335 - val_acc: 0.8692\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1212 - acc: 0.8809 - val_loss: 0.1324 - val_acc: 0.8697\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1199 - acc: 0.8814 - val_loss: 0.1319 - val_acc: 0.8700\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8895 - val_loss: 0.1323 - val_acc: 0.8703\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8898 - val_loss: 0.1330 - val_acc: 0.8703\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1183 - acc: 0.8853 - val_loss: 0.1330 - val_acc: 0.8702\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8852 - val_loss: 0.1321 - val_acc: 0.8699\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1119 - acc: 0.8876 - val_loss: 0.1309 - val_acc: 0.8694\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1110 - acc: 0.8888 - val_loss: 0.1302 - val_acc: 0.8687\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1073 - acc: 0.8909 - val_loss: 0.1301 - val_acc: 0.8679\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1072 - acc: 0.8904 - val_loss: 0.1303 - val_acc: 0.8672\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1063 - acc: 0.8952 - val_loss: 0.1302 - val_acc: 0.8669\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8906 - val_loss: 0.1297 - val_acc: 0.8669\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1031 - acc: 0.8969 - val_loss: 0.1291 - val_acc: 0.8673\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1167 - acc: 0.8807 - val_loss: 0.1291 - val_acc: 0.8678\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1173 - acc: 0.8901 - val_loss: 0.1295 - val_acc: 0.8680\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8929 - val_loss: 0.1296 - val_acc: 0.8679\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8852 - val_loss: 0.1292 - val_acc: 0.8675\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8926 - val_loss: 0.1286 - val_acc: 0.8669\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1147 - acc: 0.8849 - val_loss: 0.1283 - val_acc: 0.8662\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1142 - acc: 0.8860 - val_loss: 0.1284 - val_acc: 0.8654\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1146 - acc: 0.8812 - val_loss: 0.1286 - val_acc: 0.8649\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1044 - acc: 0.8928 - val_loss: 0.1284 - val_acc: 0.8652\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1038 - acc: 0.8930 - val_loss: 0.1281 - val_acc: 0.8660\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1104 - acc: 0.8855 - val_loss: 0.1282 - val_acc: 0.8667\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1101 - acc: 0.8861 - val_loss: 0.1285 - val_acc: 0.8671\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1123 - acc: 0.8848 - val_loss: 0.1285 - val_acc: 0.8671\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1037 - acc: 0.8932 - val_loss: 0.1282 - val_acc: 0.8668\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1033 - acc: 0.8929 - val_loss: 0.1278 - val_acc: 0.8662\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1075 - acc: 0.8892 - val_loss: 0.1277 - val_acc: 0.8654\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1073 - acc: 0.8887 - val_loss: 0.1277 - val_acc: 0.8649\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1050 - acc: 0.8888 - val_loss: 0.1277 - val_acc: 0.8647\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1048 - acc: 0.8887 - val_loss: 0.1276 - val_acc: 0.8648\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1046 - acc: 0.8878 - val_loss: 0.1275 - val_acc: 0.8651\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1041 - acc: 0.8883 - val_loss: 0.1275 - val_acc: 0.8656\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2396 - acc: 0.8701 - val_loss: 0.1283 - val_acc: 0.8647\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1163 - acc: 0.8862 - val_loss: 0.1300 - val_acc: 0.8640\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1123 - acc: 0.8837 - val_loss: 0.1305 - val_acc: 0.8644\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1093 - acc: 0.8878 - val_loss: 0.1299 - val_acc: 0.8657\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1083 - acc: 0.8891 - val_loss: 0.1294 - val_acc: 0.8672\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1086 - acc: 0.8885 - val_loss: 0.1295 - val_acc: 0.8683\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8867 - val_loss: 0.1301 - val_acc: 0.8691\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1161 - acc: 0.8875 - val_loss: 0.1304 - val_acc: 0.8694\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1112 - acc: 0.8887 - val_loss: 0.1299 - val_acc: 0.8693\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8843 - val_loss: 0.1291 - val_acc: 0.8688\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1244 - acc: 0.8892 - val_loss: 0.1292 - val_acc: 0.8680\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8836 - val_loss: 0.1298 - val_acc: 0.8672\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8874 - val_loss: 0.1301 - val_acc: 0.8668\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2640 - acc: 0.8669 - val_loss: 0.1334 - val_acc: 0.8658\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8862 - val_loss: 0.1360 - val_acc: 0.8656\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1126 - acc: 0.8912 - val_loss: 0.1360 - val_acc: 0.8664\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8851 - val_loss: 0.1340 - val_acc: 0.8676\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1150 - acc: 0.8890 - val_loss: 0.1317 - val_acc: 0.8689\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1763 - acc: 0.8762 - val_loss: 0.1314 - val_acc: 0.8696\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1411 - acc: 0.8758 - val_loss: 0.1317 - val_acc: 0.8701\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8967 - val_loss: 0.1323 - val_acc: 0.8705\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1103 - acc: 0.8930 - val_loss: 0.1329 - val_acc: 0.8706\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8826 - val_loss: 0.1329 - val_acc: 0.8705\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1146 - acc: 0.8900 - val_loss: 0.1325 - val_acc: 0.8704\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1131 - acc: 0.8906 - val_loss: 0.1320 - val_acc: 0.8702\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1124 - acc: 0.8904 - val_loss: 0.1316 - val_acc: 0.8699\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2156 - acc: 0.8830 - val_loss: 0.1329 - val_acc: 0.8693\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1108 - acc: 0.8902 - val_loss: 0.1347 - val_acc: 0.8688\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1132 - acc: 0.8899 - val_loss: 0.1354 - val_acc: 0.8686\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1258 - acc: 0.8787 - val_loss: 0.1348 - val_acc: 0.8688\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8873 - val_loss: 0.1334 - val_acc: 0.8693\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8931 - val_loss: 0.1321 - val_acc: 0.8698\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1088 - acc: 0.8936 - val_loss: 0.1319 - val_acc: 0.8702\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8867 - val_loss: 0.1325 - val_acc: 0.8704\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1260 - acc: 0.8769 - val_loss: 0.1329 - val_acc: 0.8705\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1124 - acc: 0.8904 - val_loss: 0.1325 - val_acc: 0.8704\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3101 - acc: 0.8736 - val_loss: 0.1311 - val_acc: 0.8700\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1132 - acc: 0.8865 - val_loss: 0.1331 - val_acc: 0.8694\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8861 - val_loss: 0.1360 - val_acc: 0.8688\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8886 - val_loss: 0.1374 - val_acc: 0.8685\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1226 - acc: 0.8903 - val_loss: 0.1366 - val_acc: 0.8687\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1219 - acc: 0.8859 - val_loss: 0.1346 - val_acc: 0.8692\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1172 - acc: 0.8855 - val_loss: 0.1327 - val_acc: 0.8696\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1089 - acc: 0.8953 - val_loss: 0.1323 - val_acc: 0.8700\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1122 - acc: 0.8926 - val_loss: 0.1336 - val_acc: 0.8703\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8816 - val_loss: 0.1347 - val_acc: 0.8704\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1084 - acc: 0.8959 - val_loss: 0.1348 - val_acc: 0.8703\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8849 - val_loss: 0.1331 - val_acc: 0.8701\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1039 - acc: 0.8968 - val_loss: 0.1313 - val_acc: 0.8696\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1053 - acc: 0.8954 - val_loss: 0.1303 - val_acc: 0.8691\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1047 - acc: 0.8948 - val_loss: 0.1300 - val_acc: 0.8684\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1108 - acc: 0.8911 - val_loss: 0.1300 - val_acc: 0.8679\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8850 - val_loss: 0.1298 - val_acc: 0.8675\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1067 - acc: 0.8922 - val_loss: 0.1294 - val_acc: 0.8674\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1123 - acc: 0.8876 - val_loss: 0.1288 - val_acc: 0.8677\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1113 - acc: 0.8880 - val_loss: 0.1285 - val_acc: 0.8680\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1058 - acc: 0.8928 - val_loss: 0.1287 - val_acc: 0.8683\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1515 - acc: 0.8841 - val_loss: 0.1287 - val_acc: 0.8681\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1067 - acc: 0.8883 - val_loss: 0.1285 - val_acc: 0.8677\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1084 - acc: 0.8874 - val_loss: 0.1281 - val_acc: 0.8671\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1060 - acc: 0.8908 - val_loss: 0.1279 - val_acc: 0.8665\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1056 - acc: 0.8900 - val_loss: 0.1277 - val_acc: 0.8660\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1033 - acc: 0.8914 - val_loss: 0.1276 - val_acc: 0.8657\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1030 - acc: 0.8913 - val_loss: 0.1275 - val_acc: 0.8657\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1121 - acc: 0.8841 - val_loss: 0.1275 - val_acc: 0.8659\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1118 - acc: 0.8845 - val_loss: 0.1274 - val_acc: 0.8662\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1018 - acc: 0.8959 - val_loss: 0.1272 - val_acc: 0.8665\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0984 - acc: 0.8966 - val_loss: 0.1272 - val_acc: 0.8667\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1059 - acc: 0.8900 - val_loss: 0.1273 - val_acc: 0.8669\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1056 - acc: 0.8902 - val_loss: 0.1274 - val_acc: 0.8669\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1112 - acc: 0.8841 - val_loss: 0.1273 - val_acc: 0.8667\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1106 - acc: 0.8840 - val_loss: 0.1271 - val_acc: 0.8662\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.3241 - acc: 0.8585 - val_loss: 0.1293 - val_acc: 0.8640\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8800 - val_loss: 0.1340 - val_acc: 0.8620\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1191 - acc: 0.8786 - val_loss: 0.1360 - val_acc: 0.8618\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1110 - acc: 0.8889 - val_loss: 0.1344 - val_acc: 0.8636\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1103 - acc: 0.8925 - val_loss: 0.1314 - val_acc: 0.8661\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1104 - acc: 0.8910 - val_loss: 0.1298 - val_acc: 0.8680\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1002 - acc: 0.9010 - val_loss: 0.1309 - val_acc: 0.8692\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1004 - acc: 0.9019 - val_loss: 0.1335 - val_acc: 0.8698\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1096 - acc: 0.8897 - val_loss: 0.1343 - val_acc: 0.8700\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1171 - acc: 0.8883 - val_loss: 0.1326 - val_acc: 0.8699\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1152 - acc: 0.8883 - val_loss: 0.1305 - val_acc: 0.8694\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1124 - acc: 0.8867 - val_loss: 0.1297 - val_acc: 0.8687\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1202 - acc: 0.8786 - val_loss: 0.1301 - val_acc: 0.8679\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1207 - acc: 0.8779 - val_loss: 0.1307 - val_acc: 0.8674\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1083 - acc: 0.8913 - val_loss: 0.1307 - val_acc: 0.8674\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1502 - acc: 0.8746 - val_loss: 0.1307 - val_acc: 0.8675\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1182 - acc: 0.8806 - val_loss: 0.1299 - val_acc: 0.8679\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1218 - acc: 0.8795 - val_loss: 0.1291 - val_acc: 0.8683\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8845 - val_loss: 0.1287 - val_acc: 0.8688\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1588 - acc: 0.8738 - val_loss: 0.1287 - val_acc: 0.8690\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1088 - acc: 0.8899 - val_loss: 0.1287 - val_acc: 0.8691\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1534 - acc: 0.8806 - val_loss: 0.1287 - val_acc: 0.8690\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2468 - acc: 0.8772 - val_loss: 0.1297 - val_acc: 0.8685\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1077 - acc: 0.8938 - val_loss: 0.1313 - val_acc: 0.8681\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1075 - acc: 0.8942 - val_loss: 0.1323 - val_acc: 0.8680\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1112 - acc: 0.8923 - val_loss: 0.1324 - val_acc: 0.8683\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1311 - acc: 0.8910 - val_loss: 0.1323 - val_acc: 0.8687\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1069 - acc: 0.8941 - val_loss: 0.1318 - val_acc: 0.8691\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1205 - acc: 0.8893 - val_loss: 0.1316 - val_acc: 0.8695\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1118 - acc: 0.8904 - val_loss: 0.1318 - val_acc: 0.8698\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1162 - acc: 0.8872 - val_loss: 0.1322 - val_acc: 0.8701\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1095 - acc: 0.8898 - val_loss: 0.1323 - val_acc: 0.8701\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1093 - acc: 0.8900 - val_loss: 0.1318 - val_acc: 0.8701\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1165 - acc: 0.8876 - val_loss: 0.1310 - val_acc: 0.8699\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8875 - val_loss: 0.1302 - val_acc: 0.8695\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8858 - val_loss: 0.1297 - val_acc: 0.8691\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1128 - acc: 0.8854 - val_loss: 0.1296 - val_acc: 0.8685\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1128 - acc: 0.8865 - val_loss: 0.1294 - val_acc: 0.8681\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1053 - acc: 0.8947 - val_loss: 0.1290 - val_acc: 0.8680\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1782 - acc: 0.8760 - val_loss: 0.1291 - val_acc: 0.8677\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1168 - acc: 0.8827 - val_loss: 0.1291 - val_acc: 0.8677\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1050 - acc: 0.8971 - val_loss: 0.1288 - val_acc: 0.8680\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1043 - acc: 0.8972 - val_loss: 0.1285 - val_acc: 0.8685\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1094 - acc: 0.8928 - val_loss: 0.1284 - val_acc: 0.8689\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8837 - val_loss: 0.1283 - val_acc: 0.8691\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1139 - acc: 0.8848 - val_loss: 0.1281 - val_acc: 0.8690\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1107 - acc: 0.8877 - val_loss: 0.1276 - val_acc: 0.8687\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1099 - acc: 0.8873 - val_loss: 0.1272 - val_acc: 0.8682\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8826 - val_loss: 0.1269 - val_acc: 0.8675\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1195 - acc: 0.8788 - val_loss: 0.1270 - val_acc: 0.8668\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1099 - acc: 0.8893 - val_loss: 0.1270 - val_acc: 0.8664\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1037 - acc: 0.8946 - val_loss: 0.1269 - val_acc: 0.8664\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1492 - acc: 0.8864 - val_loss: 0.1270 - val_acc: 0.8663\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1238 - acc: 0.8865 - val_loss: 0.1271 - val_acc: 0.8664\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1020 - acc: 0.8942 - val_loss: 0.1270 - val_acc: 0.8667\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8777 - val_loss: 0.1268 - val_acc: 0.8670\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1185 - acc: 0.8788 - val_loss: 0.1265 - val_acc: 0.8672\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1179 - acc: 0.8792 - val_loss: 0.1265 - val_acc: 0.8672\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1189 - acc: 0.8781 - val_loss: 0.1266 - val_acc: 0.8671\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1186 - acc: 0.8782 - val_loss: 0.1266 - val_acc: 0.8669\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1036 - acc: 0.8944 - val_loss: 0.1265 - val_acc: 0.8667\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8920 - val_loss: 0.1263 - val_acc: 0.8664\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1107 - acc: 0.8850 - val_loss: 0.1261 - val_acc: 0.8663\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2936 - acc: 0.8616 - val_loss: 0.1280 - val_acc: 0.8650\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1128 - acc: 0.8836 - val_loss: 0.1312 - val_acc: 0.8640\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1200 - acc: 0.8781 - val_loss: 0.1326 - val_acc: 0.8642\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1055 - acc: 0.8942 - val_loss: 0.1314 - val_acc: 0.8657\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1305 - acc: 0.8790 - val_loss: 0.1297 - val_acc: 0.8673\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1419 - acc: 0.8813 - val_loss: 0.1291 - val_acc: 0.8685\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1089 - acc: 0.8885 - val_loss: 0.1296 - val_acc: 0.8693\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1212 - acc: 0.8809 - val_loss: 0.1307 - val_acc: 0.8697\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1239 - acc: 0.8849 - val_loss: 0.1312 - val_acc: 0.8698\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1220 - acc: 0.8932 - val_loss: 0.1306 - val_acc: 0.8696\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1253 - acc: 0.8793 - val_loss: 0.1299 - val_acc: 0.8692\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1059 - acc: 0.8912 - val_loss: 0.1297 - val_acc: 0.8687\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1057 - acc: 0.8909 - val_loss: 0.1299 - val_acc: 0.8683\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1804 - acc: 0.8752 - val_loss: 0.1312 - val_acc: 0.8679\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1222 - acc: 0.8827 - val_loss: 0.1319 - val_acc: 0.8679\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1109 - acc: 0.8895 - val_loss: 0.1314 - val_acc: 0.8683\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1792 - acc: 0.8808 - val_loss: 0.1316 - val_acc: 0.8685\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1190 - acc: 0.8856 - val_loss: 0.1308 - val_acc: 0.8690\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1071 - acc: 0.8944 - val_loss: 0.1301 - val_acc: 0.8695\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8947 - val_loss: 0.1299 - val_acc: 0.8698\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1069 - acc: 0.8955 - val_loss: 0.1303 - val_acc: 0.8701\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1055 - acc: 0.8971 - val_loss: 0.1309 - val_acc: 0.8702\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1045 - acc: 0.8964 - val_loss: 0.1310 - val_acc: 0.8702\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1149 - acc: 0.8865 - val_loss: 0.1301 - val_acc: 0.8700\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1235 - acc: 0.8841 - val_loss: 0.1291 - val_acc: 0.8695\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1026 - acc: 0.8976 - val_loss: 0.1285 - val_acc: 0.8691\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1166 - acc: 0.8834 - val_loss: 0.1284 - val_acc: 0.8687\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1138 - acc: 0.8864 - val_loss: 0.1283 - val_acc: 0.8684\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1136 - acc: 0.8862 - val_loss: 0.1280 - val_acc: 0.8683\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1190 - acc: 0.8831 - val_loss: 0.1274 - val_acc: 0.8683\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1129 - acc: 0.8851 - val_loss: 0.1268 - val_acc: 0.8684\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1017 - acc: 0.8954 - val_loss: 0.1267 - val_acc: 0.8685\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1086 - acc: 0.8883 - val_loss: 0.1270 - val_acc: 0.8685\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1509 - acc: 0.8803 - val_loss: 0.1268 - val_acc: 0.8683\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1105 - acc: 0.8862 - val_loss: 0.1264 - val_acc: 0.8677\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1276 - acc: 0.8836 - val_loss: 0.1262 - val_acc: 0.8669\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0984 - acc: 0.8957 - val_loss: 0.1263 - val_acc: 0.8662\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1276 - acc: 0.8774 - val_loss: 0.1265 - val_acc: 0.8657\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1109 - acc: 0.8836 - val_loss: 0.1265 - val_acc: 0.8657\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2874 - acc: 0.8543 - val_loss: 0.1301 - val_acc: 0.8641\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1206 - acc: 0.8744 - val_loss: 0.1327 - val_acc: 0.8636\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2337 - acc: 0.8535 - val_loss: 0.1374 - val_acc: 0.8630\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1173 - acc: 0.8880 - val_loss: 0.1380 - val_acc: 0.8643\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1255 - acc: 0.8814 - val_loss: 0.1354 - val_acc: 0.8666\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1198 - acc: 0.8864 - val_loss: 0.1323 - val_acc: 0.8686\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1126 - acc: 0.8907 - val_loss: 0.1314 - val_acc: 0.8698\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1078 - acc: 0.8946 - val_loss: 0.1333 - val_acc: 0.8705\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1177 - acc: 0.8886 - val_loss: 0.1361 - val_acc: 0.8708\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1193 - acc: 0.8890 - val_loss: 0.1370 - val_acc: 0.8709\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1163 - acc: 0.8888 - val_loss: 0.1355 - val_acc: 0.8707\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1146 - acc: 0.8887 - val_loss: 0.1334 - val_acc: 0.8704\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1422 - acc: 0.8875 - val_loss: 0.1322 - val_acc: 0.8699\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1086 - acc: 0.8911 - val_loss: 0.1323 - val_acc: 0.8694\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1090 - acc: 0.8909 - val_loss: 0.1329 - val_acc: 0.8690\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1085 - acc: 0.8935 - val_loss: 0.1330 - val_acc: 0.8688\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1143 - acc: 0.8922 - val_loss: 0.1325 - val_acc: 0.8689\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1135 - acc: 0.8923 - val_loss: 0.1314 - val_acc: 0.8691\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1113 - acc: 0.8890 - val_loss: 0.1304 - val_acc: 0.8695\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1087 - acc: 0.8931 - val_loss: 0.1298 - val_acc: 0.8699\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1177 - acc: 0.8816 - val_loss: 0.1300 - val_acc: 0.8701\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1944 - acc: 0.8828 - val_loss: 0.1302 - val_acc: 0.8701\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1037 - acc: 0.8963 - val_loss: 0.1301 - val_acc: 0.8699\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1035 - acc: 0.8961 - val_loss: 0.1298 - val_acc: 0.8697\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1160 - acc: 0.8860 - val_loss: 0.1291 - val_acc: 0.8694\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1062 - acc: 0.8934 - val_loss: 0.1285 - val_acc: 0.8691\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1057 - acc: 0.8932 - val_loss: 0.1281 - val_acc: 0.8688\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1022 - acc: 0.8969 - val_loss: 0.1278 - val_acc: 0.8686\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1132 - acc: 0.8871 - val_loss: 0.1276 - val_acc: 0.8684\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1231 - acc: 0.8950 - val_loss: 0.1276 - val_acc: 0.8682\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1372 - acc: 0.8927 - val_loss: 0.1278 - val_acc: 0.8679\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1134 - acc: 0.8841 - val_loss: 0.1277 - val_acc: 0.8678\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8867 - val_loss: 0.1275 - val_acc: 0.8677\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1185 - acc: 0.8782 - val_loss: 0.1271 - val_acc: 0.8678\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1554 - acc: 0.8787 - val_loss: 0.1271 - val_acc: 0.8676\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1102 - acc: 0.8836 - val_loss: 0.1272 - val_acc: 0.8675\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1023 - acc: 0.8930 - val_loss: 0.1272 - val_acc: 0.8674\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8792 - val_loss: 0.1269 - val_acc: 0.8676\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1155 - acc: 0.8814 - val_loss: 0.1266 - val_acc: 0.8679\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1119 - acc: 0.8911 - val_loss: 0.1266 - val_acc: 0.8681\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1043 - acc: 0.8920 - val_loss: 0.1267 - val_acc: 0.8682\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1042 - acc: 0.8921 - val_loss: 0.1267 - val_acc: 0.8682\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1127 - acc: 0.8813 - val_loss: 0.1262 - val_acc: 0.8679\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1118 - acc: 0.8811 - val_loss: 0.1257 - val_acc: 0.8675\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1020 - acc: 0.8931 - val_loss: 0.1255 - val_acc: 0.8671\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0935 - acc: 0.9062 - val_loss: 0.1255 - val_acc: 0.8669\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1016 - acc: 0.8950 - val_loss: 0.1257 - val_acc: 0.8669\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1106 - acc: 0.8845 - val_loss: 0.1256 - val_acc: 0.8669\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1042 - acc: 0.8902 - val_loss: 0.1255 - val_acc: 0.8670\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1137 - acc: 0.8799 - val_loss: 0.1253 - val_acc: 0.8671\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1131 - acc: 0.8800 - val_loss: 0.1252 - val_acc: 0.8670\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1146 - acc: 0.8798 - val_loss: 0.1253 - val_acc: 0.8668\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1142 - acc: 0.8799 - val_loss: 0.1253 - val_acc: 0.8667\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1135 - acc: 0.8794 - val_loss: 0.1251 - val_acc: 0.8665\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1130 - acc: 0.8795 - val_loss: 0.1249 - val_acc: 0.8663\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1100 - acc: 0.8847 - val_loss: 0.1247 - val_acc: 0.8661\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1096 - acc: 0.8846 - val_loss: 0.1246 - val_acc: 0.8659\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1077 - acc: 0.8885 - val_loss: 0.1246 - val_acc: 0.8657\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1459 - acc: 0.8826 - val_loss: 0.1248 - val_acc: 0.8652\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1221 - acc: 0.8702 - val_loss: 0.1250 - val_acc: 0.8649\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1038 - acc: 0.8906 - val_loss: 0.1249 - val_acc: 0.8650\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1033 - acc: 0.8910 - val_loss: 0.1249 - val_acc: 0.8654\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8863 - val_loss: 0.1249 - val_acc: 0.8660\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2092 - acc: 0.8734 - val_loss: 0.1254 - val_acc: 0.8657\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1034 - acc: 0.8889 - val_loss: 0.1260 - val_acc: 0.8657\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0994 - acc: 0.8957 - val_loss: 0.1260 - val_acc: 0.8663\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0992 - acc: 0.8962 - val_loss: 0.1258 - val_acc: 0.8671\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1184 - acc: 0.8795 - val_loss: 0.1257 - val_acc: 0.8679\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1176 - acc: 0.8806 - val_loss: 0.1259 - val_acc: 0.8684\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1102 - acc: 0.8851 - val_loss: 0.1260 - val_acc: 0.8685\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1100 - acc: 0.8853 - val_loss: 0.1257 - val_acc: 0.8683\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.0995 - acc: 0.8965 - val_loss: 0.1256 - val_acc: 0.8678\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1507 - acc: 0.8799 - val_loss: 0.1258 - val_acc: 0.8671\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2645 - acc: 0.8617 - val_loss: 0.1293 - val_acc: 0.8656\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1178 - acc: 0.8829 - val_loss: 0.1332 - val_acc: 0.8645\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1036 - acc: 0.8958 - val_loss: 0.1345 - val_acc: 0.8648\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1125 - acc: 0.8908 - val_loss: 0.1326 - val_acc: 0.8664\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1433 - acc: 0.8787 - val_loss: 0.1305 - val_acc: 0.8681\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1124 - acc: 0.8879 - val_loss: 0.1290 - val_acc: 0.8693\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1111 - acc: 0.8895 - val_loss: 0.1296 - val_acc: 0.8701\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1100 - acc: 0.8893 - val_loss: 0.1311 - val_acc: 0.8704\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1112 - acc: 0.8896 - val_loss: 0.1318 - val_acc: 0.8704\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1151 - acc: 0.8868 - val_loss: 0.1312 - val_acc: 0.8701\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8868 - val_loss: 0.1301 - val_acc: 0.8697\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1061 - acc: 0.8924 - val_loss: 0.1293 - val_acc: 0.8692\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1059 - acc: 0.8947 - val_loss: 0.1288 - val_acc: 0.8687\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2328 - acc: 0.8734 - val_loss: 0.1303 - val_acc: 0.8679\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1125 - acc: 0.8895 - val_loss: 0.1320 - val_acc: 0.8674\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1207 - acc: 0.8802 - val_loss: 0.1325 - val_acc: 0.8675\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1308 - acc: 0.8711 - val_loss: 0.1316 - val_acc: 0.8680\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1128 - acc: 0.8896 - val_loss: 0.1300 - val_acc: 0.8688\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1051 - acc: 0.8982 - val_loss: 0.1289 - val_acc: 0.8695\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1206 - acc: 0.8778 - val_loss: 0.1289 - val_acc: 0.8700\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2085 - acc: 0.8728 - val_loss: 0.1292 - val_acc: 0.8702\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1072 - acc: 0.8926 - val_loss: 0.1294 - val_acc: 0.8703\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1055 - acc: 0.8947 - val_loss: 0.1293 - val_acc: 0.8703\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1129 - acc: 0.8848 - val_loss: 0.1289 - val_acc: 0.8702\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1123 - acc: 0.8847 - val_loss: 0.1285 - val_acc: 0.8699\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1114 - acc: 0.8878 - val_loss: 0.1283 - val_acc: 0.8696\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2368 - acc: 0.8757 - val_loss: 0.1295 - val_acc: 0.8690\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1128 - acc: 0.8877 - val_loss: 0.1311 - val_acc: 0.8686\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1192 - acc: 0.8858 - val_loss: 0.1316 - val_acc: 0.8685\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1253 - acc: 0.8885 - val_loss: 0.1308 - val_acc: 0.8689\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1260 - acc: 0.8858 - val_loss: 0.1299 - val_acc: 0.8694\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1071 - acc: 0.8919 - val_loss: 0.1293 - val_acc: 0.8698\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1153 - acc: 0.8858 - val_loss: 0.1295 - val_acc: 0.8701\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1150 - acc: 0.8864 - val_loss: 0.1302 - val_acc: 0.8703\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1063 - acc: 0.8948 - val_loss: 0.1307 - val_acc: 0.8704\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1062 - acc: 0.8948 - val_loss: 0.1305 - val_acc: 0.8703\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1973 - acc: 0.8873 - val_loss: 0.1288 - val_acc: 0.8700\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1099 - acc: 0.8889 - val_loss: 0.1283 - val_acc: 0.8695\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1098 - acc: 0.8884 - val_loss: 0.1285 - val_acc: 0.8690\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1049 - acc: 0.8971 - val_loss: 0.1290 - val_acc: 0.8686\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1051 - acc: 0.8968 - val_loss: 0.1290 - val_acc: 0.8685\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1115 - acc: 0.8913 - val_loss: 0.1284 - val_acc: 0.8686\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1057 - acc: 0.8936 - val_loss: 0.1276 - val_acc: 0.8690\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1124 - acc: 0.8881 - val_loss: 0.1272 - val_acc: 0.8694\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1084 - acc: 0.8890 - val_loss: 0.1272 - val_acc: 0.8696\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1081 - acc: 0.8893 - val_loss: 0.1273 - val_acc: 0.8697\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1180 - acc: 0.8826 - val_loss: 0.1268 - val_acc: 0.8695\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1088 - acc: 0.8902 - val_loss: 0.1261 - val_acc: 0.8692\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1018 - acc: 0.8947 - val_loss: 0.1255 - val_acc: 0.8688\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2509 - acc: 0.8791 - val_loss: 0.1261 - val_acc: 0.8678\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1025 - acc: 0.8953 - val_loss: 0.1278 - val_acc: 0.8671\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1185 - acc: 0.8757 - val_loss: 0.1288 - val_acc: 0.8668\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1204 - acc: 0.8758 - val_loss: 0.1285 - val_acc: 0.8671\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2428 - acc: 0.8667 - val_loss: 0.1306 - val_acc: 0.8671\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1100 - acc: 0.8910 - val_loss: 0.1309 - val_acc: 0.8677\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1170 - acc: 0.8895 - val_loss: 0.1302 - val_acc: 0.8686\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1063 - acc: 0.8946 - val_loss: 0.1293 - val_acc: 0.8694\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2097 - acc: 0.8870 - val_loss: 0.1304 - val_acc: 0.8699\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1035 - acc: 0.9013 - val_loss: 0.1315 - val_acc: 0.8703\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1175 - acc: 0.8861 - val_loss: 0.1321 - val_acc: 0.8705\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1152 - acc: 0.8893 - val_loss: 0.1322 - val_acc: 0.8706\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1617 - acc: 0.8840 - val_loss: 0.1318 - val_acc: 0.8705\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1200 - acc: 0.8863 - val_loss: 0.1319 - val_acc: 0.8704\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1141 - acc: 0.8907 - val_loss: 0.1321 - val_acc: 0.8703\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1094 - acc: 0.8963 - val_loss: 0.1324 - val_acc: 0.8702\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1094 - acc: 0.8964 - val_loss: 0.1325 - val_acc: 0.8701\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1212 - acc: 0.8839 - val_loss: 0.1321 - val_acc: 0.8701\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1200 - acc: 0.8918 - val_loss: 0.1313 - val_acc: 0.8702\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1116 - acc: 0.8926 - val_loss: 0.1305 - val_acc: 0.8703\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1177 - acc: 0.8869 - val_loss: 0.1298 - val_acc: 0.8704\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1247 - acc: 0.8863 - val_loss: 0.1293 - val_acc: 0.8704\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1145 - acc: 0.8846 - val_loss: 0.1290 - val_acc: 0.8703\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1044 - acc: 0.8975 - val_loss: 0.1288 - val_acc: 0.8701\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8870 - val_loss: 0.1284 - val_acc: 0.8699\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1692 - acc: 0.8841 - val_loss: 0.1280 - val_acc: 0.8696\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1073 - acc: 0.8902 - val_loss: 0.1277 - val_acc: 0.8692\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1097 - acc: 0.8930 - val_loss: 0.1275 - val_acc: 0.8689\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1094 - acc: 0.8929 - val_loss: 0.1271 - val_acc: 0.8688\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1251 - acc: 0.8903 - val_loss: 0.1268 - val_acc: 0.8688\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1108 - acc: 0.8886 - val_loss: 0.1266 - val_acc: 0.8689\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1262 - acc: 0.8924 - val_loss: 0.1266 - val_acc: 0.8689\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1346 - acc: 0.8862 - val_loss: 0.1265 - val_acc: 0.8690\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1032 - acc: 0.8964 - val_loss: 0.1262 - val_acc: 0.8691\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1153 - acc: 0.8921 - val_loss: 0.1259 - val_acc: 0.8691\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1081 - acc: 0.8900 - val_loss: 0.1259 - val_acc: 0.8691\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1119 - acc: 0.8853 - val_loss: 0.1258 - val_acc: 0.8689\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1115 - acc: 0.8851 - val_loss: 0.1257 - val_acc: 0.8686\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1056 - acc: 0.8896 - val_loss: 0.1255 - val_acc: 0.8684\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2657 - acc: 0.8725 - val_loss: 0.1264 - val_acc: 0.8678\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.1144 - acc: 0.8795 - val_loss: 0.1282 - val_acc: 0.8673\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1160 - acc: 0.8792 - val_loss: 0.1293 - val_acc: 0.8672\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1196 - acc: 0.8797 - val_loss: 0.1289 - val_acc: 0.8677\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1119 - acc: 0.8880 - val_loss: 0.1278 - val_acc: 0.8684\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2576 - acc: 0.8652 - val_loss: 0.1296 - val_acc: 0.8685\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1156 - acc: 0.8842 - val_loss: 0.1306 - val_acc: 0.8687\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1116 - acc: 0.8870 - val_loss: 0.1305 - val_acc: 0.8692\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1226 - acc: 0.8884 - val_loss: 0.1301 - val_acc: 0.8696\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1111 - acc: 0.8889 - val_loss: 0.1297 - val_acc: 0.8700\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1066 - acc: 0.8979 - val_loss: 0.1297 - val_acc: 0.8702\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1059 - acc: 0.8982 - val_loss: 0.1302 - val_acc: 0.8702\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1074 - acc: 0.8931 - val_loss: 0.1307 - val_acc: 0.8702\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1039 - acc: 0.9004 - val_loss: 0.1307 - val_acc: 0.8701\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1181 - acc: 0.8833 - val_loss: 0.1299 - val_acc: 0.8698\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1214 - acc: 0.8919 - val_loss: 0.1291 - val_acc: 0.8695\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.2438 - acc: 0.8740 - val_loss: 0.1291 - val_acc: 0.8688\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1140 - acc: 0.8859 - val_loss: 0.1305 - val_acc: 0.8681\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1100 - acc: 0.8929 - val_loss: 0.1315 - val_acc: 0.8679\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1188 - acc: 0.8855 - val_loss: 0.1313 - val_acc: 0.8682\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1674 - acc: 0.8761 - val_loss: 0.1312 - val_acc: 0.8687\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1163 - acc: 0.8876 - val_loss: 0.1304 - val_acc: 0.8693\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1176 - acc: 0.8842 - val_loss: 0.1297 - val_acc: 0.8699\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1187 - acc: 0.8966 - val_loss: 0.1297 - val_acc: 0.8703\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1050 - acc: 0.8979 - val_loss: 0.1305 - val_acc: 0.8707\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1122 - acc: 0.8897 - val_loss: 0.1312 - val_acc: 0.8708\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1148 - acc: 0.8880 - val_loss: 0.1310 - val_acc: 0.8708\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1121 - acc: 0.8918 - val_loss: 0.1300 - val_acc: 0.8707\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2273 - acc: 0.8854 - val_loss: 0.1288 - val_acc: 0.8703\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.2222 - acc: 0.8786 - val_loss: 0.1310 - val_acc: 0.8694\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1114 - acc: 0.8912 - val_loss: 0.1348 - val_acc: 0.8685\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1237 - acc: 0.8817 - val_loss: 0.1369 - val_acc: 0.8682\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1163 - acc: 0.8919 - val_loss: 0.1366 - val_acc: 0.8685\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1215 - acc: 0.8845 - val_loss: 0.1345 - val_acc: 0.8692\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.1129 - acc: 0.8918 - val_loss: 0.1321 - val_acc: 0.8698\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 64, 64, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 64, 64, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 32, 32, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 32, 32, 8)         1160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "latent (Dense)               (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "reshape_4 (Reshape)          (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 16, 16, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "up_sampling2d_11 (UpSampling (None, 32, 32, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 32, 32, 16)        1168      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_12 (UpSampling (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "output (Conv2D)              (None, 64, 64, 1)         145       \n",
            "=================================================================\n",
            "Total params: 1,053,473\n",
            "Trainable params: 1,053,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
            "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"Adding an axes using the same arguments as a previous axes \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAMHCAYAAAD7ABn5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABUkAAANHCAYAAAALxtxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1728x1728 with 19 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "GWblA8zL5Y_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "shuffled_encoder.save('shuffled_encoder.h5')\n",
        "shuffled_autoencoder.save('shuffled_autoencoder.h5')\n",
        "files.download('shuffled_encoder.h5')\n",
        "files.download('shuffled_autoencoder.h5')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuo2sG7LY8ek",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Accuracy using seen-encoder"
      ]
    },
    {
      "metadata": {
        "id": "baxeAO-YTkpA",
        "colab_type": "code",
        "outputId": "3d3c45b8-332e-47b9-b7d2-102bdcf30e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(seen_dataset,seen_encoder)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.869757174392936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "gjmNU-KtKWd5",
        "colab_type": "code",
        "outputId": "764b5b3e-e969-4e83-984a-a2368a8c2e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(shuffled_dataset,seen_encoder)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6925113464447806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "kfnTQbHkKVcN",
        "colab_type": "code",
        "outputId": "101b141a-97a7-4dc1-abe1-4458b8d29c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(unseen_dataset,seen_encoder)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.61688654353562"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "metadata": {
        "id": "s5CtzF79ZE4H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Accuracy using unseen-encoder"
      ]
    },
    {
      "metadata": {
        "id": "iAA0iqxUX5Tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cd96335-8ed2-4d82-a4cb-4d2ffd4c9236"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(seen_dataset,unseen_encoder)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.782560706401766"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "metadata": {
        "id": "B9RV9-u1ZUnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25492a46-a5c3-43d0-d6bb-517217450314"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(shuffled_dataset,unseen_encoder)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.504160363086233"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "_dQ7gRXQZQcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41135f8d-d7a4-461c-c4de-84fe1f904f3e"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(unseen_dataset,unseen_encoder)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5032981530343008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "Zp7S9i3UZdD5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Accuracy using shuffled-encoder"
      ]
    },
    {
      "metadata": {
        "id": "q5e8V4KfZg6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93bd38ac-31d7-492d-87ef-c16bd074a39e"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(seen_dataset,shuffled_encoder)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6854304635761589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "XC2e_7FkZtwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd73ce96-43ed-4f82-8c99-2d15f9b12710"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(shuffled_dataset,shuffled_encoder)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.550302571860817"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "metadata": {
        "id": "l2-n9clYZpm3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c59bf133-c34a-4d72-9ff9-1cb1bd149ad6"
      },
      "cell_type": "code",
      "source": [
        "cosine_accuracy(unseen_dataset,shuffled_encoder)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5523746701846965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    }
  ]
}